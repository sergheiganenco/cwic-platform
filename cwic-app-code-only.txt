

====================================================================================================
  CWIC PLATFORM - APPLICATION CODE EXTRACT (Enhanced)
====================================================================================================

Generated on: 10/02/2025 09:33:06
Mode: CodeOnly
Includes: Business logic, components, services
Excludes: Secrets, heavy binaries, build outputs


====================================================================================================
  API GATEWAY - SRC
====================================================================================================


------------------------------------------------------------
FILE: backend\api-gateway\src\app.ts
------------------------------------------------------------
﻿// src/app.ts
import compression from "compression";
import cors from "cors";
import "dotenv/config";
import express, { type NextFunction, type Request, type Response } from "express";
import rateLimit from "express-rate-limit";
import helmet from "helmet";
import morgan from "morgan";
import { randomUUID } from "node:crypto";

import { resolveUpstreams } from "./config/upstreams.js";
import { normalizeDataSourceBody } from "./middleware/normalizeDataSourceBody.js";
import aiServiceProxy from "./proxy/aiServiceProxy.js";
import authServiceProxy from "./proxy/authServiceProxy.js";
import dataServiceProxy from "./proxy/dataServiceProxy.js";

const app = express();

const NODE_ENV = process.env.NODE_ENV || "development";
const isProd = NODE_ENV === "production";
const isDev = !isProd;
const bodyLimit = process.env.BODY_LIMIT || "1mb";
const DEV_BEARER = process.env.DEV_BEARER ?? "";

/** Parse comma-separated CORS origins from env */
function parseOrigins(val?: string): string[] {
  if (!val) return [];
  return val.split(",").map((s) => s.trim()).filter(Boolean);
}

// Allow explicit env origins; in dev, default to localhost ports if none provided
const origins = parseOrigins(
  process.env.CORS_ORIGIN ||
    (isDev ? "http://localhost:3000,http://localhost:5173,http://localhost:4173" : "")
);
/** If no origins provided or '*' present, reflect any origin */
const allowAll = origins.length === 0 || origins.includes("*");

// ────────────────────────── App hardening & basics ──────────────────────────
app.disable("x-powered-by");
app.set("trust proxy", process.env.TRUST_PROXY ?? (isProd ? "1" : "true"));

app.use(
  helmet({
    contentSecurityPolicy: false,
    crossOriginEmbedderPolicy: false,
    hsts: isProd ? undefined : false,
  })
);

// ──────────────────────── BULLETPROOF CORS PRE-FLIGHT ───────────────────────
app.use((req: Request, res: Response, next: NextFunction) => {
  if (req.method !== "OPTIONS") return next();

  const origin = (req.headers.origin as string) || "";
  const isAllowedOrigin = allowAll || origins.includes(origin);
  if (!isAllowedOrigin) return next();

  // Reflect origin (credentials-compatible)
  res.setHeader("Access-Control-Allow-Origin", origin);
  res.setHeader("Vary", "Origin");
  res.setHeader("Access-Control-Allow-Credentials", "true");

  // Reflect requested methods/headers so *any* custom headers are accepted
  const reqMethods =
    (req.headers["access-control-request-method"] as string) ||
    "GET,POST,PUT,PATCH,DELETE,OPTIONS";
  const reqHeaders =
    (req.headers["access-control-request-headers"] as string) ||
    "authorization,content-type";

  res.setHeader("Access-Control-Allow-Methods", reqMethods);
  res.setHeader("Access-Control-Allow-Headers", reqHeaders);
  res.setHeader("Access-Control-Max-Age", "86400"); // 24h

  return res.status(204).end();
});

// Standard CORS for non-OPTIONS requests
const corsOptions: cors.CorsOptions = {
  origin: allowAll ? true : origins,
  credentials: true,
  methods: ["GET", "POST", "PUT", "PATCH", "DELETE", "OPTIONS"],
  exposedHeaders: ["X-Request-Id"],
  maxAge: 86400,
  optionsSuccessStatus: 204,
};
app.use(cors(corsOptions));

// ─────────────────────────── Rate limit (prod only) ─────────────────────────
const limiter = rateLimit({
  windowMs: 60_000,
  max: 300,
  standardHeaders: true,
  legacyHeaders: false,
  skip: (req) => req.method === "OPTIONS" || !isProd,
}) as unknown as express.RequestHandler;
app.use(limiter);

// ─────────────────────────── Parsers & logging ──────────────────────────────
app.use(compression());
app.use(express.json({ limit: bodyLimit }));
app.use(express.urlencoded({ extended: true, limit: bodyLimit }));
app.use(morgan(isDev ? "dev" : "combined"));

// Request ID (echo/propagate downstream)
app.use((req: Request, res: Response, next: NextFunction) => {
  const rid = (req.headers["x-request-id"] as string) || randomUUID();
  req.headers["x-request-id"] = rid;
  res.setHeader("X-Request-Id", rid);
  next();
});

// ───────────────────────────── Health & debug ───────────────────────────────
app.get("/health", (_req, res) => res.json({ ok: true, service: "api-gateway", env: NODE_ENV }));
app.get("/ready", (_req, res) => res.json({ ready: true }));
app.get("/upstreams", (_req, res) => res.json({ env: NODE_ENV, upstreams: resolveUpstreams() }));

// ─────────────────────────── Dev stubs (must be early) ──────────────────────
if (isDev) {
  // Token refresh helper for local dev
  app.post("/api/auth/refresh", (_req, res) => {
    if (!DEV_BEARER) return res.status(500).json({ error: "DEV_BEARER not set" });
    const raw = DEV_BEARER.startsWith("Bearer ") ? DEV_BEARER.slice(7) : DEV_BEARER;
    return res.json({ token: raw });
  });

  // Local AI health stub so the UI has something to ping
  app.get("/api/ai/health", (_req, res) => {
    res.json({ status: "ok", stub: true });
  });

  // Frontend expectations (permissions/current user)
  app.get(["/api/auth/me", "/auth/me"], (_req, res) => {
    res.json({
      id: "dev-user-1",
      email: "dev@example.com",
      name: "Dev User",
      roles: ["admin"],
      permissions: [
        "datasources:read",
        "datasources:write",
        "catalog:read",
        "requests:read",
      ],
    });
  });

  app.get(["/api/user/permissions", "/user/permissions"], (_req, res) => {
    res.json({
      success: true,
      data: [
        "datasources:read",
        "datasources:write",
        "catalog:read",
        "requests:read",
      ],
      timestamp: new Date().toISOString(),
    });
  });
}

// In dev, if no Authorization header, attach DEV_BEARER (do not overwrite a real one)
if (isDev) {
  app.use(["/api", "/api/ai", "/api/auth"], (req, _res, next) => {
    if (!req.headers.authorization && DEV_BEARER) {
      req.headers.authorization = DEV_BEARER.startsWith("Bearer ")
        ? DEV_BEARER
        : `Bearer ${DEV_BEARER}`;
    }
    next();
  });
}

app.use(
  [
    "/api/data-sources/test",
    "/api/data-sources/databases/preview",
    "/api/data-sources",               // create/update routes from the UI
  ],
  express.json({ limit: bodyLimit }),  // ensure JSON parser runs here too
  normalizeDataSourceBody
);

// Proxies (order matters)
app.use("/api/ai",   aiServiceProxy);
app.use("/api/auth", authServiceProxy);
app.use("/api",      dataServiceProxy);


// ──────────────────────────────── Proxies ───────────────────────────────────
// NOTE: Our data proxy STRIPS the '^/api' prefix, so the upstream sees bare routes.
// The data-service also mounts '/api/*' internally for flexibility, but the gateway
// forwards '/api/*' and removes the prefix at the proxy layer. Order matters: specific first.
app.use("/api/ai",   aiServiceProxy);     // rewrites ^/api/ai → /api on upstream
app.use("/api/auth", authServiceProxy);   // rewrites ^/api/auth → /auth on upstream (health → /health)
app.use("/api",      dataServiceProxy);   // strips '^/api' so upstream sees '/data-sources', etc.

// ───────────────────────────── 404 + error handling ─────────────────────────
app.use((req, res) => {
  res.status(404).json({
    success: false,
    error: "NOT_FOUND",
    message: `Route ${req.method} ${req.originalUrl} not found`,
  });
});

// Centralized JSON error handler
// eslint-disable-next-line @typescript-eslint/no-unused-vars
app.use((err: any, _req: Request, res: Response, _next: NextFunction) => {
  const status = err.status || err.statusCode || 500;
  const code = err.code || "INTERNAL_SERVER_ERROR";
  const publicMessage = isProd ? err.publicMessage || "Internal server error" : err.message || "Internal server error";

  if (!res.headersSent) {
    res.status(status).json({
      success: false,
      error: { code, message: publicMessage },
    });
  }
});

export default app;



------------------------------------------------------------
FILE: backend\api-gateway\src\config\upstreams.ts
------------------------------------------------------------
// src/config/upstreams.ts
type Upstreams = {
  dataService: string;
  authService: string;
  aiService: string;
};

function envOr(def: string, ...keys: string[]): string {
  for (const k of keys) {
    const v = process.env[k];
    if (v && v.trim()) return v.trim();
  }
  return def;
}

/** Resolve service URLs. In Docker, service names are resolvable on the bridge network. */
export function resolveUpstreams(): Upstreams {
  const isDev = (process.env.NODE_ENV || "development") !== "production";

  return {
    dataService: envOr(
      isDev ? "http://data-service:3002" : "http://data-service:3002",
      "DATA_SERVICE_URL"
    ),
    authService: envOr(
      isDev ? "http://auth-service:3001" : "http://auth-service:8001",
      "AUTH_SERVICE_URL"
    ),
    aiService: envOr(
      "http://ai-service:3003",
      "AI_SERVICE_URL"
    )
  };
}



------------------------------------------------------------
FILE: backend\api-gateway\src\middleware\cors.ts
------------------------------------------------------------
import cors from "cors";

const ALLOWLIST = new Set([
  "http://localhost:5173", // Vite dev (your container)
  "http://localhost:3000", // if you run a local dev UI on 3000
]);

export default cors({
  credentials: true,
  origin: (origin, cb) => {
    // allow same-origin (curl/postman) and allowlisted origins
    if (!origin || ALLOWLIST.has(origin)) return cb(null, true);
    return cb(new Error(`CORS: origin not allowed: ${origin}`));
  },
  allowedHeaders: [
    "Content-Type",
    "Authorization",
    "X-Requested-With",
    "X-Request-Id",
  ],
  methods: ["GET", "POST", "PUT", "PATCH", "DELETE", "OPTIONS"],
  preflightContinue: false,
  optionsSuccessStatus: 204,
});



------------------------------------------------------------
FILE: backend\api-gateway\src\middleware\healthCheck.ts
------------------------------------------------------------
import { Request, Response } from 'express';
// These clients come from @cwic/shared (weâ€™ll wire them as simple axios wrappers)
import { AIServiceClient, AuthServiceClient, DataServiceClient } from '@cwic/shared';

const serviceClients = {
  auth: new AuthServiceClient(),
  data: new DataServiceClient(),
  ai: new AIServiceClient()
};

export const healthCheck = async (req: Request, res: Response): Promise<void> => {
  const startTime = Date.now();
  try {
    const serviceChecks = await Promise.allSettled([
      checkServiceHealth('auth', serviceClients.auth),
      checkServiceHealth('data', serviceClients.data),
      checkServiceHealth('ai', serviceClients.ai)
    ]);

    const services = serviceChecks.reduce((acc, result, index) => {
      const serviceName = ['auth', 'data', 'ai'][index];
      acc[serviceName] = result.status === 'fulfilled'
        ? result.value
        : { status: 'unhealthy', error: (result as any).reason?.message };
      return acc;
    }, {} as any);

    const allHealthy = Object.values(services).every((s: any) => s.status === 'healthy');

    res.status(allHealthy ? 200 : 503).json({
      status: allHealthy ? 'healthy' : 'degraded',
      timestamp: new Date().toISOString(),
      uptime: process.uptime(),
      responseTime: Date.now() - startTime,
      version: process.env.npm_package_version || '1.0.0',
      environment: process.env.NODE_ENV || 'development',
      services
    });
  } catch (error) {
    res.status(503).json({
      status: 'unhealthy',
      timestamp: new Date().toISOString(),
      uptime: process.uptime(),
      responseTime: Date.now() - startTime,
      error: error instanceof Error ? error.message : 'Unknown error'
    });
  }
};

async function checkServiceHealth(_name: string, client: any): Promise<any> {
  try {
    const start = Date.now();
    await client.get('/health');
    return { status: 'healthy', responseTime: Date.now() - start };
  } catch (error) {
    return { status: 'unhealthy', error: error instanceof Error ? error.message : 'Unknown error' };
  }
}



------------------------------------------------------------
FILE: backend\api-gateway\src\middleware\normalizeDataSourceBody.ts
------------------------------------------------------------
import type { NextFunction, Request, Response } from "express";

/**
 * Normalizes request bodies sent to data-source endpoints so the data-service
 * always receives a consistent shape:
 *
 * {
 *   type: "<engine>",                      // e.g. "postgres" | "mysql" | "mssql" | "snowflake" | "bigquery"
 *   connection: {
 *     host: string,
 *     port?: number,
 *     database?: string,
 *     user?: string,
 *     username?: string,                   // will be mapped to user
 *     password?: string,
 *     ssl?: boolean | object
 *   },
 *   sql?: string
 * }
 *
 * Accepted aliases:
 * - "driver" or "engine" â†’ "type"
 * - "postgresql" | "pg" â†’ "postgres"
 * - "ms-sql" | "sqlserver" â†’ "mssql"
 * - "user" | "username" normalized to "user"
 * - top-level connection fields flattened into connection object if needed
 */
export function normalizeDataSourceBody(req: Request, _res: Response, next: NextFunction) {
  if (!req.is("application/json")) return next(); // only normalize JSON payloads

  // Only touch bodies that are objects
  const body = (req.body && typeof req.body === "object") ? req.body as Record<string, any> : null;
  if (!body) return next();

  // 1) Normalize engine key to "type"
  let type: unknown =
    body.type ??
    body.driver ??
    body.engine ??
    (body.connection?.type ?? body.connection?.driver ?? body.connection?.engine);

  if (typeof type === "string") {
    const t = type.toLowerCase().trim();

    const typeMap: Record<string, string> = {
      // Postgres
      "postgres": "postgres",
      "postgresql": "postgres",
      "pg": "postgres",
      // MySQL
      "mysql": "mysql",
      "mariadb": "mysql",           // treat as mysql for connection test/preview
      // Microsoft SQL Server
      "mssql": "mssql",
      "ms-sql": "mssql",
      "sqlserver": "mssql",
      "sql-server": "mssql",
      // Snowflake
      "snowflake": "snowflake",
      // BigQuery
      "bigquery": "bigquery",
      "bq": "bigquery",
    };

    body.type = typeMap[t] ?? t;    // if unknown, still pass the string through
  }

  // 2) Build/normalize connection object
  const srcConn = ((): Record<string, any> => {
    // allow connection under body.connection, or flatten top-level host/port/etc
    if (body.connection && typeof body.connection === "object") {
      return { ...(body.connection as Record<string, any>) };
    }
    const {
      host, hostname, server,
      port,
      database, db, catalog, schema,
      user, username,
      password, pass,
      ssl,
      projectId, dataset, location, // BigQuery style
      account, warehouse, role      // Snowflake style
    } = body;

    const conn: Record<string, any> = {};
    if (host ?? hostname ?? server) conn.host = host ?? hostname ?? server;
    if (typeof port !== "undefined") conn.port = Number(port);
    if (database ?? db ?? catalog ?? schema) conn.database = database ?? db ?? catalog ?? schema;
    if (user ?? username) conn.user = user ?? username;
    if (password ?? pass) conn.password = password ?? pass;
    if (typeof ssl !== "undefined") conn.ssl = ssl;

    // Pass through cloud-specific fields if present
    if (projectId) conn.projectId = projectId;
    if (dataset) conn.dataset = dataset;
    if (location) conn.location = location;

    if (account) conn.account = account;
    if (warehouse) conn.warehouse = warehouse;
    if (role) conn.role = role;

    return conn;
  })();

  // Ensure username alias is mapped
  if (srcConn.username && !srcConn.user) {
    srcConn.user = srcConn.username;
    delete srcConn.username;
  }

  // 3) Attach normalized connection back
  body.connection = srcConn;

  // 4) For legacy shapes { db: {...} } or { config: {...} } â†’ move into connection
  if (body.db && typeof body.db === "object") {
    body.connection = { ...body.connection, ...body.db };
    delete body.db;
  }
  if (body.config && typeof body.config === "object") {
    body.connection = { ...body.connection, ...body.config };
    delete body.config;
  }

  // 5) Ensure sql is a string when present
  if (typeof body.sql !== "undefined" && body.sql !== null) {
    body.sql = String(body.sql);
  }

  // 6) Put normalized body back on req
  req.body = body;

  return next();
}



------------------------------------------------------------
FILE: backend\api-gateway\src\proxy\aiServiceProxy.ts
------------------------------------------------------------
// src/proxy/aiServiceProxy.ts
import type { IncomingMessage, ServerResponse } from "http";
import { createProxyMiddleware, type Options } from "http-proxy-middleware";
import { resolveUpstreams } from "../config/upstreams.js";
import {
  isDev,
  maybeAttachDevAuth,
  propagateCommon,
  reflectCors,
  writeBodyIfAny
} from "./shared.js";

const { aiService: target } = resolveUpstreams();

/** Mounted at /api/ai â†’ upstream wants /api/* */
const options: Options<IncomingMessage, ServerResponse> = {
  target,
  changeOrigin: true,
  xfwd: true,
  secure: !isDev,
  proxyTimeout: 30_000,
  timeout: 30_000,
  pathRewrite: { "^/api/ai": "/api" },

  on: {
    proxyReq: (proxyReq, req) => {
      maybeAttachDevAuth(proxyReq, req);
      propagateCommon(proxyReq, req);
      writeBodyIfAny(proxyReq, req);
      if (isDev) {
        const url = (proxyReq as any).path || "";
        // eslint-disable-next-line no-console
        console.debug(`[proxyâ†’ai] ${req.method} ${(req as any).url} â†’ ${target}${url}`);
      }
    },
    proxyRes: (proxyRes, req) => {
      reflectCors(proxyRes as unknown as ServerResponse, req);
      if (isDev) {
        // eslint-disable-next-line no-console
        console.debug(`[proxyâ†’ai] ${req.method} ${(req as any).url} â‡ ${proxyRes.statusCode}`);
      }
    },
    error: (err, req, res) => {
      if (typeof (res as any).destroy === "function" && !(res as any).setHeader) {
        try { (res as any).destroy(); } catch {}
        return;
      }
      const r = res as unknown as ServerResponse & { headersSent?: boolean };
      if ((r as any).headersSent) return;
      const origin = req.headers["origin"] as string | undefined;
      if (origin) {
        (r as any).setHeader?.("Access-Control-Allow-Origin", origin);
        (r as any).setHeader?.("Access-Control-Allow-Credentials", "true");
      }
      (r as any).statusCode = 502;
      (r as any).setHeader?.("content-type", "application/json; charset=utf-8");
      (r as any).end(JSON.stringify({
        success: false,
        error: "AI_SERVICE_UNAVAILABLE",
        message: "AI service is currently unavailable",
        details: err.message,
        upstream: target,
        timestamp: new Date().toISOString()
      }));
    }
  }
};

export default createProxyMiddleware<IncomingMessage, ServerResponse>(options);



------------------------------------------------------------
FILE: backend\api-gateway\src\proxy\authServiceProxy.ts
------------------------------------------------------------
// src/proxy/authServiceProxy.ts
import type { IncomingMessage, ServerResponse } from "http";
import { createProxyMiddleware, type Options } from "http-proxy-middleware";
import { resolveUpstreams } from "../config/upstreams.js";
import {
  isDev,
  maybeAttachDevAuth,
  propagateCommon,
  reflectCors,
  writeBodyIfAny
} from "./shared.js";

const { authService: target } = resolveUpstreams();

/**
 * Mounted at /api/auth
 * - /api/auth/health â†’ /health  (auth exposes simple health at root)
 * - Everything else  â†’ /auth/*  (most routes under /auth)
 * If your auth exposes /me at root, switch to { "^/api/auth": "" }.
 */
const options: Options<IncomingMessage, ServerResponse> = {
  target,
  changeOrigin: true,
  xfwd: true,
  secure: !isDev,
  proxyTimeout: 30_000,
  timeout: 30_000,

  pathRewrite: (path: string, _req: IncomingMessage) => {
    if (path === "/api/auth/health") return "/health";
    // default: prefix with /auth
    return path.replace(/^\/api\/auth/, "/auth");
  },

  on: {
    proxyReq: (proxyReq, req) => {
      maybeAttachDevAuth(proxyReq, req);
      propagateCommon(proxyReq, req);
      writeBodyIfAny(proxyReq, req);
      if (isDev) {
        const url = (proxyReq as any).path || "";
        // eslint-disable-next-line no-console
        console.debug(`[proxyâ†’auth] ${req.method} ${(req as any).url} â†’ ${target}${url}`);
      }
    },
    proxyRes: (proxyRes, req) => {
      reflectCors(proxyRes as unknown as ServerResponse, req);
      if (isDev) {
        // eslint-disable-next-line no-console
        console.debug(`[proxyâ†’auth] ${req.method} ${(req as any).url} â‡ ${proxyRes.statusCode}`);
      }
    },
    error: (err, req, res) => {
      if (typeof (res as any).destroy === "function" && !(res as any).setHeader) {
        try { (res as any).destroy(); } catch {}
        return;
      }
      const r = res as unknown as ServerResponse & { headersSent?: boolean };
      if ((r as any).headersSent) return;
      const origin = req.headers["origin"] as string | undefined;
      if (origin) {
        (r as any).setHeader?.("Access-Control-Allow-Origin", origin);
        (r as any).setHeader?.("Access-Control-Allow-Credentials", "true");
      }
      (r as any).statusCode = 502;
      (r as any).setHeader?.("content-type", "application/json; charset=utf-8");
      (r as any).end(JSON.stringify({
        success: false,
        error: "AUTH_SERVICE_UNAVAILABLE",
        message: "Auth service is currently unavailable",
        details: err.message,
        upstream: target,
        timestamp: new Date().toISOString()
      }));
    }
  }
};

export default createProxyMiddleware<IncomingMessage, ServerResponse>(options);



------------------------------------------------------------
FILE: backend\api-gateway\src\proxy\dataServiceProxy.ts
------------------------------------------------------------
// src/proxy/dataServiceProxy.ts
import type { IncomingMessage, ServerResponse } from "http";
import { createProxyMiddleware, type Options } from "http-proxy-middleware";
import { resolveUpstreams } from "../config/upstreams.js";
import {
  isDev,
  maybeAttachDevAuth,
  propagateCommon,
  reflectCors,
  writeBodyIfAny
} from "./shared.js";

const { dataService: target } = resolveUpstreams();

/**
 * FE â†’ Gateway: /api/data-sources
 * Gateway â†’ DataSvc: /data-sources  (strip the `/api` prefix)
 */
const options: Options<IncomingMessage, ServerResponse> = {
  target,
  changeOrigin: true,
  xfwd: true,
  secure: !isDev,
  proxyTimeout: 30_000,
  timeout: 30_000,
  pathRewrite: { "^/api": "" },

  on: {
    proxyReq: (proxyReq, req) => {
      maybeAttachDevAuth(proxyReq, req);
      propagateCommon(proxyReq, req);
      writeBodyIfAny(proxyReq, req);
      if (isDev) {
        const url = (proxyReq as any).path || "";
        // eslint-disable-next-line no-console
        console.debug(`[proxyâ†’data] ${req.method} ${(req as any).url} â†’ ${target}${url}`);
      }
    },
    proxyRes: (proxyRes, req) => {
      reflectCors(proxyRes as unknown as ServerResponse, req);
      if (isDev) {
        // eslint-disable-next-line no-console
        console.debug(`[proxyâ†’data] ${req.method} ${(req as any).url} â‡ ${proxyRes.statusCode}`);
      }
    },
    error: (err, req, res) => {
      // If raw socket (e.g., WS) just destroy
      if (typeof (res as any).destroy === "function" && !(res as any).setHeader) {
        try { (res as any).destroy(); } catch {}
        return;
      }
      const r = res as unknown as ServerResponse & { headersSent?: boolean };
      if ((r as any).headersSent) return;
      const origin = req.headers["origin"] as string | undefined;
      if (origin) {
        (r as any).setHeader?.("Access-Control-Allow-Origin", origin);
        (r as any).setHeader?.("Access-Control-Allow-Credentials", "true");
      }
      (r as any).statusCode = 502;
      (r as any).setHeader?.("content-type", "application/json; charset=utf-8");
      (r as any).end(JSON.stringify({
        success: false,
        error: "DATA_SERVICE_UNAVAILABLE",
        message: "Data service is currently unavailable",
        details: err.message,
        upstream: target,
        timestamp: new Date().toISOString()
      }));
    }
  }
};

export default createProxyMiddleware<IncomingMessage, ServerResponse>(options);



------------------------------------------------------------
FILE: backend\api-gateway\src\proxy\shared.ts
------------------------------------------------------------
// src/proxy/shared.ts
import type { IncomingMessage, ServerResponse } from "http";

export const isProd = (process.env.NODE_ENV || "development") === "production";
export const isDev = !isProd;
export const devBearer = process.env.DEV_BEARER ?? "";

/** Re-stream body if Express has already parsed it. */
export function writeBodyIfAny(proxyReq: any, req: IncomingMessage) {
  const r: any = req as any;
  if (!r.method || r.method === "GET" || r.method === "HEAD") return;

  const contentType =
    String(
      proxyReq.getHeader("content-type") ||
      proxyReq.getHeader("Content-Type") ||
      ""
    ).toLowerCase();

  if (r.body && typeof r.body === "object") {
    if (contentType.includes("application/json")) {
      const body = JSON.stringify(r.body);
      proxyReq.setHeader("content-length", Buffer.byteLength(body));
      proxyReq.write(body);
    } else if (contentType.includes("application/x-www-form-urlencoded")) {
      const body = new URLSearchParams(r.body as Record<string, string>).toString();
      proxyReq.setHeader("content-length", Buffer.byteLength(body));
      proxyReq.write(body);
    }
  }
}

/** Reflect origin & credentials on proxied responses */
export function reflectCors(proxyRes: ServerResponse, req: IncomingMessage) {
  const origin = (req.headers["origin"] as string) || "";
  if (!origin) return;
  (proxyRes as any).headers ??= {};
  (proxyRes as any).headers["access-control-allow-origin"] = origin;
  (proxyRes as any).headers["access-control-allow-credentials"] = "true";
}

/** Attach Authorization (dev bearer) if missing */
export function maybeAttachDevAuth(proxyReq: any, req: IncomingMessage) {
  const auth = req.headers["authorization"];
  if (!auth && isDev && devBearer) {
    proxyReq.setHeader(
      "authorization",
      devBearer.startsWith("Bearer ") ? devBearer : `Bearer ${devBearer}`
    );
    proxyReq.setHeader("x-dev-auth", "gateway");
  }
}

/** Propagate useful headers */
export function propagateCommon(proxyReq: any, req: IncomingMessage) {
  const rid = req.headers["x-request-id"] as string | undefined;
  if (rid) proxyReq.setHeader("x-request-id", rid);
  const cookie = req.headers["cookie"] as string | undefined;
  if (cookie) proxyReq.setHeader("cookie", cookie);
}



------------------------------------------------------------
FILE: backend\api-gateway\src\server.ts
------------------------------------------------------------
// src/server.ts
import http from "node:http";
import process from "node:process";
import app from "./app.js";

const PORT = Number(process.env.PORT || 8000);
const HOST = process.env.HOST || "0.0.0.0";

const server = http.createServer(app);
server.keepAliveTimeout = 75_000;
server.headersTimeout = 90_000;

const log = (...a: unknown[]) => console.log("[api-gateway]", ...a);
const err = (...a: unknown[]) => console.error("[api-gateway]", ...a);

server
  .listen(PORT, HOST, () => {
    log(`listening on http://${HOST}:${PORT}`);
  })
  .on("error", (e: NodeJS.ErrnoException) => {
    if (e.code === "EADDRINUSE") err(`port ${PORT} already in use`);
    else if (e.code === "EACCES") err(`no permission to bind ${HOST}:${PORT}`);
    else err("server error:", e);
    setTimeout(() => process.exit(1), 1000);
  });

process.on("uncaughtException", (e) => err("uncaughtException:", e));
process.on("unhandledRejection", (r) => err("unhandledRejection:", r as any));

const shutdown = (signal: NodeJS.Signals) => {
  log(`${signal} received → closing server...`);
  server.close((closeErr) => {
    if (closeErr) err("error during close:", closeErr);
    process.exit(0);
  });
};
process.on("SIGTERM", shutdown);
process.on("SIGINT", shutdown);



====================================================================================================
  AUTH SERVICE - SRC
====================================================================================================


------------------------------------------------------------
FILE: backend\auth-service\src\app.ts
------------------------------------------------------------
import compression from 'compression';
import cors from 'cors';
import express from 'express';
import helmet from 'helmet';

export const app = express();

app.use(helmet());
app.use(cors());
app.use(compression());
app.use(express.json());

// Health endpoint for Docker HEALTHCHECK
app.get('/health', (_req, res) => {
  res.status(200).json({ status: 'ok', service: 'auth-service' });
});



------------------------------------------------------------
FILE: backend\auth-service\src\config\env.ts
------------------------------------------------------------
import 'dotenv/config';
import { z } from 'zod';

const Env = z.object({
  NODE_ENV: z.enum(['development','test','production']).default('development'),
  PORT: z.coerce.number().default(3001),
  CORS_ORIGIN: z.string().default('http://localhost:5173'),

  DATABASE_URL: z.string(),
  REDIS_URL: z.string(),

  JWT_ACCESS_SECRET: z.string().min(16),
  JWT_REFRESH_SECRET: z.string().min(16),
  ACCESS_TTL: z.string().default('15m'),
  REFRESH_TTL: z.string().default('7d'),
});

export const env = Env.parse(process.env);
export const corsOrigins = env.CORS_ORIGIN.split(',').map(s => s.trim());



------------------------------------------------------------
FILE: backend\auth-service\src\db.ts
------------------------------------------------------------
import { Pool } from 'pg';
import { env } from './config/env.js';

export const pool = new Pool({
  connectionString: env.DATABASE_URL,
  max: 15,
  idleTimeoutMillis: 30_000,
  statement_timeout: 60_000,
});



------------------------------------------------------------
FILE: backend\auth-service\src\middleware\error.ts
------------------------------------------------------------
import type { NextFunction, Request, Response } from 'express';

export class HttpError extends Error {
  status: number; code?: string;
  constructor(status: number, message: string, code?: string) {
    super(message); this.status = status; this.code = code;
  }
}
export function errorHandler(err: any, _req: Request, res: Response, _next: NextFunction) {
  const status = err.status || 500;
  res.status(status).json({
    type: 'about:blank',
    title: err.code || 'ServerError',
    status,
    detail: err.message || 'Unexpected error'
  });
}



------------------------------------------------------------
FILE: backend\auth-service\src\middleware\requireAuth.ts
------------------------------------------------------------
import type { NextFunction, Request, Response } from 'express';
import jwt from 'jsonwebtoken';
import { env } from '../config/env.js';

export function requireAuth(roles?: string[]) {
  return (req: Request, res: Response, next: NextFunction) => {
    const h = req.headers.authorization || '';
    const token = h.startsWith('Bearer ') ? h.slice(7) : null;
    if (!token) return res.status(401).json({ detail: 'Missing token' });
    try {
      const decoded: any = jwt.verify(token, env.JWT_ACCESS_SECRET);
      (req as any).user = decoded;
      if (roles && !roles.some(r => (decoded.roles || []).includes(r))) {
        return res.status(403).json({ detail: 'Forbidden' });
      }
      next();
    } catch { return res.status(401).json({ detail: 'Invalid token' }); }
  };
}



------------------------------------------------------------
FILE: backend\auth-service\src\redis.ts
------------------------------------------------------------
import { createClient } from 'redis';
import { env } from './config/env.js';

export const redis = createClient({ url: env.REDIS_URL });

export async function initRedis() {
  redis.on('error', (e) => console.error('[redis] error', e));
  if (!redis.isOpen) {
    await redis.connect();
  }
}



------------------------------------------------------------
FILE: backend\auth-service\src\routes\auth.ts
------------------------------------------------------------
import { randomUUID } from 'crypto';
import { Router } from 'express';
import { z } from 'zod';
import { pool } from '../db.js';
import { HttpError } from '../middleware/error.js';
import { redis } from '../redis.js';
import { signAccess, signRefresh, verifyRefresh } from '../utils/jwt.js';
import { hashPassword, verifyPassword } from '../utils/password.js';

export const authRouter = Router();

const RegisterSchema = z.object({
  email: z.string().email(),
  password: z.string().min(8),
  display_name: z.string().min(2).max(100)
});

const LoginSchema = z.object({
  email: z.string().email(),
  password: z.string().min(8)
});

/** POST /auth/register */
authRouter.post('/register', async (req, res, next) => {
  try {
    const { email, password, display_name } = RegisterSchema.parse(req.body);
    const pwHash = await hashPassword(password);

    const { rows } = await pool.query(
      `INSERT INTO users (email, password_hash, display_name, roles, is_verified)
       VALUES ($1, $2, $3, ARRAY['user'], false)
       ON CONFLICT (email) DO NOTHING
       RETURNING id, email, display_name, roles, is_verified, created_at`,
      [email, pwHash, display_name]
    );
    const user = rows[0];
    if (!user) throw new HttpError(409, 'Email already registered', 'EmailTaken');

    const sid = randomUUID();
    const access = signAccess({ sub: user.id, roles: user.roles, sid });
    const refresh = signRefresh({ sub: user.id, sid });
    res.status(201).json({ user, tokens: { access, refresh } });
  } catch (e) { next(e); }
});

/** POST /auth/login */
authRouter.post('/login', async (req, res, next) => {
  try {
    const { email, password } = LoginSchema.parse(req.body);
    const { rows } = await pool.query(
      'SELECT id, email, password_hash, display_name, roles, is_verified FROM users WHERE email=$1',
      [email]
    );
    const u = rows[0];
    if (!u || !(await verifyPassword(password, u.password_hash))) {
      throw new HttpError(401, 'Invalid credentials', 'AuthFailed');
    }
    const sid = randomUUID();
    const access = signAccess({ sub: u.id, roles: u.roles, sid });
    const refresh = signRefresh({ sub: u.id, sid });
    res.json({ user: { id: u.id, email: u.email, display_name: u.display_name, roles: u.roles }, tokens: { access, refresh } });
  } catch (e) { next(e); }
});

/** POST /auth/refresh */
authRouter.post('/refresh', async (req, res, next) => {
  try {
    const { refresh } = (req.body || {}) as { refresh?: string };
    if (!refresh) throw new HttpError(400, 'Missing refresh token', 'BadRequest');

    let decoded: any;
    try { decoded = verifyRefresh(refresh); }
    catch { throw new HttpError(401, 'Invalid refresh token', 'InvalidRefresh'); }

    // revoked?
    const revoked = await redis.get(`revoked:${decoded.sid}`);
    if (revoked) throw new HttpError(401, 'Refresh revoked', 'TokenRevoked');

    // rotate: revoke old session id
    await redis.setEx(`revoked:${decoded.sid}`, 60 * 60 * 24 * 8, '1');
    const newSid = randomUUID();

    // fetch roles to embed (optional)
    const { rows } = await pool.query('SELECT roles FROM users WHERE id=$1', [decoded.sub]);
    const roles = rows[0]?.roles || ['user'];

    const access = signAccess({ sub: decoded.sub, roles, sid: newSid });
    const newRefresh = signRefresh({ sub: decoded.sub, sid: newSid });
    res.json({ access, refresh: newRefresh });
  } catch (e) { next(e); }
});

/** POST /auth/logout */
authRouter.post('/logout', async (req, res, _next) => {
  try {
    const { refresh } = (req.body || {}) as { refresh?: string };
    if (refresh) {
      try {
        const decoded: any = verifyRefresh(refresh);
        await redis.setEx(`revoked:${decoded.sid}`, 60 * 60 * 24 * 8, '1');
      } catch { /* ignore */ }
    }
    res.status(204).send();
  } catch { res.status(204).send(); }
});

/** GET /auth/me (requires Authorization: Bearer <access>) */
authRouter.get('/me', async (req, res, next) => {
  try {
    const h = req.headers.authorization || '';
    const token = h.startsWith('Bearer ') ? h.slice(7) : '';
    if (!token) throw new HttpError(401, 'Missing token', 'AuthRequired');

    // Verify access; we donâ€™t need roles here
    const jwt = await import('jsonwebtoken');
    const { env } = await import('../config/env.js');
    const decoded: any = jwt.default.verify(token, env.JWT_ACCESS_SECRET);

    const { rows } = await pool.query(
      'SELECT id, email, display_name, roles, is_verified, created_at FROM users WHERE id=$1',
      [decoded.sub]
    );
    const u = rows[0];
    if (!u) throw new HttpError(404, 'User not found', 'NotFound');
    res.json(u);
  } catch (e) { next(e); }
});



------------------------------------------------------------
FILE: backend\auth-service\src\server.ts
------------------------------------------------------------
// backend/auth-service/src/server.ts
import "dotenv/config";
import process from "node:process";
import { app } from "./app.js";

const port = Number(process.env.PORT) || 3001; // standardize on 3001
app.listen(port, () => {
  console.log(`auth-service listening on :${port}`);
});



------------------------------------------------------------
FILE: backend\auth-service\src\utils\jwt.ts
------------------------------------------------------------
import jwt, { type JwtPayload, type Secret, type SignOptions } from 'jsonwebtoken';
import type { StringValue } from 'ms';
import { env } from '../config/env.js';

const accessOpts: SignOptions = { expiresIn: env.ACCESS_TTL as StringValue };
const refreshOpts: SignOptions = { expiresIn: env.REFRESH_TTL as StringValue };

export function signAccess(payload: JwtPayload | string | object) {
  return jwt.sign(payload as any, env.JWT_ACCESS_SECRET as Secret, accessOpts);
}

export function signRefresh(payload: JwtPayload | string | object) {
  return jwt.sign(payload as any, env.JWT_REFRESH_SECRET as Secret, refreshOpts);
}

export function verifyAccess(token: string) {
  return jwt.verify(token, env.JWT_ACCESS_SECRET as Secret);
}

export function verifyRefresh(token: string) {
  return jwt.verify(token, env.JWT_REFRESH_SECRET as Secret);
}



------------------------------------------------------------
FILE: backend\auth-service\src\utils\password.ts
------------------------------------------------------------
import bcrypt from 'bcryptjs';
export async function hashPassword(pw: string) { return bcrypt.hash(pw, 12); }
export async function verifyPassword(pw: string, hash: string) { return bcrypt.compare(pw, hash); }



====================================================================================================
  DATA SERVICE - SRC
====================================================================================================


------------------------------------------------------------
FILE: backend\data-service\src\app.ts
------------------------------------------------------------
// backend/data-service/src/app.ts
import compression from 'compression';
import cors from 'cors';
import express, { type Express } from 'express';
import helmet from 'helmet';
import {
  cleanupMiddleware,
  limitRequestSize,
  requestTimeout,
  sanitizeInput,
  securityHeaders,
} from './middleware/audit';
import { DatabaseService } from './services/DatabaseService';
import { logger } from './utils/logger';

// Routes
import assetRoutes from './routes/assets';
import dataSourceRoutes from './routes/dataSources';
import governanceRoutes from './routes/governance';
import lineageRoutes from './routes/lineage';
import qualityRoutes from './routes/quality';
import requestsRoutes from './routes/requests';
import statsRoutes from './routes/stats';

/* ──────────────────────────────────────────────────────────────────────────
 * Helpers
 * ────────────────────────────────────────────────────────────────────────── */

type AppError = Error & { code?: string; statusCode?: number };
const toAppError = (err: unknown): AppError => {
  if (err instanceof Error) return err as AppError;
  try {
    return new Error(typeof err === 'string' ? err : JSON.stringify(err)) as AppError;
  } catch {
    return new Error(String(err)) as AppError;
  }
};

const healthToBoolean = (v: unknown): boolean => {
  if (typeof v === 'boolean') return v;
  if (v && typeof v === 'object') {
    const anyV = v as any;
    if (typeof anyV.ok === 'boolean') return anyV.ok;
    if (typeof anyV.healthy === 'boolean') return anyV.healthy;
    if (typeof anyV.status === 'string') {
      const s = anyV.status.toLowerCase();
      return s === 'healthy' || s === 'ok' || s === 'ready';
    }
  }
  return false;
};

/* ──────────────────────────────────────────────────────────────────────────
 * Default-exported App class (matches server.ts expectations)
 * ────────────────────────────────────────────────────────────────────────── */

export default class App {
  private readonly app: Express;
  private readonly db: DatabaseService;

  constructor() {
    this.app = express();
    this.db = new DatabaseService();
    this.configure();
    this.registerRoutes();
    this.registerGlobalErrorHandler();
  }

  /** server.ts calls this to get the Express instance and start listening */
  public getExpressApp(): Express {
    return this.app;
  }

  /** server.ts calls this async init after listen (migrations, warmups, etc.) */
  public async initialize(): Promise<void> {
    // Run migrations & any warm-up tasks
    await this.db.runMigrations();
    logger.info('[data-service] initialize complete');
  }

  /** server.ts calls this during shutdown */
  public async cleanup(): Promise<void> {
    try {
      await this.db.close();
      await cleanupMiddleware();
      logger.info('[data-service] cleanup completed');
    } catch (e) {
      const err = toAppError(e);
      logger.error('[data-service] cleanup error', { message: err.message, stack: err.stack });
    }
  }

  /* ────────────────────────────────────────────────────────────────────────
   * Private configuration & routes
   * ──────────────────────────────────────────────────────────────────────── */

  private configure(): void {
    // Trust proxy for accurate IP addresses behind load balancers
    this.app.set('trust proxy', 1);

    // Security middleware
    this.app.use(
      helmet({
        contentSecurityPolicy: {
          directives: {
            defaultSrc: ["'self'"],
            styleSrc: ["'self'", "'unsafe-inline'"],
            scriptSrc: ["'self'"],
            imgSrc: ["'self'", 'data:', 'https:'],
            connectSrc: ["'self'"],
            fontSrc: ["'self'"],
            objectSrc: ["'none'"],
            mediaSrc: ["'self'"],
            frameSrc: ["'none'"],
          },
        },
        crossOriginEmbedderPolicy: false,
      })
    );

    // CORS configuration
    this.app.use(
      cors({
        origin: (origin, callback) => {
          const allowedOrigins = (process.env.CORS_ORIGIN || '')
            .split(',')
            .map((o) => o.trim())
            .filter(Boolean);

          // Allow requests with no origin (mobile apps, curl, etc.)
          if (!origin) return callback(null, true);

          if (allowedOrigins.includes(origin) || process.env.NODE_ENV === 'development') {
            callback(null, true);
          } else {
            logger.warn('CORS origin rejected', { origin });
            callback(new Error('Not allowed by CORS'));
          }
        },
        credentials: true,
        methods: ['GET', 'POST', 'PUT', 'DELETE', 'OPTIONS'],
        allowedHeaders: ['Content-Type', 'Authorization', 'X-Requested-With'],
        maxAge: 86_400,
      })
    );

    // Compression
    this.app.use(
      compression({
        filter: (req, res) => {
          if (req.headers['x-no-compression']) return false;
          return compression.filter(req, res);
        },
        threshold: 1024,
      })
    );

    // Request parsing with size limits
    this.app.use(
      express.json({
        limit: process.env.MAX_REQUEST_SIZE || '10mb',
        strict: true,
      })
    );
    this.app.use(
      express.urlencoded({
        extended: true,
        limit: process.env.MAX_REQUEST_SIZE || '10mb',
      })
    );

    // Custom security middleware
    this.app.use(securityHeaders);
    this.app.use(sanitizeInput);
    this.app.use(requestTimeout(parseInt(process.env.REQUEST_TIMEOUT_MS || '30000', 10)));
    this.app.use(limitRequestSize(parseInt(process.env.MAX_REQUEST_SIZE || '10485760', 10)));

    // Request logging
    this.app.use((req, res, next) => {
      const start = Date.now();
      res.on('finish', () => {
        const duration = Date.now() - start;
        logger.info('HTTP Request', {
          method: req.method,
          path: req.path,
          statusCode: res.statusCode,
          duration,
          ip: req.ip,
          userAgent: req.get('User-Agent'),
        });
      });
      next();
    });
  }

  private registerRoutes(): void {
    // Health check
    this.app.get('/health', async (_req, res) => {
      try {
        const dbHealthRaw = (await this.db.healthCheck()) as unknown;
        const dbHealthy = healthToBoolean(dbHealthRaw);

        res.json({
          status: 'healthy',
          service: 'cwic-data-service',
          version: process.env.APP_VERSION || '1.0.0',
          environment: process.env.NODE_ENV || 'development',
          timestamp: new Date().toISOString(),
          uptime: process.uptime(),
          memory: process.memoryUsage(),
          database: dbHealthRaw, // raw payload if object
          databaseHealthy: dbHealthy, // normalized boolean
        });
      } catch (error) {
        const err = toAppError(error);
        logger.error('Health check failed', { error: err.message });
        res.status(503).json({
          status: 'unhealthy',
          service: 'cwic-data-service',
          error: err.message,
          timestamp: new Date().toISOString(),
        });
      }
    });

    // Readiness check
    this.app.get('/ready', async (_req, res) => {
      try {
        const maybe = (this.db as any).isReady?.() ?? this.db.healthCheck();
        const raw = await Promise.resolve(maybe as unknown);
        const isReady = healthToBoolean(raw);
        if (!isReady) throw new Error('Database not ready');

        res.json({ status: 'ready', timestamp: new Date().toISOString() });
      } catch (error) {
        const err = toAppError(error);
        res.status(503).json({
          status: 'not ready',
          error: err.message,
          timestamp: new Date().toISOString(),
        });
      }
    });

    // Mount routes with both /api prefix and without (gateway flexibility)
    const routes = [
      { path: '/data-sources', router: dataSourceRoutes },
      { path: '/assets', router: assetRoutes },
      { path: '/quality', router: qualityRoutes },
      { path: '/governance', router: governanceRoutes },
      { path: '/requests', router: requestsRoutes },
      { path: '/lineage', router: lineageRoutes },
      { path: '/stats', router: statsRoutes },
    ];

    routes.forEach(({ path, router }) => {
      this.app.use(`/api${path}`, router);
      this.app.use(path, router);
    });

    // 404 handler
    this.app.use('*', (req, res) => {
      logger.warn('Route not found', {
        method: req.method,
        path: req.originalUrl,
        ip: req.ip,
      });

      res.status(404).json({
        success: false,
        error: {
          code: 'NOT_FOUND',
          message: `Route ${req.method} ${req.originalUrl} not found`,
          timestamp: new Date().toISOString(),
        },
      });
    });
  }

  private registerGlobalErrorHandler(): void {
    // Global error handler
    this.app.use((error: unknown, req: express.Request, res: express.Response, _next: express.NextFunction) => {
      const err = toAppError(error);
      const errorId = Math.random().toString(36).substring(7);

      logger.error('Unhandled application error', {
        errorId,
        message: err.message,
        stack: err.stack,
        path: req.path,
        method: req.method,
        ip: req.ip,
      });

      let statusCode = 500;
      let errorCode = 'INTERNAL_ERROR';
      let message = 'An unexpected error occurred';

      if (err.name === 'ValidationError') {
        statusCode = 400;
        errorCode = 'VALIDATION_ERROR';
        message = err.message;
      } else if ((err as any).code === '23505') {
        statusCode = 409;
        errorCode = 'DUPLICATE_ENTRY';
        message = 'A record with this information already exists';
      } else if ((err as any).code === '23503') {
        statusCode = 400;
        errorCode = 'INVALID_REFERENCE';
        message = 'Referenced record does not exist';
      } else if ((err as any).statusCode) {
        statusCode = (err as any).statusCode;
        errorCode = (err as any).code || errorCode;
        message = err.message || message;
      }

      if (statusCode >= 500 && process.env.NODE_ENV === 'production') {
        message = 'Internal server error';
      }

      res.status(statusCode).json({
        success: false,
        error: {
          code: errorCode,
          message,
          errorId,
          timestamp: new Date().toISOString(),
        },
      });
    });

    // Process-level guards (logging only; actual shutdown handled in server.ts)
    process.on('uncaughtException', (error: unknown) => {
      const err = toAppError(error);
      logger.error('Uncaught exception', { error: err.message, stack: err.stack });
    });

    process.on('unhandledRejection', (reason: unknown, promise) => {
      const msg =
        reason instanceof Error
          ? reason.message
          : typeof reason === 'string'
          ? reason
          : (() => {
              try {
                return JSON.stringify(reason);
              } catch {
                return String(reason);
              }
            })();
      logger.error('Unhandled promise rejection', { reason: msg, promise });
    });
  }
}



------------------------------------------------------------
FILE: backend\data-service\src\config\database.ts
------------------------------------------------------------
// src/config/database.ts
import { Pool, PoolConfig, QueryResult, QueryResultRow } from 'pg';

/**
 * Minimal env parsing with sane defaults.
 * You can swap this for zod if you want strict validation.
 */
const {
  DATABASE_URL,
  PG_MAX = '10',
  PG_IDLE_TIMEOUT_MS = '30000',
  PG_CONN_TIMEOUT_MS = '5000',
  PG_SSL = 'false',
} = process.env;

if (!DATABASE_URL) {
  // Fail fast in production; stay permissive in dev if you prefer
  console.warn('[db] DATABASE_URL is not set. Using default localhost URL may be required for local dev.');
}

const poolConfig: PoolConfig = {
  connectionString: DATABASE_URL,
  max: Number(PG_MAX) || 10,
  idleTimeoutMillis: Number(PG_IDLE_TIMEOUT_MS) || 30_000,
  connectionTimeoutMillis: Number(PG_CONN_TIMEOUT_MS) || 5_000,
  ssl: String(PG_SSL).toLowerCase() === 'true' ? { rejectUnauthorized: false } : undefined,
};

/**
 * Shared Pool instance.
 * - Listeners log errors so the process doesn't crash silently.
 * - Graceful shutdown is provided via closePool().
 */
export const pool = new Pool(poolConfig);

pool.on('error', (err) => {
  console.error('[db] Unexpected error on idle client:', err);
});

/** Generic helpers â€” strongly typed results */
export async function query<R extends QueryResultRow = QueryResultRow>(
  text: string,
  params?: any[],
): Promise<R[]> {
  const res: QueryResult<R> = await pool.query<R>(text, params);
  return res.rows;
}

export async function queryOne<R extends QueryResultRow = QueryResultRow>(
  text: string,
  params?: any[],
): Promise<R | null> {
  const res: QueryResult<R> = await pool.query<R>(text, params);
  return res.rows[0] ?? null;
}

/**
 * Execute a function within a transaction.
 * Automatically commits on success and rolls back on error.
 */
export async function withTransaction<T>(fn: (client: import('pg').PoolClient) => Promise<T>): Promise<T> {
  const client = await pool.connect();
  try {
    await client.query('BEGIN');
    const result = await fn(client);
    await client.query('COMMIT');
    return result;
  } catch (err) {
    try {
      await client.query('ROLLBACK');
    } catch (rollbackErr) {
      console.error('[db] Rollback failed:', rollbackErr);
    }
    throw err;
  } finally {
    client.release();
  }
}

/** Cheap health check for liveness/readiness probes */
export async function healthCheck(): Promise<boolean> {
  try {
    const res = await pool.query('SELECT 1 as ok');
    return res.rows?.[0]?.ok === 1;
  } catch {
    return false;
  }
}

/** Graceful shutdown helper for process signals */
export async function closePool(): Promise<void> {
  await pool.end();
}



------------------------------------------------------------
FILE: backend\data-service\src\config\env.ts
------------------------------------------------------------
// backend/data-service/src/config/env.ts
import dotenv from 'dotenv';
import path from 'path';
import { URL } from 'url';

dotenv.config({ path: path.resolve(process.cwd(), '.env') });

export interface Config {
  server: {
    port: number;
    host: string;
    env: string;
    corsOrigin: string | string[];
    serviceName: string;
  };
  database: {
    url: string;
    host: string;
    port: number;
    name: string;
    user: string;
    password: string;
    ssl: boolean;
    poolMax: number;
    poolMin: number;
    idleTimeout: number;
    connectionTimeout: number;
  };
  security: {
    jwtSecret: string;
    jwtExpiresIn: string;
    helmet: {
      contentSecurityPolicy: boolean;
      crossOriginEmbedderPolicy: boolean;
    };
  };
  monitoring: {
    enableMetrics: boolean;
    enableHealthCheck: boolean;
  };
  logging: {
    level: string;
    enableFileLogging: boolean;
  };
}

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */

function coerceBool(v: unknown, def = false): boolean {
  const s = String(v ?? '').trim().toLowerCase();
  if (!s) return def;
  return s === '1' || s === 'true' || s === 'yes' || s === 'on';
}

function coerceInt(v: unknown, def: number): number {
  const n = Number(v);
  return Number.isFinite(n) ? n : def;
}

/** Accept CSV or leave string; if empty, default to dev origins */
function resolveCorsOrigin(raw?: string): string | string[] {
  if (!raw) return ['http://localhost:5173', 'http://localhost:3000', 'http://localhost:8000'];
  const parts = raw.split(',').map((o) => o.trim()).filter(Boolean);
  return parts.length <= 1 ? (parts[0] ?? '') : parts;
}

/** Strip accidental "DATABASE_URL=" prefix and surrounding quotes */
function normalizeDatabaseUrl(input?: string): string {
  let v = (input ?? '').trim();
  if (!v) return '';
  if (/^DATABASE_URL=/i.test(v)) v = v.replace(/^DATABASE_URL=/i, '').trim();
  if ((v.startsWith('"') && v.endsWith('"')) || (v.startsWith("'") && v.endsWith("'"))) {
    v = v.slice(1, -1);
  }
  return v;
}

/** Parse PostgreSQL/MySQL/MSSQL-style URL */
function parseDatabaseUrl(url: string): {
  host: string;
  port: number;
  database: string;
  user: string;
  password: string;
} {
  const normalized = normalizeDatabaseUrl(url);
  try {
    const u = new URL(normalized);
    return {
      host: u.hostname,
      port: parseInt(u.port) || 5432,
      database: u.pathname.replace(/^\//, ''),
      user: decodeURIComponent(u.username),
      password: decodeURIComponent(u.password),
    };
  } catch {
    throw new Error(`Invalid DATABASE_URL format: ${normalized}`);
  }
}

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ load & build config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */

const rawDbUrl = process.env.DATABASE_URL || 'postgresql://cwic_user:cwic_secure_pass@localhost:5432/cwic_platform';
const databaseUrl = normalizeDatabaseUrl(rawDbUrl);
const parsedDb = parseDatabaseUrl(databaseUrl);

export const config: Config = {
  server: {
    port: coerceInt(process.env.PORT, 3002),
    host: process.env.HOST || '0.0.0.0',
    env: process.env.NODE_ENV || 'development',
    corsOrigin: resolveCorsOrigin(process.env.CORS_ORIGIN),
    serviceName: process.env.SERVICE_NAME || 'data-service',
  },
  database: {
    url: databaseUrl,
    host: parsedDb.host,
    port: parsedDb.port,
    name: parsedDb.database,
    user: parsedDb.user,
    password: parsedDb.password,
    ssl: coerceBool(process.env.DB_SSL, process.env.NODE_ENV === 'production'),
    poolMax: coerceInt(process.env.DB_POOL_MAX, 20),
    poolMin: coerceInt(process.env.DB_POOL_MIN, 2),
    idleTimeout: coerceInt(process.env.DB_IDLE_TIMEOUT, 30_000),
    connectionTimeout: coerceInt(process.env.DB_CONNECTION_TIMEOUT, 10_000),
  },
  security: {
    jwtSecret: process.env.JWT_SECRET || 'your-super-secret-jwt-key-change-this-in-production',
    jwtExpiresIn: process.env.JWT_EXPIRES_IN || '7d',
    helmet: {
      contentSecurityPolicy: process.env.NODE_ENV === 'production',
      crossOriginEmbedderPolicy: false,
    },
  },
  monitoring: {
    enableMetrics: coerceBool(process.env.ENABLE_METRICS, process.env.NODE_ENV === 'production'),
    enableHealthCheck: process.env.ENABLE_HEALTH_CHECK !== 'false',
  },
  logging: {
    level: process.env.LOG_LEVEL || (process.env.NODE_ENV === 'production' ? 'info' : 'debug'),
    enableFileLogging: coerceBool(process.env.ENABLE_FILE_LOGGING, process.env.NODE_ENV === 'production'),
  },
};

export const isProduction = config.server.env === 'production';

/** Small shim for modules that expect `env.JWT_SECRET` etc. */
export const env = {
  NODE_ENV: config.server.env,
  PORT: String(config.server.port),
  HOST: config.server.host,
  SERVICE_NAME: config.server.serviceName,
  JWT_SECRET: config.security.jwtSecret,
  JWT_EXPIRES_IN: config.security.jwtExpiresIn,
  DATABASE_URL: config.database.url,
  LOG_LEVEL: config.logging.level,
  CORS_ORIGIN: Array.isArray(config.server.corsOrigin)
    ? config.server.corsOrigin.join(',')
    : config.server.corsOrigin,
} as const;

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ validation & logging â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */

export const validateConfig = (): void => {
  if (!config.database.url) throw new Error('DATABASE_URL environment variable is required');

  // Re-validate URL (throws with normalized string if bad)
  parseDatabaseUrl(config.database.url);

  // Ports
  if (config.server.port < 1 || config.server.port > 65535) {
    throw new Error('Server port must be between 1 and 65535');
  }
  if (config.database.port < 1 || config.database.port > 65535) {
    throw new Error('Database port must be between 1 and 65535');
  }

  // JWT secret length in prod
  if (isProduction && config.security.jwtSecret.length < 32) {
    throw new Error('JWT secret must be at least 32 characters long in production');
  }

  // Pool sizes
  if (config.database.poolMax < config.database.poolMin) {
    throw new Error('Database pool max must be greater than or equal to pool min');
  }

  // CORS origins are URLs if provided as strings; arrays can include plain origins
  const origins = Array.isArray(config.server.corsOrigin)
    ? config.server.corsOrigin
    : [config.server.corsOrigin];
  origins.forEach((origin) => {
    if (!origin) return;
    try {
      // Allow wildcard-like strings only if exactly "*"
      if (origin === '*') return;
      new URL(origin);
    } catch {
      throw new Error(`Invalid CORS_ORIGIN URL: ${origin}`);
    }
  });
};

export const logConfig = (): void => {
  console.log('ðŸ”§ Service Configuration:');
  console.log(`   Service: ${config.server.serviceName}`);
  console.log(`   Port: ${config.server.port}`);
  console.log(`   Host: ${config.server.host}`);
  console.log(`   Environment: ${config.server.env}`);
  console.log(
    `   CORS Origin: ${
      Array.isArray(config.server.corsOrigin) ? config.server.corsOrigin.join(', ') : config.server.corsOrigin
    }`
  );
  console.log(`   Database: ${config.database.host}:${config.database.port}/${config.database.name}`);
  console.log(`   Database User: ${config.database.user}`);
  console.log(`   SSL: ${config.database.ssl ? 'enabled' : 'disabled'}`);
  console.log(`   Pool Max: ${config.database.poolMax}`);
  console.log(`   Pool Min: ${config.database.poolMin}`);
  console.log(`   Metrics: ${config.monitoring.enableMetrics ? 'enabled' : 'disabled'}`);
  console.log(`   Log Level: ${config.logging.level}`);
  console.log('');
};



------------------------------------------------------------
FILE: backend\data-service\src\controllers\AssetController.ts
------------------------------------------------------------
// backend/data-service/src/controllers/AssetController.ts
import { Request, Response } from 'express';
import { AssetService } from '../services/AssetService';
import { logger, loggerUtils } from '../utils/logger';

export interface AssetRequest extends Request {
  user?: {
    id: string;
    email: string;
    role: string;
  };
}

export interface Column {
  name: string;
  type: string;
  nullable: boolean;
  primaryKey: boolean;
  foreignKey?: { table: string; column: string };
  description?: string;
  tags?: string[];
}

export interface Asset {
  id: string;
  name: string;
  type:
    | 'table'
    | 'view'
    | 'procedure'
    | 'function'
    | 'schema'
    | 'file'
    | 'api_endpoint'
    | 'stream'
    | 'model';
  dataSourceId: string;
  schemaName?: string;
  tableName?: string;
  description?: string;
  columns?: Column[];
  tags?: string[];
  status: 'active' | 'inactive' | 'deprecated';
  classification?: 'public' | 'internal' | 'confidential' | 'restricted';
  createdAt: Date;
  updatedAt: Date;
  metadata?: {
    rowCount?: number;
    size?: string;
    lastAccessed?: Date;
    sensitivity?: 'public' | 'internal' | 'confidential' | 'restricted';
  };
}

type LineageDirection = 'upstream' | 'downstream' | 'both';

type ListFilters = {
  search?: string;
  type?: string;
  dataSourceId?: string;
  status?: string;
  tags?: string[];
  sensitivity?: string;
};

type Pagination = { page: number; limit: number };

export class AssetController {
  private assetService: AssetService;

  constructor() {
    this.assetService = new AssetService();
  }

  /**
   * GET /api/assets
   */
  public getAllAssets = async (req: AssetRequest, res: Response): Promise<void> => {
    try {
      const {
        page = '1',
        limit = '20',
        search,
        type,
        dataSourceId,
        status,
        tags,
        sensitivity,
      } = req.query;

      const filters: ListFilters = {
        search: typeof search === 'string' ? search : undefined,
        type: typeof type === 'string' ? type : undefined,
        dataSourceId: typeof dataSourceId === 'string' ? dataSourceId : undefined,
        status: typeof status === 'string' ? status : undefined,
        tags:
          typeof tags === 'string'
            ? tags
                .split(',')
                .map((s) => s.trim())
                .filter(Boolean)
            : undefined,
        sensitivity: typeof sensitivity === 'string' ? sensitivity : undefined,
      };

      const pagination: Pagination = {
        page: Number(page) || 1,
        limit: Number(limit) || 20,
      };

      const t0 = Date.now();
      const result = await this.assetService.getAssets(filters, pagination);
      const dt = Date.now() - t0;

      loggerUtils.logDbOperation('select', 'assets', dt, true);

      res.status(200).json({
        success: true,
        data: result.assets,
        pagination: {
          page: result.page,
          limit: result.limit,
          total: result.total,
          totalPages: result.totalPages,
        },
        meta: {
          processingTime: `${dt}ms`,
          filters,
        },
      });
    } catch (error) {
      logger.error('Error fetching assets:', error);
      res.status(500).json({
        success: false,
        error: 'FETCH_ASSETS_FAILED',
        message: error instanceof Error ? error.message : 'Unknown error',
      });
    }
  };

  /**
   * GET /api/assets/:id
   */
  public getAssetById = async (req: AssetRequest, res: Response): Promise<void> => {
    try {
      const { id } = req.params;

      const t0 = Date.now();
      const asset = await this.assetService.getAssetById(id);
      const dt = Date.now() - t0;

      if (!asset) {
        res.status(404).json({ success: false, error: 'NOT_FOUND', message: 'Asset not found' });
        return;
      }

      loggerUtils.logDbOperation('select', 'assets', dt, true);

      res.status(200).json({
        success: true,
        data: asset,
        meta: { processingTime: `${dt}ms` },
      });
    } catch (error) {
      logger.error('Error fetching asset:', error);
      res.status(500).json({
        success: false,
        error: 'FETCH_ASSET_FAILED',
        message: error instanceof Error ? error.message : 'Unknown error',
      });
    }
  };

  /**
   * GET /api/assets/:id/schema
   */
  public getAssetSchema = async (req: AssetRequest, res: Response): Promise<void> => {
    try {
      const { id } = req.params;

      const t0 = Date.now();
      const schema = await this.assetService.getAssetSchema(id);
      const dt = Date.now() - t0;

      if (!schema) {
        res.status(404).json({ success: false, error: 'NOT_FOUND', message: 'Asset schema not found' });
        return;
      }

      res.status(200).json({
        success: true,
        data: schema,
        meta: { processingTime: `${dt}ms` },
      });
    } catch (error) {
      logger.error('Error fetching asset schema:', error);
      res.status(500).json({
        success: false,
        error: 'FETCH_SCHEMA_FAILED',
        message: error instanceof Error ? error.message : 'Unknown error',
      });
    }
  };

  /**
   * GET /api/assets/:id/lineage
   */
  public getAssetLineage = async (req: AssetRequest, res: Response): Promise<void> => {
    try {
      const { id } = req.params;
      const direction = (req.query.direction as LineageDirection) || 'both';

      const t0 = Date.now();
      const lineage = await this.assetService.getAssetLineage(id, direction);
      const dt = Date.now() - t0;

      res.status(200).json({
        success: true,
        data: lineage,
        meta: { processingTime: `${dt}ms` },
      });
    } catch (error) {
      logger.error('Error fetching asset lineage:', error);
      res.status(500).json({
        success: false,
        error: 'FETCH_LINEAGE_FAILED',
        message: error instanceof Error ? error.message : 'Unknown error',
      });
    }
  };

  /**
   * GET /api/assets/:id/profile
   */
  public getAssetProfile = async (req: AssetRequest, res: Response): Promise<void> => {
    try {
      const { id } = req.params;

      const t0 = Date.now();
      const profile = await this.assetService.getAssetProfile(id);
      const dt = Date.now() - t0;

      if (!profile) {
        res.status(404).json({
          success: false,
          error: 'NOT_FOUND',
          message: 'Asset profile not found',
        });
        return;
      }

      res.status(200).json({
        success: true,
        data: profile,
        meta: { processingTime: `${dt}ms` },
      });
    } catch (error) {
      logger.error('Error fetching asset profile:', error);
      res.status(500).json({
        success: false,
        error: 'FETCH_PROFILE_FAILED',
        message: error instanceof Error ? error.message : 'Unknown error',
      });
    }
  };

  /**
   * POST /api/assets
   */
  public createAsset = async (req: AssetRequest, res: Response): Promise<void> => {
    try {
      const assetData = req.body;

      const t0 = Date.now();
      const newAsset = await this.assetService.createAsset(assetData);
      const dt = Date.now() - t0;

      loggerUtils.logDbOperation('insert', 'assets', dt, true);
      logger.info(`Asset created: ${newAsset?.id}`, { userId: req.user?.id });

      res.status(201).json({
        success: true,
        data: newAsset,
        meta: { processingTime: `${dt}ms` },
      });
    } catch (error) {
      logger.error('Error creating asset:', error);
      res.status(500).json({
        success: false,
        error: 'CREATE_ASSET_FAILED',
        message: error instanceof Error ? error.message : 'Unknown error',
      });
    }
  };

  /**
   * PUT /api/assets/:id
   */
  public updateAsset = async (req: AssetRequest, res: Response): Promise<void> => {
    try {
      const { id } = req.params;
      const updateData = req.body;

      const t0 = Date.now();
      const updatedAsset = await this.assetService.updateAsset(id, updateData);
      const dt = Date.now() - t0;

      if (!updatedAsset) {
        res.status(404).json({ success: false, error: 'NOT_FOUND', message: 'Asset not found' });
        return;
      }

      loggerUtils.logDbOperation('update', 'assets', dt, true);
      logger.info(`Asset updated: ${id}`, { userId: req.user?.id });

      res.status(200).json({
        success: true,
        data: updatedAsset,
        meta: { processingTime: `${dt}ms` },
      });
    } catch (error) {
      logger.error('Error updating asset:', error);
      res.status(500).json({
        success: false,
        error: 'UPDATE_ASSET_FAILED',
        message: error instanceof Error ? error.message : 'Unknown error',
      });
    }
  };

  /**
   * PUT /api/assets/:id/classification
   */
  public updateClassification = async (req: AssetRequest, res: Response): Promise<void> => {
    try {
      const { id } = req.params;
      const { classification } = req.body as { classification: Asset['classification'] };

      const t0 = Date.now();
      const updated =
        typeof (this.assetService as any).updateClassification === 'function'
          ? await (this.assetService as any).updateClassification(id, { classification })
          : await this.assetService.updateAsset(id, { classification });
      const dt = Date.now() - t0;

      if (!updated) {
        res.status(404).json({ success: false, error: 'NOT_FOUND', message: 'Asset not found' });
        return;
      }

      loggerUtils.logDbOperation('update', 'assets', dt, true);

      res.status(200).json({
        success: true,
        data: updated,
        meta: { processingTime: `${dt}ms` },
      });
    } catch (error) {
      logger.error('Error updating asset classification:', error);
      res.status(500).json({
        success: false,
        error: 'UPDATE_CLASSIFICATION_FAILED',
        message: error instanceof Error ? error.message : 'Unknown error',
      });
    }
  };

  /**
   * POST /api/assets/:id/tag
   */
  public addTags = async (req: AssetRequest, res: Response): Promise<void> => {
    try {
      const { id } = req.params;
      const { tags } = req.body as { tags: string[] };

      if (!Array.isArray(tags)) {
        res
          .status(400)
          .json({ success: false, error: 'VALIDATION_ERROR', message: 'Tags must be an array' });
        return;
      }

      const t0 = Date.now();
      const result = await this.assetService.addTags(id, tags);
      const dt = Date.now() - t0;

      loggerUtils.logDbOperation('update', 'asset_tags', dt, true);

      res.status(200).json({
        success: true,
        data: result,
        meta: { processingTime: `${dt}ms` },
      });
    } catch (error) {
      logger.error('Error adding tags:', error);
      res.status(500).json({
        success: false,
        error: 'ADD_TAGS_FAILED',
        message: error instanceof Error ? error.message : 'Unknown error',
      });
    }
  };

  /**
   * DELETE /api/assets/:id/tag
   */
  public removeTags = async (req: AssetRequest, res: Response): Promise<void> => {
    try {
      const { id } = req.params;
      const { tags } = req.body as { tags: string[] };

      if (!Array.isArray(tags)) {
        res
          .status(400)
          .json({ success: false, error: 'VALIDATION_ERROR', message: 'Tags must be an array' });
        return;
      }

      const t0 = Date.now();
      const result = await this.assetService.removeTags(id, tags);
      const dt = Date.now() - t0;

      loggerUtils.logDbOperation('update', 'asset_tags', dt, true);

      res.status(200).json({
        success: true,
        data: result,
        meta: { processingTime: `${dt}ms` },
      });
    } catch (error) {
      logger.error('Error removing tags:', error);
      res.status(500).json({
        success: false,
        error: 'REMOVE_TAGS_FAILED',
        message: error instanceof Error ? error.message : 'Unknown error',
      });
    }
  };

  /**
   * GET /api/assets/stats  (global)
   */
  public getAssetStats = async (req: AssetRequest, res: Response): Promise<void> => {
    try {
      const { period = '30d' } = req.query as { period?: string };

      const t0 = Date.now();
      // Prefer a dedicated overview method if it exists
      const stats =
        typeof (this.assetService as any).getOverviewStats === 'function'
          ? await (this.assetService as any).getOverviewStats(period)
          : await this.assetService.getAssets({}, { page: 1, limit: 1 }).then((r) => ({
              totalAssets: r.total,
            }));

      const dt = Date.now() - t0;

      res.status(200).json({
        success: true,
        data: stats,
        meta: { processingTime: `${dt}ms` },
      });
    } catch (error) {
      logger.error('Error fetching asset stats:', error);
      res.status(500).json({
        success: false,
        error: 'FETCH_STATS_FAILED',
        message: error instanceof Error ? error.message : 'Unknown error',
      });
    }
  };

  /**
   * POST /api/assets/:id/scan
   */
  public scanAsset = async (req: AssetRequest, res: Response): Promise<void> => {
    try {
      const { id } = req.params;
      const { type = 'full', force = false } = req.body as {
        type?: 'full' | 'incremental' | 'schema_only' | 'profile_only';
        force?: boolean;
      };

      const t0 = Date.now();
      const result =
        typeof (this.assetService as any).scanAsset === 'function'
          ? await (this.assetService as any).scanAsset(id, { type, force })
          : await (this.assetService as any).syncAsset(id, { type, force }); // cast to any to avoid arity/type mismatch
      const dt = Date.now() - t0;

      logger.info(`Asset scan triggered: ${id}`, { userId: req.user?.id, type, force, duration: `${dt}ms` });

      res.status(200).json({
        success: true,
        data: result,
        meta: { processingTime: `${dt}ms` },
      });
    } catch (error) {
      logger.error('Error scanning asset:', error);
      res.status(500).json({
        success: false,
        error: 'SCAN_ASSET_FAILED',
        message: error instanceof Error ? error.message : 'Unknown error',
      });
    }
  };

  /**
   * DELETE /api/assets/:id
   */
  public deleteAsset = async (req: AssetRequest, res: Response): Promise<void> => {
    try {
      const { id } = req.params;

      const t0 = Date.now();
      const deleted =
        typeof (this.assetService as any).deleteAsset === 'function'
          ? await (this.assetService as any).deleteAsset(id)
          : await this.assetService.updateAsset(id, { status: 'inactive' as Asset['status'] });
      const dt = Date.now() - t0;

      if (!deleted) {
        res.status(404).json({ success: false, error: 'NOT_FOUND', message: 'Asset not found' });
        return;
      }

      loggerUtils.logDbOperation('delete', 'assets', dt, true);

      res.status(200).json({
        success: true,
        data: { id, deleted: true },
        meta: { processingTime: `${dt}ms` },
      });
    } catch (error) {
      logger.error('Error deleting asset:', error);
      res.status(500).json({
        success: false,
        error: 'DELETE_ASSET_FAILED',
        message: error instanceof Error ? error.message : 'Unknown error',
      });
    }
  };

  /**
   * GET /api/assets/search
   */
  public searchAssets = async (req: AssetRequest, res: Response): Promise<void> => {
    try {
      const { q, type, limit = '20', page = '1' } = req.query;

      // Ensure `search` is a string (service expects a required string)
      const searchTerm: string = typeof q === 'string' ? q : '';

      const filters: { search: string; type?: string } = {
        search: searchTerm,
        type: typeof type === 'string' ? type : undefined,
      };

      const pagination: Pagination = {
        page: Number(page) || 1,
        limit: Number(limit) || 20,
      };

      const t0 = Date.now();
      const result = await this.assetService.searchAssets(filters, pagination);
      const dt = Date.now() - t0;

      loggerUtils.logDbOperation('select', 'assets', dt, true);

      res.status(200).json({
        success: true,
        data: result.assets,
        pagination: {
          page: result.page,
          limit: result.limit,
          total: result.total,
          totalPages: result.totalPages,
        },
        meta: {
          processingTime: `${dt}ms`,
          query: filters.search,
        },
      });
    } catch (error) {
      logger.error('Error searching assets:', error);
      res.status(500).json({
        success: false,
        error: 'SEARCH_ASSETS_FAILED',
        message: error instanceof Error ? error.message : 'Unknown error',
      });
    }
  };
}

export default AssetController;



------------------------------------------------------------
FILE: backend\data-service\src\controllers\DataSourceController.ts
------------------------------------------------------------
// backend/data-service/src/controllers/DataSourceController.ts
import type { Request, Response } from 'express';
import { ConnectionTestService } from '../services/ConnectionTestService';
import { DataSourceService } from '../services/DataSourceService';
import { logger } from '../utils/logger';

import type {
  DataSource,
  DataSourceFilters,
  DataSourceStatus,
  DataSourceType,
} from '../models/DataSource';

type ReqWithUser = Request & { user?: { id?: string; email?: string; role?: string } };

/* ----------------------------------------------------------------------------
 * Helpers
 * -------------------------------------------------------------------------- */

const normalizeType = (t?: string): DataSourceType | undefined => {
  if (!t) return undefined;
  const x = String(t).toLowerCase();
  if (['azure_sql', 'azure-sql', 'sqlserver', 'sql-server'].includes(x)) return 'mssql' as DataSourceType;
  if (x === 'postgres') return 'postgresql' as DataSourceType;
  return x as DataSourceType;
};

const buildFilters = (q: Request['query']): DataSourceFilters => {
  const filters: DataSourceFilters = {};
  if (typeof q.status === 'string' && q.status.trim()) {
    filters.status = q.status.toLowerCase() as DataSourceStatus;
  }
  if (typeof q.type === 'string' && q.type.trim()) {
    filters.type = normalizeType(q.type) as DataSourceType;
  }
  if (typeof q.createdBy === 'string' && q.createdBy.trim()) {
    filters.createdBy = q.createdBy;
  }
  if (typeof q.search === 'string' && q.search.trim()) {
    filters.search = q.search.trim();
  }
  return filters;
};

const toInt = (v: unknown, def: number): number => {
  const n = Number(v);
  return Number.isFinite(n) && n > 0 ? n : def;
};

const allowedSortBy = new Set(['updatedAt', 'createdAt', 'name', 'status', 'type'] as const);
const normSortBy = (v: unknown): 'updatedAt' | 'createdAt' | 'name' | 'status' | 'type' =>
  allowedSortBy.has(String(v || '') as any) ? (String(v) as any) : 'updatedAt';
const normSortOrder = (v: unknown): 'asc' | 'desc' =>
  String(v || '').toLowerCase() === 'asc' ? 'asc' : 'desc';

/* ----------------------------------------------------------------------------
 * Controller
 * -------------------------------------------------------------------------- */

export class DataSourceController {
  private dataSourceService = new DataSourceService();
  private connectionTestService = new ConnectionTestService();

  /* ------------------------------- Listing -------------------------------- */

  getAllDataSources = async (req: Request, res: Response) => {
    try {
      const page = toInt(req.query.page, 1);
      const limit = toInt(req.query.limit, 20);
      const filters = buildFilters(req.query);
      const sortBy = normSortBy(req.query.sortBy);
      const sortOrder = normSortOrder(req.query.sortOrder);

      const result = await this.dataSourceService.getAllDataSources({
        page,
        limit,
        filters,
        sortBy,
        sortOrder,
      });

      res.json({
        success: true,
        data: result.dataSources,
        pagination: {
          page: result.page,
          limit: result.limit,
          total: result.total,
          totalPages: result.totalPages,
          sortBy,
          sortOrder,
        },
      });
    } catch (error) {
      logger.error('Error fetching data sources:', error);
      res
        .status(500)
        .json({ success: false, error: { code: 'FETCH_ERROR', message: 'Failed to fetch data sources' } });
    }
  };

  getDataSourceById = async (req: Request, res: Response) => {
    try {
      const { id } = req.params;
      const ds = await this.dataSourceService.getDataSourceById(id);
      if (!ds) {
        res.status(404).json({ success: false, error: { code: 'NOT_FOUND', message: 'Data source not found' } });
        return;
      }
      res.json({ success: true, data: ds });
    } catch (error) {
      logger.error('Error fetching data source:', error);
      res
        .status(500)
        .json({ success: false, error: { code: 'FETCH_ERROR', message: 'Failed to fetch data source' } });
    }
  };

  /* --------------------------------- CRUD --------------------------------- */

  createDataSource = async (req: Request, res: Response) => {
    try {
      const payload = req.body;

      const err = this.validateDataSourceData(payload);
      if (err) {
        res.status(400).json({ success: false, error: { code: 'VALIDATION_ERROR', message: err } });
        return;
      }

      const normType = normalizeType(payload.type) ?? payload.type;
      const userId = (req as ReqWithUser).user?.id ?? 'system';

      // Skip connection test during creation - we already tested it in the wizard
      const created = await this.dataSourceService.createDataSource({
        ...payload,
        type: normType,
        status: 'connected', // Mark as connected since test passed
        lastTestAt: new Date(),
        createdBy: userId,
      });

      res.status(201).json({ success: true, data: created });
    } catch (error) {
      logger.error('Error creating data source:', error);
      res.status(500).json({ 
        success: false, 
        error: { code: 'CREATE_ERROR', message: 'Failed to create data source' } 
      });
    }
  };

  updateDataSource = async (req: Request, res: Response) => {
    try {
      const { id } = req.params;
      const patch = req.body;
      const userId = (req as ReqWithUser).user?.id ?? 'system';

      const updated = await this.dataSourceService.updateDataSource(id, {
        ...patch,
        ...(patch.type ? { type: normalizeType(patch.type) } : {}),
        updatedBy: userId,
        updatedAt: new Date(),
      });

      if (!updated) {
        res.status(404).json({ success: false, error: { code: 'NOT_FOUND', message: 'Data source not found' } });
        return;
      }
      res.json({ success: true, data: updated });
    } catch (error) {
      logger.error('Error updating data source:', error);
      res
        .status(500)
        .json({ success: false, error: { code: 'UPDATE_ERROR', message: 'Failed to update data source' } });
    }
  };

  deleteDataSource = async (req: Request, res: Response) => {
    try {
      const { id } = req.params;
      const ok = await this.dataSourceService.deleteDataSource(id);
      if (!ok) {
        res.status(404).json({ success: false, error: { code: 'NOT_FOUND', message: 'Data source not found' } });
        return;
      }
      res.json({ success: true, message: 'Data source deleted successfully' });
    } catch (error) {
      logger.error('Error deleting data source:', error);
      res
        .status(500)
        .json({ success: false, error: { code: 'DELETE_ERROR', message: 'Failed to delete data source' } });
    }
  };

  /* ------------------------------- Testing -------------------------------- */

  /** Test a saved data source by id */
  testConnection = async (req: Request, res: Response) => {
    try {
      const { id } = req.params;
      const ds = await this.dataSourceService.getDataSourceById(id);
      if (!ds) {
        res.status(404).json({ success: false, error: { code: 'NOT_FOUND', message: 'Data source not found' } });
        return;
      }

      const result = await this.connectionTestService.testConnection(ds);
      const patch: Partial<DataSource> = {
        lastTestAt: new Date(),
        status: (result.success ? 'connected' : 'error') as DataSourceStatus,
      };
      if (!result.success) (patch as any).lastError = result.error || 'Connection test failed';

      await this.dataSourceService.updateDataSource(id, patch);

      res.json({
        success: true,
        data: {
          success: !!result.success,
          connectionStatus: result.success ? 'connected' : 'failed',
          responseTime: result.responseTime, // your model uses responseTime
          details: result.details,
          error: result.error,
          testedAt: new Date().toISOString(),
        },
      });
    } catch (error) {
      logger.error('Error testing connection:', error);
      res.status(500).json({ success: false, error: { code: 'TEST_ERROR', message: 'Failed to test connection' } });
    }
  };

  /** Test a raw config (wizard step) â€” works even if your service lacks testRawConfig */
  /** Test a raw config (wizard step) â€” works even if your service lacks testRawConfig */
testConfig = async (req: Request, res: Response) => {
    try {
      // API Gateway transforms 'config' to 'connection', so we check both
      const { type } = req.body ?? {};
      const config = req.body?.config || req.body?.connection;
      
      console.log('ðŸ” Controller received - type:', type);
      console.log('ðŸ” Controller received - config:', JSON.stringify(config, null, 2));
      
      const normType = normalizeType(type);
      if (!normType) {
        res.status(400).json({ success: false, error: { code: 'VALIDATION_ERROR', message: 'Invalid type' } });
        return;
      }
      if (!config || typeof config !== 'object') {
        res.status(400).json({ success: false, error: { code: 'VALIDATION_ERROR', message: 'Invalid config' } });
        return;
      }

      // Create a mock DataSource object that matches what your service expects
      const mockDataSource = {
        id: 'tmp',
        name: 'tmp',
        type: normType,
        connectionConfig: config,
        // Add any other required fields your DataSource interface needs
        status: 'testing' as DataSourceStatus,
        createdAt: new Date(),
        updatedAt: new Date(),
        createdBy: 'system',
        updatedBy: 'system',
      };

      console.log('ðŸ” Testing connection with mock DataSource:', JSON.stringify(mockDataSource, null, 2));

      const result = await this.connectionTestService.testConnection(mockDataSource as DataSource);

      res.json({
        success: true,
        data: {
          success: !!result?.success,
          connectionStatus: result?.success ? 'connected' : 'failed',
          responseTime: result?.responseTime,
          details: result?.details,
          error: result?.error,
          testedAt: new Date().toISOString(),
        },
      });
    } catch (error) {
      logger.error('Error testing raw config:', error);
      res
        .status(500)
        .json({ success: false, error: { code: 'TEST_ERROR', message: 'Failed to test data source config' } });
    }
  };

  /* ------------------------------ Discovery ------------------------------- */

  /** Discover DBs from a raw config (wizard preview) */
  previewDatabases = async (req: Request, res: Response) => {
    try {
      console.log('ðŸ” Preview databases request body:', JSON.stringify(req.body, null, 2));
      
      // API Gateway transforms 'config' to 'connection', so we check both
      const { type } = req.body ?? {};
      const config = req.body?.config || req.body?.connection;
      
      console.log('ðŸ” Preview databases - type:', type);
      console.log('ðŸ” Preview databases - config:', JSON.stringify(config, null, 2));
      
      const normType = normalizeType(type);
      if (!normType) {
        res.status(400).json({ success: false, error: { code: 'VALIDATION_ERROR', message: 'Invalid type' } });
        return;
      }
      if (!config || typeof config !== 'object') {
        res.status(400).json({ success: false, error: { code: 'VALIDATION_ERROR', message: 'Invalid config' } });
        return;
      }

      console.log('ðŸ” Preview databases - calling discovery for type:', normType);

      // Call the method directly since it exists in your service
      let databases: Array<{ name: string }> = [];

      try {
        databases = await this.connectionTestService.discoverDatabasesFromConfig(normType, config);
        console.log('ðŸ” Preview databases - discovered:', databases);
      } catch (error) {
        logger.warn('Database discovery failed:', error);
        console.log('âŒ Preview databases - discovery failed:', error);
        databases = []; // Return empty array on failure
      }

      const data = Array.isArray(databases) && databases.length > 0 ? databases : [];

      console.log('ðŸ” Preview databases - returning data:', data);
      res.json({ success: true, data });
    } catch (error) {
      logger.error('Error previewing databases:', error);
      console.error('âŒ Preview databases - error:', error);
      res.status(500).json({
        success: false,
        error: { code: 'DISCOVERY_ERROR', message: 'Failed to discover databases' },
      });
    }
  };

  /** List DBs for a saved data source (card "Browse Databases") */
  listDatabases = async (req: Request, res: Response) => {
    try {
      const { id } = req.params;
      const ds = await this.dataSourceService.getDataSourceById(id);
      if (!ds) {
        res.status(404).json({ success: false, error: { code: 'NOT_FOUND', message: 'Data source not found' } });
        return;
      }

      // Use service if you add it later; otherwise default to empty list.
      const tryList = (this.dataSourceService as any).listDatabases;
      let databases: Array<string | { name: string }> = [];

      if (typeof tryList === 'function') {
        databases = (await tryList.call(this.dataSourceService, id, ds)) as Array<string | { name: string }>;
      } else {
        databases = [];
      }

      const data =
        Array.isArray(databases) && databases.length > 0
          ? typeof databases[0] === 'string'
            ? (databases as string[]).map((name) => ({ name }))
            : (databases as Array<{ name: string }>)
          : [];

      res.json({ success: true, data });
    } catch (error) {
      logger.error('Error listing databases:', error);
      res
        .status(500)
        .json({ success: false, error: { code: 'DB_LIST_ERROR', message: 'Failed to list databases' } });
    }
  };

  /* -------------------------------- Health -------------------------------- */

  getHealthSummary = async (_req: Request, res: Response) => {
    try {
      const summary = await this.dataSourceService.getHealthSummary();
      res.json({ success: true, data: summary });
    } catch (error) {
      logger.error('Error fetching health summary:', error);
      res
        .status(500)
        .json({ success: false, error: { code: 'HEALTH_ERROR', message: 'Failed to fetch health summary' } });
    }
  };

  getDataSourceSchema = async (req: Request, res: Response) => {
    try {
      const { id } = req.params;
      const schema = await this.dataSourceService.getDataSourceSchema(id);
      res.json({ success: true, data: schema });
    } catch (error) {
      logger.error('Error fetching schema:', error);
      res
        .status(500)
        .json({ success: false, error: { code: 'SCHEMA_ERROR', message: 'Failed to fetch data source schema' } });
    }
  };

  /* --------------------------------- Sync --------------------------------- */

  syncDataSource = async (req: Request, res: Response) => {
    try {
      const { id } = req.params;
      const { force = false } = req.body ?? {};

      const result = await this.dataSourceService.syncDataSource(id, { force: !!force });

      const normalizedStatus: 'queued' | 'started' | 'running' | 'completed' | 'failed' =
        (result as any)?.status ??
        ((result as any)?.completedAt ? 'completed' : 'started');

      const normalizedSyncId =
        (result as any)?.syncId ??
        (result as any)?.id ??
        `run_${Date.now()}`;

      // Spread first, then override to avoid duplicate keys warning
      const payload = {
        ...(result as Record<string, any>),
        status: normalizedStatus,
        syncId: normalizedSyncId,
      };

      res.json({ success: true, data: payload });
    } catch (error) {
      logger.error('Error syncing data source:', error);
      res
        .status(500)
        .json({ success: false, error: { code: 'SYNC_ERROR', message: 'Failed to sync data source' } });
    }
  };

  getSyncStatus = async (req: Request, res: Response) => {
    try {
      const { id } = req.params;
      const tryStatus = (this.dataSourceService as any).getSyncStatus;

      if (typeof tryStatus !== 'function') {
        res.json({
          success: true,
          data: { syncId: `unknown_${id}`, status: 'started' as const },
        });
        return;
      }

      const result = await tryStatus.call(this.dataSourceService, id);

      const normalizedStatus: 'queued' | 'started' | 'running' | 'completed' | 'failed' =
        (result as any)?.status ??
        ((result as any)?.completedAt ? 'completed' : 'running');

      const normalizedSyncId =
        (result as any)?.syncId ??
        (result as any)?.id ??
        `run_${Date.now()}`;

      // Spread first, then override to avoid duplicate keys warning
      const payload = {
        ...(result as Record<string, any>),
        status: normalizedStatus,
        syncId: normalizedSyncId,
      };

      res.json({ success: true, data: payload });
    } catch (error) {
      logger.error('Error fetching sync status:', error);
      res
        .status(500)
        .json({ success: false, error: { code: 'SYNC_STATUS_ERROR', message: 'Failed to get sync status' } });
    }
  };

  /* ------------------------------- Validation ------------------------------ */

  private validateDataSourceData(data: any): string | null {
    if (!data?.name) return 'Name is required';
    if (!data?.type) return 'Type is required';
    
    const connectionConfig = data?.connectionConfig || data?.config || data?.connection;
    if (!connectionConfig) return 'Connection configuration is required';

    const t = normalizeType(data.type);
    const hasConnStr = !!connectionConfig.connectionString;
    const hasHost = !!connectionConfig.host;
    const hasDatabase = !!connectionConfig.database;

    switch (t) {
      case 'postgresql':
      case 'mysql':
      case 'oracle':
      case 'redshift':
        // These typically require database specification
        if (!hasConnStr && !hasHost) {
          return 'Host or connection string is required';
        }
        break;

      case 'mssql':
        // SQL Server can connect at server level without specifying database
        if (!hasConnStr && !hasHost) {
          return 'Host or connection string is required for SQL Server';
        }
        // Allow server-level connections - don't require database
        break;

      case 'mongodb':
        if (!hasConnStr && !hasHost) {
          return 'Host or connection string is required for MongoDB';
        }
        break;

      case 's3':
        if (!connectionConfig.bucket) return 'Bucket is required for S3';
        break;

      case 'api':
        if (!connectionConfig.baseUrl) return 'Base URL is required for API connections';
        break;
    }

    return null;
  }
}


------------------------------------------------------------
FILE: backend\data-service\src\controllers\GovernanceController.ts
------------------------------------------------------------
import { Request, Response } from 'express';
import { GovernanceService } from '../services/GovernanceService';

export class GovernanceController {
  private svc = new GovernanceService();

  listPolicies = async (req: Request, res: Response) => {
    const data = await this.svc.listPolicies(String(req.query.status || ''));
    res.json({ success: true, data });
  };

  createPolicy = async (req: Request, res: Response) => {
    const data = await this.svc.createPolicy(req.body, (req as any).user?.id);
    res.status(201).json({ success: true, data });
  };

  updatePolicy = async (req: Request, res: Response) => {
    const data = await this.svc.updatePolicy(req.params.id, req.body, (req as any).user?.id);
    if (!data) return res.status(404).json({ success: false, error: { code: 'NOT_FOUND' } });
    res.json({ success: true, data });
  };

  deletePolicy = async (req: Request, res: Response) => {
    const ok = await this.svc.deletePolicy(req.params.id);
    if (!ok) return res.status(404).json({ success: false, error: { code: 'NOT_FOUND' } });
    res.json({ success: true });
  };
}



------------------------------------------------------------
FILE: backend\data-service\src\controllers\LineageController.ts
------------------------------------------------------------
import { Request, Response } from 'express';
import { LineageService } from '../services/LineageService';

export class LineageController {
  private svc = new LineageService();
  graph = async (_req: Request, res: Response) => {
    const data = await this.svc.buildDemoGraph();
    res.json({ success: true, data });
  };
}


------------------------------------------------------------
FILE: backend\data-service\src\controllers\QualityController.ts
------------------------------------------------------------
// backend/data-service/src/controllers/QualityController.ts
import { NextFunction, Request, Response } from 'express';
import { z } from 'zod';
import { QualityService } from '../services/QualityService';
import { logger } from '../utils/logger';

// Custom error classes
class ValidationError extends Error {
  constructor(message: string, public details?: any) {
    super(message);
    this.name = 'ValidationError';
  }
}

class BusinessError extends Error {
  constructor(message: string, public code: string, public statusCode: number = 400) {
    super(message);
    this.name = 'BusinessError';
  }
}

// Request validation schemas
const ListRulesSchema = z.object({
  q: z.string().max(100).optional(),
  severity: z.enum(['low', 'medium', 'high', 'critical']).optional(),
  enabled: z.coerce.boolean().optional(),
  limit: z.coerce.number().min(1).max(100).default(50),
  offset: z.coerce.number().min(0).default(0),
});

const ExecuteRuleSchema = z.object({
  dataSourceId: z.string().uuid().optional(),
  timeout: z.coerce.number().min(1000).max(300000).default(30000),
});

const ListResultsSchema = z.object({
  ruleId: z.string().uuid().optional(),
  dataSourceId: z.string().uuid().optional(),
  status: z.enum(['passed', 'failed', 'error', 'skipped', 'timeout']).optional(),
  limit: z.coerce.number().min(1).max(100).default(50),
  offset: z.coerce.number().min(0).default(0),
});

const StatsSchema = z.object({
  timeframe: z.enum(['24h', '7d', '30d', '90d']).default('7d').optional(),
  groupBy: z.enum(['severity', 'status', 'data_source']).default('status').optional(),
});

export class QualityController {
  // allow DI for tests, default to real service
  constructor(private svc: QualityService = new QualityService()) {}

  listRules = async (req: Request, res: Response, next: NextFunction): Promise<void> => {
    try {
      const startTime = Date.now();
      const validatedQuery = ListRulesSchema.parse(req.query);
      const result = await this.svc.listRules(validatedQuery);
      const processingTime = Date.now() - startTime;

      logger.info('Quality rules listed', {
        userId: (req as any).user?.id,
        filters: validatedQuery,
        resultCount: result.rules.length,
        processingTimeMs: processingTime,
      });

      res.json({
        success: true,
        data: {
          rules: result.rules,
          pagination: {
            total: result.total,
            limit: validatedQuery.limit,
            offset: validatedQuery.offset,
            hasMore: validatedQuery.offset + validatedQuery.limit < result.total,
          },
        },
        meta: { processingTimeMs: processingTime, timestamp: new Date().toISOString() },
      });
    } catch (error) {
      next(this.handleError(error, 'listRules'));
    }
  };

  createRule = async (req: Request, res: Response, next: NextFunction): Promise<void> => {
    try {
      const startTime = Date.now();
      const userId = (req as any).user?.id;
      if (!userId) throw new BusinessError('Authentication required', 'AUTH_REQUIRED', 401);

      const rule = await this.svc.createRule(req.body, userId);
      const processingTime = Date.now() - startTime;

      logger.info('Quality rule created', { ruleId: rule.id, name: rule.name, createdBy: userId, processingTimeMs: processingTime });

      res.status(201).json({
        success: true,
        data: rule,
        meta: { processingTimeMs: processingTime, timestamp: new Date().toISOString() },
      });
    } catch (error) {
      next(this.handleError(error, 'createRule'));
    }
  };

  updateRule = async (req: Request, res: Response, next: NextFunction): Promise<void> => {
    try {
      const startTime = Date.now();
      const userId = (req as any).user?.id;
      const ruleId = req.params.id;
      if (!userId) throw new BusinessError('Authentication required', 'AUTH_REQUIRED', 401);
      if (!z.string().uuid().safeParse(ruleId).success) throw new ValidationError('Invalid rule ID format');

      const updated = await this.svc.updateRule(ruleId, req.body, userId);
      if (!updated) throw new BusinessError('Rule not found', 'RULE_NOT_FOUND', 404);

      const processingTime = Date.now() - startTime;

      logger.info('Quality rule updated', { ruleId, updatedBy: userId, processingTimeMs: processingTime });

      res.json({
        success: true,
        data: updated,
        meta: { processingTimeMs: processingTime, timestamp: new Date().toISOString() },
      });
    } catch (error) {
      next(this.handleError(error, 'updateRule'));
    }
  };

  deleteRule = async (req: Request, res: Response, next: NextFunction): Promise<void> => {
    try {
      const startTime = Date.now();
      const userId = (req as any).user?.id;
      const ruleId = req.params.id;
      if (!userId) throw new BusinessError('Authentication required', 'AUTH_REQUIRED', 401);
      if (!z.string().uuid().safeParse(ruleId).success) throw new ValidationError('Invalid rule ID format');

      const deleted = await this.svc.deleteRule(ruleId, userId);
      if (!deleted) throw new BusinessError('Rule not found', 'RULE_NOT_FOUND', 404);

      const processingTime = Date.now() - startTime;

      logger.info('Quality rule deleted', { ruleId, deletedBy: userId, processingTimeMs: processingTime });

      res.json({
        success: true,
        message: 'Rule successfully disabled',
        meta: { processingTimeMs: processingTime, timestamp: new Date().toISOString() },
      });
    } catch (error) {
      next(this.handleError(error, 'deleteRule'));
    }
  };

  listResults = async (req: Request, res: Response, next: NextFunction): Promise<void> => {
    try {
      const startTime = Date.now();
      const validatedQuery = ListResultsSchema.parse(req.query);
      const result = await this.svc.listResults(validatedQuery);
      const processingTime = Date.now() - startTime;

      logger.info('Quality results listed', {
        userId: (req as any).user?.id,
        filters: validatedQuery,
        resultCount: result.results.length,
        processingTimeMs: processingTime,
      });

      res.json({
        success: true,
        data: {
          results: result.results,
          pagination: {
            total: result.total,
            limit: validatedQuery.limit,
            offset: validatedQuery.offset,
            hasMore: validatedQuery.offset + validatedQuery.limit < result.total,
          },
        },
        meta: { processingTimeMs: processingTime, timestamp: new Date().toISOString() },
      });
    } catch (error) {
      next(this.handleError(error, 'listResults'));
    }
  };

  executeRule = async (req: Request, res: Response, next: NextFunction): Promise<void> => {
    try {
      const startTime = Date.now();
      const userId = (req as any).user?.id;
      const ruleId = req.params.id;

      if (!userId) throw new BusinessError('Authentication required', 'AUTH_REQUIRED', 401);
      if (!z.string().uuid().safeParse(ruleId).success) throw new ValidationError('Invalid rule ID format');

      const validatedBody = ExecuteRuleSchema.parse(req.body);

      const result = await this.svc.executeRule(ruleId, validatedBody.dataSourceId, {
        timeout: validatedBody.timeout,
        userId,
      });

      const processingTime = Date.now() - startTime;

      logger.info('Quality rule executed', {
        ruleId,
        dataSourceId: validatedBody.dataSourceId,
        status: result.status,
        executionTimeMs: result.execution_time_ms,
        executedBy: userId,
        processingTimeMs: processingTime,
      });

      res.json({
        success: true,
        data: result,
        meta: { processingTimeMs: processingTime, timestamp: new Date().toISOString() },
      });
    } catch (error) {
      next(this.handleError(error, 'executeRule'));
    }
  };

  getRule = async (req: Request, res: Response, next: NextFunction): Promise<void> => {
    try {
      const startTime = Date.now();
      const ruleId = req.params.id;
      if (!z.string().uuid().safeParse(ruleId).success) throw new ValidationError('Invalid rule ID format');

      const rule = await this.svc.getRule(ruleId);
      if (!rule) throw new BusinessError('Rule not found', 'RULE_NOT_FOUND', 404);

      const processingTime = Date.now() - startTime;

      res.json({
        success: true,
        data: rule,
        meta: { processingTimeMs: processingTime, timestamp: new Date().toISOString() },
      });
    } catch (error) {
      next(this.handleError(error, 'getRule'));
    }
  };

  // GET /api/quality/health
  healthCheck = async (_req: Request, res: Response, next: NextFunction): Promise<void> => {
    try {
      const startTime = Date.now();
      // Prefer a DB ping in the service if available
      const ok = (this.svc as any).healthCheck ? await (this.svc as any).healthCheck() : (await this.svc.listRules({ limit: 1 })).rules !== undefined;
      const processingTime = Date.now() - startTime;

      res.json({
        success: true,
        data: {
          status: ok ? 'healthy' : 'degraded',
          service: 'quality-service',
          timestamp: new Date().toISOString(),
          responseTimeMs: processingTime,
        },
      });
    } catch (error) {
      next(this.handleError(error, 'healthCheck'));
    }
  };

  // GET /api/quality/stats
  getQualityStats = async (req: Request, res: Response, next: NextFunction): Promise<void> => {
    try {
      const { timeframe = '7d', groupBy = 'status' } = StatsSchema.parse(req.query);
      // âœ… FIX: use this.svc, not this.service
      const stats = await this.svc.getStats({ timeframe, groupBy });
      res.json({ success: true, data: stats, meta: { timestamp: new Date().toISOString() } });
    } catch (error) {
      next(this.handleError(error, 'getQualityStats'));
    }
  };

  // POST /api/quality/rules/bulk/execute  (used by router)
  executeRulesBulk = async (req: Request, res: Response, next: NextFunction): Promise<void> => {
    try {
      const userId = (req as any).user?.id;
      if (!userId) throw new BusinessError('Authentication required', 'AUTH_REQUIRED', 401);

      const body = z.object({
        ruleIds: z.array(z.string().uuid()).min(1).max(10),
        dataSourceId: z.string().uuid().optional(),
        timeout: z.coerce.number().min(1000).max(300000).optional(),
      }).parse(req.body);

      const concurrency = 3;
      const results: any[] = [];
      let idx = 0;

      const worker = async () => {
        while (idx < body.ruleIds.length) {
          const myIndex = idx++;
          const id = body.ruleIds[myIndex];
          try {
            const r = await this.svc.executeRule(id, body.dataSourceId, { timeout: body.timeout, userId });
            results[myIndex] = { ok: true, result: r };
          } catch (e: any) {
            results[myIndex] = { ok: false, error: String(e?.message || e) };
          }
        }
      };

      await Promise.all(Array.from({ length: Math.min(concurrency, body.ruleIds.length) }, worker));
      res.status(202).json({ success: true, data: { results } });
    } catch (error) {
      next(this.handleError(error, 'executeRulesBulk'));
    }
  };

  // Error handling helper
  private handleError(error: any, operation: string): Error {
    const errorId = Math.random().toString(36).substring(7);

    logger.error(`Quality controller error in ${operation}`, {
      errorId,
      operation,
      message: error?.message,
      stack: error?.stack,
      type: error?.constructor?.name,
    });

    if (error instanceof ValidationError) {
      const err = new Error(error.message) as any;
      err.statusCode = 400;
      err.code = 'VALIDATION_ERROR';
      err.details = error.details;
      err.errorId = errorId;
      return err;
    }

    if (error instanceof BusinessError) {
      const err = new Error(error.message) as any;
      err.statusCode = error.statusCode;
      err.code = error.code;
      err.errorId = errorId;
      return err;
    }

    if (error?.name === 'ZodError') {
      const err = new Error('Invalid request parameters') as any;
      err.statusCode = 400;
      err.code = 'VALIDATION_ERROR';
      err.details = error.errors;
      err.errorId = errorId;
      return err;
    }

    if (error?.code && String(error.code).startsWith('23')) {
      const err = new Error('Database constraint violation') as any;
      err.statusCode = 409;
      err.code = 'CONSTRAINT_ERROR';
      err.errorId = errorId;
      return err;
    }

    const err = new Error('Internal server error') as any;
    err.statusCode = 500;
    err.code = 'INTERNAL_ERROR';
    err.errorId = errorId;
    return err;
  }
}



------------------------------------------------------------
FILE: backend\data-service\src\controllers\RequestsController.ts
------------------------------------------------------------
import { Request, Response } from 'express';
import { RequestsService } from '../services/RequestsService';

export class RequestsController {
  private svc = new RequestsService();

  list = async (req: Request, res: Response) => {
    const data = await this.svc.list(String(req.query.status || ''), String(req.query.type || ''));
    res.json({ success: true, data });
  };

  create = async (req: Request, res: Response) => {
    const data = await this.svc.create(req.body, (req as any).user?.id);
    res.status(201).json({ success: true, data });
  };

  update = async (req: Request, res: Response) => {
    const data = await this.svc.update(req.params.id, req.body, (req as any).user?.id);
    if (!data) return res.status(404).json({ success: false, error: { code: 'NOT_FOUND' } });
    res.json({ success: true, data });
  };
}



------------------------------------------------------------
FILE: backend\data-service\src\controllers\StatsController.ts
------------------------------------------------------------
import { Request, Response } from 'express';
import { StatsService } from '../services/StatsService';

export class StatsController {
  private svc = new StatsService();
  get = async (_req: Request, res: Response) => {
    const data = await this.svc.snapshot();
    res.json({ success: true, data });
  };
}


------------------------------------------------------------
FILE: backend\data-service\src\cron.ts
------------------------------------------------------------
// src/cron.ts (optional)
import { Pool } from 'pg';
import { SyncQueue } from './queue';
const cpdb = new Pool({ connectionString: process.env.DATABASE_URL });

export async function scheduleSyncAll() {
  const { rows } = await cpdb.query(`SELECT id::text AS id FROM data_sources WHERE status='connected'`);
  for (const r of rows) {
    await SyncQueue.add('sync-source', { dataSourceId: r.id }, { removeOnComplete: 50, removeOnFail: 50 });
  }
}



------------------------------------------------------------
FILE: backend\data-service\src\db.ts
------------------------------------------------------------
// backend/data-service/src/db.ts - Updated with correct imports
import { Pool, PoolConfig } from 'pg';
import { config } from './config/env';
import { logger } from './utils/logger';

export interface DatabaseConfig extends PoolConfig {
  host: string;
  port: number;
  database: string;
  user: string;
  password: string;
  ssl?: boolean | object;
  max?: number;
  min?: number;
  idleTimeoutMillis?: number;
  connectionTimeoutMillis?: number;
}

class Database {
  private pool: Pool;
  private static instance: Database;

  constructor() {
    const dbConfig: DatabaseConfig = {
      host: config.database.host,
      port: config.database.port,
      database: config.database.name,
      user: config.database.user,
      password: config.database.password,
      ssl: config.database.ssl ? { rejectUnauthorized: false } : false,
      max: config.database.poolMax,
      min: config.database.poolMin,
      idleTimeoutMillis: config.database.idleTimeout,
      connectionTimeoutMillis: config.database.connectionTimeout,
    };

    this.pool = new Pool(dbConfig);

    // Handle pool events
    this.pool.on('connect', (client) => {
      logger.debug('New database client connected', {
        totalConnections: this.pool.totalCount,
        idleConnections: this.pool.idleCount,
      });
    });

    this.pool.on('acquire', (client) => {
      logger.debug('Database client acquired from pool', {
        totalConnections: this.pool.totalCount,
        idleConnections: this.pool.idleCount,
        waitingClients: this.pool.waitingCount,
      });
    });

    this.pool.on('remove', (client) => {
      logger.debug('Database client removed from pool', {
        totalConnections: this.pool.totalCount,
        idleConnections: this.pool.idleCount,
      });
    });

    this.pool.on('error', (err, client) => {
      logger.error('Database pool error:', {
        error: err.message,
        stack: err.stack,
        totalConnections: this.pool.totalCount,
        idleConnections: this.pool.idleCount,
      });
    });

    logger.info('Database pool initialized', {
      host: dbConfig.host,
      port: dbConfig.port,
      database: dbConfig.database,
      maxConnections: dbConfig.max,
      minConnections: dbConfig.min,
      ssl: !!dbConfig.ssl,
    });
  }

  public static getInstance(): Database {
    if (!Database.instance) {
      Database.instance = new Database();
    }
    return Database.instance;
  }

  public getPool(): Pool {
    return this.pool;
  }

  public async query(text: string, params?: any[]): Promise<any> {
    const start = Date.now();
    const queryId = Math.random().toString(36).substring(7);
    
    try {
      logger.debug('Database query started', {
        queryId,
        query: text.substring(0, 100) + (text.length > 100 ? '...' : ''),
        paramCount: params?.length || 0,
      });

      const result = await this.pool.query(text, params);
      const duration = Date.now() - start;
      
      logger.debug('Database query completed', {
        queryId,
        duration: `${duration}ms`,
        rowCount: result.rowCount,
        command: result.command,
      });
      
      return result;
    } catch (error) {
      const duration = Date.now() - start;
      logger.error('Database query failed', {
        queryId,
        query: text.substring(0, 100) + (text.length > 100 ? '...' : ''),
        duration: `${duration}ms`,
        error: error instanceof Error ? error.message : 'Unknown error',
        paramCount: params?.length || 0,
      });
      throw error;
    }
  }

  public async transaction<T>(callback: (client: any) => Promise<T>): Promise<T> {
    const client = await this.pool.connect();
    const transactionId = Math.random().toString(36).substring(7);
    
    try {
      await client.query('BEGIN');
      logger.debug('Database transaction started', { transactionId });
      
      const result = await callback(client);
      
      await client.query('COMMIT');
      logger.debug('Database transaction committed', { transactionId });
      
      return result;
    } catch (error) {
      await client.query('ROLLBACK');
      logger.error('Database transaction rolled back', {
        transactionId,
        error: error instanceof Error ? error.message : 'Unknown error'
      });
      throw error;
    } finally {
      client.release();
      logger.debug('Database transaction client released', { transactionId });
    }
  }

  public async healthCheck(): Promise<{
    status: 'healthy' | 'unhealthy';
    latency?: number;
    connections?: {
      total: number;
      idle: number;
      waiting: number;
    };
    error?: string;
    timestamp: string;
  }> {
    const start = Date.now();
    
    try {
      // Simple connectivity test
      await this.pool.query('SELECT 1 as health_check');
      const latency = Date.now() - start;
      
      return {
        status: 'healthy',
        latency,
        connections: {
          total: this.pool.totalCount,
          idle: this.pool.idleCount,
          waiting: this.pool.waitingCount
        },
        timestamp: new Date().toISOString(),
      };
    } catch (error) {
      const latency = Date.now() - start;
      return {
        status: 'unhealthy',
        latency,
        error: error instanceof Error ? error.message : 'Unknown error',
        timestamp: new Date().toISOString(),
      };
    }
  }

  public async deepHealthCheck(): Promise<{
    status: 'healthy' | 'unhealthy';
    checks: {
      connectivity: boolean;
      writeable: boolean;
      performant: boolean;
    };
    latency: number;
    error?: string;
  }> {
    const start = Date.now();
    const checks = {
      connectivity: false,
      writeable: false,
      performant: false,
    };

    try {
      // Test connectivity
      await this.pool.query('SELECT 1');
      checks.connectivity = true;

      // Test write capability (create temp table and drop it)
      const tempTableName = `health_check_${Date.now()}`;
      await this.pool.query(`CREATE TEMP TABLE ${tempTableName} (id INTEGER)`);
      await this.pool.query(`INSERT INTO ${tempTableName} VALUES (1)`);
      await this.pool.query(`DROP TABLE ${tempTableName}`);
      checks.writeable = true;

      const latency = Date.now() - start;
      
      // Check if performance is acceptable (under 1 second)
      checks.performant = latency < 1000;

      return {
        status: Object.values(checks).every(Boolean) ? 'healthy' : 'unhealthy',
        checks,
        latency,
      };
    } catch (error) {
      const latency = Date.now() - start;
      return {
        status: 'unhealthy',
        checks,
        latency,
        error: error instanceof Error ? error.message : 'Unknown error',
      };
    }
  }

  public getStats(): {
    totalCount: number;
    idleCount: number;
    waitingCount: number;
  } {
    return {
      totalCount: this.pool.totalCount,
      idleCount: this.pool.idleCount,
      waitingCount: this.pool.waitingCount,
    };
  }

  public async getDetailedStats(): Promise<{
    pool: {
      totalCount: number;
      idleCount: number;
      waitingCount: number;
      maxConnections: number;
      minConnections: number;
    };
    database: {
      version: string;
      size: string;
      activeConnections: number;
    };
  }> {
    try {
      // Get database version
      const versionResult = await this.pool.query('SELECT version()');
      const version = versionResult.rows[0].version;

      // Get database size
      const sizeResult = await this.pool.query(`
        SELECT pg_size_pretty(pg_database_size(current_database())) as size
      `);
      const size = sizeResult.rows[0].size;

      // Get active connections count
      const connectionsResult = await this.pool.query(`
        SELECT count(*) as active_connections 
        FROM pg_stat_activity 
        WHERE state = 'active'
      `);
      const activeConnections = parseInt(connectionsResult.rows[0].active_connections);

      return {
        pool: {
          totalCount: this.pool.totalCount,
          idleCount: this.pool.idleCount,
          waitingCount: this.pool.waitingCount,
          maxConnections: config.database.poolMax,
          minConnections: config.database.poolMin,
        },
        database: {
          version: version.split(' ')[1], // Extract version number
          size,
          activeConnections,
        },
      };
    } catch (error) {
      logger.error('Error getting detailed database stats:', error);
      throw error;
    }
  }

  public async close(): Promise<void> {
    try {
      logger.info('Closing database pool...');
      await this.pool.end();
      logger.info('Database pool closed successfully');
    } catch (error) {
      logger.error('Error closing database pool:', error);
      throw error;
    }
  }

  // Migration and schema management
  public async runMigrations(): Promise<void> {
    try {
      logger.info('Running database migrations...');

      // Create migrations table if it doesn't exist
      await this.pool.query(`
        CREATE TABLE IF NOT EXISTS migrations (
          id SERIAL PRIMARY KEY,
          name VARCHAR(255) NOT NULL UNIQUE,
          executed_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
        )
      `);

      // List of migrations to run
      const migrations = [
        {
          name: '001_create_data_sources_table',
          sql: `
            CREATE TABLE IF NOT EXISTS data_sources (
              id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
              name VARCHAR(100) NOT NULL,
              type VARCHAR(50) NOT NULL,
              host VARCHAR(255),
              port INTEGER,
              database_name VARCHAR(100),
              username VARCHAR(100),
              password_encrypted TEXT,
              ssl BOOLEAN DEFAULT FALSE,
              connection_string TEXT,
              description TEXT,
              tags TEXT[] DEFAULT '{}',
              status VARCHAR(20) DEFAULT 'active',
              metadata JSONB DEFAULT '{}',
              created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
              updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
            );
            CREATE INDEX IF NOT EXISTS idx_data_sources_type ON data_sources(type);
            CREATE INDEX IF NOT EXISTS idx_data_sources_status ON data_sources(status);
          `
        },
        {
          name: '002_create_assets_table',
          sql: `
            CREATE TABLE IF NOT EXISTS assets (
              id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
              name VARCHAR(100) NOT NULL,
              type VARCHAR(50) NOT NULL,
              data_source_id UUID NOT NULL REFERENCES data_sources(id) ON DELETE CASCADE,
              schema_name VARCHAR(100),
              table_name VARCHAR(100),
              description TEXT,
              columns JSONB DEFAULT '[]',
              tags TEXT[] DEFAULT '{}',
              status VARCHAR(20) DEFAULT 'active',
              metadata JSONB DEFAULT '{}',
              created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
              updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
            );
            CREATE INDEX IF NOT EXISTS idx_assets_data_source_id ON assets(data_source_id);
            CREATE INDEX IF NOT EXISTS idx_assets_type ON assets(type);
            CREATE INDEX IF NOT EXISTS idx_assets_status ON assets(status);
          `
        },
        {
          name: '003_create_asset_lineage_table',
          sql: `
            CREATE TABLE IF NOT EXISTS asset_lineage (
              id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
              upstream_asset_id UUID NOT NULL REFERENCES assets(id) ON DELETE CASCADE,
              downstream_asset_id UUID NOT NULL REFERENCES assets(id) ON DELETE CASCADE,
              relationship_type VARCHAR(50) NOT NULL,
              description TEXT,
              created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
            );
            CREATE INDEX IF NOT EXISTS idx_asset_lineage_upstream ON asset_lineage(upstream_asset_id);
            CREATE INDEX IF NOT EXISTS idx_asset_lineage_downstream ON asset_lineage(downstream_asset_id);
          `
        }
      ];

      for (const migration of migrations) {
        // Check if migration has already been run
        const result = await this.pool.query(
          'SELECT id FROM migrations WHERE name = $1',
          [migration.name]
        );

        if (result.rows.length === 0) {
          logger.info(`Running migration: ${migration.name}`);
          
          // Run migration in a transaction
          await this.transaction(async (client) => {
            await client.query(migration.sql);
            await client.query(
              'INSERT INTO migrations (name) VALUES ($1)',
              [migration.name]
            );
          });

          logger.info(`Migration completed: ${migration.name}`);
        } else {
          logger.debug(`Migration already applied: ${migration.name}`);
        }
      }

      logger.info('All migrations completed successfully');
    } catch (error) {
      logger.error('Migration failed:', error);
      throw error;
    }
  }
}

// Export singleton instance
export const db = Database.getInstance();
export default db;


------------------------------------------------------------
FILE: backend\data-service\src\db\pool.ts
------------------------------------------------------------
// backend/data-service/src/db/pool.ts
import { Pool } from "pg";

const {
  DATABASE_URL,
  DB_POOL_MAX = "20",
  DB_IDLE_TIMEOUT = "30000",
  DB_CONNECTION_TIMEOUT = "10000",
  DB_SSL = "false",
} = process.env;

if (!DATABASE_URL) {
  throw new Error("DATABASE_URL is not set for data-service");
}

export const pool = new Pool({
  connectionString: DATABASE_URL,
  max: Number(DB_POOL_MAX),
  idleTimeoutMillis: Number(DB_IDLE_TIMEOUT),
  connectionTimeoutMillis: Number(DB_CONNECTION_TIMEOUT),
  ssl: String(DB_SSL).toLowerCase() === "true" ? { rejectUnauthorized: false } : undefined,
});

pool.on("error", (err) => {
  // Do not crash the process on idle client error; log and continue.
  console.error("[pg] Pool error:", err);
});



------------------------------------------------------------
FILE: backend\data-service\src\middleware\audit.ts
------------------------------------------------------------
// backend/data-service/src/middleware/audit.ts
import { NextFunction, Request, Response } from 'express';
import { DatabaseService } from '../services/DatabaseService';
import { logger } from '../utils/logger';

interface AuditLogEntry {
  entity_type: string;
  entity_id: string;
  action: string;
  actor?: string;
  actor_ip?: string;
  user_agent?: string;
  changes?: any;
  metadata?: any;
}

class AuditService {
  private db = new DatabaseService();
  private logQueue: AuditLogEntry[] = [];
  private flushInterval: NodeJS.Timeout;

  constructor() {
    // Batch insert audit logs every 5 seconds
    this.flushInterval = setInterval(() => this.flushLogs(), 5000);
  }

  async logAction(entry: AuditLogEntry): Promise<void> {
    this.logQueue.push({
      ...entry,
      metadata: {
        ...entry.metadata,
        timestamp: new Date().toISOString()
      }
    });

    // Flush immediately for critical actions
    if (['DELETE', 'EXECUTE'].includes(entry.action)) {
      await this.flushLogs();
    }
  }

  private async flushLogs(): Promise<void> {
    if (this.logQueue.length === 0) return;

    const logsToFlush = [...this.logQueue];
    this.logQueue = [];

    try {
      for (const log of logsToFlush) {
        await this.db.query(`
          INSERT INTO audit_logs (entity_type, entity_id, action, actor, actor_ip, user_agent, changes, metadata)
          VALUES ($1, $2, $3, $4, $5, $6, $7::jsonb, $8::jsonb)
        `, [
          log.entity_type,
          log.entity_id,
          log.action,
          log.actor || null,
          log.actor_ip || null,
          log.user_agent || null,
          JSON.stringify(log.changes || {}),
          JSON.stringify(log.metadata || {})
        ]);
      }
    } catch (error) {
      logger.error('Failed to flush audit logs', { 
        error: (error as Error).message, 
        queueSize: logsToFlush.length 
      });
      // Re-queue the failed logs
      this.logQueue.unshift(...logsToFlush);
    }
  }

  async cleanup(): Promise<void> {
    clearInterval(this.flushInterval);
    await this.flushLogs();
  }
}

const auditService = new AuditService();

export const auditMiddleware = (entityType: string, action: string) => {
  return (req: Request, res: Response, next: NextFunction) => {
    const originalSend = res.send;
    
    res.send = function(body: any) {
      const user = (req as any).user;
      const entityId = req.params.id || 'bulk_operation';
      const clientIp = req.ip || req.connection.remoteAddress || 'unknown';
      const userAgent = req.get('User-Agent') || 'unknown';

      // Log the action
      auditService.logAction({
        entity_type: entityType,
        entity_id: entityId,
        action: action,
        actor: user?.id || user?.email || 'anonymous',
        actor_ip: clientIp,
        user_agent: userAgent,
        changes: req.method === 'POST' || req.method === 'PUT' ? req.body : undefined,
        metadata: {
          method: req.method,
          path: req.path,
          query: req.query,
          statusCode: res.statusCode,
          contentLength: body ? Buffer.byteLength(body) : 0
        }
      }).catch(error => {
        logger.error('Audit logging failed', { error: error.message });
      });

      return originalSend.call(this, body);
    };

    next();
  };
};

// Enhanced rate limiting with Redis-like token bucket implementation
export class TokenBucket {
  private tokens: number;
  private lastRefill: number;
  private readonly capacity: number;
  private readonly refillRate: number;
  private readonly refillInterval: number;

  constructor(capacity: number, refillRate: number, refillInterval: number = 1000) {
    this.capacity = capacity;
    this.refillRate = refillRate;
    this.refillInterval = refillInterval;
    this.tokens = capacity;
    this.lastRefill = Date.now();
  }

  consume(tokens: number = 1): boolean {
    this.refill();
    
    if (this.tokens >= tokens) {
      this.tokens -= tokens;
      return true;
    }
    
    return false;
  }

  private refill(): void {
    const now = Date.now();
    const timePassed = now - this.lastRefill;
    const tokensToAdd = Math.floor(timePassed / this.refillInterval) * this.refillRate;
    
    if (tokensToAdd > 0) {
      this.tokens = Math.min(this.capacity, this.tokens + tokensToAdd);
      this.lastRefill = now;
    }
  }

  getTokens(): number {
    this.refill();
    return this.tokens;
  }
}

// Enhanced rate limiting middleware
export const createRateLimit = (options: {
  windowMs: number;
  max: number;
  skipSuccessfulRequests?: boolean;
  standardHeaders?: boolean;
  message?: string;
}) => {
  const buckets = new Map<string, TokenBucket>();
  const {
    windowMs,
    max,
    skipSuccessfulRequests = false,
    standardHeaders = true,
    message = 'Too many requests'
  } = options;

  return (req: Request, res: Response, next: NextFunction) => {
    const key = `${req.ip}:${req.path}`;
    
    if (!buckets.has(key)) {
      buckets.set(key, new TokenBucket(max, max, windowMs));
    }

    const bucket = buckets.get(key)!;
    const hasTokens = bucket.consume(1);

    if (standardHeaders) {
      res.set({
        'X-RateLimit-Limit': max.toString(),
        'X-RateLimit-Remaining': Math.max(0, bucket.getTokens()).toString(),
        'X-RateLimit-Reset': new Date(Date.now() + windowMs).toISOString()
      });
    }

    if (!hasTokens) {
      logger.warn('Rate limit exceeded', {
        ip: req.ip,
        path: req.path,
        userAgent: req.get('User-Agent')
      });

      return res.status(429).json({
        success: false,
        error: {
          code: 'RATE_LIMIT_EXCEEDED',
          message,
          retryAfter: Math.ceil(windowMs / 1000)
        }
      });
    }

    // Clean up old buckets periodically
    if (Math.random() < 0.01) { // 1% chance
      const now = Date.now();
      for (const [key, bucket] of buckets) {
        if (bucket.getTokens() === max && now - windowMs > 0) {
          buckets.delete(key);
        }
      }
    }

    next();
  };
};

// Security headers middleware
export const securityHeaders = (req: Request, res: Response, next: NextFunction) => {
  // Security headers
  res.set({
    'X-Content-Type-Options': 'nosniff',
    'X-Frame-Options': 'DENY',
    'X-XSS-Protection': '1; mode=block',
    'Strict-Transport-Security': 'max-age=31536000; includeSubDomains',
    'Referrer-Policy': 'strict-origin-when-cross-origin',
    'Content-Security-Policy': "default-src 'self'; script-src 'self'; style-src 'self' 'unsafe-inline'",
    'X-Permitted-Cross-Domain-Policies': 'none'
  });

  next();
};

// Request sanitization middleware
export const sanitizeInput = (req: Request, res: Response, next: NextFunction) => {
  const sanitizeValue = (value: any): any => {
    if (typeof value === 'string') {
      // Remove potentially dangerous characters
      return value
        .replace(/[<>]/g, '') // Remove angle brackets
        .replace(/javascript:/gi, '') // Remove javascript: protocol
        .replace(/data:/gi, '') // Remove data: protocol
        .trim();
    }
    
    if (Array.isArray(value)) {
      return value.map(sanitizeValue);
    }
    
    if (value && typeof value === 'object') {
      const sanitized: any = {};
      for (const [key, val] of Object.entries(value)) {
        sanitized[key] = sanitizeValue(val);
      }
      return sanitized;
    }
    
    return value;
  };

  if (req.body && typeof req.body === 'object') {
    req.body = sanitizeValue(req.body);
  }

  if (req.query && typeof req.query === 'object') {
    req.query = sanitizeValue(req.query);
  }

  next();
};

// Request timeout middleware
export const requestTimeout = (timeoutMs: number = 30000) => {
  return (req: Request, res: Response, next: NextFunction) => {
    const timeout = setTimeout(() => {
      if (!res.headersSent) {
        logger.warn('Request timeout', {
          method: req.method,
          path: req.path,
          ip: req.ip,
          timeout: timeoutMs
        });

        res.status(408).json({
          success: false,
          error: {
            code: 'REQUEST_TIMEOUT',
            message: 'Request timed out'
          }
        });
      }
    }, timeoutMs);

    res.on('finish', () => {
      clearTimeout(timeout);
    });

    res.on('close', () => {
      clearTimeout(timeout);
    });

    next();
  };
};

// Request size limiting middleware
export const limitRequestSize = (maxSize: number = 10 * 1024 * 1024) => { // 10MB default
  return (req: Request, res: Response, next: NextFunction) => {
    const contentLength = parseInt(req.get('Content-Length') || '0', 10);
    
    if (contentLength > maxSize) {
      logger.warn('Request too large', {
        contentLength,
        maxSize,
        ip: req.ip,
        path: req.path
      });

      return res.status(413).json({
        success: false,
        error: {
          code: 'PAYLOAD_TOO_LARGE',
          message: `Request size exceeds limit of ${maxSize} bytes`
        }
      });
    }

    next();
  };
};

// Export cleanup function for graceful shutdown
export const cleanupMiddleware = async (): Promise<void> => {
  await auditService.cleanup();
};


------------------------------------------------------------
FILE: backend\data-service\src\middleware\auth.ts
------------------------------------------------------------
// backend/data-service/src/middleware/auth.ts
import type { NextFunction, Request, Response } from 'express';
import jwt from 'jsonwebtoken';

const IS_PROD = (process.env.NODE_ENV || '').toLowerCase() === 'production';

function devBypass(req: Request): boolean {
  const hdr = (req.get('X-Dev-Auth') || req.get('x-dev-auth') || '').trim();
  const envSkip = (process.env.SKIP_AUTH || '').toLowerCase() === 'true';
  const envMock = (process.env.MOCK_AUTH || '').toLowerCase() === 'true';
  return !IS_PROD && (envSkip || envMock || hdr === '1');
}

function getJwtSecret(): string {
  const s = (process.env.JWT_SECRET || '').trim();
  if (s) return s;
  if (!IS_PROD) return 'devsecret';
  throw new Error('JWT is not configured (missing JWT_SECRET).');
}

function extractToken(req: Request): string | undefined {
  const h = (req.headers.authorization || req.headers.Authorization) as string | undefined;
  if (typeof h === 'string' && h.startsWith('Bearer ')) return h.slice(7).trim();
  const c = req.headers.cookie;
  if (c) {
    const m = c.match(/(?:^|;\s*)access_token=([^;]+)/i);
    if (m) return decodeURIComponent(m[1]);
  }
  return undefined;
}

export function authMiddleware(req: Request, res: Response, next: NextFunction) {
  if (devBypass(req)) return next();
  const token = extractToken(req);
  if (!token) return res.status(401).json({ success: false, error: 'Access denied. No token provided.' });
  try {
    const decoded = jwt.verify(token, getJwtSecret(), { algorithms: ['HS256'] });
    (req as any).user = decoded;
    next();
  } catch {
    return res.status(401).json({ success: false, error: 'Access denied. Invalid or expired token.' });
  }
}

export function optionalAuthMiddleware(req: Request, _res: Response, next: NextFunction) {
  if (devBypass(req)) return next();
  const token = extractToken(req);
  if (!token) return next();
  try {
    const decoded = jwt.verify(token, getJwtSecret(), { algorithms: ['HS256'] });
    (req as any).user = decoded;
  } catch {/* ignore */}
  next();
}



------------------------------------------------------------
FILE: backend\data-service\src\middleware\error.ts
------------------------------------------------------------
// backend/data-service/src/middleware/error.ts
import { NextFunction, Request, Response } from 'express';
import { isProduction } from '../config/env';
import { logger } from '../utils/logger';

export interface ErrorResponse {
  success: false;
  error: {
    code: string;
    message: string;
    details?: any;
    timestamp: string;
    requestId?: string;
  };
}

export class AppError extends Error {
  public statusCode: number;
  public code: string;
  public isOperational: boolean;
  public details?: any;

  constructor(
    message: string,
    statusCode: number = 500,
    code: string = 'INTERNAL_ERROR',
    isOperational: boolean = true,
    details?: any
  ) {
    super(message);
    this.statusCode = statusCode;
    this.code = code;
    this.isOperational = isOperational;
    this.details = details;
    Error.captureStackTrace?.(this, this.constructor);
  }
}

/** Factory used by other middleware/controllers */
export const createError = (
  message: string,
  statusCode: number = 500,
  code: string = 'INTERNAL_ERROR',
  details?: any
): AppError => new AppError(message, statusCode, code, true, details);

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// Common error types
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
export class ValidationError extends AppError {
  constructor(message: string, details?: any) {
    super(message, 400, 'VALIDATION_ERROR', true, details);
  }
}
export class NotFoundError extends AppError {
  constructor(resource: string = 'Resource') {
    super(`${resource} not found`, 404, 'NOT_FOUND', true);
  }
}
export class UnauthorizedError extends AppError {
  constructor(message: string = 'Unauthorized') {
    super(message, 401, 'UNAUTHORIZED', true);
  }
}
export class ForbiddenError extends AppError {
  constructor(message: string = 'Forbidden') {
    super(message, 403, 'FORBIDDEN', true);
  }
}
export class ConflictError extends AppError {
  constructor(message: string = 'Resource already exists') {
    super(message, 409, 'CONFLICT', true);
  }
}
export class DatabaseError extends AppError {
  constructor(message: string, details?: any) {
    super(message, 500, 'DATABASE_ERROR', true, details);
  }
}
export class ExternalServiceError extends AppError {
  constructor(service: string, message: string, details?: any) {
    super(`External service error (${service}): ${message}`, 502, 'EXTERNAL_SERVICE_ERROR', true, details);
  }
}

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// Error handler
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
export const errorHandler = (
  error: Error | AppError,
  req: Request,
  res: Response,
  next: NextFunction
): void => {
  if (res.headersSent) return next(error);

  // Defaults
  let statusCode = 500;
  let code = 'INTERNAL_ERROR';
  let message = 'Internal server error';
  let details: any;

  if (error instanceof AppError) {
    statusCode = error.statusCode;
    code = error.code;
    message = error.message;
    details = error.details;
  } else if (error.name === 'ValidationError') {
    statusCode = 400;
    code = 'VALIDATION_ERROR';
    message = error.message;
  } else if (error.name === 'JsonWebTokenError') {
    statusCode = 401;
    code = 'INVALID_TOKEN';
    message = 'Invalid token';
  } else if (error.name === 'TokenExpiredError') {
    statusCode = 401;
    code = 'TOKEN_EXPIRED';
    message = 'Token expired';
  } else if ((error as any).code === '23505') {
    statusCode = 409;
    code = 'DUPLICATE_ENTRY';
    message = 'Resource already exists';
  } else if ((error as any).code === '23503') {
    statusCode = 400;
    code = 'FOREIGN_KEY_VIOLATION';
    message = 'Referenced resource does not exist';
  } else if ((error as any).code === 'ECONNREFUSED') {
    statusCode = 503;
    code = 'SERVICE_UNAVAILABLE';
    message = 'External service unavailable';
  } else if ((error as any).code === 'ENOTFOUND') {
    statusCode = 503;
    code = 'SERVICE_UNREACHABLE';
    message = 'External service unreachable';
  } else if ((error as any).code === 'ETIMEDOUT') {
    statusCode = 504;
    code = 'SERVICE_TIMEOUT';
    message = 'External service timeout';
  }

  const requestId =
    (req as any).requestId ||
    req.get('X-Request-ID') ||
    `req_${Date.now()}_${Math.random().toString(36).slice(2, 9)}`;

  const logPayload = {
    requestId,
    method: req.method,
    url: req.originalUrl || req.url,
    statusCode,
    code,
    message: (error as any).message,
    stack: (error as any).stack,
    body: req.body,
    params: req.params,
    query: req.query,
    userAgent: req.get('User-Agent'),
    ip: req.ip,
  };

  if (statusCode >= 500) {
    logger.error('Server error:', logPayload);
  } else {
    logger.warn('Client error:', logPayload);
  }

  const payload: ErrorResponse = {
    success: false,
    error: {
      code,
      message,
      timestamp: new Date().toISOString(),
      requestId,
    },
  };

  // Only include details/stack outside production
  if (!isProduction) {
    if (details) payload.error.details = details;
    payload.error.details = {
      ...(payload.error.details || {}),
      stack: (error as any).stack,
    };
  }

  res.status(statusCode).json(payload);
};

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
export const notFoundHandler = (req: Request, res: Response): void => {
  const requestId =
    (req as any).requestId ||
    req.get('X-Request-ID') ||
    `req_${Date.now()}_${Math.random().toString(36).slice(2, 9)}`;

  const payload: ErrorResponse = {
    success: false,
    error: {
      code: 'NOT_FOUND',
      message: `Route ${req.method} ${req.originalUrl} not found`,
      timestamp: new Date().toISOString(),
      requestId,
    },
  };

  logger.warn('Route not found:', {
    method: req.method,
    url: req.originalUrl,
    ip: req.ip,
    userAgent: req.get('User-Agent'),
    requestId,
  });

  res.status(404).json(payload);
};

// Wrap async route handlers
export const asyncHandler = (fn: (...args: any[]) => Promise<any>) => {
  return (req: Request, res: Response, next: NextFunction) => {
    Promise.resolve(fn(req, res, next)).catch(next);
  };
};

// Attach/propagate a request ID for tracing
export const requestIdMiddleware = (req: Request, res: Response, next: NextFunction): void => {
  const requestId = req.get('X-Request-ID') || `req_${Date.now()}_${Math.random().toString(36).slice(2, 9)}`;
  (req as any).requestId = requestId;
  res.set('X-Request-ID', requestId);
  next();
};

export default errorHandler;



------------------------------------------------------------
FILE: backend\data-service\src\middleware\rateLimit.ts
------------------------------------------------------------
import type { RequestHandler } from 'express';
import rateLimit from 'express-rate-limit';
import { logger, loggerUtils } from '../utils/logger';

// helper to coerce the rate-limit handler to Express's RequestHandler
const asExpressHandler = (h: unknown) => h as unknown as RequestHandler;

/** Default rate limiting middleware for general use */
const _defaultRateLimit = rateLimit({
  windowMs: 15 * 60 * 1000,
  max: 1000,
  message: {
    success: false,
    error: 'RATE_LIMIT_EXCEEDED',
    message: 'Too many requests from this IP, please try again later.',
    retryAfter: '15 minutes',
  },
  standardHeaders: true,
  legacyHeaders: false,
  handler: (req: any, res: any) => {
    logger.warn('Default rate limit exceeded', {
      ip: req.ip,
      userAgent: req.get('User-Agent'),
      path: req.path,
    });
    res.status(429).json({
      success: false,
      error: 'RATE_LIMIT_EXCEEDED',
      message: 'Too many requests from this IP, please try again later.',
      retryAfter: res.get('Retry-After'),
      timestamp: new Date().toISOString(),
    });
  },
});
export const defaultRateLimit: RequestHandler = asExpressHandler(_defaultRateLimit);

/** Custom key generator */
const keyGenerator = (req: any): string => {
  const user = req.user;
  return user ? `user:${user.id}` : `ip:${req.ip}`;
};

/** Common response body */
const rateLimitMessage = (req: any, res: any) => {
  const user = req.user;
  loggerUtils.logAuth('rate_limit_exceeded', user?.id, req.ip, req.get('User-Agent'));
  return {
    success: false,
    error: 'RATE_LIMIT_EXCEEDED',
    message: 'Too many requests. Please try again later.',
    retryAfter: res.get('Retry-After'),
    timestamp: new Date().toISOString(),
  };
};

// Skip function (keep any to avoid cross-tree type binding)
const skipSuccessfulRequests = (req: any, res: any): boolean =>
  res.statusCode < 400 && req.path === '/health';

/** General rate limiting middleware */
export const rateLimitMiddleware: RequestHandler = asExpressHandler(
  rateLimit({
    windowMs: 15 * 60 * 1000,
    max: 100,
    standardHeaders: true,
    legacyHeaders: false,
    keyGenerator,
    skip: skipSuccessfulRequests,
    handler: (req: any, res: any) => {
      res.status(429).json(rateLimitMessage(req, res));
    },
  })
);

/** Strict auth limiter */
export const strictRateLimitMiddleware: RequestHandler = asExpressHandler(
  rateLimit({
    windowMs: 15 * 60 * 1000,
    max: 5,
    standardHeaders: true,
    legacyHeaders: false,
    keyGenerator: (req: any) => `auth:${req.ip}`,
    handler: (req: any, res: any) => {
      res.status(429).json(rateLimitMessage(req, res));
    },
  })
);

/** API limiter */
export const apiRateLimitMiddleware: RequestHandler = asExpressHandler(
  rateLimit({
    windowMs: 60 * 1000,
    max: 20,
    standardHeaders: true,
    legacyHeaders: false,
    keyGenerator,
    skip: skipSuccessfulRequests,
    handler: (req: any, res: any) => {
      res.status(429).json(rateLimitMessage(req, res));
    },
  })
);

/** Connection test limiter */
export const connectionTestRateLimitMiddleware: RequestHandler = asExpressHandler(
  rateLimit({
    windowMs: 5 * 60 * 1000,
    max: 10,
    standardHeaders: true,
    legacyHeaders: false,
    keyGenerator,
    handler: (req: any, res: any) => {
      res.status(429).json(rateLimitMessage(req, res));
    },
  })
);

/** Search limiter */
export const searchRateLimitMiddleware: RequestHandler = asExpressHandler(
  rateLimit({
    windowMs: 60 * 1000,
    max: 30,
    standardHeaders: true,
    legacyHeaders: false,
    keyGenerator,
    skip: skipSuccessfulRequests,
    handler: (req: any, res: any) => {
      res.status(429).json(rateLimitMessage(req, res));
    },
  })
);

/** Export limiter */
export const exportRateLimitMiddleware: RequestHandler = asExpressHandler(
  rateLimit({
    windowMs: 60 * 60 * 1000,
    max: 5,
    standardHeaders: true,
    legacyHeaders: false,
    keyGenerator,
    handler: (req: any, res: any) => {
      res.status(429).json(rateLimitMessage(req, res));
    },
  })
);

/** Upload limiter */
export const uploadRateLimitMiddleware: RequestHandler = asExpressHandler(
  rateLimit({
    windowMs: 15 * 60 * 1000,
    max: 10,
    standardHeaders: true,
    legacyHeaders: false,
    keyGenerator,
    handler: (req: any, res: any) => {
      res.status(429).json(rateLimitMessage(req, res));
    },
  })
);

/** Factory */
/** Factory */
export const createRateLimit = (options: {
  windowMs: number;
  max: number;
  message?: string;
  skipSuccessfulRequests?: boolean;

  // NEW: allow callers to customize headers (matches express-rate-limit v6)
  standardHeaders?: boolean;
  legacyHeaders?: boolean;

  // (optional) allow a custom keyGenerator/skip override
  keyGenerator?: (req: any) => string;
  skip?: (req: any, res: any) => boolean;
}): RequestHandler =>
  asExpressHandler(
    rateLimit({
      windowMs: options.windowMs,
      max: options.max,

      // keep your nice JSON body when a custom message is provided
      message: options.message
        ? {
            success: false,
            error: 'RATE_LIMIT_EXCEEDED',
            message: options.message,
            timestamp: new Date().toISOString(),
          }
        : undefined,

      // use provided header prefs, fall back to your defaults
      standardHeaders: options.standardHeaders ?? true,
      legacyHeaders: options.legacyHeaders ?? false,

      // prefer provided keyGenerator/skip, else your defaults
      keyGenerator: options.keyGenerator ?? keyGenerator,
      skip:
        options.skip ??
        (options.skipSuccessfulRequests ? skipSuccessfulRequests : undefined),

      handler: (req: any, res: any) => {
        res.status(429).json(rateLimitMessage(req, res));
      },
    })
  );


export const RATE_LIMITS = {
  GENERAL: { windowMs: 15 * 60 * 1000, max: 100 },
  AUTH: { windowMs: 15 * 60 * 1000, max: 5 },
  API: { windowMs: 1 * 60 * 1000, max: 20 },
  CONNECTION_TEST: { windowMs: 5 * 60 * 1000, max: 10 },
  SEARCH: { windowMs: 1 * 60 * 1000, max: 30 },
  EXPORT: { windowMs: 60 * 60 * 1000, max: 5 },
  UPLOAD: { windowMs: 15 * 60 * 1000, max: 10 },
} as const;



------------------------------------------------------------
FILE: backend\data-service\src\middleware\validation.ts
------------------------------------------------------------
// src/middleware/validation.ts - Data source validation rules
import { NextFunction, Request, Response } from 'express';
import { body, param, query, validationResult } from 'express-validator';

/**
 * Validate request and return errors if any
 */
export const validateRequest = (req: Request, res: Response, next: NextFunction) => {
  const errors = validationResult(req);
  
  if (!errors.isEmpty()) {
    const errorMessage = formatValidationError(errors.array());
    return res.status(400).json({
      success: false,
      error: 'VALIDATION_ERROR',
      message: errorMessage,
      details: errors.array(),
      timestamp: new Date().toISOString(),
    });
  }
  
  next();
};

/**
 * Validation error formatter
 */
export const formatValidationError = (errors: any[]): string => {
  return errors.map(error => {
    if (error.type === 'field') {
      return `${error.path}: ${error.msg}`;
    }
    return error.msg;
  }).join(', ');
};

/**
 * Data source validation rules
 */
export const validateDataSource = [
  body('name')
    .trim()
    .isLength({ min: 1, max: 100 })
    .withMessage('Name must be between 1 and 100 characters'),
  
  body('type')
    .isIn(['postgres', 'mysql', 'sqlserver', 'mongodb', 's3', 'api', 'file'])
    .withMessage('Invalid data source type'),
  
  body('host')
    .optional()
    .isLength({ min: 1, max: 255 })
    .withMessage('Host must be between 1 and 255 characters'),
  
  body('port')
    .optional()
    .isInt({ min: 1, max: 65535 })
    .withMessage('Port must be between 1 and 65535'),
  
  body('database')
    .optional()
    .isLength({ min: 1, max: 100 })
    .withMessage('Database name must be between 1 and 100 characters'),
  
  body('username')
    .optional()
    .isLength({ min: 1, max: 100 })
    .withMessage('Username must be between 1 and 100 characters'),
  
  body('password')
    .optional()
    .isLength({ min: 1, max: 255 })
    .withMessage('Password must be between 1 and 255 characters'),
  
  body('ssl')
    .optional()
    .isBoolean()
    .withMessage('SSL must be a boolean value'),
  
  body('description')
    .optional()
    .isLength({ max: 500 })
    .withMessage('Description must be less than 500 characters'),
  
  body('tags')
    .optional()
    .isArray()
    .withMessage('Tags must be an array'),
  
  body('tags.*')
    .optional()
    .isString()
    .trim()
    .isLength({ min: 1, max: 50 })
    .withMessage('Each tag must be between 1 and 50 characters'),

  validateRequest
];

/**
 * Data source update validation rules
 */
export const validateDataSourceUpdate = [
  param('id')
    .isUUID()
    .withMessage('Invalid data source ID'),
  
  body('name')
    .optional()
    .trim()
    .isLength({ min: 1, max: 100 })
    .withMessage('Name must be between 1 and 100 characters'),
  
  body('host')
    .optional()
    .isLength({ min: 1, max: 255 })
    .withMessage('Host must be between 1 and 255 characters'),
  
  body('port')
    .optional()
    .isInt({ min: 1, max: 65535 })
    .withMessage('Port must be between 1 and 65535'),
  
  body('database')
    .optional()
    .isLength({ min: 1, max: 100 })
    .withMessage('Database name must be between 1 and 100 characters'),
  
  body('username')
    .optional()
    .isLength({ min: 1, max: 100 })
    .withMessage('Username must be between 1 and 100 characters'),
  
  body('password')
    .optional()
    .isLength({ min: 1, max: 255 })
    .withMessage('Password must be between 1 and 255 characters'),
  
  body('ssl')
    .optional()
    .isBoolean()
    .withMessage('SSL must be a boolean value'),
  
  body('description')
    .optional()
    .isLength({ max: 500 })
    .withMessage('Description must be less than 500 characters'),
  
  body('tags')
    .optional()
    .isArray()
    .withMessage('Tags must be an array'),

  validateRequest
];

/**
 * Asset validation rules
 */
export const validateAsset = [
  body('name')
    .trim()
    .isLength({ min: 1, max: 100 })
    .withMessage('Name must be between 1 and 100 characters'),
  
  body('type')
    .isIn(['table', 'view', 'procedure', 'function', 'schema'])
    .withMessage('Invalid asset type'),
  
  body('dataSourceId')
    .isUUID()
    .withMessage('Invalid data source ID'),
  
  body('schemaName')
    .optional()
    .isLength({ min: 1, max: 100 })
    .withMessage('Schema name must be between 1 and 100 characters'),
  
  body('tableName')
    .optional()
    .isLength({ min: 1, max: 100 })
    .withMessage('Table name must be between 1 and 100 characters'),
  
  body('description')
    .optional()
    .isLength({ max: 500 })
    .withMessage('Description must be less than 500 characters'),
  
  body('tags')
    .optional()
    .isArray()
    .withMessage('Tags must be an array'),
  
  body('status')
    .optional()
    .isIn(['active', 'inactive', 'deprecated'])
    .withMessage('Invalid status'),

  validateRequest
];

/**
 * ID parameter validation
 */
export const validateId = [
  param('id')
    .isUUID()
    .withMessage('Invalid ID format'),
  
  validateRequest
];

/**
 * Pagination validation
 */
export const validatePagination = [
  query('page')
    .optional()
    .isInt({ min: 1 })
    .withMessage('Page must be a positive integer'),
  
  query('limit')
    .optional()
    .isInt({ min: 1, max: 100 })
    .withMessage('Limit must be between 1 and 100'),
  
  query('search')
    .optional()
    .isString()
    .trim()
    .isLength({ max: 100 })
    .withMessage('Search term must be less than 100 characters'),

  validateRequest
];

/**
 * Connection test validation
 */
export const validateConnectionTest = [
  body('type')
    .isIn(['postgres', 'mysql', 'sqlserver', 'mongodb', 's3', 'api'])
    .withMessage('Invalid connection type'),
  
  body('host')
    .isLength({ min: 1, max: 255 })
    .withMessage('Host is required and must be less than 255 characters'),
  
  body('port')
    .isInt({ min: 1, max: 65535 })
    .withMessage('Port must be between 1 and 65535'),
  
  body('database')
    .optional()
    .isLength({ min: 1, max: 100 })
    .withMessage('Database name must be between 1 and 100 characters'),
  
  body('username')
    .isLength({ min: 1, max: 100 })
    .withMessage('Username is required and must be less than 100 characters'),
  
  body('password')
    .isLength({ min: 1, max: 255 })
    .withMessage('Password is required and must be less than 255 characters'),

  validateRequest
];

/**
 * Tags validation
 */
export const validateTags = [
  body('tags')
    .isArray({ min: 1 })
    .withMessage('Tags must be a non-empty array'),
  
  body('tags.*')
    .isString()
    .trim()
    .isLength({ min: 1, max: 50 })
    .withMessage('Each tag must be between 1 and 50 characters'),

  validateRequest
];


------------------------------------------------------------
FILE: backend\data-service\src\models\Connection.ts
------------------------------------------------------------
// backend/data-service/src/models/Connection.ts
// Back-compat shim: re-export the canonical connection types from DataSource.
// This prevents drift between modules and ensures 'mssql' etc. exist here too.

export type {
  APIConnection, AzureBlobConnection, BigQueryConnection, ConnectionConfig, ConnectionTestResult, DatabricksConnection, ElasticsearchConnection, FileConnection, GCSConnection, KafkaConnection, MongoDBConnection, MSSQLConnection, MySQLConnection, OracleConnection, PostgreSQLConnection, RedisConnection, RedshiftConnection, S3Connection, SnowflakeConnection
} from './DataSource';




------------------------------------------------------------
FILE: backend\data-service\src\models\ConnectionRuntime.ts
------------------------------------------------------------
// backend/data-service/src/models/ConnectionRuntime.ts

export interface ConnectionPool {
  id: string;
  dataSourceId: string;
  poolSize: number;
  activeConnections: number;
  idleConnections: number;
  waitingConnections: number;
  createdAt: Date;
  lastUsedAt: Date;
}

export interface ConnectionMetrics {
  dataSourceId: string;
  totalConnections: number;
  successfulConnections: number;
  failedConnections: number;
  averageResponseTime: number;
  lastConnectionAt?: Date;
  lastFailureAt?: Date;
  lastErrorMessage?: string;
  uptime: number;       // percentage
  availability: number; // percentage
}

export interface ConnectionHistory {
  id: string;
  dataSourceId: string;
  connectionStatus: 'success' | 'failed' | 'timeout' | 'refused';
  responseTime?: number; // ms
  errorCode?: string;
  errorMessage?: string;
  connectionDetails?: {
    host?: string;
    port?: number;
    database?: string;
    serverVersion?: string;
    serverInfo?: Record<string, any>;
  };
  testedAt: Date;
  testedBy?: string;
  testType: 'manual' | 'scheduled' | 'health_check' | 'startup';
}

export interface ConnectionCredentials {
  username?: string;
  password?: string;
  apiKey?: string;
  secretKey?: string;
  accessToken?: string;
  refreshToken?: string;
  tokenType?: string;
  certificate?: string;
  privateKey?: string;
  passphrase?: string;
  accessKeyId?: string;
  secretAccessKey?: string;
  serviceAccountKey?: string;
  authMethod?: 'basic' | 'bearer' | 'oauth2' | 'certificate' | 'api-key' | 'iam';
  authUrl?: string;
  tokenUrl?: string;
  scope?: string[];
}

export interface RuntimeConnectionSecurity {
  ssl: boolean;
  sslMode?: 'disable' | 'allow' | 'prefer' | 'require' | 'verify-ca' | 'verify-full';
  sslCert?: string;
  sslKey?: string;
  sslRootCert?: string;
  verifyCertificate: boolean;
  allowSelfSigned: boolean;
  encryption?: 'none' | 'tls' | 'ssl';
  tlsVersion?: string;
}

export interface RuntimeConnectionOptions {
  connectionTimeout: number; // ms
  queryTimeout: number;      // ms
  idleTimeout: number;       // ms
  minConnections: number;
  maxConnections: number;
  acquireTimeout: number;    // ms
  retryAttempts: number;
  retryDelay: number;        // ms
  exponentialBackoff: boolean;
  keepAlive: boolean;
  keepAliveInterval?: number; // ms
  charset?: string;
  timezone?: string;
  applicationName?: string;
  customOptions: Record<string, any>;
}

export interface ConnectionTest {
  id: string;
  dataSourceId: string;
  testType: 'basic' | 'advanced' | 'schema' | 'performance';
  status: 'pending' | 'running' | 'completed' | 'failed';
  testQueries?: string[];
  expectedResults?: any[];
  performanceThresholds?: {
    maxResponseTime: number;
    minThroughput: number;
  };
  results?: {
    connectionSuccessful: boolean;
    responseTime: number;
    queryResults?: any[];
    performanceMetrics?: {
      throughput: number;
      latency: number;
      errorRate: number;
    };
    schemaInfo?: {
      databases?: string[];
      tables?: string[];
      columns?: string[];
    };
  };
  startedAt: Date;
  completedAt?: Date;
  duration?: number; // ms
  errorMessage?: string;
  testedBy: string;
}

export interface ConnectionFactory {
  createConnection(dataSourceId: string): Promise<any>;
  testConnection(dataSourceId: string): Promise<ConnectionTest>;
  closeConnection(dataSourceId: string): Promise<void>;
  getConnectionMetrics(dataSourceId: string): Promise<ConnectionMetrics>;
}

export const defaultConnectionOptions: RuntimeConnectionOptions = {
  connectionTimeout: 30000,
  queryTimeout: 60000,
  idleTimeout: 300000,
  minConnections: 1,
  maxConnections: 10,
  acquireTimeout: 30000,
  retryAttempts: 3,
  retryDelay: 1000,
  exponentialBackoff: true,
  keepAlive: true,
  keepAliveInterval: 30000,
  customOptions: {},
};

// helper (only for telemetry layer â€” separate from canonical config)
export function getDefaultPort(type: string): number {
  const ports: Record<string, number> = {
    postgresql: 5432,
    mysql: 3306,
    mssql: 1433,
    oracle: 1521,
    mongodb: 27017,
    redis: 6379,
    elasticsearch: 9200,
    cassandra: 9042,
    clickhouse: 8123,
  };
  return ports[type] || 0;
}



------------------------------------------------------------
FILE: backend\data-service\src\models\DataSource.ts
------------------------------------------------------------
/* ===========================================================================
 * DataSource models & helpers (canonical, production-ready)
 * =========================================================================== */

export type DataSourceType =
  | 'postgresql'
  | 'mysql'
  | 'mssql'
  | 'oracle'
  | 'mongodb'
  | 'redis'
  | 's3'
  | 'azure-blob'
  | 'gcs'
  | 'snowflake'
  | 'bigquery'
  | 'redshift'
  | 'databricks'
  | 'api'
  | 'file'
  | 'kafka'
  | 'elasticsearch';

export type DataSourceStatus =
  | 'pending'
  | 'connected'
  | 'disconnected'
  | 'error'
  | 'warning'
  | 'syncing'
  | 'testing'
  // back-compat / ops-friendly synonyms
  | 'active'
  | 'inactive';

/* ---------------------------------------------------------------------------
 * TLS / SSL
 * --------------------------------------------------------------------------- */
export interface ConnectionSecurity {
  enabled?: boolean;
  rejectUnauthorized?: boolean;
  ca?: string;
  cert?: string;
  key?: string;
  mode?: 'disable' | 'allow' | 'prefer' | 'require' | 'verify-ca' | 'verify-full';
}

/* ---------------------------------------------------------------------------
 * Shared base for all connectors
 * --------------------------------------------------------------------------- */
export interface CommonConnectionFields {
  host?: string;
  port?: number;
  database?: string | number;
  username?: string;
  password?: string;
  schema?: string;
  connectionString?: string;
  ssl?: boolean | ConnectionSecurity;

  timeout?: number;
  maxConnections?: number;
  retryAttempts?: number;
}

/* ---------------------------------------------------------------------------
 * Per-connector configs (discriminated by `type`)
 * --------------------------------------------------------------------------- */
// Relational
export interface PostgreSQLConnection extends CommonConnectionFields { type: 'postgresql' }
export interface MySQLConnection     extends CommonConnectionFields { type: 'mysql' }
export interface MSSQLConnection     extends CommonConnectionFields { type: 'mssql' }
export interface OracleConnection    extends CommonConnectionFields { type: 'oracle' }
export interface RedshiftConnection  extends CommonConnectionFields { type: 'redshift' }
export interface DatabricksConnection extends CommonConnectionFields {
  type: 'databricks';
  httpPath?: string;
  token?: string;
}

// Doc/KV
export interface MongoDBConnection extends CommonConnectionFields { type: 'mongodb' }
export interface RedisConnection extends CommonConnectionFields {
  type: 'redis';
  cluster?: boolean;
  nodes?: Array<{ host: string; port: number }>;
}

// Object storage
export interface S3Connection extends CommonConnectionFields {
  type: 's3';
  bucket?: string;
  region?: string;
  accessKeyId?: string;
  secretAccessKey?: string;
  prefix?: string;
}
export interface AzureBlobConnection extends CommonConnectionFields {
  type: 'azure-blob';
  container?: string;
  accountName?: string;
  accountKey?: string;
  connectionString?: string; // Azure style
  prefix?: string;
}
export interface GCSConnection extends CommonConnectionFields {
  type: 'gcs';
  bucket?: string;
  serviceAccountKey?: string; // JSON
  prefix?: string;
}

// SaaS DW / Analytics
export interface SnowflakeConnection extends CommonConnectionFields {
  type: 'snowflake';
  warehouse?: string;
  role?: string;
}
export interface BigQueryConnection extends CommonConnectionFields {
  type: 'bigquery';
  projectId?: string;
  dataset?: string;
  location?: string;
  serviceAccountKey?: string; // JSON
}

// REST / File / Streaming / Search
export interface APIConnection extends CommonConnectionFields {
  type: 'api';
  baseUrl?: string;
  apiKey?: string;
  headers?: Record<string, string>;
  authentication?: {
    type: 'basic' | 'bearer' | 'oauth2' | 'api-key';
    credentials: Record<string, string>;
  };
}
export interface FileConnection extends CommonConnectionFields {
  type: 'file';
  path?: string;
  format?: 'csv' | 'json' | 'parquet' | 'avro' | 'xml';
}
export interface KafkaConnection extends CommonConnectionFields {
  type: 'kafka';
  brokers?: string[];  // host:port
  topics?: string[];
  consumerGroup?: string;
  sasl?: {
    mechanism: 'plain' | 'scram-sha-256' | 'scram-sha-512';
    username: string;
    password: string;
  };
  ssl?: boolean | ConnectionSecurity;
}
export interface ElasticsearchConnection extends CommonConnectionFields { type: 'elasticsearch' }

/* ---------------------------------------------------------------------------
 * Canonical union
 * --------------------------------------------------------------------------- */
export type ConnectionConfig =
  | PostgreSQLConnection
  | MySQLConnection
  | MSSQLConnection
  | OracleConnection
  | MongoDBConnection
  | RedisConnection
  | S3Connection
  | AzureBlobConnection
  | GCSConnection
  | SnowflakeConnection
  | BigQueryConnection
  | RedshiftConnection
  | DatabricksConnection
  | APIConnection
  | FileConnection
  | KafkaConnection
  | ElasticsearchConnection;

/* ---------------------------------------------------------------------------
 * Filters & pagination
 * --------------------------------------------------------------------------- */
export interface DataSourceFilters {
  status?: DataSourceStatus;
  type?: DataSourceType;
  search?: string;
  tags?: string[];
  createdBy?: string;              // â† added (fixes controller/service usage)
}

export type SortBy = 'updatedAt' | 'createdAt' | 'name' | 'status' | 'type';
export interface ListOptions {
  page?: number;
  limit?: number;
  filters?: DataSourceFilters;
  sortBy?: SortBy;
  sortOrder?: 'asc' | 'desc';
}

export interface ListOptions {
  page?: number;
  limit?: number;
  filters?: DataSourceFilters;
  sortBy?: 'createdAt' | 'updatedAt' | 'name' | 'type' | 'status';  // â† added
  sortOrder?: 'asc' | 'desc';                                        // â† added
}

/* ---------------------------------------------------------------------------
 * DataSource record
 * --------------------------------------------------------------------------- */
export interface DataSourceMetadata {
  version?: string;
  driver?: string;
  encoding?: string;
  timezone?: string;
  tableCount?: number;
  estimatedSize?: string;
  lastSchemaUpdate?: Date;
  customFields?: Record<string, any>;
}

export interface DataSource {
  id: string; // UUID string
  name: string;
  description?: string;
  type: DataSourceType;
  status: DataSourceStatus;
  connectionConfig: ConnectionConfig;
  tags: string[];
  metadata: DataSourceMetadata;

  createdAt: Date;
  updatedAt: Date;
  createdBy: string;
  updatedBy?: string;
  deletedAt?: Date;

  lastTestAt?: Date;
  lastSyncAt?: Date;
  lastError?: string;

  publicId?: string | null;

  // optional live metrics
  responseTime?: number;
  availability?: number;

  // sync & ingestion scheduling
  syncEnabled?: boolean;
  syncSchedule?: string; // cron
  syncOptions?: {
    fullSync?: boolean;
    incrementalField?: string;
    batchSize?: number;
  };
}

/* ---------------------------------------------------------------------------
 * PostgreSQL DDL (idempotent)
 * --------------------------------------------------------------------------- */
export const createDataSourcesTable = `
  CREATE TABLE IF NOT EXISTS data_sources (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    name VARCHAR(255) NOT NULL,
    description TEXT,
    type VARCHAR(50) NOT NULL,
    status VARCHAR(20) NOT NULL DEFAULT 'pending',
    connection_config JSONB NOT NULL,
    tags TEXT[] DEFAULT '{}',               -- TEXT[] (not JSONB)
    metadata JSONB DEFAULT '{}',

    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    created_by VARCHAR(255),
    updated_by VARCHAR(255),
    deleted_at TIMESTAMPTZ,

    last_test_at TIMESTAMPTZ,
    last_tested_at TIMESTAMPTZ,             -- legacy tolerated (COALESCE)
    last_sync_at TIMESTAMPTZ,
    last_error TEXT,

    public_id VARCHAR(100),

    response_time INTEGER,
    availability DECIMAL(5,2),

    sync_enabled BOOLEAN DEFAULT false,
    sync_schedule VARCHAR(255),
    sync_options JSONB DEFAULT '{}'
  );

  CREATE INDEX IF NOT EXISTS idx_ds_type ON data_sources(type);
  CREATE INDEX IF NOT EXISTS idx_ds_status ON data_sources(status);
  CREATE INDEX IF NOT EXISTS idx_ds_created_by ON data_sources(created_by);
  CREATE INDEX IF NOT EXISTS idx_ds_deleted_at ON data_sources(deleted_at);
  CREATE INDEX IF NOT EXISTS idx_ds_last_sync ON data_sources(last_sync_at);
  CREATE INDEX IF NOT EXISTS idx_ds_updated_at ON data_sources(updated_at);

  DO $$
  BEGIN
    IF NOT EXISTS (
      SELECT 1 FROM pg_indexes
      WHERE schemaname = 'public' AND indexname = 'uq_data_sources_public_id'
    ) THEN
      CREATE UNIQUE INDEX uq_data_sources_public_id
        ON data_sources((public_id)) WHERE public_id IS NOT NULL;
    END IF;
  END $$;
`;

/* ---------------------------------------------------------------------------
 * Result & stats
 * --------------------------------------------------------------------------- */
export interface ConnectionTestResult {
  success: boolean;
  responseTime?: number;
  error?: string;
  details?: {
    version?: string;
    serverInfo?: Record<string, any>;
    capabilities?: string[];
  };
  testedAt: Date;
}

export interface DataSourceStats {
  dataSourceId: string;
  totalTables: number;
  totalColumns: number;
  totalRows: number;
  estimatedSize: string;
  lastUpdated: Date;
  tableStats: TableStats[];
}
export interface TableStats {
  name: string;
  schema?: string;
  rowCount: number;
  columnCount: number;
  sizeBytes: number;
  lastModified?: Date;
}

/* ---------------------------------------------------------------------------
 * Helpers
 * --------------------------------------------------------------------------- */
export function validateDataSourceType(s: string): s is DataSourceType {
  const all: readonly DataSourceType[] = [
    'postgresql','mysql','mssql','oracle','mongodb','redis',
    's3','azure-blob','gcs','snowflake','bigquery','redshift',
    'databricks','api','file','kafka','elasticsearch',
  ];
  return (all as readonly string[]).includes(s);
}

export function validateDataSourceStatus(s: string): s is DataSourceStatus {
  const all: readonly DataSourceStatus[] = [
    'pending','connected','disconnected','error','warning','syncing','testing','active','inactive',
  ];
  return (all as readonly string[]).includes(s);
}

/** Map common aliases to canonical types */
export function normalizeDataSourceType(t: string): DataSourceType {
  const x = (t || '').toLowerCase();
  if (x === 'azure_sql' || x === 'azure-sql' || x === 'sqlserver' || x === 'sql-server') return 'mssql';
  return validateDataSourceType(x) ? (x as DataSourceType) : (x as DataSourceType);
}

export function getDefaultPort(type: DataSourceType): number | undefined {
  switch (type) {
    case 'postgresql': return 5432;
    case 'mysql': return 3306;
    case 'mssql': return 1433;
    case 'oracle': return 1521;
    case 'mongodb': return 27017;
    case 'redis': return 6379;
    case 'elasticsearch': return 9200;
    default: return undefined;
  }
}

/** Strong validation per connector (narrow, then read special props). */
export function validateConnectionConfig(type: DataSourceType, cfg: Partial<ConnectionConfig>): string[] {
  const errors: string[] = [];
  const t = normalizeDataSourceType(type);
  const need = (ok: boolean, msg: string) => { if (!ok) errors.push(msg); };

  switch (t) {
    case 'postgresql':
    case 'mysql':
    case 'mssql':
    case 'oracle':
    case 'redshift':
    case 'databricks': {
      need(!!(cfg.connectionString || cfg.host), 'Host or connection string is required');
      need(!!(cfg.connectionString || (cfg as any).database), 'Database is required');
      break;
    }

    case 'mongodb': {
      need(!!(cfg.connectionString || cfg.host), 'Host or connection string is required');
      break;
    }

    case 'redis': {
      const rc = cfg as any;
      if (!rc.cluster) {
        need(!!(rc.host || rc.connectionString), 'Host or connection string is required');
      } else {
        need(Array.isArray(rc.nodes) && rc.nodes.length > 0, 'At least one cluster node is required');
      }
      break;
    }

    case 's3': {
      const sc = cfg as any;
      need(!!sc.bucket, 'Bucket is required');
      need(!!sc.region, 'Region is required');
      break;
    }

    case 'azure-blob': {
      const ac = cfg as any;
      need(!!ac.container, 'Container is required');
      break;
    }

    case 'gcs': {
      const gc = cfg as any;
      need(!!gc.bucket, 'Bucket is required');
      break;
    }

    case 'snowflake': {
      const sn = cfg as any;
      need(!!sn.host, 'Account URL/host is required');
      need(!!sn.username, 'Username is required');
      need(!!sn.database, 'Database is required');
      break;
    }

    case 'bigquery': {
      const bq = cfg as any;
      need(!!bq.serviceAccountKey, 'Service account key is required');
      break;
    }

    case 'api': {
      const api = cfg as any;
      need(!!api.baseUrl, 'Base URL is required');
      if (api.baseUrl) {
        try { new URL(api.baseUrl); } catch { errors.push('Base URL must be a valid URL'); }
      }
      break;
    }

    case 'file': {
      const fc = cfg as any;
      need(!!fc.path, 'File path is required');
      break;
    }

    case 'kafka': {
      const kc = cfg as any;
      need(Array.isArray(kc.brokers) && kc.brokers.length > 0, 'At least one broker is required');
      break;
    }

    case 'elasticsearch': {
      need(!!(cfg.host || cfg.connectionString), 'Host or connection string is required');
      break;
    }
  }

  if (cfg.port !== undefined && (cfg.port < 1 || cfg.port > 65535)) {
    errors.push('Port must be between 1 and 65535');
  }
  return errors;
}

/* ---------------------------------------------------------------------------
 * UI helpers
 * --------------------------------------------------------------------------- */
export function getDataSourceDisplayName(type: DataSourceType): string {
  const t = normalizeDataSourceType(type);
  const display: Record<DataSourceType, string> = {
    postgresql: 'PostgreSQL',
    mysql: 'MySQL',
    mssql: 'SQL Server',
    oracle: 'Oracle',
    mongodb: 'MongoDB',
    redis: 'Redis',
    s3: 'Amazon S3',
    'azure-blob': 'Azure Blob Storage',
    gcs: 'Google Cloud Storage',
    snowflake: 'Snowflake',
    bigquery: 'Google BigQuery',
    redshift: 'Amazon Redshift',
    databricks: 'Databricks',
    api: 'REST API',
    file: 'File System',
    kafka: 'Apache Kafka',
    elasticsearch: 'Elasticsearch',
  };
  return display[t] || t;
}

export function getDataSourceIcon(type: DataSourceType): string {
  const t = normalizeDataSourceType(type);
  const icons: Record<DataSourceType, string> = {
    postgresql: 'ðŸ˜',
    mysql: 'ðŸ¬',
    mssql: 'ðŸ¢',
    oracle: 'ðŸ›ï¸',
    mongodb: 'ðŸƒ',
    redis: 'ðŸ“¦',
    s3: 'â˜ï¸',
    'azure-blob': 'â˜ï¸',
    gcs: 'â˜ï¸',
    snowflake: 'â„ï¸',
    bigquery: 'ðŸ“Š',
    redshift: 'ðŸ“Š',
    databricks: 'ðŸ§±',
    api: 'ðŸ”Œ',
    file: 'ðŸ“',
    kafka: 'ðŸš€',
    elasticsearch: 'ðŸ”',
  };
  return icons[t] || 'ðŸ’¾';
}

export function getStatusColor(status: DataSourceStatus): string {
  const colors: Record<DataSourceStatus, string> = {
    pending: '#fbbf24',
    connected: '#10b981',
    disconnected: '#6b7280',
    error: '#ef4444',
    warning: '#f59e0b',
    syncing: '#3b82f6',
    testing: '#8b5cf6',
    active: '#10b981',    // synonym of connected
    inactive: '#6b7280',  // synonym of disconnected
  };
  return colors[status];
}

/* ---------------------------------------------------------------------------
 * Safe creation template for UI flows
 * --------------------------------------------------------------------------- */
export type NewDataSourceTemplate =
  Partial<Omit<DataSource, 'connectionConfig'>> & {
    connectionConfig: Partial<ConnectionConfig>;
  };

export function createDataSourceTemplate(kind: DataSourceType): NewDataSourceTemplate {
  const t = normalizeDataSourceType(kind);
  return {
    type: t,
    status: 'pending',
    tags: [],
    metadata: {},
    connectionConfig: {
      port: getDefaultPort(t),
      timeout: 30_000,
      maxConnections: 10,
      retryAttempts: 3,
    },
    syncEnabled: false,
    syncOptions: {
      fullSync: true,
      batchSize: 1000,
    },
  };
}

/* ---------------------------------------------------------------------------
 * Type guards
 * --------------------------------------------------------------------------- */
export const isAPIConfig = (c: Partial<ConnectionConfig>): c is APIConnection =>
  (c as APIConnection).type === 'api' || typeof (c as APIConnection).baseUrl === 'string';

export const isS3Config = (c: Partial<ConnectionConfig>): c is S3Connection =>
  (c as S3Connection).type === 's3' || !!(c as S3Connection).accessKeyId || !!(c as S3Connection).secretAccessKey;

export const isSnowflakeConfig = (c: Partial<ConnectionConfig>): c is SnowflakeConnection =>
  (c as SnowflakeConnection).type === 'snowflake';

export const isBigQueryConfig = (c: Partial<ConnectionConfig>): c is BigQueryConnection =>
  (c as BigQueryConnection).type === 'bigquery' || typeof (c as BigQueryConnection).serviceAccountKey === 'string';

/* ---------------------------------------------------------------------------
 * Back-compat type aliases (old names used elsewhere)
 * --------------------------------------------------------------------------- */
export type APIConfig        = APIConnection;
export type BigQueryConfig   = BigQueryConnection;
export type S3Config         = S3Connection;
export type SnowflakeConfig  = SnowflakeConnection;
// For places that refer to "AzureSQLConnection", use MSSQL config
export type AzureSQLConnection = MSSQLConnection;



------------------------------------------------------------
FILE: backend\data-service\src\queue\index.ts
------------------------------------------------------------
// backend/data-service/src/queue/index.ts
/* eslint-disable @typescript-eslint/no-explicit-any */
/**
 * Production-safe queue bootstrap:
 * - If bullmq/ioredis are available and REDIS_URL is set, use a real Queue
 * - Otherwise export a NOOP queue so the app still boots (no crash loops)
 */

export type QueueLike = {
  add: (name: string, data?: any, opts?: any) => Promise<any>;
  isMock?: boolean;
};

export let queueEnabled = false;
export let queueStatus: "ready" | "disabled" | "error" = "disabled";

function makeNoopQueue(label: string): QueueLike {
  queueEnabled = false;
  queueStatus = "disabled";
  // Returns a shape compatible with bullmq's .add()
  return {
    isMock: true,
    async add(name: string, data?: any) {
      // Log once per process to avoid spam
      if (!("QUEUE_NOOP_LOGGED" in (global as any))) {
        // eslint-disable-next-line no-console
        console.warn(
          `[queue:${label}] bullmq disabled (missing deps or REDIS_URL). Using NOOP queue.`
        );
        (global as any).QUEUE_NOOP_LOGGED = true;
      }
      return { id: `mock_${Date.now()}`, name, data, mocked: true };
    },
  };
}

function makeQueue(): QueueLike {
  try {
    // Use require() to avoid ESM import pitfalls in TS during runtime
    // eslint-disable-next-line @typescript-eslint/no-var-requires
    const { Queue } = require("bullmq");
    // eslint-disable-next-line @typescript-eslint/no-var-requires
    const IORedis = require("ioredis");

    const redisUrl =
      process.env.REDIS_URL ||
      process.env.BULL_REDIS_URL ||
      "redis://redis:6379";

    if (!redisUrl) {
      return makeNoopQueue("catalog-profile");
    }

    const connection = new IORedis(redisUrl, {
      maxRetriesPerRequest: null,
      enableReadyCheck: true,
    });

    const q = new Queue("catalog-profile", {
      connection,
      defaultJobOptions: {
        attempts: 3,
        backoff: { type: "exponential", delay: 1500 },
        removeOnComplete: 200,
        removeOnFail: 200,
      },
    });

    queueEnabled = true;
    queueStatus = "ready";
    return q as QueueLike;
  } catch (e: any) {
    // Missing bullmq or ioredis, or other init error â†’ NOOP
    // eslint-disable-next-line no-console
    console.warn(`[queue] disabled: ${e?.message || String(e)}`);
    return makeNoopQueue("catalog-profile");
  }
}

export const ProfileQueue: QueueLike = makeQueue();



------------------------------------------------------------
FILE: backend\data-service\src\repositories\dataSourcesRepo.ts
------------------------------------------------------------
// backend/data-service/src/repositories/dataSourcesRepo.ts
import { pool } from "../db/pool";

export type SortBy =
  | "name"
  | "type"
  | "status"
  | "createdAt"
  | "updatedAt"
  | "lastSyncAt"
  | "lastTestAt";

const SORT_MAP: Record<SortBy, string> = {
  name: "name",
  type: "type",
  status: "status",
  createdAt: "created_at",
  updatedAt: "updated_at",
  lastSyncAt: "last_sync_at",
  lastTestAt: "last_test_at",
};

export async function listDataSources(opts: {
  page?: number;
  limit?: number;
  sortBy?: SortBy;
  sortOrder?: "asc" | "desc";
}) {
  const page = Math.max(1, Number(opts.page ?? 1));
  const limit = Math.min(100, Math.max(1, Number(opts.limit ?? 20)));
  const offset = (page - 1) * limit;

  const sortBy = (opts.sortBy ?? "updatedAt") as SortBy;
  const sortCol = SORT_MAP[sortBy] ?? "updated_at";
  const sortOrder = (opts.sortOrder ?? "desc").toLowerCase() === "asc" ? "asc" : "desc";

  const client = await pool.connect();
  try {
    const countSql = `SELECT COUNT(*)::int AS total FROM data_sources WHERE deleted_at IS NULL`;
    const countRes = await client.query<{ total: number }>(countSql);
    const total = countRes.rows[0]?.total ?? 0;

    const sql = `
      SELECT
        id,
        name,
        description,
        type,
        status,
        connection_config           AS "connectionConfig",
        tags,
        metadata,
        created_at                  AS "createdAt",
        updated_at                  AS "updatedAt",
        created_by                  AS "createdBy",
        updated_by                  AS "updatedBy",
        deleted_at                  AS "deletedAt",
        last_test_at                AS "lastTestAt",
        last_sync_at                AS "lastSyncAt",
        last_error                  AS "lastError",
        response_time               AS "responseTime",
        availability,
        sync_enabled                AS "syncEnabled",
        sync_schedule               AS "syncSchedule",
        sync_options                AS "syncOptions"
      FROM data_sources
      WHERE deleted_at IS NULL
      ORDER BY ${sortCol} ${sortOrder}
      LIMIT $1 OFFSET $2
    `;
    const res = await client.query(sql, [limit, offset]);

    return {
      success: true as const,
      data: res.rows,
      page,
      limit,
      total,
      totalPages: Math.ceil(total / limit),
      sortBy,
      sortOrder,
    };
  } finally {
    client.release();
  }
}



------------------------------------------------------------
FILE: backend\data-service\src\routes\assets.ts
------------------------------------------------------------
// backend/data-service/src/routes/assets.ts
import { Router, type RequestHandler } from 'express';
import { body, param, query } from 'express-validator';
import { AssetController } from '../controllers/AssetController';
import { authMiddleware } from '../middleware/auth';
import { asyncHandler } from '../middleware/error';
import { createRateLimit } from '../middleware/rateLimit';
import { validateRequest } from '../middleware/validation';

const router = Router();
const assetController = new AssetController();

// Apply authentication to all routes
router.use(authMiddleware as unknown as RequestHandler);

// Validation schemas
const createAssetValidation = [
  body('name').isString().isLength({ min: 1, max: 255 }).withMessage('Name must be between 1 and 255 characters'),
  body('type')
    .isIn(['table', 'view', 'file', 'api_endpoint', 'stream', 'model'])
    .withMessage('Invalid asset type'),
  body('dataSourceId').isString().withMessage('Data source ID is required'),
  body('path').isString().withMessage('Asset path is required'),
  body('description').optional().isString().isLength({ max: 1000 }).withMessage('Description must be less than 1000 characters'),
  body('metadata').optional().isObject().withMessage('Metadata must be an object'),
  body('tags').optional().isArray().withMessage('Tags must be an array'),
  body('classification')
    .optional()
    .isIn(['public', 'internal', 'confidential', 'restricted'])
    .withMessage('Invalid classification level'),
];

const updateAssetValidation = [
  param('id').isString().withMessage('Asset ID must be a string'),
  body('name').optional().isString().isLength({ min: 1, max: 255 }).withMessage('Name must be between 1 and 255 characters'),
  body('description').optional().isString().isLength({ max: 1000 }).withMessage('Description must be less than 1000 characters'),
  body('metadata').optional().isObject().withMessage('Metadata must be an object'),
  body('tags').optional().isArray().withMessage('Tags must be an array'),
  body('classification')
    .optional()
    .isIn(['public', 'internal', 'confidential', 'restricted'])
    .withMessage('Invalid classification level'),
];

const paginationValidation = [
  query('page').optional().isInt({ min: 1 }).withMessage('Page must be a positive integer'),
  query('limit').optional().isInt({ min: 1, max: 100 }).withMessage('Limit must be between 1 and 100'),
  query('type')
    .optional()
    .isIn(['table', 'view', 'file', 'api_endpoint', 'stream', 'model'])
    .withMessage('Invalid asset type filter'),
  query('dataSourceId').optional().isString().withMessage('Data source ID must be a string'),
  query('classification')
    .optional()
    .isIn(['public', 'internal', 'confidential', 'restricted'])
    .withMessage('Invalid classification filter'),
  query('search').optional().isString().isLength({ min: 1, max: 100 }).withMessage('Search term must be between 1 and 100 characters'),
];

const idValidation = [param('id').isString().withMessage('Asset ID must be a string')];

// --- Rate limiters (cast to RequestHandler to avoid type incompatibilities) ---
const asHandler = (h: any) => h as unknown as RequestHandler;

const listAssetsLimit = asHandler(createRateLimit({ windowMs: 60_000, max: 100 }));
const searchAssetsLimit = asHandler(createRateLimit({ windowMs: 60_000, max: 50 }));
const getAssetStatsLimit = asHandler(createRateLimit({ windowMs: 60_000, max: 30 }));
const getAssetLimit = asHandler(createRateLimit({ windowMs: 60_000, max: 200 }));
const getSchemaLimit = asHandler(createRateLimit({ windowMs: 60_000, max: 30 }));
const getLineageLimit = asHandler(createRateLimit({ windowMs: 60_000, max: 20 }));
const getProfileLimit = asHandler(createRateLimit({ windowMs: 60_000, max: 10 }));
const createAssetLimit = asHandler(createRateLimit({ windowMs: 60_000, max: 20 }));
const scanAssetLimit = asHandler(createRateLimit({ windowMs: 60_000, max: 5 }));
const tagOperationsLimit = asHandler(createRateLimit({ windowMs: 60_000, max: 30 }));
const updateAssetLimit = asHandler(createRateLimit({ windowMs: 60_000, max: 30 }));
const updateClassificationLimit = asHandler(createRateLimit({ windowMs: 60_000, max: 20 }));
const deleteAssetLimit = asHandler(createRateLimit({ windowMs: 60_000, max: 10 }));

/**
 * @route GET /api/assets
 * @desc Get all assets with pagination, filtering, and search
 * @access Private
 */
router.get('/', paginationValidation, validateRequest, listAssetsLimit, asyncHandler(assetController.getAllAssets));

/**
 * @route GET /api/assets/search
 * @desc Search assets by name, description, or metadata
 * @access Private
 */
router.get(
  '/search',
  [
    query('q').isString().isLength({ min: 1, max: 100 }).withMessage('Search query must be between 1 and 100 characters'),
    query('type')
      .optional()
      .isIn(['table', 'view', 'file', 'api_endpoint', 'stream', 'model'])
      .withMessage('Invalid asset type filter'),
    query('limit').optional().isInt({ min: 1, max: 50 }).withMessage('Limit must be between 1 and 50'),
  ],
  validateRequest,
  searchAssetsLimit,
  asyncHandler(assetController.searchAssets),
);

/**
 * @route GET /api/assets/stats
 * @desc Get asset statistics and overview (global)
 * @access Private
 */
router.get('/stats', getAssetStatsLimit, asyncHandler(assetController.getAssetStats));

/**
 * @route GET /api/assets/:id
 * @desc Get a specific asset by ID
 * @access Private
 */
router.get('/:id', idValidation, validateRequest, getAssetLimit, asyncHandler(assetController.getAssetById));

/**
 * @route GET /api/assets/:id/schema
 * @desc Get schema information for an asset
 * @access Private
 */
router.get('/:id/schema', idValidation, validateRequest, getSchemaLimit, asyncHandler(assetController.getAssetSchema));

/**
 * @route GET /api/assets/:id/lineage
 * @desc Get data lineage for an asset
 * @access Private
 */
router.get('/:id/lineage', idValidation, validateRequest, getLineageLimit, asyncHandler(assetController.getAssetLineage));

/**
 * @route GET /api/assets/:id/profile
 * @desc Get data profile for an asset
 * @access Private
 */
router.get('/:id/profile', idValidation, validateRequest, getProfileLimit, asyncHandler(assetController.getAssetProfile));

/**
 * @route GET /api/assets/:id/stats
 * @desc Get usage statistics for a specific asset
 * @access Private
 */
router.get('/:id/stats', idValidation, validateRequest, getAssetStatsLimit, asyncHandler(assetController.getAssetStats));

/**
 * @route POST /api/assets
 * @desc Create a new asset
 * @access Private
 */
router.post('/', createAssetValidation, validateRequest, createAssetLimit, asyncHandler(assetController.createAsset));

/**
 * @route POST /api/assets/:id/scan
 * @desc Trigger a scan/discovery for an asset
 * @access Private
 */
router.post(
  '/:id/scan',
  idValidation,
  [
    body('type').optional().isIn(['full', 'incremental', 'schema_only', 'profile_only']).withMessage('Invalid scan type'),
    body('force').optional().isBoolean().withMessage('Force must be a boolean'),
  ],
  validateRequest,
  scanAssetLimit,
  asyncHandler(assetController.scanAsset),
);

/**
 * @route POST /api/assets/:id/tags
 * @desc Add tags to an asset
 * @access Private
 */
router.post(
  '/:id/tags',
  idValidation,
  [
    body('tags').isArray({ min: 1 }).withMessage('Tags must be a non-empty array'),
    body('tags.*').isString().isLength({ min: 1, max: 50 }).withMessage('Each tag must be between 1 and 50 characters'),
  ],
  validateRequest,
  tagOperationsLimit,
  asyncHandler(assetController.addTags),
);

/**
 * @route PUT /api/assets/:id
 * @desc Update an asset
 * @access Private
 */
router.put('/:id', updateAssetValidation, validateRequest, updateAssetLimit, asyncHandler(assetController.updateAsset));

/**
 * @route PUT /api/assets/:id/classification
 * @desc Update asset classification
 * @access Private
 */
router.put(
  '/:id/classification',
  idValidation,
  [
    body('classification')
      .isIn(['public', 'internal', 'confidential', 'restricted'])
      .withMessage('Invalid classification level'),
    body('reason').optional().isString().isLength({ max: 500 }).withMessage('Reason must be less than 500 characters'),
  ],
  validateRequest,
  updateClassificationLimit,
  asyncHandler(assetController.updateClassification),
);

/**
 * @route DELETE /api/assets/:id
 * @desc Delete an asset (soft delete)
 * @access Private
 */
router.delete('/:id', idValidation, validateRequest, deleteAssetLimit, asyncHandler(assetController.deleteAsset));

/**
 * @route DELETE /api/assets/:id/tags
 * @desc Remove tags from an asset
 * @access Private
 */
router.delete(
  '/:id/tags',
  idValidation,
  [body('tags').isArray({ min: 1 }).withMessage('Tags must be a non-empty array'), body('tags.*').isString().withMessage('Each tag must be a string')],
  validateRequest,
  tagOperationsLimit,
  asyncHandler(assetController.removeTags),
);

export default router;



------------------------------------------------------------
FILE: backend\data-service\src\routes\catalog.ts
------------------------------------------------------------
// backend/data-service/src/routes/catalog.ts
import { Request, Response, Router } from 'express';
import mssql from 'mssql';
import { Client as PgClient, Pool, QueryResult } from 'pg';
import { z } from 'zod';
import { ProfileQueue } from '../queue';

const router = Router();
const cpdb = new Pool({ connectionString: process.env.DATABASE_URL });

/* ---------------------------- Utilities ---------------------------- */

const ok = <T>(res: Response, data: T, extra: Record<string, unknown> = {}) =>
  res.json({ success: true, data, ...extra });

const fail = (res: Response, code: number, message: string, extra?: Record<string, unknown>) =>
  res.status(code).json({ success: false, error: message, ...(extra ?? {}) });

type DSRow = {
  id: string;
  tenant_id: number | null;
  type: 'postgresql' | 'mssql';
  config?: any;
  connection_config?: any;
};

async function getDataSourceById(
  id: string
): Promise<{ tenantId: number; type: DSRow['type']; cfg: any; idText: string }> {
  const { rows } = await cpdb.query<DSRow>(
    `SELECT id::text AS id, COALESCE(tenant_id, 1) AS tenant_id, type,
            COALESCE(config, connection_config) AS cfg
     FROM data_sources WHERE id::text = $1`,
    [id]
  );
  const row = rows[0];
  if (!row) throw new Error('Data source not found');
  return { tenantId: row.tenant_id ?? 1, type: row.type, cfg: (row as any).cfg || {}, idText: (row as any).id };
}

/* ------------------------- Ingest (Harvest) ------------------------ */

async function ingestPostgres(tenantId: number, dataSourceId: string, cfg: any) {
  const src = new PgClient({
    host: cfg.host,
    port: Number(cfg.port ?? 5432),
    database: cfg.database,
    user: cfg.username,
    password: cfg.password,
    ssl: cfg.ssl === false || cfg.ssl?.mode === 'disable' ? undefined : cfg.ssl,
  });
  await src.connect();

  const tables = await src.query(`
    SELECT table_schema, table_name, table_type
    FROM information_schema.tables
    WHERE table_schema NOT IN ('pg_catalog','information_schema')
  `);

  const columns = await src.query(`
    SELECT c.table_schema, c.table_name, c.column_name, c.data_type, c.is_nullable, c.ordinal_position,
           d.description AS column_comment
    FROM information_schema.columns c
    LEFT JOIN pg_catalog.pg_class cls ON cls.relname = c.table_name
    LEFT JOIN pg_catalog.pg_namespace ns ON ns.nspname = c.table_schema
    LEFT JOIN pg_catalog.pg_description d ON d.objoid = cls.oid AND d.objsubid = c.ordinal_position
    WHERE c.table_schema NOT IN ('pg_catalog','information_schema')
    ORDER BY c.table_schema, c.table_name, c.ordinal_position
  `);

  const counts = await src.query(`
    SELECT schemaname AS table_schema, relname AS table_name, n_live_tup AS row_estimate
    FROM pg_stat_user_tables
  `);
  await src.end();

  const cnt = new Map<string, number>();
  counts.rows.forEach((r: any) => cnt.set(`${r.table_schema}.${r.table_name}`, Number(r.row_estimate)));

  let assets = 0, cols = 0;
  for (const t of tables.rows) {
    const assetType = t.table_type === 'VIEW' ? 'view' : 'table';
    const rowCount = cnt.get(`${t.table_schema}.${t.table_name}`) ?? null;

    const ar: QueryResult<{ id: string }> = await cpdb.query(
      `INSERT INTO catalog_assets
         (tenant_id, datasource_id, asset_type, schema_name, table_name, row_count, updated_at)
       VALUES ($1,$2,$3,$4,$5,$6,now())
       ON CONFLICT (tenant_id, datasource_id, asset_type, schema_name, table_name)
       DO UPDATE SET row_count = EXCLUDED.row_count, updated_at = now()
       RETURNING id`,
      [tenantId, dataSourceId, assetType, t.table_schema, t.table_name, rowCount]
    );
    const assetId = ar.rows[0].id; assets++;

    const colsForTable = columns.rows.filter((c: any) => c.table_schema === t.table_schema && c.table_name === t.table_name);
    for (const c of colsForTable) {
      await cpdb.query(
        `INSERT INTO catalog_columns (asset_id, column_name, data_type, is_nullable, ordinal, description, updated_at)
         VALUES ($1,$2,$3,$4,$5,$6,now())
         ON CONFLICT (asset_id, column_name)
         DO UPDATE SET data_type = EXCLUDED.data_type,
                       is_nullable = EXCLUDED.is_nullable,
                       ordinal = EXCLUDED.ordinal,
                       description = EXCLUDED.description,
                       updated_at = now()`,
        [assetId, c.column_name, c.data_type, c.is_nullable === 'YES', c.ordinal_position, c.column_comment ?? null]
      );
      cols++;
    }
  }

  await cpdb.query(`DO $$ BEGIN
    IF EXISTS (SELECT 1 FROM pg_matviews WHERE matviewname = 'catalog_metrics') THEN
      PERFORM 1 FROM pg_sleep(0);
      REFRESH MATERIALIZED VIEW CONCURRENTLY catalog_metrics;
    END IF;
  END $$;`);

  return { assets, columns: cols };
}

async function ingestMSSQL(tenantId: number, dataSourceId: string, cfg: any) {
  const pool = await mssql.connect({
    server: cfg.host,
    port: Number(cfg.port ?? 1433),
    database: cfg.database,
    user: cfg.username,
    password: cfg.password,
    options: { encrypt: true, trustServerCertificate: true, ...(cfg.options || {}) }
  });

  const tables = (await pool.request().query(`
    SELECT s.name AS schema_name, t.name AS object_name, 'table' AS asset_type
    FROM sys.tables t JOIN sys.schemas s ON t.schema_id = s.schema_id
    WHERE t.is_ms_shipped = 0
    UNION ALL
    SELECT s.name, v.name, 'view'
    FROM sys.views v JOIN sys.schemas s ON v.schema_id = s.schema_id
  `)).recordset;

  const columns = (await pool.request().query(`
    SELECT s.name AS schema_name, o.name AS object_name, c.name AS column_name,
           ty.name AS data_type, c.is_nullable, c.column_id AS ordinal,
           CAST(ep.value AS NVARCHAR(4000)) AS column_comment
    FROM sys.columns c
    JOIN sys.types ty ON c.user_type_id = ty.user_type_id
    JOIN sys.objects o ON c.object_id = o.object_id AND o.type IN ('U','V')
    JOIN sys.schemas s ON o.schema_id = s.schema_id
    LEFT JOIN sys.extended_properties ep
      ON ep.major_id = c.object_id AND ep.minor_id = c.column_id AND ep.name='MS_Description'
  `)).recordset;

  const counts = (await pool.request().query(`
    SELECT s.name AS schema_name, t.name AS object_name, SUM(p.rows) AS row_count
    FROM sys.tables t
    JOIN sys.partitions p ON t.object_id=p.object_id AND p.index_id IN (0,1)
    JOIN sys.schemas s ON t.schema_id=s.schema_id
    GROUP BY s.name, t.name
  `)).recordset;

  await pool.close();

  const cnt = new Map<string, number>();
  counts.forEach((r: any) => cnt.set(`${r.schema_name}.${r.object_name}`, Number(r.row_count)));

  let assets = 0, cols = 0;
  for (const t of tables as any[]) {
    const rowCount = cnt.get(`${t.schema_name}.${t.object_name}`) ?? null;

    const ar: QueryResult<{ id: string }> = await cpdb.query(
      `INSERT INTO catalog_assets
         (tenant_id, datasource_id, asset_type, schema_name, table_name, row_count, updated_at)
       VALUES ($1,$2,$3,$4,$5,$6,now())
       ON CONFLICT (tenant_id, datasource_id, asset_type, schema_name, table_name)
       DO UPDATE SET row_count = EXCLUDED.row_count, updated_at = now()
       RETURNING id`,
      [tenantId, dataSourceId, t.asset_type, t.schema_name, t.object_name, rowCount]
    );
    const assetId = ar.rows[0].id; assets++;

    const colsForTable = (columns as any[]).filter(c => c.schema_name === t.schema_name && c.object_name === t.object_name);
    for (const c of colsForTable) {
      await cpdb.query(
        `INSERT INTO catalog_columns (asset_id, column_name, data_type, is_nullable, ordinal, description, updated_at)
         VALUES ($1,$2,$3,$4,$5,$6,now())
         ON CONFLICT (asset_id, column_name)
         DO UPDATE SET data_type = EXCLUDED.data_type,
                       is_nullable = EXCLUDED.is_nullable,
                       ordinal = EXCLUDED.ordinal,
                       description = EXCLUDED.description,
                       updated_at = now()`,
        [assetId, c.column_name, c.data_type, !!c.is_nullable, c.ordinal, c.column_comment ?? null]
      );
      cols++;
    }
  }

  await cpdb.query(`DO $$ BEGIN
    IF EXISTS (SELECT 1 FROM pg_matviews WHERE matviewname = 'catalog_metrics') THEN
      REFRESH MATERIALIZED VIEW CONCURRENTLY catalog_metrics;
    END IF;
  END $$;`);

  return { assets, columns: cols };
}

/* -------------------------- Validation/Zod ------------------------- */

const PatchAsset = z.object({
  display_name: z.string().min(1).optional(),
  description: z.string().optional(),
  owner: z.string().optional(),
  classification: z.enum(['public','internal','confidential','restricted']).optional(),
  quality: z.enum(['low','medium','high']).optional(),
  tags: z.array(z.string()).optional()
});

/* ----------------------- Handlers (shared) ------------------------ */

const listAssets = async (req: Request, res: Response) => {
  try {
    const q = req.query as Record<string, string|undefined>;
    const page = Math.max(1, parseInt(q.page ?? '1', 10));
    const limit = Math.min(200, Math.max(1, parseInt(q.limit ?? '50', 10)));
    const offset = (page - 1) * limit;

    const sortBy = (q.sortBy ?? 'name');
    const sortOrder = (q.sortOrder ?? 'asc') === 'desc' ? 'desc' : 'asc';
    const sortCol = sortBy === 'name' ? 'table_name'
                    : sortBy === 'updatedAt' ? 'updated_at'
                    : sortBy === 'createdAt' ? 'created_at'
                    : sortBy === 'quality' ? 'quality'
                    : sortBy === 'owner' ? 'owner'
                    : 'table_name';

    const p: any[] = [];
    let i = 1;
    const where: string[] = [];

    if (q.search) { where.push(`(schema_name || '.' || table_name || ' ' || coalesce(description,'')) ILIKE $${i++}`); p.push(`%${q.search}%`); }
    if (q.type)   { where.push(`asset_type = $${i++}`); p.push(q.type); }
    if (q.owner)  { where.push(`owner = $${i++}`); p.push(q.owner); }
    if (q.quality){ where.push(`quality = $${i++}`); p.push(q.quality); }
    if (q.classification){ where.push(`classification = $${i++}`); p.push(q.classification); }
    if (q.datasourceId){ where.push(`datasource_id::text = $${i++}`); p.push(q.datasourceId); }
    if (q.tags) {
      where.push(`
        (
          (pg_typeof(tags)::text = 'jsonb' AND (tags ?| $${i}))
          OR
          (pg_typeof(tags)::text <> 'jsonb' AND (tags && $${i}::text[]))
        )
      `);
      p.push(q.tags.split(',').map(t => t.trim()));
      i++;
    }

    const whereSql = where.length ? `WHERE ${where.join(' AND ')}` : '';

    const listSql = `
      SELECT id, datasource_id, asset_type, schema_name, table_name, owner, quality, classification, tags,
             row_count, description, created_at, updated_at, display_name
      FROM catalog_assets
      ${whereSql}
      ORDER BY ${sortCol} ${sortOrder}
      LIMIT ${limit} OFFSET ${offset};`;

    const countSql = `SELECT COUNT(*)::bigint AS total FROM catalog_assets ${whereSql};`;

    const [list, total] = await Promise.all([cpdb.query(listSql, p), cpdb.query(countSql, p)]);
    const t = Number(total.rows[0]?.total || 0);
    const totalPages = Math.max(1, Math.ceil(t / limit));
    const payload = { items: list.rows, pagination: { page, limit, total: t, totalPages } };

    const newest = list.rows.reduce<number>((acc: number, r: any) => {
      const ts = r?.updated_at ? new Date(r.updated_at).getTime() : 0;
      return Math.max(acc, ts);
    }, 0);
    const etag = `"assets-${t}-${newest}"`;
    res.set('ETag', etag);
    if (req.headers['if-none-match'] === etag) return res.status(304).end();

    ok(res, payload);
  } catch (e: any) {
    fail(res, 500, e.message);
  }
};

const getAsset = async (req: Request, res: Response) => {
  try {
    const { rows } = await cpdb.query(
      `SELECT a.*, jsonb_agg(c ORDER BY c.ordinal) AS columns
       FROM catalog_assets a
       LEFT JOIN catalog_columns c ON c.asset_id = a.id
       WHERE a.id::text = $1
       GROUP BY a.id`,
      [req.params.id]
    );
    if (!rows[0]) return fail(res, 404, 'Not found');
    ok(res, rows[0]);
  } catch (e: any) {
    fail(res, 500, e.message);
  }
};

const exportAssets = async (req: Request, res: Response) => {
  try {
    const q = req.query as Record<string, string|undefined>;

    const p: any[] = [];
    let i = 1;
    const where: string[] = [];

    if (q.search) { where.push(`(schema_name || '.' || table_name || ' ' || coalesce(description,'')) ILIKE $${i++}`); p.push(`%${q.search}%`); }
    if (q.type)   { where.push(`asset_type = $${i++}`); p.push(q.type); }
    if (q.owner)  { where.push(`owner = $${i++}`); p.push(q.owner); }
    if (q.quality){ where.push(`quality = $${i++}`); p.push(q.quality); }
    if (q.classification){ where.push(`classification = $${i++}`); p.push(q.classification); }
    if (q.datasourceId){ where.push(`datasource_id::text = $${i++}`); p.push(q.datasourceId); }
    if (q.tags) {
      where.push(`
        (
          (pg_typeof(tags)::text = 'jsonb' AND (tags ?| $${i}))
          OR
          (pg_typeof(tags)::text <> 'jsonb' AND (tags && $${i}::text[]))
        )
      `);
      p.push(q.tags.split(',').map(t => t.trim()));
      i++;
    }
    const whereSql = where.length ? `WHERE ${where.join(' AND ')}` : '';

    const { rows } = await cpdb.query(
      `SELECT datasource_id::text AS datasource_id, asset_type, schema_name, table_name, display_name, owner, quality, classification, row_count, tags, description, updated_at
       FROM catalog_assets
       ${whereSql}
       ORDER BY schema_name, table_name`,
      p
    );

    res.setHeader('Content-Type', 'text/csv; charset=utf-8');
    res.setHeader('Content-Disposition', `attachment; filename="assets-${Date.now()}.csv"`);

    const header = [
      'datasource_id','asset_type','schema_name','table_name','display_name',
      'owner','quality','classification','row_count','tags','description','updated_at'
    ];
    res.write(header.join(',') + '\n');

    for (const r of rows) {
      const tags =
        Array.isArray(r.tags) ? r.tags.join('|')
        : (typeof r.tags === 'object' && r.tags ? Object.values(r.tags as any).join('|') : '');
      const esc = (v: any) => {
        const s = String(v ?? '');
        return (s.includes(',') || s.includes('"') || s.includes('\n')) ? `"${s.replace(/"/g, '""')}"` : s;
      };
      res.write([
        esc(r.datasource_id),
        esc(r.asset_type),
        esc(r.schema_name),
        esc(r.table_name),
        esc(r.display_name ?? ''),
        esc(r.owner ?? ''),
        esc(r.quality ?? ''),
        esc(r.classification ?? ''),
        esc(r.row_count ?? ''),
        esc(tags),
        esc(r.description ?? ''),
        esc(r.updated_at ? new Date(r.updated_at).toISOString() : '')
      ].join(',') + '\n');
    }

    res.end();
  } catch (e: any) {
    fail(res, 500, e.message);
  }
};

/* ------------------------------ Routes ---------------------------- */

// PATCH asset metadata
router.patch('/catalog/assets/:id', async (req, res) => {
  try {
    const body = PatchAsset.parse(req.body || {});
    const fields = Object.keys(body);
    if (fields.length === 0) return fail(res, 400, 'No fields');

    const sets = fields.map((k, idx) => `${k}=$${idx+1}`).join(', ') + ', updated_at=now()';
    const vals = fields.map(k => (body as any)[k]);
    vals.push(req.params.id);

    const q = await cpdb.query(
      `UPDATE catalog_assets SET ${sets} WHERE id::text=$${vals.length} RETURNING *`, vals
    );
    if (!q.rows[0]) return fail(res, 404, 'Not found');
    ok(res, q.rows[0]);
  } catch (e: any) {
    fail(res, 400, e?.message || 'Invalid payload');
  }
});

// Profile launch & read
router.post('/catalog/assets/:id/profile', async (req, res) => {
  try {
    const assetId = String(req.params.id);
    await ProfileQueue.add('profile-one', { assetId }, { removeOnComplete: 100, removeOnFail: 100 });
    ok(res, { queued: true });
  } catch (e: any) {
    fail(res, 500, e.message);
  }
});
router.get('/catalog/assets/:id/profile', async (req, res) => {
  try {
    const assetId = String(req.params.id);
    const runs = await cpdb.query(
      `SELECT * FROM catalog_profile_runs WHERE asset_id=$1 ORDER BY started_at DESC LIMIT 1`, [assetId]
    );
    const cols = await cpdb.query(
      `SELECT column_name, null_frac, distinct_frac, min_value, max_value, avg_length, pii_type, inferred_type
       FROM catalog_column_profiles WHERE asset_id=$1 ORDER BY column_name`, [assetId]
    );
    ok(res, { run: runs.rows[0] || null, columns: cols.rows });
  } catch (e: any) {
    fail(res, 500, e.message);
  }
});

// Search
router.get('/catalog/search', async (req, res) => {
  try {
    const q = String(req.query.q || '').trim();
    if (!q) return ok(res, { items: [] });
    const limit = Math.min(50, Number(req.query.limit || 20));
    const sql = `
      SELECT id, datasource_id, asset_type, schema_name, table_name, display_name, description, tags,
             ts_rank(search, plainto_tsquery('simple',$1)) AS rank
      FROM catalog_assets
      WHERE search @@ plainto_tsquery('simple',$1)
      ORDER BY rank DESC, updated_at DESC
      LIMIT $2
    `;
    const { rows } = await cpdb.query(sql, [q, limit]);
    ok(res, { items: rows });
  } catch (e: any) {
    fail(res, 500, e.message);
  }
});

// Lineage
router.get('/catalog/assets/:id/lineage', async (req, res) => {
  try {
    const id = String(req.params.id);
    const { rows } = await cpdb.query(
      `SELECT upstream_asset_id, downstream_asset_id, edge_type, confidence
       FROM catalog_edges
       WHERE upstream_asset_id=$1 OR downstream_asset_id=$1`, [id]
    );
    ok(res, { edges: rows });
  } catch (e: any) {
    fail(res, 500, e.message);
  }
});

// Metrics (matview if present, fallback otherwise)
router.get('/catalog/metrics', async (_req: Request, res: Response) => {
  try {
    const { rows } = await cpdb.query(`
      WITH ensure AS (
        SELECT 1
        FROM pg_matviews
        WHERE matviewname = 'catalog_metrics'
      )
      SELECT * FROM catalog_metrics LIMIT 1;
    `).catch(async () => {
      const fb = await cpdb.query(`
        SELECT COUNT(*)::bigint AS total,
               COUNT(*) FILTER (WHERE asset_type='table')::bigint AS tables,
               COUNT(*) FILTER (WHERE asset_type='view')::bigint AS views
        FROM catalog_assets;
      `);
      return { rows: [fb.rows[0]] } as any;
    });

    ok(res, rows?.[0] || { total: 0, tables: 0, views: 0 });
  } catch (e: any) {
    fail(res, 500, e.message);
  }
});

// Export CSV
router.get('/catalog/assets/export', exportAssets);

// Sync (harvest)
router.post('/data-sources/:id/sync', async (req: Request, res: Response) => {
  const id = String(req.params.id);
  const doAsync = String(req.query.async ?? 'false') === 'true';

  try {
    const { tenantId, type, cfg, idText } = await getDataSourceById(id);

    const run = async () => {
      if (type === 'postgresql') return ingestPostgres(tenantId, idText, cfg);
      if (type === 'mssql') return ingestMSSQL(tenantId, idText, cfg);
      throw new Error(`Unsupported datasource type: ${type}`);
    };

    if (doAsync) {
      res.status(202).json({ success: true, syncId: `sync_${Date.now()}` });
      run().catch((e) => console.error('[data-service] async sync failed', e));
      return;
    }

    const result = await run();
    ok(res, { ...result });
  } catch (e: any) {
    fail(res, 500, e.message);
  }
});

/* -------------------------- Dual registration --------------------- */
/* These ensure the FE can call either /api/catalog/assets or /api/assets */
router.get('/catalog/assets', listAssets);
router.get('/assets', listAssets);

router.get('/catalog/assets/:id', getAsset);
router.get('/assets/:id', getAsset);

router.get('/catalog/assets/export', exportAssets);
router.get('/assets/export', exportAssets);

export default router;



------------------------------------------------------------
FILE: backend\data-service\src\routes\chat.ts
------------------------------------------------------------
import { Router } from 'express';
import { z } from 'zod';

const r = Router();

const MsgSchema = z.object({
  role: z.enum(['user','assistant','system']),
  content: z.string().min(1)
});
const BodySchema = z.object({
  messages: z.array(MsgSchema).min(1),
});

r.post('/chat', async (req, res) => {
  const parse = BodySchema.safeParse(req.body);
  if (!parse.success) return res.status(400).json({ success: false, error: 'Invalid payload' });

  const messages = parse.data.messages;
  const lastUser = [...messages].reverse().find(m => m.role === 'user')?.content || '';

  // If OPENAI_API_KEY is present, try a short completion; else echo
  const key = (process.env.OPENAI_API_KEY || '').trim();
  let reply = `Echo: ${lastUser}`;
  if (key) {
    try {
      // Lazy import to avoid hard dep if key is missing
      const fetch = (await import('node-fetch')).default as any;
      const resp = await fetch('https://api.openai.com/v1/chat/completions', {
        method: 'POST',
        headers: { 'Authorization': `Bearer ${key}`, 'Content-Type': 'application/json' },
        body: JSON.stringify({ model: 'gpt-4o-mini', messages })
      });
      const json = await resp.json();
      reply = json?.choices?.[0]?.message?.content || reply;
    } catch (e: any) {
      reply = `Assistant: ${lastUser}`; // graceful fallback
    }
  }

  res.json({ success: true, data: { reply } });
});

export default r;



------------------------------------------------------------
FILE: backend\data-service\src\routes\dataSources.routes.ts
------------------------------------------------------------
import { Router } from 'express';
import { DataSourceController } from '../controllers/DataSourceController';
import { authMiddleware, optionalAuthMiddleware } from '../middleware/auth';

const r = Router();
const ctrl = new DataSourceController();

// READ (no hard auth; optional in dev)
r.get('/data-sources', optionalAuthMiddleware, ctrl.getAllDataSources);
r.get('/data-sources/health', optionalAuthMiddleware, ctrl.getHealthSummary);
r.get('/data-sources/:id', optionalAuthMiddleware, ctrl.getDataSourceById);
r.get('/data-sources/:id/schema', optionalAuthMiddleware, ctrl.getDataSourceSchema);

// WRITE (protected; in dev SKIP_AUTH=true bypasses)
r.post('/data-sources', authMiddleware, ctrl.createDataSource);
r.put('/data-sources/:id', authMiddleware, ctrl.updateDataSource);
r.delete('/data-sources/:id', authMiddleware, ctrl.deleteDataSource);
r.post('/data-sources/:id/test', authMiddleware, ctrl.testConnection);
r.post('/data-sources/:id/sync', authMiddleware, ctrl.syncDataSource);

export default r;



------------------------------------------------------------
FILE: backend\data-service\src\routes\dataSources.ts
------------------------------------------------------------
// backend/data-service/src/routes/dataSources.ts
import { Router, type RequestHandler } from 'express';
import { body, param, query } from 'express-validator';

import { DataSourceController } from '../controllers/DataSourceController';
import { authMiddleware } from '../middleware/auth';
import { asyncHandler } from '../middleware/error';
import { createRateLimit } from '../middleware/rateLimit';
import { validateRequest } from '../middleware/validation';

// Single router file for data sources
const router = Router();
const ctrl = new DataSourceController();
const asHandler = (h: any) => h as unknown as RequestHandler;

const IS_PROD = (process.env.NODE_ENV || '').toLowerCase() === 'production';

/* -------------------------------------------------------------------------- */
/* Type & status normalization                                                */
/* -------------------------------------------------------------------------- */

const CANONICAL_TYPES = [
  'postgresql','mysql','mssql','oracle','mongodb','redis',
  's3','azure-blob','gcs','snowflake','bigquery','redshift',
  'databricks','api','file','kafka','elasticsearch',
] as const;

type CanonicalType = (typeof CANONICAL_TYPES)[number];

const INPUT_TYPES = new Set<string>([...CANONICAL_TYPES, 'postgres']); // accept "postgres"
const INPUT_STATUSES = new Set<string>([
  'active','inactive','pending','error','testing','connected','disconnected','warning','syncing',
]);

const normalizeType = (t?: string): CanonicalType | undefined => {
  if (!t) return undefined;
  const x = t.toLowerCase();
  const mapped = x === 'postgres' ? 'postgresql' : x;
  return (CANONICAL_TYPES as readonly string[]).includes(mapped)
    ? (mapped as CanonicalType)
    : undefined;
};

const ALLOWED_SORT_BY = new Set(['updatedAt','createdAt','name','status','type'] as const);

const normalizeListParams: RequestHandler = (req, _res, next) => {
  // pagination
  const page = Math.max(parseInt(String(req.query.page ?? '1'), 10) || 1, 1);
  const limitRaw = Math.max(parseInt(String(req.query.limit ?? '20'), 10) || 20, 1);
  const limit = Math.min(limitRaw, 100);

  // sorting (keep UI names; service maps -> DB columns)
  const sortByRaw = String(req.query.sortBy ?? '').trim();
  const sortOrderRaw = String(req.query.sortOrder ?? '').trim().toLowerCase();
  const sortBy = ALLOWED_SORT_BY.has(sortByRaw as any) ? sortByRaw : 'updatedAt';
  const sortOrder = sortOrderRaw === 'asc' ? 'asc' : 'desc';

  // filters (normalized)
  const status = typeof req.query.status === 'string' && INPUT_STATUSES.has(req.query.status.toLowerCase())
    ? req.query.status.toLowerCase()
    : undefined;
  const type = normalizeType(req.query.type as string | undefined);

  req.query.page = String(page);
  req.query.limit = String(limit);
  req.query.sortBy = sortBy;
  req.query.sortOrder = sortOrder;
  if (status) req.query.status = status; else delete req.query.status;
  if (type) req.query.type = type; else delete req.query.type;

  next();
};

/* -------------------------------------------------------------------------- */
/* Rate limits                                                                */
/* -------------------------------------------------------------------------- */

const listLimit    = asHandler(createRateLimit({ windowMs: 60_000, max: 100 }));
const healthLimit  = asHandler(createRateLimit({ windowMs: 60_000, max: 60  }));
const getByIdLimit = asHandler(createRateLimit({ windowMs: 60_000, max: 200 }));
const schemaLimit  = asHandler(createRateLimit({ windowMs: 60_000, max: 30  }));
const createLimit  = asHandler(createRateLimit({ windowMs: 60_000, max: 20  }));
const testLimit    = asHandler(createRateLimit({ windowMs: 60_000, max: 60  })); // â†‘ allow wizard to click often
const syncLimit    = asHandler(createRateLimit({ windowMs: 60_000, max: 15  }));
const updateLimit  = asHandler(createRateLimit({ windowMs: 60_000, max: 30  }));
const deleteLimit  = asHandler(createRateLimit({ windowMs: 60_000, max: 10  }));

/* -------------------------------------------------------------------------- */
/* Validation                                                                 */
/* -------------------------------------------------------------------------- */

// Fixed validator that accepts both 'config' and 'connection' (API Gateway transforms field names)
const validateConnectionConfig = () => {
  return body().custom((value, { req }) => {
    // Log what we're receiving for debugging
    console.log('ðŸ” Full request body received:', JSON.stringify(req.body, null, 2));
    
    // API Gateway transforms 'config' to 'connection', so we check both
    const config = req.body?.config || req.body?.connection;
    
    console.log('ðŸ” Backend validating config/connection:', JSON.stringify(config, null, 2));
    console.log('ðŸ” Config type:', typeof config);
    console.log('ðŸ” Config is array:', Array.isArray(config));
    console.log('ðŸ” Config is null:', config === null);
    
    // Basic checks
    if (config === undefined) {
      console.log('âŒ Config/connection is undefined');
      throw new Error('Connection config is required');
    }
    
    if (config === null) {
      console.log('âŒ Config/connection is null');
      throw new Error('Connection config cannot be null');
    }
    
    if (typeof config !== 'object') {
      console.log('âŒ Config/connection is not an object, type:', typeof config);
      throw new Error('Connection config must be an object');
    }
    
    if (Array.isArray(config)) {
      console.log('âŒ Config/connection is an array');
      throw new Error('Connection config cannot be an array');
    }
    
    console.log('âœ… Connection config validation passed');
    return true;
  });
};

const paginationValidation = [
  query('page').optional().isInt({ min: 1 }),
  query('limit').optional().isInt({ min: 1, max: 100 }),
  query('status').optional().isString().custom((v) => INPUT_STATUSES.has(String(v).toLowerCase())),
  query('type').optional().isString().custom((v) => INPUT_TYPES.has(String(v).toLowerCase())),
  query('sortBy').optional().isString(),
  query('sortOrder').optional().isIn(['asc','desc']),
  query('search').optional().isString(),
  query('createdBy').optional().isString(),
];

const idValidation = [param('id').isString()];

const createDataSourceValidation = [
  body('name').isString().isLength({ min: 1, max: 255 }),
  body('description').optional().isString().isLength({ max: 1000 }),
  body('type').isString()
    .custom((val) => INPUT_TYPES.has(String(val).toLowerCase()))
    .customSanitizer((val) => normalizeType(String(val))),
  body('connectionConfig').custom((value) => {
    if (!value || typeof value !== 'object' || Array.isArray(value)) {
      throw new Error('Connection config must be a valid object');
    }
    return true;
  }),
  body('tags').optional().isArray(),
  body('metadata').optional().isObject(),
];

const updateDataSourceValidation = [
  param('id').isString(),
  body('name').optional().isString().isLength({ min: 1, max: 255 }),
  body('description').optional().isString().isLength({ max: 1000 }),
  body('type').optional().isString()
    .custom((val) => INPUT_TYPES.has(String(val).toLowerCase()))
    .customSanitizer((val) => normalizeType(String(val))),
  body('connectionConfig').optional().custom((value) => {
    if (value !== undefined && (!value || typeof value !== 'object' || Array.isArray(value))) {
      throw new Error('Connection config must be a valid object');
    }
    return true;
  }),
  body('tags').optional().isArray(),
  body('metadata').optional().isObject(),
];

/* -------------------------------------------------------------------------- */
/* Auth guard                                                                 */
/* -------------------------------------------------------------------------- */

const guard: RequestHandler = (req, res, next) => {
  const devBypass =
    !IS_PROD &&
    (
      (process.env.SKIP_AUTH || '').toLowerCase() === 'true' ||
      (process.env.MOCK_AUTH || '').toLowerCase() === 'true' ||
      req.header('x-dev-auth') === '1'
    );
  if (devBypass) return next();
  return authMiddleware(req, res, next);
};

/* -------------------------------------------------------------------------- */
/* Routes                                                                     */
/* (Note: the app mounts this router at /api/data-sources)                    */
/* -------------------------------------------------------------------------- */

// List + summary
router.get(
  '/',
  guard,
  paginationValidation,
  validateRequest,
  normalizeListParams,
  listLimit,
  asyncHandler(ctrl.getAllDataSources),
);
router.get('/health', guard, healthLimit, asyncHandler(ctrl.getHealthSummary));

// CRUD
router.get('/:id', guard, idValidation, validateRequest, getByIdLimit, asyncHandler(ctrl.getDataSourceById));
router.get('/:id/schema', guard, idValidation, validateRequest, schemaLimit, asyncHandler(ctrl.getDataSourceSchema));
router.post('/', guard, createDataSourceValidation, validateRequest, createLimit, asyncHandler(ctrl.createDataSource));
router.put('/:id', guard, updateDataSourceValidation, validateRequest, updateLimit, asyncHandler(ctrl.updateDataSource));
router.delete('/:id', guard, idValidation, validateRequest, deleteLimit, asyncHandler(ctrl.deleteDataSource));

/* ------------------------- Wizard-specific endpoints ---------------------- */
// Test a raw config BEFORE create
router.post(
  '/test',
  guard,
  body('type').isString().custom((v) => INPUT_TYPES.has(String(v).toLowerCase()))
    .customSanitizer((v) => normalizeType(String(v))),
  validateConnectionConfig(),
  validateRequest,
  testLimit,
  asyncHandler(ctrl.testConfig),
);

// Preview discovered DBs from a raw config BEFORE create
router.post(
  '/databases/preview',
  guard,
  body('type').isString().custom((v) => INPUT_TYPES.has(String(v).toLowerCase()))
    .customSanitizer((v) => normalizeType(String(v))),
  validateConnectionConfig(),
  validateRequest,
  listLimit,
  asyncHandler(ctrl.previewDatabases),
);

/* ------------------------- Saved-source operations ------------------------ */
// Connection test for a saved source
router.post('/:id/test', guard, idValidation, validateRequest, testLimit, asyncHandler(ctrl.testConnection));

// Trigger sync/discovery for a saved source
router.post(
  '/:id/sync',
  guard,
  idValidation,
  body('force').optional().isBoolean(),
  validateRequest,
  syncLimit,
  asyncHandler(ctrl.syncDataSource),
);

// Optional: poll sync status (frontend can use this if needed)
router.get('/:id/sync/status', guard, idValidation, validateRequest, listLimit, asyncHandler(ctrl.getSyncStatus));

// List databases belonging to a saved source (used by "Browse Databases")
router.get('/:id/databases', guard, idValidation, validateRequest, listLimit, asyncHandler(ctrl.listDatabases));

export default router;


------------------------------------------------------------
FILE: backend\data-service\src\routes\governance.ts
------------------------------------------------------------
import { Router } from 'express';
import { body, param, query } from 'express-validator';
import { GovernanceController } from '../controllers/GovernanceController';
import { authMiddleware, optionalAuthMiddleware } from '../middleware/auth';
import { asyncHandler } from '../middleware/error';
import { createRateLimit } from '../middleware/rateLimit';
import { validateRequest } from '../middleware/validation';

const r = Router();
const ctrl = new GovernanceController();
const listLimit = createRateLimit({ windowMs: 60_000, max: 120 });
const writeLimit = createRateLimit({ windowMs: 60_000, max: 30  });

r.get(
  '/policies',
  optionalAuthMiddleware,
  query('status').optional().isIn(['active','inactive']),
  validateRequest,
  listLimit,
  asyncHandler(ctrl.listPolicies),
);

r.post(
  '/policies',
  authMiddleware,
  body('name').isString().isLength({ min: 2, max: 255 }),
  body('category').optional().isIn(['access','privacy','retention']),
  body('status').optional().isIn(['active','inactive']),
  body('rules').optional().isArray(),
  validateRequest,
  writeLimit,
  asyncHandler(ctrl.createPolicy),
);

r.put(
  '/policies/:id',
  authMiddleware,
  param('id').isString(),
  validateRequest,
  writeLimit,
  asyncHandler(ctrl.updatePolicy),
);

r.delete(
  '/policies/:id',
  authMiddleware,
  param('id').isString(),
  validateRequest,
  writeLimit,
  asyncHandler(ctrl.deletePolicy),
);

export default r;



------------------------------------------------------------
FILE: backend\data-service\src\routes\index.ts
------------------------------------------------------------
import { Router } from 'express';
import dataSourceRoutes from './dataSources';

const api = Router();

// mount exactly as the frontend/gateway calls it
api.use('/data-sources', dataSourceRoutes);

export default api;



------------------------------------------------------------
FILE: backend\data-service\src\routes\lineage.ts
------------------------------------------------------------
import { Router } from 'express';
import { LineageController } from '../controllers/LineageController';
import { optionalAuthMiddleware } from '../middleware/auth';
import { asyncHandler } from '../middleware/error';

const r = Router();
const ctrl = new LineageController();

r.get('/graph', optionalAuthMiddleware, asyncHandler(ctrl.graph));
export default r;


------------------------------------------------------------
FILE: backend\data-service\src\routes\quality.ts
------------------------------------------------------------
// backend/data-service/src/routes/quality.ts
import { Router } from 'express';
import { body, param, query } from 'express-validator';
import { QualityController } from '../controllers/QualityController';
import { auditMiddleware } from '../middleware/audit';
import { authMiddleware, optionalAuthMiddleware } from '../middleware/auth';
import { asyncHandler } from '../middleware/error';
import { createRateLimit } from '../middleware/rateLimit';
import { validateRequest } from '../middleware/validation';

const router = Router();
const controller = new QualityController();

// Enhanced rate limiting with different tiers
const strictRateLimit = createRateLimit({ 
  windowMs: 60_000, 
  max: 10,
  skipSuccessfulRequests: false,
  standardHeaders: true
});

const moderateRateLimit = createRateLimit({ 
  windowMs: 60_000, 
  max: 60,
  skipSuccessfulRequests: true,
  standardHeaders: true
});

const listRateLimit = createRateLimit({ 
  windowMs: 60_000, 
  max: 120,
  skipSuccessfulRequests: true,
  standardHeaders: true
});

// Validation schemas for reuse
const uuidValidation = param('id')
  .isUUID(4)
  .withMessage('Invalid UUID format')
  .bail();

const paginationValidation = [
  query('limit')
    .optional()
    .isInt({ min: 1, max: 100 })
    .withMessage('Limit must be between 1 and 100')
    .toInt(),
  query('offset')
    .optional()
    .isInt({ min: 0 })
    .withMessage('Offset must be non-negative')
    .toInt()
];

const sqlValidationFunction = (value: string) => {
  // Basic SQL injection prevention
  const dangerous = /(\b(DROP|DELETE|INSERT|UPDATE|ALTER|CREATE|TRUNCATE|EXEC|EXECUTE)\b)/i;
  if (dangerous.test(value)) {
    throw new Error('Expression contains forbidden SQL keywords');
  }
  if (!value.trim().toUpperCase().startsWith('SELECT')) {
    throw new Error('Expression must start with SELECT');
  }
  return true;
};

const ruleValidation = [
  body('name')
    .isString()
    .isLength({ min: 2, max: 255 })
    .trim()
    .withMessage('Name must be between 2 and 255 characters'),
  body('description')
    .optional()
    .isString()
    .isLength({ max: 1000 })
    .trim()
    .withMessage('Description must not exceed 1000 characters'),
  body('severity')
    .optional()
    .isIn(['low', 'medium', 'high', 'critical'])
    .withMessage('Invalid severity level'),
  body('type')
    .optional()
    .isIn(['sql', 'metric'])
    .withMessage('Invalid rule type'),
  body('dialect')
    .optional()
    .isIn(['postgres', 'generic'])
    .withMessage('Invalid dialect'),
  body('expression')
    .isString()
    .isLength({ min: 3, max: 10000 })
    .withMessage('Expression must be between 3 and 10000 characters')
    .custom(sqlValidationFunction),
  body('tags')
    .optional()
    .isArray({ max: 20 })
    .withMessage('Tags must be an array with maximum 20 items')
    .custom((tags) => {
      if (tags && !tags.every((tag: any) => typeof tag === 'string' && tag.length <= 50)) {
        throw new Error('Each tag must be a string with maximum 50 characters');
      }
      return true;
    }),
  body('enabled')
    .optional()
    .isBoolean()
    .withMessage('Enabled must be a boolean')
];

// Routes

/**
 * @route GET /api/quality/health
 * @desc Health check for quality service
 * @access Public
 */
router.get(
  '/health',
  listRateLimit,
  asyncHandler(controller.healthCheck)
);

/**
 * @route GET /api/quality/rules
 * @desc List quality rules with filtering and pagination
 * @access Public (with optional auth for enhanced features)
 */
router.get(
  '/rules',
  optionalAuthMiddleware,
  [
    query('q')
      .optional()
      .isString()
      .isLength({ max: 100 })
      .trim()
      .withMessage('Search query must not exceed 100 characters'),
    query('severity')
      .optional()
      .isIn(['low', 'medium', 'high', 'critical'])
      .withMessage('Invalid severity filter'),
    query('enabled')
      .optional()
      .isBoolean()
      .toBoolean()
      .withMessage('Enabled filter must be boolean'),
    ...paginationValidation
  ],
  validateRequest,
  listRateLimit,
  auditMiddleware('QUALITY_RULES', 'LIST'),
  asyncHandler(controller.listRules)
);

/**
 * @route GET /api/quality/rules/:id
 * @desc Get a specific quality rule
 * @access Public
 */
router.get(
  '/rules/:id',
  uuidValidation,
  validateRequest,
  moderateRateLimit,
  auditMiddleware('QUALITY_RULE', 'ACCESS'),
  asyncHandler(controller.getRule)
);

/**
 * @route POST /api/quality/rules
 * @desc Create a new quality rule
 * @access Private
 */
router.post(
  '/rules',
  authMiddleware,
  ruleValidation,
  validateRequest,
  strictRateLimit,
  auditMiddleware('QUALITY_RULE', 'CREATE'),
  asyncHandler(controller.createRule)
);

/**
 * @route PUT /api/quality/rules/:id
 * @desc Update an existing quality rule
 * @access Private
 */
router.put(
  '/rules/:id',
  authMiddleware,
  uuidValidation,
  [
    body('name')
      .optional()
      .isString()
      .isLength({ min: 2, max: 255 })
      .trim()
      .withMessage('Name must be between 2 and 255 characters'),
    body('description')
      .optional()
      .isString()
      .isLength({ max: 1000 })
      .trim()
      .withMessage('Description must not exceed 1000 characters'),
    body('severity')
      .optional()
      .isIn(['low', 'medium', 'high', 'critical'])
      .withMessage('Invalid severity level'),
    body('expression')
      .optional()
      .isString()
      .isLength({ min: 3, max: 10000 })
      .withMessage('Expression must be between 3 and 10000 characters')
      .custom((value) => {
        if (value) {
          const dangerous = /(\b(DROP|DELETE|INSERT|UPDATE|ALTER|CREATE|TRUNCATE|EXEC|EXECUTE)\b)/i;
          if (dangerous.test(value)) {
            throw new Error('Expression contains forbidden SQL keywords');
          }
          if (!value.trim().toUpperCase().startsWith('SELECT')) {
            throw new Error('Expression must start with SELECT');
          }
        }
        return true;
      }),
    body('tags')
      .optional()
      .isArray({ max: 20 })
      .withMessage('Tags must be an array with maximum 20 items')
      .custom((tags) => {
        if (tags && !tags.every((tag: any) => typeof tag === 'string' && tag.length <= 50)) {
          throw new Error('Each tag must be a string with maximum 50 characters');
        }
        return true;
      }),
    body('enabled')
      .optional()
      .isBoolean()
      .withMessage('Enabled must be a boolean')
  ],
  validateRequest,
  strictRateLimit,
  auditMiddleware('QUALITY_RULE', 'UPDATE'),
  asyncHandler(controller.updateRule)
);

/**
 * @route DELETE /api/quality/rules/:id
 * @desc Delete (disable) a quality rule
 * @access Private
 */
router.delete(
  '/rules/:id',
  authMiddleware,
  uuidValidation,
  validateRequest,
  strictRateLimit,
  auditMiddleware('QUALITY_RULE', 'DELETE'),
  asyncHandler(controller.deleteRule)
);

/**
 * @route POST /api/quality/rules/:id/execute
 * @desc Execute a quality rule
 * @access Private
 */
router.post(
  '/rules/:id/execute',
  authMiddleware,
  uuidValidation,
  [
    body('dataSourceId')
      .optional()
      .isUUID(4)
      .withMessage('Invalid data source ID format'),
    body('timeout')
      .optional()
      .isInt({ min: 1000, max: 300000 })
      .withMessage('Timeout must be between 1000 and 300000 milliseconds')
      .toInt()
  ],
  validateRequest,
  strictRateLimit,
  auditMiddleware('QUALITY_RULE', 'EXECUTE'),
  asyncHandler(controller.executeRule)
);

/**
 * @route GET /api/quality/results
 * @desc List quality rule execution results
 * @access Public (with optional auth)
 */
router.get(
  '/results',
  optionalAuthMiddleware,
  [
    query('ruleId')
      .optional()
      .isUUID(4)
      .withMessage('Invalid rule ID format'),
    query('dataSourceId')
      .optional()
      .isUUID(4)
      .withMessage('Invalid data source ID format'),
    query('status')
      .optional()
      .isIn(['passed', 'failed', 'error', 'skipped', 'timeout'])
      .withMessage('Invalid status filter'),
    ...paginationValidation
  ],
  validateRequest,
  listRateLimit,
  auditMiddleware('QUALITY_RESULTS', 'LIST'),
  asyncHandler(controller.listResults)
);

// Bulk operations endpoint
/**
 * @route POST /api/quality/rules/bulk/execute
 * @desc Execute multiple quality rules
 * @access Private
 */
router.post(
  '/rules/bulk/execute',
  authMiddleware,
  [
    body('ruleIds')
      .isArray({ min: 1, max: 10 })
      .withMessage('Must provide 1-10 rule IDs')
      .custom((ruleIds) => {
        if (!ruleIds.every((id: any) => typeof id === 'string' && /^[0-9a-f]{8}-[0-9a-f]{4}-4[0-9a-f]{3}-[89ab][0-9a-f]{3}-[0-9a-f]{12}$/i.test(id))) {
          throw new Error('All rule IDs must be valid UUIDs');
        }
        return true;
      }),
    body('dataSourceId')
      .optional()
      .isUUID(4)
      .withMessage('Invalid data source ID format')
  ],
  validateRequest,
  createRateLimit({ windowMs: 300_000, max: 5 }), // Very limited for bulk operations
  auditMiddleware('QUALITY_RULES', 'BULK_EXECUTE'),
  asyncHandler(controller.executeRule)
);

// Statistics endpoint
/**
 * @route GET /api/quality/stats
 * @desc Get quality statistics
 * @access Public (with optional auth)
 */
router.get(
  '/stats',
  optionalAuthMiddleware,
  [
    query('timeframe')
      .optional()
      .isIn(['24h', '7d', '30d', '90d'])
      .withMessage('Invalid timeframe'),
    query('groupBy')
      .optional()
      .isIn(['severity', 'status', 'data_source'])
      .withMessage('Invalid groupBy parameter')
  ],
  validateRequest,
  moderateRateLimit,
  auditMiddleware('QUALITY_STATS', 'ACCESS'),
  asyncHandler(controller.getQualityStats)
);

// Error handling middleware for this router
router.use((error: any, req: any, res: any, next: any) => {
  const errorResponse = {
    success: false,
    error: {
      code: error.code || 'INTERNAL_ERROR',
      message: error.message || 'An unexpected error occurred',
      ...(error.details && { details: error.details }),
      ...(error.errorId && { errorId: error.errorId })
    },
    meta: {
      timestamp: new Date().toISOString(),
      path: req.path,
      method: req.method
    }
  };

  const statusCode = error.statusCode || 500;
  
  // Don't expose internal error details in production
  if (statusCode >= 500 && process.env.NODE_ENV === 'production') {
    errorResponse.error.message = 'Internal server error';
    delete errorResponse.error.details;
  }

  res.status(statusCode).json(errorResponse);
});

export default router;


------------------------------------------------------------
FILE: backend\data-service\src\routes\requests.ts
------------------------------------------------------------
import { Router } from 'express';
import { body, param, query } from 'express-validator';
import { RequestsController } from '../controllers/RequestsController';
import { authMiddleware, optionalAuthMiddleware } from '../middleware/auth';
import { asyncHandler } from '../middleware/error';
import { createRateLimit } from '../middleware/rateLimit';
import { validateRequest } from '../middleware/validation';

const r = Router();
const ctrl = new RequestsController();

r.get(
  '/',
  optionalAuthMiddleware,
  query('status').optional().isString(),
  query('type').optional().isString(),
  validateRequest,
  createRateLimit({ windowMs: 60_000, max: 120 }),
  asyncHandler(ctrl.list),
);

r.post(
  '/',
  authMiddleware,
  body('title').isString().isLength({ min: 3, max: 255 }),
  body('type').optional().isIn(['access','change','incident']),
  body('payload').optional().isObject(),
  validateRequest,
  createRateLimit({ windowMs: 60_000, max: 30 }),
  asyncHandler(ctrl.create),
);

r.put(
  '/:id',
  authMiddleware,
  param('id').isString(),
  body('status').optional().isIn(['open','approved','rejected','closed']),
  validateRequest,
  createRateLimit({ windowMs: 60_000, max: 60 }),
  asyncHandler(ctrl.update),
);

export default r;



------------------------------------------------------------
FILE: backend\data-service\src\routes\sources.ts
------------------------------------------------------------
// backend/data-service/src/routes/sources.ts
import { Router, type RequestHandler } from 'express';
import { body, param, query } from 'express-validator';
import { DataSourceController } from '../controllers/DataSourceController';
import { authMiddleware } from '../middleware/auth';
import { asyncHandler } from '../middleware/error';
import { createRateLimit } from '../middleware/rateLimit';
import { validateDataSource, validateDataSourceUpdate, validateRequest } from '../middleware/validation';

const router = Router();
const dataSourceController = new DataSourceController();

// Helper to coerce mixed-type middlewares into Express' RequestHandler
const asHandler = (h: any) => h as unknown as RequestHandler;

// ðŸ” Auth on every route
router.use(asHandler(authMiddleware));

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// Validation
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const paginationValidation = [
  query('page').optional().isInt({ min: 1 }).withMessage('Page must be a positive integer'),
  query('limit').optional().isInt({ min: 1, max: 100 }).withMessage('Limit must be between 1 and 100'),
  query('type')
    .optional()
    .isIn([
      'postgresql', 'mysql', 'mssql', 'oracle', 'mongodb', 'redis',
      's3', 'azure-blob', 'gcs', 'snowflake', 'bigquery', 'redshift',
      'databricks', 'api', 'file', 'kafka', 'elasticsearch',
    ])
    .withMessage('Invalid source type filter'),
  query('status')
    .optional()
    .isIn(['pending', 'connected', 'disconnected', 'error', 'warning', 'syncing', 'testing'])
    .withMessage('Invalid status filter'),
];

const idValidation = [param('id').isUUID().withMessage('Source ID must be a valid UUID')];

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// Per-route rate limiters (use the factory; donâ€™t â€œcallâ€ a handler as a fn)
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const listSourcesLimit          = asHandler(createRateLimit({ windowMs: 60_000, max: 100 }));
const healthLimit               = asHandler(createRateLimit({ windowMs: 60_000, max: 60 }));
const getSourceLimit            = asHandler(createRateLimit({ windowMs: 60_000, max: 200 }));
const schemaLimit               = asHandler(createRateLimit({ windowMs: 60_000, max: 30 }));
const createSourceLimit         = asHandler(createRateLimit({ windowMs: 60_000, max: 20 }));
const testLimit                 = asHandler(createRateLimit({ windowMs: 60_000, max: 10 }));
const discoverSourceLimit       = asHandler(createRateLimit({ windowMs: 60_000, max: 5 }));
const updateSourceLimit         = asHandler(createRateLimit({ windowMs: 60_000, max: 30 }));
const updateStatusLimit         = asHandler(createRateLimit({ windowMs: 60_000, max: 20 }));
const deleteSourceLimit         = asHandler(createRateLimit({ windowMs: 60_000, max: 10 }));

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// Routes â€“ only methods that exist on DataSourceController
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

/**
 * @route GET /api/sources
 * @desc Get all data sources with pagination & filters
 */
router.get(
  '/',
  paginationValidation,
  validateRequest,
  listSourcesLimit,
  asyncHandler(dataSourceController.getAllDataSources),
);

/**
 * @route GET /api/sources/health
 * @desc Health summary of all data sources
 */
router.get(
  '/health',
  healthLimit,
  asyncHandler(dataSourceController.getHealthSummary),
);

/**
 * @route GET /api/sources/:id
 * @desc Get a data source by ID
 */
router.get(
  '/:id',
  idValidation,
  validateRequest,
  getSourceLimit,
  asyncHandler(dataSourceController.getDataSourceById),
);

/**
 * @route GET /api/sources/:id/schema
 * @desc Get schema for a data source
 */
router.get(
  '/:id/schema',
  idValidation,
  validateRequest,
  schemaLimit,
  asyncHandler(dataSourceController.getDataSourceSchema),
);

/**
 * @route POST /api/sources
 * @desc Create a new data source
 */
router.post(
  '/',
  validateDataSource,
  validateRequest,
  createSourceLimit,
  asyncHandler(dataSourceController.createDataSource),
);

/**
 * @route POST /api/sources/:id/test
 * @desc Test connection for an existing source
 * (if you want a â€œtest without creatingâ€ endpoint, add a controller method first)
 */
router.post(
  '/:id/test',
  idValidation,
  validateRequest,
  testLimit,
  asyncHandler(dataSourceController.testConnection),
);

/**
 * @route POST /api/sources/:id/discover
 * @desc Trigger discovery/sync on a source
 */
router.post(
  '/:id/discover',
  idValidation,
  [
    body('force').optional().isBoolean().withMessage('Force must be a boolean'),
  ],
  validateRequest,
  discoverSourceLimit,
  asyncHandler(dataSourceController.syncDataSource),
);

/**
 * @route PUT /api/sources/:id
 * @desc Update a data source
 */
router.put(
  '/:id',
  validateDataSourceUpdate,
  validateRequest,
  updateSourceLimit,
  asyncHandler(dataSourceController.updateDataSource),
);

/**
 * @route PUT /api/sources/:id/status
 * @desc Update status for a data source (reuses updateDataSource)
 */
router.put(
  '/:id/status',
  idValidation,
  [
    body('status')
      .isIn(['pending', 'connected', 'disconnected', 'error', 'warning', 'syncing', 'testing'])
      .withMessage('Invalid status'),
    body('reason').optional().isString().isLength({ max: 500 }).withMessage('Reason must be less than 500 characters'),
  ],
  validateRequest,
  updateStatusLimit,
  asyncHandler(dataSourceController.updateDataSource),
);

/**
 * @route DELETE /api/sources/:id
 * @desc Delete a data source
 */
router.delete(
  '/:id',
  idValidation,
  validateRequest,
  deleteSourceLimit,
  asyncHandler(dataSourceController.deleteDataSource),
);

export default router;



------------------------------------------------------------
FILE: backend\data-service\src\routes\stats.ts
------------------------------------------------------------
import { Router } from 'express';
import { StatsController } from '../controllers/StatsController';
import { optionalAuthMiddleware } from '../middleware/auth';
import { asyncHandler } from '../middleware/error';

const r = Router();
const ctrl = new StatsController();

r.get('/', optionalAuthMiddleware, asyncHandler(ctrl.get));
export default r;


------------------------------------------------------------
FILE: backend\data-service\src\server.ts
------------------------------------------------------------
// src/server.ts
import compression from 'compression';
import cors from 'cors';
import 'dotenv/config';
import type { Express, NextFunction, Request, Response } from 'express';
import helmet from 'helmet';
import App from './app';
import { config, logConfig } from './config/env';
import catalogRouter from './routes/catalog';
import { logger } from './utils/logger';

type AppLifecycle = {
  initialize?: () => Promise<void> | void;
  cleanup?: () => Promise<void> | void;
  getExpressApp: () => Express;
};

class Server {
  private app: App;
  private server: any;

  constructor() {
    this.app = new (App as any)();
  }

  public async start(): Promise<void> {
    try {
      try { logConfig?.(); } catch (e) { logger.warn('[data-service] logConfig failed', e as any); }

      const host = config?.server?.host || process.env.HOST || '0.0.0.0';
      const port = Number(config?.server?.port || process.env.PORT || 3002);

      const expressApp = (this.app as unknown as AppLifecycle).getExpressApp();

      // --- hardening & DX ---
      expressApp.disable('x-powered-by');
      // Allow local dev UIs
      expressApp.use(cors({ origin: [/^http:\/\/localhost:(5173|3000)$/], credentials: true }));
      expressApp.use(helmet({ contentSecurityPolicy: false }));
      expressApp.use(compression());

      // Request ID (no extra deps)
      expressApp.use((req: Request, res: Response, next: NextFunction) => {
        // @ts-ignore
        req.id = (globalThis.crypto?.randomUUID?.() || Math.random().toString(36).slice(2));
        res.setHeader('x-request-id', (req as any).id);
        next();
      });

      // ---- Mount service routes BEFORE listen ----
      expressApp.use('/api', catalogRouter);
      logger.info('[data-service] Catalog routes mounted at /api (sync, assets, metrics, details)');

      this.server = expressApp.listen(port, host, () => {
        logger.info(`🚀 data-service listening on http://${host}:${port}`);
        logger.info(`📍 liveness:  GET /health`);
        logger.info(`📍 readiness: GET /ready`);
        logger.info(`🌱 NODE_ENV=${process.env.NODE_ENV || 'development'}`);
      });

      this.server.on('error', (err: any) => {
        logger.error('[data-service] HTTP server error', {
          message: err?.message, code: err?.code, stack: err?.stack,
        });
      });

      const lifecycle = this.app as unknown as AppLifecycle;
      Promise.resolve(lifecycle.initialize?.()).catch((err: any) => {
        logger.error('[data-service] App init failed', { message: err?.message, stack: err?.stack });
      });

      // 404 JSON & error handler (after routes)
      expressApp.use((req: Request, res: Response) => {
        res.status(404).json({ success: false, error: `Route ${req.method} ${req.path} not found` });
      });
      // eslint-disable-next-line @typescript-eslint/no-unused-vars
      expressApp.use((err: any, _req: Request, res: Response, _next: NextFunction) => {
        logger.error('[data-service] Unhandled error', { message: err?.message, stack: err?.stack });
        res.status(500).json({ success: false, error: 'Internal Server Error' });
      });

      const shutdown = (signal: string) => {
        logger.warn(`[data-service] ${signal} received. Shutting down...`);
        this.server?.close(async (err?: Error) => {
          if (err) {
            logger.error('[data-service] Error during close', { message: err.message, stack: err.stack });
            process.exit(1);
            return;
          }
          logger.info('[data-service] HTTP server closed');
          try {
            if (typeof lifecycle.cleanup === 'function') await Promise.resolve(lifecycle.cleanup());
          } catch (e: any) {
            logger.error('[data-service] cleanup failed', { message: e?.message, stack: e?.stack });
          } finally {
            process.exit(0);
          }
        });
        setTimeout(() => {
          logger.warn('[data-service] Forced shutdown after 10s');
          process.exit(1);
        }, 10_000).unref();
      };

      process.on('SIGINT', () => shutdown('SIGINT'));
      process.on('SIGTERM', () => shutdown('SIGTERM'));
      process.on('uncaughtException', (err: any) => {
        logger.error('[data-service] Uncaught exception', { message: err?.message, stack: err?.stack });
      });
      process.on('unhandledRejection', (reason: any) => {
        logger.error('[data-service] Unhandled rejection', {
          reason: reason?.message || String(reason),
          stack: reason?.stack,
        });
      });
    } catch (e: any) {
      logger.error('[data-service] Startup failed', { message: e?.message, stack: e?.stack });
      process.exit(1);
    }
  }
}

if (require.main === module) {
  new Server().start().catch((err) => {
    logger.error('[data-service] Failed to start server', { message: err?.message, stack: err?.stack });
    process.exit(1);
  });
}

export default Server;



------------------------------------------------------------
FILE: backend\data-service\src\services\AssetService.ts
------------------------------------------------------------
// src/services/AssetService.ts
import { Asset, Column } from '../controllers/AssetController';
import { logger } from '../utils/logger';
import { DatabaseService } from './DatabaseService';

export interface AssetFilters {
  search?: string;
  type?: string;
  dataSourceId?: string;
  status?: string;
  tags?: string[];
  sensitivity?: string;
}

export interface AssetPagination {
  page: number;
  limit: number;
}

export interface AssetResult {
  assets: Asset[];
  total: number;
  page: number;
  limit: number;
  totalPages: number;
}

export interface AssetLineage {
  upstream: Asset[];
  downstream: Asset[];
  relationships: LineageRelationship[];
}

export interface LineageRelationship {
  fromAsset: string;
  toAsset: string;
  type: 'table_to_view' | 'procedure_call' | 'data_flow' | 'dependency';
  description?: string;
}

export interface AssetStats {
  accessCount: number;
  lastAccessed: Date | null;
  avgQueryTime: number;
  dataVolume: {
    current: number;
    trend: 'increasing' | 'decreasing' | 'stable';
    changePercent: number;
  };
  qualityScore: number;
  usageMetrics: {
    date: string;
    count: number;
  }[];
}

export class AssetService {
  private db: DatabaseService;

  constructor() {
    this.db = new DatabaseService();
  }

  /**
   * Get assets with filtering and pagination
   */
  public async getAssets(filters: AssetFilters, pagination: AssetPagination): Promise<AssetResult> {
    try {
      const { page, limit } = pagination;
      const offset = (page - 1) * limit;

      // Build dynamic WHERE clause
      const conditions: string[] = [];
      const params: any[] = [];
      let paramIndex = 1;

      if (filters.search) {
        conditions.push(`(a.name ILIKE $${paramIndex} OR a.description ILIKE $${paramIndex})`);
        params.push(`%${filters.search}%`);
        paramIndex++;
      }

      if (filters.type) {
        conditions.push(`a.type = $${paramIndex}`);
        params.push(filters.type);
        paramIndex++;
      }

      if (filters.dataSourceId) {
        conditions.push(`a.data_source_id = $${paramIndex}`);
        params.push(filters.dataSourceId);
        paramIndex++;
      }

      if (filters.status) {
        conditions.push(`a.status = $${paramIndex}`);
        params.push(filters.status);
        paramIndex++;
      }

      if (filters.sensitivity) {
        conditions.push(`a.metadata->>'sensitivity' = $${paramIndex}`);
        params.push(filters.sensitivity);
        paramIndex++;
      }

      if (filters.tags && filters.tags.length > 0) {
        conditions.push(`a.tags && $${paramIndex}`);
        params.push(filters.tags);
        paramIndex++;
      }

      const whereClause = conditions.length > 0 ? `WHERE ${conditions.join(' AND ')}` : '';

      // Count query
      const countQuery = `
        SELECT COUNT(*) as total
        FROM assets a
        ${whereClause}
      `;

      // Data query
      const dataQuery = `
        SELECT 
          a.*,
          ds.name as data_source_name,
          ds.type as data_source_type
        FROM assets a
        LEFT JOIN data_sources ds ON a.data_source_id = ds.id
        ${whereClause}
        ORDER BY a.updated_at DESC
        LIMIT $${paramIndex} OFFSET $${paramIndex + 1}
      `;

      params.push(limit, offset);

      const [countResult, dataResult] = await Promise.all([
        this.db.query(countQuery, params.slice(0, -2)),
        this.db.query(dataQuery, params)
      ]);

      const total = parseInt(countResult.rows[0].total);
      const totalPages = Math.ceil(total / limit);

      const assets: Asset[] = dataResult.rows.map(row => ({
        id: row.id,
        name: row.name,
        type: row.type,
        dataSourceId: row.data_source_id,
        schemaName: row.schema_name,
        tableName: row.table_name,
        description: row.description,
        columns: row.columns || [],
        tags: row.tags || [],
        status: row.status,
        createdAt: new Date(row.created_at),
        updatedAt: new Date(row.updated_at),
        metadata: row.metadata || {},
      }));

      return {
        assets,
        total,
        page,
        limit,
        totalPages,
      };
    } catch (error) {
      logger.error('Error in getAssets:', error);
      throw new Error('Failed to fetch assets');
    }
  }

  /**
   * Get asset by ID
   */
  public async getAssetById(id: string): Promise<Asset | null> {
    try {
      const query = `
        SELECT 
          a.*,
          ds.name as data_source_name,
          ds.type as data_source_type
        FROM assets a
        LEFT JOIN data_sources ds ON a.data_source_id = ds.id
        WHERE a.id = $1
      `;

      const result = await this.db.query(query, [id]);

      if (result.rows.length === 0) {
        return null;
      }

      const row = result.rows[0];
      return {
        id: row.id,
        name: row.name,
        type: row.type,
        dataSourceId: row.data_source_id,
        schemaName: row.schema_name,
        tableName: row.table_name,
        description: row.description,
        columns: row.columns || [],
        tags: row.tags || [],
        status: row.status,
        createdAt: new Date(row.created_at),
        updatedAt: new Date(row.updated_at),
        metadata: row.metadata || {},
      };
    } catch (error) {
      logger.error('Error in getAssetById:', error);
      throw new Error('Failed to fetch asset');
    }
  }

  /**
   * Create a new asset
   */
  public async createAsset(assetData: Partial<Asset>): Promise<Asset> {
    try {
      const {
        name,
        type,
        dataSourceId,
        schemaName,
        tableName,
        description,
        columns,
        tags,
        status = 'active',
        metadata = {}
      } = assetData;

      const query = `
        INSERT INTO assets (
          name, type, data_source_id, schema_name, table_name,
          description, columns, tags, status, metadata
        )
        VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10)
        RETURNING *
      `;

      const values = [
        name,
        type,
        dataSourceId,
        schemaName,
        tableName,
        description,
        JSON.stringify(columns || []),
        tags || [],
        status,
        JSON.stringify(metadata)
      ];

      const result = await this.db.query(query, values);
      return this.mapRowToAsset(result.rows[0]);
    } catch (error) {
      logger.error('Error in createAsset:', error);
      throw new Error('Failed to create asset');
    }
  }

  /**
   * Search assets
   */
  public async searchAssets(
    filters: { search: string; type?: string },
    pagination: AssetPagination
  ): Promise<AssetResult> {
    try {
      const { page, limit } = pagination;
      const offset = (page - 1) * limit;

      // Build search query with full-text search
      const conditions: string[] = [];
      const params: any[] = [];
      let paramIndex = 1;

      if (filters.search) {
        conditions.push(`(
          to_tsvector('english', coalesce(a.name, '') || ' ' || coalesce(a.description, '')) 
          @@ plainto_tsquery('english', $${paramIndex})
          OR a.name ILIKE $${paramIndex + 1}
          OR a.description ILIKE $${paramIndex + 1}
        )`);
        params.push(filters.search, `%${filters.search}%`);
        paramIndex += 2;
      }

      if (filters.type) {
        conditions.push(`a.type = $${paramIndex}`);
        params.push(filters.type);
        paramIndex++;
      }

      const whereClause = conditions.length > 0 ? `WHERE ${conditions.join(' AND ')}` : '';

      // Count query
      const countQuery = `
        SELECT COUNT(*) as total
        FROM assets a
        ${whereClause}
      `;

      // Data query
      const dataQuery = `
        SELECT 
          a.*,
          ds.name as data_source_name,
          ds.type as data_source_type,
          ts_rank(to_tsvector('english', coalesce(a.name, '') || ' ' || coalesce(a.description, '')), 
                   plainto_tsquery('english', $1)) as search_rank
        FROM assets a
        LEFT JOIN data_sources ds ON a.data_source_id = ds.id
        ${whereClause}
        ORDER BY ${filters.search ? 'search_rank DESC,' : ''} a.updated_at DESC
        LIMIT $${paramIndex} OFFSET $${paramIndex + 1}
      `;

      params.push(limit, offset);

      const [countResult, dataResult] = await Promise.all([
        this.db.query(countQuery, params.slice(0, -2)),
        this.db.query(dataQuery, params)
      ]);

      const total = parseInt(countResult.rows[0].total);
      const totalPages = Math.ceil(total / limit);

      const assets: Asset[] = dataResult.rows.map(row => this.mapRowToAsset(row));

      return {
        assets,
        total,
        page,
        limit,
        totalPages,
      };
    } catch (error) {
      logger.error('Error in searchAssets:', error);
      throw new Error('Failed to search assets');
    }
  }

  /**
   * Get asset schema details
   */
  public async getAssetSchema(id: string): Promise<Column[] | null> {
    try {
      const query = `
        SELECT columns
        FROM assets
        WHERE id = $1
      `;

      const result = await this.db.query(query, [id]);

      if (result.rows.length === 0) {
        return null;
      }

      return result.rows[0].columns || [];
    } catch (error) {
      logger.error('Error in getAssetSchema:', error);
      throw new Error('Failed to fetch asset schema');
    }
  }

  /**
   * Get asset lineage
   */
  public async getAssetLineage(id: string, direction: 'upstream' | 'downstream' | 'both'): Promise<AssetLineage> {
    try {
      // Mock implementation - in real scenario, you'd analyze SQL queries, ETL processes, etc.
      const upstreamQuery = `
        SELECT DISTINCT a.*
        FROM assets a
        JOIN asset_lineage al ON a.id = al.upstream_asset_id
        WHERE al.downstream_asset_id = $1
      `;

      const downstreamQuery = `
        SELECT DISTINCT a.*
        FROM assets a
        JOIN asset_lineage al ON a.id = al.downstream_asset_id
        WHERE al.upstream_asset_id = $1
      `;

      const relationshipsQuery = `
        SELECT *
        FROM asset_lineage
        WHERE upstream_asset_id = $1 OR downstream_asset_id = $1
      `;

      let upstream: Asset[] = [];
      let downstream: Asset[] = [];

      if (direction === 'upstream' || direction === 'both') {
        const upstreamResult = await this.db.query(upstreamQuery, [id]);
        upstream = upstreamResult.rows.map(this.mapRowToAsset);
      }

      if (direction === 'downstream' || direction === 'both') {
        const downstreamResult = await this.db.query(downstreamQuery, [id]);
        downstream = downstreamResult.rows.map(this.mapRowToAsset);
      }

      const relationshipsResult = await this.db.query(relationshipsQuery, [id]);
      const relationships: LineageRelationship[] = relationshipsResult.rows.map(row => ({
        fromAsset: row.upstream_asset_id,
        toAsset: row.downstream_asset_id,
        type: row.relationship_type,
        description: row.description,
      }));

      return {
        upstream,
        downstream,
        relationships,
      };
    } catch (error) {
      logger.error('Error in getAssetLineage:', error);
      throw new Error('Failed to fetch asset lineage');
    }
  }

  /**
   * Update asset
   */
  public async updateAsset(id: string, updateData: Partial<Asset>): Promise<Asset | null> {
    try {
      const setClause: string[] = [];
      const params: any[] = [];
      let paramIndex = 1;

      if (updateData.name) {
        setClause.push(`name = $${paramIndex++}`);
        params.push(updateData.name);
      }

      if (updateData.description) {
        setClause.push(`description = $${paramIndex++}`);
        params.push(updateData.description);
      }

      if (updateData.status) {
        setClause.push(`status = $${paramIndex++}`);
        params.push(updateData.status);
      }

      if (updateData.tags) {
        setClause.push(`tags = $${paramIndex++}`);
        params.push(updateData.tags);
      }

      if (updateData.metadata) {
        setClause.push(`metadata = $${paramIndex++}`);
        params.push(JSON.stringify(updateData.metadata));
      }

      setClause.push(`updated_at = NOW()`);
      params.push(id);

      const query = `
        UPDATE assets
        SET ${setClause.join(', ')}
        WHERE id = $${paramIndex}
        RETURNING *
      `;

      const result = await this.db.query(query, params);

      if (result.rows.length === 0) {
        return null;
      }

      return this.mapRowToAsset(result.rows[0]);
    } catch (error) {
      logger.error('Error in updateAsset:', error);
      throw new Error('Failed to update asset');
    }
  }

  /**
   * Add tags to asset
   */
  public async addTags(id: string, tags: string[]): Promise<Asset | null> {
    try {
      const query = `
        UPDATE assets
        SET tags = COALESCE(tags, '{}') || $1::text[],
            updated_at = NOW()
        WHERE id = $2
        RETURNING *
      `;

      const result = await this.db.query(query, [tags, id]);

      if (result.rows.length === 0) {
        return null;
      }

      return this.mapRowToAsset(result.rows[0]);
    } catch (error) {
      logger.error('Error in addTags:', error);
      throw new Error('Failed to add tags');
    }
  }

  /**
   * Remove tags from asset
   */
  public async removeTags(id: string, tags: string[]): Promise<Asset | null> {
    try {
      const query = `
        UPDATE assets
        SET tags = ARRAY(SELECT unnest(tags) EXCEPT SELECT unnest($1::text[])),
            updated_at = NOW()
        WHERE id = $2
        RETURNING *
      `;

      const result = await this.db.query(query, [tags, id]);

      if (result.rows.length === 0) {
        return null;
      }

      return this.mapRowToAsset(result.rows[0]);
    } catch (error) {
      logger.error('Error in removeTags:', error);
      throw new Error('Failed to remove tags');
    }
  }

  /**
   * Get asset usage statistics
   */
  public async getAssetStats(id: string, period: string): Promise<AssetStats> {
    try {
      // Mock implementation - in real scenario, you'd aggregate from usage logs
      const statsQuery = `
        SELECT 
          COALESCE(usage.access_count, 0) as access_count,
          usage.last_accessed,
          COALESCE(usage.avg_query_time, 0) as avg_query_time,
          COALESCE(metadata->>'rowCount', '0')::bigint as current_volume,
          COALESCE((metadata->>'qualityScore')::numeric, 85) as quality_score
        FROM assets a
        LEFT JOIN asset_usage_stats usage ON a.id = usage.asset_id
        WHERE a.id = $1
      `;

      const result = await this.db.query(statsQuery, [id]);
      
      if (result.rows.length === 0) {
        throw new Error('Asset not found');
      }

      const row = result.rows[0];

      // Mock usage metrics for the period
      const usageMetrics = this.generateMockUsageMetrics(period);

      return {
        accessCount: row.access_count,
        lastAccessed: row.last_accessed ? new Date(row.last_accessed) : null,
        avgQueryTime: row.avg_query_time,
        dataVolume: {
          current: row.current_volume,
          trend: 'increasing',
          changePercent: 12.5,
        },
        qualityScore: row.quality_score,
        usageMetrics,
      };
    } catch (error) {
      logger.error('Error in getAssetStats:', error);
      throw new Error('Failed to fetch asset stats');
    }
  }

  /**
   * Get asset profile/data preview
   */
  public async getAssetProfile(id: string): Promise<{
    asset: Asset;
    profile: {
      rowCount: number;
      columnCount: number;
      dataTypes: Record<string, number>;
      nullCounts: Record<string, number>;
      sampleData: any[];
      lastProfiledAt: Date;
    };
  } | null> {
    try {
      const asset = await this.getAssetById(id);
      if (!asset) {
        return null;
      }

      // Mock profile data - in real implementation, this would connect to the data source
      const profile = {
        rowCount: Math.floor(Math.random() * 1000000) + 1000,
        columnCount: asset.columns?.length || 0,
        dataTypes: {
          'string': Math.floor(Math.random() * 10) + 1,
          'integer': Math.floor(Math.random() * 5) + 1,
          'decimal': Math.floor(Math.random() * 3) + 1,
          'date': Math.floor(Math.random() * 2) + 1,
          'boolean': Math.floor(Math.random() * 2),
        },
        nullCounts: asset.columns?.reduce((acc, col) => {
          acc[col.name] = Math.floor(Math.random() * 100);
          return acc;
        }, {} as Record<string, number>) || {},
        sampleData: [
          // Mock sample data
          { id: 1, name: 'Sample Row 1', value: 100 },
          { id: 2, name: 'Sample Row 2', value: 200 },
          { id: 3, name: 'Sample Row 3', value: 300 },
        ],
        lastProfiledAt: new Date(),
      };

      return {
        asset,
        profile,
      };
    } catch (error) {
      logger.error('Error in getAssetProfile:', error);
      throw new Error('Failed to get asset profile');
    }
  }

  /**
   * Sync asset metadata from data source
   */
  public async syncAsset(id: string): Promise<{ success: boolean; updatedFields: string[] }> {
    try {
      // Mock implementation - in real scenario, you'd connect to the data source
      // and refresh metadata (row counts, schema changes, etc.)
      
      const updateQuery = `
        UPDATE assets
        SET 
          metadata = metadata || '{"lastSyncAt": "' || NOW() || '", "syncStatus": "completed"}',
          updated_at = NOW()
        WHERE id = $1
        RETURNING *
      `;

      const result = await this.db.query(updateQuery, [id]);

      if (result.rows.length === 0) {
        throw new Error('Asset not found');
      }

      return {
        success: true,
        updatedFields: ['metadata', 'rowCount', 'lastSyncAt'],
      };
    } catch (error) {
      logger.error('Error in syncAsset:', error);
      throw new Error('Failed to sync asset');
    }
  }

  /**
   * Delete asset
   */
  public async deleteAsset(id: string): Promise<boolean> {
    try {
      const query = `
        DELETE FROM assets
        WHERE id = $1
        RETURNING id
      `;

      const result = await this.db.query(query, [id]);
      return result.rows.length > 0;
    } catch (error) {
      logger.error('Error in deleteAsset:', error);
      throw new Error('Failed to delete asset');
    }
  }

  /**
   * Helper method to map database row to Asset object
   */
  private mapRowToAsset(row: any): Asset {
    return {
      id: row.id,
      name: row.name,
      type: row.type,
      dataSourceId: row.data_source_id,
      schemaName: row.schema_name,
      tableName: row.table_name,
      description: row.description,
      columns: row.columns || [],
      tags: row.tags || [],
      status: row.status,
      createdAt: new Date(row.created_at),
      updatedAt: new Date(row.updated_at),
      metadata: row.metadata || {},
    };
  }

  /**
   * Generate mock usage metrics for testing
   */
  private generateMockUsageMetrics(period: string): { date: string; count: number }[] {
    const days = period === '7d' ? 7 : period === '30d' ? 30 : 90;
    const metrics: { date: string; count: number }[] = [];

    for (let i = days - 1; i >= 0; i--) {
      const date = new Date();
      date.setDate(date.getDate() - i);
      
      metrics.push({
        date: date.toISOString().split('T')[0],
        count: Math.floor(Math.random() * 50) + 10,
      });
    }

    return metrics;
  }
}


------------------------------------------------------------
FILE: backend\data-service\src\services\connectors\azureSql.ts
------------------------------------------------------------
import { ConnectionPool, config as MSSQLConfig, Request } from 'mssql';
import type { ConnectionConfig, ConnectionTestResult } from '../../models/Connection';
import { logger } from '../../utils/logger';
import {
  BaseConnector,
  type Column,
  type QueryResult,
  type Schema,
  type SchemaInfo,
  type Table,
  type View,
} from './base';

export interface AzureSqlConfig {
  server: string;
  database: string;
  user: string;
  password: string;
  port?: number;
  options?: {
    encrypt?: boolean;
    trustServerCertificate?: boolean;
    enableArithAbort?: boolean;
    connectionTimeout?: number;
    requestTimeout?: number;
  };
  pool?: {
    max?: number;
    min?: number;
    idleTimeoutMillis?: number;
  };
}

export class AzureSqlConnector extends BaseConnector {
  private pool: ConnectionPool | null = null;
  private config: AzureSqlConfig;

  constructor(conn: ConnectionConfig) {
    super('azure-sql', conn);
    this.config = this.parseConfig(conn);
  }

  /* â”€â”€â”€â”€â”€â”€â”€â”€â”€ config parsing â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
  private parseConfig(c: ConnectionConfig): AzureSqlConfig {
    const anyC = c as any;
    const trustServerCertificate =
      typeof anyC.trustServerCertificate === 'boolean'
        ? anyC.trustServerCertificate
        : typeof c.ssl === 'object'
        ? (c.ssl as any)?.rejectUnauthorized === false
        : false;

    return {
      server: c.host ?? anyC.server ?? '',
      database: (c.database as string) ?? anyC.db ?? '',
      user: (c.username as string) ?? anyC.user ?? '',
      password: (c.password as string) ?? '',
      port: c.port ?? 1433,
      options: {
        encrypt: true, // Azure SQL requires encrypt
        trustServerCertificate,
        enableArithAbort: true,
        connectionTimeout: anyC.connectionTimeout ?? c.timeout ?? 30_000,
        requestTimeout: anyC.requestTimeout ?? c.timeout ?? 30_000,
      },
      pool: {
        max: anyC.maxConnections ?? 10,
        min: anyC.minConnections ?? 1,
        idleTimeoutMillis: anyC.idleTimeout ?? 30_000,
        ...(anyC.poolOptions ?? {}),
      },
    };
  }

  /* â”€â”€â”€â”€â”€â”€â”€â”€â”€ connect / disconnect â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
  override async connect(): Promise<void> {
    try {
      if (this.pool?.connected) return;

      const poolConfig: MSSQLConfig = {
        server: this.config.server,
        database: this.config.database,
        user: this.config.user,
        password: this.config.password,
        port: this.config.port,
        options: this.config.options,
        pool: this.config.pool,
      };

      this.pool = new ConnectionPool(poolConfig);

      this.pool.on('error', (err: Error) => {
        logger.error('Azure SQL pool error:', err);
        this.emitConnectionEvent('error', err);
      });

      await this.pool.connect();

      (this as any).metrics.connected = true;
      this.emitConnectionEvent('connected', {
        server: this.config.server,
        database: this.config.database,
      });

      logger.info(`Connected to Azure SQL: ${this.config.server}/${this.config.database}`);
    } catch (error) {
      (this as any).metrics.connected = false;
      logger.error('Failed to connect to Azure SQL:', error);
      throw this.createConnectionError(error);
    }
  }

  override async disconnect(): Promise<void> {
    try {
      if (this.pool) {
        this.pool.removeAllListeners?.('error');
        await this.pool.close();
        this.pool = null;
        (this as any).metrics.connected = false;
        this.emitConnectionEvent('disconnected');
        logger.info('Disconnected from Azure SQL');
      }
    } catch (error) {
      logger.error('Error disconnecting from Azure SQL:', error);
      throw error;
    }
  }

  /* â”€â”€â”€â”€â”€â”€â”€â”€â”€ basic ops â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
  override async testConnection(): Promise<ConnectionTestResult> {
    const t0 = Date.now();
    try {
      await this.connect();
      const req = new Request(this.pool!);
      const result = await req.query('SELECT @@VERSION AS version, DB_NAME() AS database_name');
      return {
        success: true,
        responseTime: Date.now() - t0,
        details: {
          version: (result as any)?.recordset?.[0]?.version,
          serverInfo: {
            type: 'Azure SQL Database',
            database: (result as any)?.recordset?.[0]?.database_name,
            server: this.config.server,
          },
          capabilities: ['SQL', 'ACID', 'Transactions', 'Stored Procedures', 'Functions'],
        },
        testedAt: new Date(),
      };
    } catch (error: any) {
      return {
        success: false,
        responseTime: Date.now() - t0,
        error: error?.message || 'Unknown error',
        testedAt: new Date(),
      };
    }
  }

  override async executeQuery(query: string, params?: any[]): Promise<QueryResult> {
    return this.executeWithMetrics(async () => {
      await this.ensureConnected();
      const req = new Request(this.pool!);

      if (params?.length) {
        params.forEach((p, i) => req.input(`p${i}`, p));
        let idx = 0;
        query = query.replace(/\?/g, () => `@p${idx++}`);
      }

      const r = await req.query(query);
      return {
        rows: (r as any).recordset ?? [],
        rowCount: (r as any).rowsAffected?.[0] ?? ((r as any).recordset?.length || 0),
        columns: (r as any).recordset?.columns || {},
      };
    });
  }

  /* â”€â”€â”€â”€â”€â”€â”€â”€â”€ schema & metadata â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
  override async getSchema(): Promise<SchemaInfo> {
    await this.ensureConnected();

    const schemaQuery = `
      SELECT 
        t.TABLE_SCHEMA,
        t.TABLE_NAME,
        t.TABLE_TYPE,
        c.COLUMN_NAME,
        c.DATA_TYPE,
        c.IS_NULLABLE,
        c.COLUMN_DEFAULT,
        c.CHARACTER_MAXIMUM_LENGTH,
        c.NUMERIC_PRECISION,
        c.NUMERIC_SCALE,
        CASE WHEN pk.COLUMN_NAME IS NOT NULL THEN 1 ELSE 0 END AS IS_PRIMARY_KEY
      FROM INFORMATION_SCHEMA.TABLES t
      LEFT JOIN INFORMATION_SCHEMA.COLUMNS c
        ON t.TABLE_NAME = c.TABLE_NAME AND t.TABLE_SCHEMA = c.TABLE_SCHEMA
      LEFT JOIN (
        SELECT ku.TABLE_SCHEMA, ku.TABLE_NAME, ku.COLUMN_NAME
        FROM INFORMATION_SCHEMA.TABLE_CONSTRAINTS tc
        INNER JOIN INFORMATION_SCHEMA.KEY_COLUMN_USAGE ku
          ON tc.CONSTRAINT_NAME = ku.CONSTRAINT_NAME
          AND tc.TABLE_SCHEMA = ku.TABLE_SCHEMA
        WHERE tc.CONSTRAINT_TYPE = 'PRIMARY KEY'
      ) pk ON c.TABLE_SCHEMA = pk.TABLE_SCHEMA 
         AND c.TABLE_NAME   = pk.TABLE_NAME 
         AND c.COLUMN_NAME  = pk.COLUMN_NAME
      WHERE t.TABLE_TYPE IN ('BASE TABLE', 'VIEW')
      ORDER BY t.TABLE_SCHEMA, t.TABLE_NAME, c.ORDINAL_POSITION
    `;

    const res = await this.executeQuery(schemaQuery);
    return this.buildSchemaInfo(res.rows as any[]);
  }

  private buildSchemaInfo(rows: any[]): SchemaInfo {
    const bySchema = new Map<string, { tables: Map<string, Table>; views: Map<string, View> }>();

    for (const r of rows) {
      const sName = r.TABLE_SCHEMA as string;
      const tName = r.TABLE_NAME as string;
      const isView = (r.TABLE_TYPE as string) === 'VIEW';

      if (!bySchema.has(sName)) bySchema.set(sName, { tables: new Map(), views: new Map() });
      const bucket = bySchema.get(sName)!;

      if (isView) {
        const vmap = bucket.views;
        if (!vmap.has(tName)) {
          vmap.set(tName, { name: tName, schema: sName, columns: [], definition: undefined });
        }
        if (r.COLUMN_NAME) {
          const col: Column = {
            name: r.COLUMN_NAME,
            dataType: r.DATA_TYPE,
            nullable: r.IS_NULLABLE === 'YES',
            defaultValue: r.COLUMN_DEFAULT ?? undefined,
            maxLength: r.CHARACTER_MAXIMUM_LENGTH ?? undefined,
            precision: r.NUMERIC_PRECISION ?? undefined,
            scale: r.NUMERIC_SCALE ?? undefined,
            isPrimaryKey: r.IS_PRIMARY_KEY === 1,
          };
          vmap.get(tName)!.columns.push(col);
        }
      } else {
        const tmap = bucket.tables;
        if (!tmap.has(tName)) {
          tmap.set(tName, { name: tName, schema: sName, columns: [], primaryKeys: [], foreignKeys: [], indexes: [] });
        }
        if (r.COLUMN_NAME) {
          const col: Column = {
            name: r.COLUMN_NAME,
            dataType: r.DATA_TYPE,
            nullable: r.IS_NULLABLE === 'YES',
            defaultValue: r.COLUMN_DEFAULT ?? undefined,
            maxLength: r.CHARACTER_MAXIMUM_LENGTH ?? undefined,
            precision: r.NUMERIC_PRECISION ?? undefined,
            scale: r.NUMERIC_SCALE ?? undefined,
            isPrimaryKey: r.IS_PRIMARY_KEY === 1,
          };
          const tbl = tmap.get(tName)!;
          tbl.columns.push(col);
          if (col.isPrimaryKey) tbl.primaryKeys.push(col.name);
        }
      }
    }

    const schemas: Schema[] = [];
    let totalTables = 0;
    let totalViews = 0;
    let totalColumns = 0;

    for (const [name, { tables, views }] of bySchema) {
      const tablesArr = Array.from(tables.values());
      const viewsArr = Array.from(views.values());
      totalTables += tablesArr.length;
      totalViews += viewsArr.length;
      totalColumns +=
        tablesArr.reduce((n, t) => n + t.columns.length, 0) +
        viewsArr.reduce((n, v) => n + v.columns.length, 0);
      schemas.push({ name, tables: tablesArr, views: viewsArr });
    }

    return { schemas, totalTables, totalViews, totalColumns };
  }

  override async validateQuery(query: string): Promise<{ valid: boolean; error?: string }> {
    try {
      await this.ensureConnected();
      const req = new Request(this.pool!);
      await req.batch('SET PARSEONLY ON;');
      try {
        await req.query(query);
        await req.batch('SET PARSEONLY OFF;');
        return { valid: true };
      } catch (err: any) {
        await req.batch('SET PARSEONLY OFF;');
        return { valid: false, error: err?.message || 'Invalid query' };
      }
    } catch (e: any) {
      return { valid: false, error: e?.message || 'Connection error during validation' };
    }
  }

  override async getSampleData(tableName: string, schemaName: string = 'dbo', limit: number = 100): Promise<QueryResult> {
    await this.ensureConnected();
    const full = `${this.escapeIdentifier(schemaName)}.${this.escapeIdentifier(tableName)}`;
    const q = `SELECT TOP (${limit}) * FROM ${full}`;
    return this.executeQuery(q);
  }

  async getConnectionInfo(): Promise<any> {
    await this.ensureConnected();
    const q = `
      SELECT 
        @@VERSION AS version,
        @@SERVERNAME AS server_name,
        DB_NAME() AS database_name,
        SUSER_NAME() AS login_name,
        @@LANGUAGE AS language,
        GETDATE() AS server_time
    `;
    const r = await this.executeQuery(q);
    return (r.rows as any[])?.[0];
  }

  /* â”€â”€â”€â”€â”€â”€â”€â”€â”€ internals â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
  private async ensureConnected(): Promise<void> {
    if (!this.pool || !this.pool.connected) await this.connect();
  }

  protected override escapeIdentifier(identifier: string): string {
    return `[${String(identifier).replace(/]/g, ']]')}]`;
  }

  private createConnectionError(error: any): Error {
    const message = error instanceof Error ? error.message : 'Connection failed';
    return new Error(`Azure SQL connection error: ${message}`);
  }

  private createQueryError(error: any, query: string): Error {
    const message = error instanceof Error ? error.message : 'Query failed';
    return new Error(`Azure SQL query error: ${message} (Query: ${query.substring(0, 120)}...)`);
  }

  override getMetrics(): any {
    const p: any = this.pool as any;
    const poolStats = p?.pool ?? p;
    return {
      type: 'azure-sql',
      connected: !!this.pool?.connected,
      server: this.config.server,
      database: this.config.database,
      poolSize: poolStats?.size ?? 0,
      poolAvailable: poolStats?.available ?? 0,
      poolPending: poolStats?.pending ?? 0,
    };
  }
}

export default AzureSqlConnector;



------------------------------------------------------------
FILE: backend\data-service\src\services\connectors\base.ts
------------------------------------------------------------
import { EventEmitter } from "events";
import type { ConnectionConfig } from "../../models/Connection";
import type { ConnectionTestResult } from "../../models/DataSource";

export interface ConnectorMetrics {
  type: string;
  connected: boolean;
  totalQueries: number;
  successfulQueries: number;
  failedQueries: number;
  averageQueryTime: number;
  lastQueryAt?: Date;
  lastErrorAt?: Date;
  uptime: number;
}

export interface QueryResult {
  rows: any[];
  rowCount: number;
  columns?: any;
  executionTime?: number;
  metadata?: any;
}

export interface SchemaInfo {
  schemas: Schema[];
  totalTables: number;
  totalViews: number;
  totalColumns: number;
}

export interface Schema {
  name: string;
  tables: Table[];
  views: View[];
}

export interface Table {
  name: string;
  schema: string;
  columns: Column[];
  primaryKeys: string[];
  foreignKeys: ForeignKey[];
  indexes: Index[];
  rowCount?: number;
  sizeBytes?: number;
  lastModified?: Date;
}

export interface View {
  name: string;
  schema: string;
  columns: Column[];
  definition?: string;
}

export interface Column {
  name: string;
  dataType: string;
  nullable: boolean;
  defaultValue?: string;
  maxLength?: number;
  precision?: number;
  scale?: number;
  isPrimaryKey?: boolean;
  isForeignKey?: boolean;
  isUnique?: boolean;
  comment?: string;
}

export interface ForeignKey {
  name: string;
  column: string;
  referencedTable: string;
  referencedColumn: string;
  referencedSchema?: string;
}

export interface Index {
  name: string;
  columns: string[];
  unique: boolean;
  type: string;
  clustered?: boolean;
}

export abstract class BaseConnector<C extends ConnectionConfig = ConnectionConfig> extends EventEmitter {
  protected type: string;
  protected connectionConfig: C;
  protected metrics: ConnectorMetrics;
  protected startTime: Date;

  constructor(type: string, connectionConfig: C) {
    super();
    this.type = type;
    this.connectionConfig = connectionConfig;
    this.startTime = new Date();
    this.metrics = {
      type,
      connected: false,
      totalQueries: 0,
      successfulQueries: 0,
      failedQueries: 0,
      averageQueryTime: 0,
      uptime: 0,
    };
  }

  abstract connect(): Promise<void>;
  abstract disconnect(): Promise<void>;
  abstract testConnection(): Promise<ConnectionTestResult>;
  abstract executeQuery(query: string, params?: any[]): Promise<QueryResult>;
  abstract getSchema(): Promise<SchemaInfo>;

  // Optional lifecycle hook
  cleanup?(): Promise<void> | void;

  async validateQuery(query: string): Promise<{ valid: boolean; error?: string }> {
    try {
      await this.executeQuery(`EXPLAIN ${query}`);
      return { valid: true };
    } catch (error: any) {
      return { valid: false, error: error?.message ?? "Query validation failed" };
    }
  }

  async getTableStats(tableName: string, schemaName?: string): Promise<any> {
    return {
      tableName,
      schemaName,
      rowCount: 0,
      sizeBytes: 0,
      message: "Table statistics not available for this connector type",
    };
  }

  async getSampleData(tableName: string, schemaName?: string, limit = 100): Promise<QueryResult> {
    const full = schemaName ? `${schemaName}.${tableName}` : tableName;
    const q = `SELECT * FROM ${full} LIMIT ${limit}`;
    return this.executeQuery(q);
  }

  async getColumnDistinctValues(
    tableName: string,
    columnName: string,
    schemaName?: string,
    limit = 100
  ): Promise<any[]> {
    const full = schemaName ? `${schemaName}.${tableName}` : tableName;
    const q = `SELECT DISTINCT ${columnName} FROM ${full} LIMIT ${limit}`;
    const result = await this.executeQuery(q);
    return result.rows.map((r) => r[columnName]);
  }

  getMetrics(): ConnectorMetrics {
    return { ...this.metrics, uptime: Date.now() - this.startTime.getTime() };
  }

  protected updateQueryMetrics(executionTime: number, success: boolean): void {
    this.metrics.totalQueries++;
    if (success) {
      this.metrics.successfulQueries++;
      this.metrics.lastQueryAt = new Date();
      const totalTime =
        this.metrics.averageQueryTime * (this.metrics.successfulQueries - 1) + executionTime;
      this.metrics.averageQueryTime = totalTime / this.metrics.successfulQueries;
    } else {
      this.metrics.failedQueries++;
      this.metrics.lastErrorAt = new Date();
    }
  }

  protected async executeWithMetrics<T>(operation: () => Promise<T>): Promise<T> {
    const t0 = Date.now();
    let ok = false;
    try {
      const result = await operation();
      ok = true;
      return result;
    } finally {
      const dt = Date.now() - t0;
      this.updateQueryMetrics(dt, ok);
    }
  }

  protected emitConnectionEvent(event: "connected" | "disconnected" | "error", data?: any): void {
    this.emit(event, { connector: this.type, timestamp: new Date(), data });
  }

  async healthCheck(): Promise<{
    status: "healthy" | "unhealthy" | "degraded";
    latency?: number;
    error?: string;
    details?: any;
  }> {
    try {
      const r = await this.testConnection();
      if (r.success) {
        return {
          status: (r.responseTime ?? 0) > 5000 ? "degraded" : "healthy",
          latency: r.responseTime,
          details: r.details,
        };
      }
      return { status: "unhealthy", error: r.error, details: r.details };
    } catch (e: any) {
      return { status: "unhealthy", error: e?.message ?? "Health check failed" };
    }
  }

  getConnectionConfig(): C {
    const clone: any = { ...this.connectionConfig };
    if (clone.password) clone.password = "[REDACTED]";
    return clone as C;
  }

  updateConnectionConfig(patch: Partial<C>): void {
    this.connectionConfig = { ...this.connectionConfig, ...patch };
  }

  protected escapeIdentifier(identifier: string): string {
    return `"${String(identifier).replace(/"/g, '""')}"`;
  }
  protected escapeLiteral(literal: string): string {
    return `'${String(literal).replace(/'/g, "''")}'`;
  }

  protected parseConnectionString(cs: string): Record<string, string> {
    const out: Record<string, string> = {};
    cs.split(";").forEach((pair) => {
      const [k, v] = pair.split("=");
      if (k && v) out[k.trim().toLowerCase()] = v.trim();
    });
    return out;
  }

  async getPoolStats(): Promise<{ total: number; active: number; idle: number; waiting: number }> {
    return { total: 1, active: this.metrics.connected ? 1 : 0, idle: 0, waiting: 0 };
  }
}

export default BaseConnector;



------------------------------------------------------------
FILE: backend\data-service\src\services\connectors\factory.ts
------------------------------------------------------------
// backend/data-service/src/services/connectors/factory.ts - FIXED VERSION

import type { ConnectionConfig } from "../../models/Connection";
import type { DataSourceType } from "../../models/DataSource";
import { logger } from "../../utils/logger";
import { AzureSqlConnector } from "./azureSql";
import { BaseConnector } from "./base";

// Fix: Use generic constraint that works with union types
export interface ConnectorConstructor<TConfig extends ConnectionConfig = ConnectionConfig> {
  new (config: TConfig): BaseConnector<TConfig>;
}

/* Normalize common aliases to canonical DataSourceType values */
const normalizeType = (t: string): DataSourceType => {
  const x = (t || "").toLowerCase();
  if (x === "azure_sql" || x === "azure-sql" || x === "sqlserver" || x === "sql-server") return "mssql";
  return x as DataSourceType;
};

export class ConnectorFactory {
  private static connectors: Map<DataSourceType | string, ConnectorConstructor<any>> = new Map();
  private static instances: Map<string, BaseConnector<any>> = new Map();

  /* Register built-ins with proper type casting */
  static {
    // Fix: Use type assertion to handle the union type compatibility
    ConnectorFactory.registerConnector("mssql", AzureSqlConnector as ConnectorConstructor<any>);
    ConnectorFactory.registerConnector("azure-sql", AzureSqlConnector as ConnectorConstructor<any>);
    ConnectorFactory.registerConnector("azure_sql", AzureSqlConnector as ConnectorConstructor<any>);
  }

  static registerConnector(type: DataSourceType | string, ctor: ConnectorConstructor<any>): void {
    ConnectorFactory.connectors.set(type, ctor);
    logger.info(`Registered connector for type: ${type}`);
  }

  static createConnector(config: ConnectionConfig): BaseConnector<ConnectionConfig> {
    const type = normalizeType(config.type as string);
    const Ctor =
      ConnectorFactory.connectors.get(type) || 
      ConnectorFactory.connectors.get(config.type as string);
    
    if (!Ctor) {
      throw new Error(`No connector available for data source type: ${config.type}`);
    }
    
    try {
      const inst = new Ctor(config);
      logger.info(`Created connector instance for type: ${type}`);
      return inst;
    } catch (err: any) {
      logger.error(`Failed to create connector for ${type}:`, err);
      throw new Error(`Failed to create connector: ${err?.message || "Unknown error"}`);
    }
  }

  static async getConnector(dataSourceId: string, config: ConnectionConfig): Promise<BaseConnector<ConnectionConfig>> {
    let c = ConnectorFactory.instances.get(dataSourceId);
    if (!c) {
      c = ConnectorFactory.createConnector(config);
      ConnectorFactory.instances.set(dataSourceId, c);
      
      // Fix: Add proper event handling with type safety
      c.on("disconnected", () => {
        ConnectorFactory.instances.delete(dataSourceId);
        logger.info(`Connector removed from cache: ${dataSourceId}`);
      });
      
      c.on("error", (e) => {
        logger.error(`Connector error [${dataSourceId}]`, e);
      });
    }
    return c;
  }

  static async removeConnector(dataSourceId: string): Promise<void> {
    const c = ConnectorFactory.instances.get(dataSourceId);
    if (c) {
      try {
        // Fix: Check if cleanup method exists before calling
        if (c && typeof (c as any).cleanup === "function") {
          await (c as any).cleanup();
        }
      } catch (e) {
        logger.error(`Cleanup error for ${dataSourceId}`, e);
      } finally {
        ConnectorFactory.instances.delete(dataSourceId);
      }
    }
  }

  static async testConnection(config: ConnectionConfig): Promise<any> {
    const c = ConnectorFactory.createConnector(config);
    try {
      const result = await c.testConnection();
      await c.disconnect();
      return result;
    } catch (e) {
      try {
        await c.disconnect();
      } catch (disconnectError) {
        logger.warn("Error during connector cleanup after test failure:", disconnectError);
      }
      throw e;
    }
  }

  // Fix: Updated helper methods with better type safety
  static getAvailableTypes(): DataSourceType[] {
    const uniq = new Set<DataSourceType>();
    for (const k of ConnectorFactory.connectors.keys()) {
      const normalized = normalizeType(String(k));
      if (normalized) {
        uniq.add(normalized);
      }
    }
    return Array.from(uniq);
  }

  static isTypeSupported(type: DataSourceType | string): boolean {
    const normalized = normalizeType(String(type));
    return ConnectorFactory.connectors.has(normalized) || ConnectorFactory.connectors.has(type);
  }

  // Fix: More robust config validation with type guards
  static validateConfig(type: DataSourceType | string, config: any): string[] {
    const normalizedType = normalizeType(String(type));
    const errors: string[] = [];

    // Basic validation
    if (!config || typeof config !== 'object') {
      errors.push("Configuration must be an object");
      return errors;
    }

    switch (normalizedType) {
      case "postgresql":
      case "mysql":
      case "mssql": {
        const hasConnStr = config.connectionString && typeof config.connectionString === 'string';
        if (!hasConnStr) {
          if (!config.host || typeof config.host !== 'string') {
            errors.push("Host is required when not using connection string");
          }
          if (!config.database || typeof config.database !== 'string') {
            errors.push("Database is required when not using connection string");
          }
          if (!config.username || typeof config.username !== 'string') {
            errors.push("Username is required when not using connection string");
          }
        }
        if (config.port !== undefined && (typeof config.port !== 'number' || config.port < 1 || config.port > 65535)) {
          errors.push("Port must be a number between 1 and 65535");
        }
        break;
      }
      case "mongodb": {
        const hasConnStr = config.connectionString && typeof config.connectionString === 'string';
        const hasHost = config.host && typeof config.host === 'string';
        if (!hasConnStr && !hasHost) {
          errors.push("Connection string or host is required");
        }
        break;
      }
      case "s3": {
        if (!config.bucket || typeof config.bucket !== 'string') {
          errors.push("Bucket is required");
        }
        if (!config.region || typeof config.region !== 'string') {
          errors.push("Region is required");
        }
        if (!config.accessKeyId || typeof config.accessKeyId !== 'string') {
          errors.push("Access Key ID is required");
        }
        if (!config.secretAccessKey || typeof config.secretAccessKey !== 'string') {
          errors.push("Secret Access Key is required");
        }
        break;
      }
      case "api": {
        if (!config.baseUrl || typeof config.baseUrl !== 'string') {
          errors.push("Base URL is required");
        } else {
          try {
            new URL(config.baseUrl);
          } catch {
            errors.push("Base URL must be a valid URL");
          }
        }
        break;
      }
      default:
        // For unknown types, do basic validation
        if (config.timeout !== undefined && (typeof config.timeout !== 'number' || config.timeout <= 0)) {
          errors.push("Timeout must be a positive number");
        }
        break;
    }

    return errors;
  }

  // Rest of your existing methods remain the same
  static getConfigTemplate(type: DataSourceType | string): any {
    const normalized = normalizeType(String(type));
    switch (normalized) {
      case "postgresql":
        return { 
          host: "localhost", port: 5432, database: "", username: "", password: "", 
          ssl: false, timeout: 30000, maxConnections: 10 
        };
      case "mysql":
        return { 
          host: "localhost", port: 3306, database: "", username: "", password: "", 
          ssl: false, timeout: 30000, maxConnections: 10 
        };
      case "mssql":
        return { 
          host: "localhost", port: 1433, database: "", username: "", password: "", 
          ssl: true, timeout: 30000, maxConnections: 10 
        };
      case "mongodb":
        return { 
          connectionString: "mongodb://localhost:27017", database: "", 
          username: "", password: "", timeout: 30000 
        };
      case "s3":
        return { 
          region: "us-east-1", bucket: "", accessKeyId: "", secretAccessKey: "" 
        };
      case "api":
        return { 
          baseUrl: "https://api.example.com", apiKey: "", timeout: 30000, headers: {} 
        };
      default:
        return { timeout: 30000 };
    }
  }

  static getActiveConnectors(): Map<string, BaseConnector<any>> {
    return new Map(ConnectorFactory.instances);
  }

  static getAllMetrics(): Record<string, any> {
    const out: Record<string, any> = {};
    for (const [id, c] of ConnectorFactory.instances) {
      try {
        out[id] = (c as any).getMetrics?.() || { status: "no metrics available" };
      } catch (e: any) {
        out[id] = { error: e?.message || "Failed to get metrics" };
      }
    }
    return out;
  }

  static async healthCheckAll(): Promise<Record<string, any>> {
    const results: Record<string, any> = {};
    const checks = Array.from(ConnectorFactory.instances.entries()).map(async ([id, c]) => {
      try {
        results[id] = await c.healthCheck();
      } catch (e: any) {
        results[id] = { status: "unhealthy", error: e?.message || "Health check failed" };
      }
    });
    
    await Promise.allSettled(checks);
    return results;
  }

  static async cleanupAll(): Promise<void> {
    const cleanupPromises = Array.from(ConnectorFactory.instances.keys()).map(id => 
      ConnectorFactory.removeConnector(id)
    );
    
    await Promise.allSettled(cleanupPromises);
    ConnectorFactory.instances.clear();
    logger.info("All connectors cleaned up");
  }
}

export default ConnectorFactory;


------------------------------------------------------------
FILE: backend\data-service\src\services\DatabaseService.migrations.additions.ts
------------------------------------------------------------
// backend/data-service/src/services/DatabaseService.migrations.additions.ts

export const extraMigrations = [
  {
    id: 100,
    name: '100_quality_rules_enhanced',
    sql: `
      BEGIN;

      -- Ensure UUID/crypto helpers exist (idempotent, safe to re-run)
      CREATE EXTENSION IF NOT EXISTS "pgcrypto";
      CREATE EXTENSION IF NOT EXISTS "uuid-ossp";

      -- 1) Create tables if missing (modern schema)
      CREATE TABLE IF NOT EXISTS quality_rules (
        id                  uuid PRIMARY KEY DEFAULT gen_random_uuid(),
        name                varchar(255) NOT NULL,
        description         text,
        severity            varchar(20) NOT NULL DEFAULT 'medium',
        type                varchar(30) NOT NULL DEFAULT 'sql',
        dialect             varchar(30) NOT NULL DEFAULT 'postgres',
        expression          text NOT NULL,
        expression_hash     varchar(64),
        tags                text[] NOT NULL DEFAULT '{}'::text[],
        enabled             boolean NOT NULL DEFAULT true,
        max_execution_time_ms integer NOT NULL DEFAULT 30000,
        created_by          varchar(100),
        updated_by          varchar(100),
        created_at          timestamptz NOT NULL DEFAULT now(),
        updated_at          timestamptz NOT NULL DEFAULT now(),
        last_executed_at    timestamptz,
        execution_count     integer NOT NULL DEFAULT 0
      );

      CREATE TABLE IF NOT EXISTS quality_results (
        id                uuid PRIMARY KEY DEFAULT gen_random_uuid(),
        rule_id           uuid NOT NULL REFERENCES quality_rules(id) ON DELETE CASCADE,
        data_source_id    uuid REFERENCES data_sources(id) ON DELETE SET NULL,
        asset_id          uuid,
        status            varchar(15) NOT NULL,
        run_at            timestamptz NOT NULL DEFAULT now(),
        execution_time_ms integer NOT NULL DEFAULT 0,
        metrics           jsonb NOT NULL DEFAULT '{}'::jsonb,
        error             text,
        query_hash        varchar(64),
        executed_by       varchar(100)
      );

      -- 2) Backfill columns if table existed from older schema (fixes "enabled does not exist")
      ALTER TABLE quality_rules
        ADD COLUMN IF NOT EXISTS expression_hash      varchar(64),
        ADD COLUMN IF NOT EXISTS tags                 text[] NOT NULL DEFAULT '{}'::text[],
        ADD COLUMN IF NOT EXISTS enabled              boolean NOT NULL DEFAULT true,
        ADD COLUMN IF NOT EXISTS max_execution_time_ms integer NOT NULL DEFAULT 30000,
        ADD COLUMN IF NOT EXISTS last_executed_at     timestamptz,
        ADD COLUMN IF NOT EXISTS execution_count      integer NOT NULL DEFAULT 0,
        ADD COLUMN IF NOT EXISTS severity             varchar(20) NOT NULL DEFAULT 'medium',
        ADD COLUMN IF NOT EXISTS type                 varchar(30) NOT NULL DEFAULT 'sql',
        ADD COLUMN IF NOT EXISTS dialect              varchar(30) NOT NULL DEFAULT 'postgres';

      ALTER TABLE quality_rules
        ALTER COLUMN tags SET DEFAULT '{}'::text[],
        ALTER COLUMN enabled SET DEFAULT true;

      ALTER TABLE quality_results
        ADD COLUMN IF NOT EXISTS execution_time_ms integer NOT NULL DEFAULT 0,
        ADD COLUMN IF NOT EXISTS metrics           jsonb NOT NULL DEFAULT '{}'::jsonb,
        ADD COLUMN IF NOT EXISTS query_hash        varchar(64),
        ADD COLUMN IF NOT EXISTS executed_by       varchar(100);

      -- 3) Constraints (use catalog guards so theyâ€™re re-runnable)
      DO $$
      BEGIN
        IF NOT EXISTS (SELECT 1 FROM pg_constraint WHERE conname='chk_quality_rules_severity') THEN
          ALTER TABLE quality_rules
            ADD CONSTRAINT chk_quality_rules_severity
            CHECK (severity IN ('low','medium','high','critical'));
        END IF;

        IF NOT EXISTS (SELECT 1 FROM pg_constraint WHERE conname='chk_quality_rules_type') THEN
          ALTER TABLE quality_rules
            ADD CONSTRAINT chk_quality_rules_type
            CHECK (type IN ('sql','metric'));
        END IF;

        IF NOT EXISTS (SELECT 1 FROM pg_constraint WHERE conname='chk_quality_rules_dialect') THEN
          ALTER TABLE quality_rules
            ADD CONSTRAINT chk_quality_rules_dialect
            CHECK (dialect IN ('postgres','generic'));
        END IF;

        IF NOT EXISTS (SELECT 1 FROM pg_constraint WHERE conname='chk_quality_rules_name_length') THEN
          ALTER TABLE quality_rules
            ADD CONSTRAINT chk_quality_rules_name_length
            CHECK (char_length(name) >= 2);
        END IF;

        IF NOT EXISTS (SELECT 1 FROM pg_constraint WHERE conname='chk_quality_rules_expression_length') THEN
          ALTER TABLE quality_rules
            ADD CONSTRAINT chk_quality_rules_expression_length
            CHECK (char_length(expression) BETWEEN 3 AND 10000);
        END IF;

        IF NOT EXISTS (SELECT 1 FROM pg_constraint WHERE conname='chk_quality_rules_max_exec_time') THEN
          ALTER TABLE quality_rules
            ADD CONSTRAINT chk_quality_rules_max_exec_time
            CHECK (max_execution_time_ms BETWEEN 1000 AND 300000);
        END IF;

        IF NOT EXISTS (SELECT 1 FROM pg_constraint WHERE conname='chk_quality_results_status') THEN
          ALTER TABLE quality_results
            ADD CONSTRAINT chk_quality_results_status
            CHECK (status IN ('passed','failed','error','skipped','timeout'));
        END IF;

        IF NOT EXISTS (SELECT 1 FROM pg_constraint WHERE conname='chk_quality_results_exec_time') THEN
          ALTER TABLE quality_results
            ADD CONSTRAINT chk_quality_results_exec_time
            CHECK (execution_time_ms >= 0);
        END IF;
      END $$;

      -- 4) Indexes (safe to re-run)
      CREATE INDEX IF NOT EXISTS idx_quality_rules_name            ON quality_rules(name);
      CREATE INDEX IF NOT EXISTS idx_quality_rules_type_enabled    ON quality_rules(type, enabled);
      CREATE INDEX IF NOT EXISTS idx_quality_rules_updated_at      ON quality_rules(updated_at DESC);
      CREATE INDEX IF NOT EXISTS idx_quality_rules_expression_hash ON quality_rules(expression_hash);

      CREATE INDEX IF NOT EXISTS idx_quality_results_rule_id       ON quality_results(rule_id);
      CREATE INDEX IF NOT EXISTS idx_quality_results_data_source   ON quality_results(data_source_id);
      CREATE INDEX IF NOT EXISTS idx_quality_results_status        ON quality_results(status);
      CREATE INDEX IF NOT EXISTS idx_quality_results_run_at        ON quality_results(run_at DESC);
      CREATE INDEX IF NOT EXISTS idx_quality_results_rule_run_at   ON quality_results(rule_id, run_at DESC);

      -- 5) Hash trigger (correct digest usage)
      CREATE OR REPLACE FUNCTION update_quality_rule_hash()
      RETURNS TRIGGER AS $$
      BEGIN
        -- pgcrypto: encode(digest(bytea,'sha256'),'hex')
        NEW.expression_hash := encode(digest(NEW.expression::bytea, 'sha256'), 'hex');
        NEW.updated_at := now();
        RETURN NEW;
      END;
      $$ LANGUAGE plpgsql;

      DROP TRIGGER IF EXISTS trigger_quality_rule_hash ON quality_rules;
      CREATE TRIGGER trigger_quality_rule_hash
        BEFORE INSERT OR UPDATE ON quality_rules
        FOR EACH ROW
        EXECUTE FUNCTION update_quality_rule_hash();

      -- 6) Updated-at trigger (generic)
      CREATE OR REPLACE FUNCTION set_updated_at()
      RETURNS TRIGGER AS $$
      BEGIN
        NEW.updated_at := now();
        RETURN NEW;
      END;
      $$ LANGUAGE plpgsql;

      DROP TRIGGER IF EXISTS trg_quality_rules_updated_at ON quality_rules;
      CREATE TRIGGER trg_quality_rules_updated_at
        BEFORE UPDATE ON quality_rules
        FOR EACH ROW
        EXECUTE FUNCTION set_updated_at();

      -- 7) Execution stats trigger
      CREATE OR REPLACE FUNCTION update_quality_rule_stats()
      RETURNS TRIGGER AS $$
      BEGIN
        UPDATE quality_rules
           SET last_executed_at = NEW.run_at,
               execution_count  = COALESCE(execution_count,0) + 1,
               updated_at       = now()
         WHERE id = NEW.rule_id;
        RETURN NEW;
      END;
      $$ LANGUAGE plpgsql;

      DROP TRIGGER IF EXISTS trigger_quality_rule_stats ON quality_results;
      CREATE TRIGGER trigger_quality_rule_stats
        AFTER INSERT ON quality_results
        FOR EACH ROW
        EXECUTE FUNCTION update_quality_rule_stats();

      COMMIT;
    `,
  },
  {
  id: 101,
  name: '101_governance_policies_enhanced',
  sql: `
    CREATE EXTENSION IF NOT EXISTS "pgcrypto";
    BEGIN;

    /* 1) Create table if missing (modern shape) */
    CREATE TABLE IF NOT EXISTS governance_policies (
      id uuid PRIMARY KEY DEFAULT gen_random_uuid(),
      name varchar(255) NOT NULL,
      description text,
      category varchar(50) NOT NULL DEFAULT 'access',
      status varchar(20) NOT NULL DEFAULT 'active',
      priority integer NOT NULL DEFAULT 100,
      rules jsonb NOT NULL DEFAULT '[]'::jsonb,
      conditions jsonb DEFAULT '{}'::jsonb,
      actions jsonb DEFAULT '{}'::jsonb,
      effective_from timestamptz DEFAULT now(),
      effective_until timestamptz,
      created_by varchar(100),
      updated_by varchar(100),
      approved_by varchar(100),
      approved_at timestamptz,
      created_at timestamptz NOT NULL DEFAULT now(),
      updated_at timestamptz NOT NULL DEFAULT now(),
      version integer NOT NULL DEFAULT 1
    );

    /* 2) Backfill columns for legacy tables */
    ALTER TABLE governance_policies
      ADD COLUMN IF NOT EXISTS description      text,
      ADD COLUMN IF NOT EXISTS category         varchar(50) NOT NULL DEFAULT 'access',
      ADD COLUMN IF NOT EXISTS status           varchar(20) NOT NULL DEFAULT 'active',
      ADD COLUMN IF NOT EXISTS priority         integer NOT NULL DEFAULT 100,
      ADD COLUMN IF NOT EXISTS rules            jsonb NOT NULL DEFAULT '[]'::jsonb,
      ADD COLUMN IF NOT EXISTS conditions       jsonb NOT NULL DEFAULT '{}'::jsonb,
      ADD COLUMN IF NOT EXISTS actions          jsonb NOT NULL DEFAULT '{}'::jsonb,
      ADD COLUMN IF NOT EXISTS effective_from   timestamptz DEFAULT now(),
      ADD COLUMN IF NOT EXISTS effective_until  timestamptz,
      ADD COLUMN IF NOT EXISTS created_by       varchar(100),
      ADD COLUMN IF NOT EXISTS updated_by       varchar(100),
      ADD COLUMN IF NOT EXISTS approved_by      varchar(100),
      ADD COLUMN IF NOT EXISTS approved_at      timestamptz,
      ADD COLUMN IF NOT EXISTS created_at       timestamptz NOT NULL DEFAULT now(),
      ADD COLUMN IF NOT EXISTS updated_at       timestamptz NOT NULL DEFAULT now(),
      ADD COLUMN IF NOT EXISTS version          integer NOT NULL DEFAULT 1;

    /* 3) Constraints (guarded so this block is re-runnable) */
    DO $$
    BEGIN
      IF NOT EXISTS (SELECT 1 FROM pg_constraint WHERE conname='chk_governance_policies_category') THEN
        ALTER TABLE governance_policies
          ADD CONSTRAINT chk_governance_policies_category
          CHECK (category IN ('access','privacy','retention','classification','compliance'));
      END IF;

      IF NOT EXISTS (SELECT 1 FROM pg_constraint WHERE conname='chk_governance_policies_status') THEN
        ALTER TABLE governance_policies
          ADD CONSTRAINT chk_governance_policies_status
          CHECK (status IN ('draft','active','inactive','archived'));
      END IF;

      IF NOT EXISTS (SELECT 1 FROM pg_constraint WHERE conname='chk_governance_policies_priority') THEN
        ALTER TABLE governance_policies
          ADD CONSTRAINT chk_governance_policies_priority
          CHECK (priority BETWEEN 1 AND 1000);
      END IF;

      IF NOT EXISTS (SELECT 1 FROM pg_constraint WHERE conname='chk_governance_policies_name_length') THEN
        ALTER TABLE governance_policies
          ADD CONSTRAINT chk_governance_policies_name_length
          CHECK (char_length(name) >= 2);
      END IF;
    END $$;

    /* 4) Applications table */
    CREATE TABLE IF NOT EXISTS governance_policy_applications (
      id uuid PRIMARY KEY DEFAULT gen_random_uuid(),
      policy_id uuid NOT NULL REFERENCES governance_policies(id) ON DELETE CASCADE,
      resource_type varchar(50) NOT NULL,
      resource_id varchar(255) NOT NULL,
      action varchar(100) NOT NULL,
      result varchar(20) NOT NULL,
      applied_at timestamptz NOT NULL DEFAULT now(),
      applied_by varchar(100),
      context jsonb NOT NULL DEFAULT '{}'::jsonb
    );

    DO $$
    BEGIN
      IF NOT EXISTS (SELECT 1 FROM pg_constraint WHERE conname='chk_governance_applications_result') THEN
        ALTER TABLE governance_policy_applications
          ADD CONSTRAINT chk_governance_applications_result
          CHECK (result IN ('allowed','denied','audited','warning'));
      END IF;
    END $$;

    /* 5) Indexes (after columns exist) */
    CREATE INDEX IF NOT EXISTS idx_governance_policies_status     ON governance_policies(status);
    CREATE INDEX IF NOT EXISTS idx_governance_policies_category   ON governance_policies(category);
    CREATE INDEX IF NOT EXISTS idx_governance_policies_effective  ON governance_policies(effective_from, effective_until);
    CREATE INDEX IF NOT EXISTS idx_governance_policies_priority   ON governance_policies(priority DESC);

    CREATE INDEX IF NOT EXISTS idx_governance_applications_policy   ON governance_policy_applications(policy_id);
    CREATE INDEX IF NOT EXISTS idx_governance_applications_resource ON governance_policy_applications(resource_type, resource_id);
    CREATE INDEX IF NOT EXISTS idx_governance_applications_applied  ON governance_policy_applications(applied_at DESC);

    /* 6) Version/updated_at trigger */
    CREATE OR REPLACE FUNCTION update_governance_policy_version()
    RETURNS TRIGGER AS $$
    BEGIN
      IF TG_OP = 'UPDATE' AND OLD.rules::text IS DISTINCT FROM NEW.rules::text THEN
        NEW.version := COALESCE(OLD.version, 0) + 1;
      END IF;
      NEW.updated_at := now();
      RETURN NEW;
    END;
    $$ LANGUAGE plpgsql;

    DROP TRIGGER IF EXISTS trigger_governance_policy_version ON governance_policies;
    CREATE TRIGGER trigger_governance_policy_version
      BEFORE UPDATE ON governance_policies
      FOR EACH ROW
      EXECUTE FUNCTION update_governance_policy_version();

    COMMIT;
  `,
}
,
  {
  id: 102,
  name: '102_workflow_requests_enhanced',
  sql: `
    CREATE EXTENSION IF NOT EXISTS "pgcrypto";
    BEGIN;

    /* 1) Create table if missing (modern shape) */
    CREATE TABLE IF NOT EXISTS workflow_requests (
      id uuid PRIMARY KEY DEFAULT gen_random_uuid(),
      title varchar(255) NOT NULL,
      description text,
      type varchar(40) NOT NULL DEFAULT 'access',
      priority varchar(20) NOT NULL DEFAULT 'medium',
      status varchar(20) NOT NULL DEFAULT 'open',
      requester varchar(120),
      assignee varchar(120),
      approver varchar(120),
      payload jsonb NOT NULL DEFAULT '{}'::jsonb,
      attachments text[] NOT NULL DEFAULT '{}'::text[],
      due_date timestamptz,
      resolved_at timestamptz,
      created_at timestamptz NOT NULL DEFAULT now(),
      updated_at timestamptz NOT NULL DEFAULT now(),
      updated_by varchar(100)
    );

    /* 2) Backfill columns for legacy installs */
    ALTER TABLE workflow_requests
      ADD COLUMN IF NOT EXISTS description   text,
      ADD COLUMN IF NOT EXISTS type          varchar(40)  NOT NULL DEFAULT 'access',
      ADD COLUMN IF NOT EXISTS priority      varchar(20)  NOT NULL DEFAULT 'medium',
      ADD COLUMN IF NOT EXISTS status        varchar(20)  NOT NULL DEFAULT 'open',
      ADD COLUMN IF NOT EXISTS requester     varchar(120),
      ADD COLUMN IF NOT EXISTS assignee      varchar(120),
      ADD COLUMN IF NOT EXISTS approver      varchar(120),
      ADD COLUMN IF NOT EXISTS payload       jsonb        NOT NULL DEFAULT '{}'::jsonb,
      ADD COLUMN IF NOT EXISTS attachments   text[]       NOT NULL DEFAULT '{}'::text[],
      ADD COLUMN IF NOT EXISTS due_date      timestamptz,
      ADD COLUMN IF NOT EXISTS resolved_at   timestamptz,
      ADD COLUMN IF NOT EXISTS created_at    timestamptz  NOT NULL DEFAULT now(),
      ADD COLUMN IF NOT EXISTS updated_at    timestamptz  NOT NULL DEFAULT now(),
      ADD COLUMN IF NOT EXISTS updated_by    varchar(100);

    /* 3) Ensure minimal defaults on existing rows */
    UPDATE workflow_requests
      SET type = COALESCE(type, 'access'),
          priority = COALESCE(priority, 'medium'),
          status = COALESCE(status, 'open'),
          payload = COALESCE(payload, '{}'::jsonb),
          attachments = COALESCE(attachments, '{}'::text[]),
          created_at = COALESCE(created_at, now()),
          updated_at = COALESCE(updated_at, now());

    /* 4) Constraints (guarded so re-runs are safe) */
    DO $$
    BEGIN
      IF NOT EXISTS (SELECT 1 FROM pg_constraint WHERE conname='chk_workflow_requests_type') THEN
        ALTER TABLE workflow_requests
          ADD CONSTRAINT chk_workflow_requests_type
          CHECK (type IN ('access','change','incident','data_request','policy_exception'));
      END IF;

      IF NOT EXISTS (SELECT 1 FROM pg_constraint WHERE conname='chk_workflow_requests_priority') THEN
        ALTER TABLE workflow_requests
          ADD CONSTRAINT chk_workflow_requests_priority
          CHECK (priority IN ('low','medium','high','urgent'));
      END IF;

      IF NOT EXISTS (SELECT 1 FROM pg_constraint WHERE conname='chk_workflow_requests_status') THEN
        ALTER TABLE workflow_requests
          ADD CONSTRAINT chk_workflow_requests_status
          CHECK (status IN ('open','in_progress','pending_approval','approved','rejected','closed','cancelled'));
      END IF;

      IF NOT EXISTS (SELECT 1 FROM pg_constraint WHERE conname='chk_workflow_requests_title_length') THEN
        ALTER TABLE workflow_requests
          ADD CONSTRAINT chk_workflow_requests_title_length
          CHECK (char_length(title) >= 3);
      END IF;
    END $$;

    /* 5) Comments/history table */
    CREATE TABLE IF NOT EXISTS workflow_request_comments (
      id uuid PRIMARY KEY DEFAULT gen_random_uuid(),
      request_id uuid NOT NULL REFERENCES workflow_requests(id) ON DELETE CASCADE,
      comment_type varchar(20) NOT NULL DEFAULT 'comment',
      content text NOT NULL,
      author varchar(120) NOT NULL,
      created_at timestamptz NOT NULL DEFAULT now(),
      is_internal boolean NOT NULL DEFAULT false
    );

    DO $$
    BEGIN
      IF NOT EXISTS (SELECT 1 FROM pg_constraint WHERE conname='chk_workflow_comments_type') THEN
        ALTER TABLE workflow_request_comments
          ADD CONSTRAINT chk_workflow_comments_type
          CHECK (comment_type IN ('comment','status_change','assignment','approval','rejection'));
      END IF;
    END $$;

    /* 6) Approvals table */
    CREATE TABLE IF NOT EXISTS workflow_request_approvals (
      id uuid PRIMARY KEY DEFAULT gen_random_uuid(),
      request_id uuid NOT NULL REFERENCES workflow_requests(id) ON DELETE CASCADE,
      approver varchar(120) NOT NULL,
      decision varchar(20) NOT NULL,
      comments text,
      decided_at timestamptz NOT NULL DEFAULT now()
    );

    DO $$
    BEGIN
      IF NOT EXISTS (SELECT 1 FROM pg_constraint WHERE conname='chk_workflow_approvals_decision') THEN
        ALTER TABLE workflow_request_approvals
          ADD CONSTRAINT chk_workflow_approvals_decision
          CHECK (decision IN ('approved','rejected','needs_info'));
      END IF;
    END $$;

    /* 7) Indexes */
    CREATE INDEX IF NOT EXISTS idx_workflow_requests_status     ON workflow_requests(status);
    CREATE INDEX IF NOT EXISTS idx_workflow_requests_type       ON workflow_requests(type);
    CREATE INDEX IF NOT EXISTS idx_workflow_requests_assignee   ON workflow_requests(assignee);
    CREATE INDEX IF NOT EXISTS idx_workflow_requests_requester  ON workflow_requests(requester);
    CREATE INDEX IF NOT EXISTS idx_workflow_requests_updated_at ON workflow_requests(updated_at DESC);
    CREATE INDEX IF NOT EXISTS idx_workflow_requests_due_date   ON workflow_requests(due_date) WHERE due_date IS NOT NULL;

    CREATE INDEX IF NOT EXISTS idx_workflow_comments_request    ON workflow_request_comments(request_id, created_at DESC);
    CREATE INDEX IF NOT EXISTS idx_workflow_approvals_request   ON workflow_request_approvals(request_id);

    /* 8) Auto-resolve trigger (maintains resolved_at and updated_at) */
    CREATE OR REPLACE FUNCTION auto_resolve_workflow_request()
    RETURNS TRIGGER AS $$
    BEGIN
      IF TG_OP = 'UPDATE' THEN
        IF NEW.status IN ('approved','rejected','closed','cancelled') AND OLD.resolved_at IS NULL THEN
          NEW.resolved_at := now();
        END IF;
        NEW.updated_at := now();
      END IF;
      RETURN NEW;
    END;
    $$ LANGUAGE plpgsql;

    DROP TRIGGER IF EXISTS trigger_auto_resolve_workflow ON workflow_requests;
    CREATE TRIGGER trigger_auto_resolve_workflow
      BEFORE UPDATE ON workflow_requests
      FOR EACH ROW
      EXECUTE FUNCTION auto_resolve_workflow_request();

    COMMIT;
  `,
}
,
  {
    id: 103,
    name: '103_security_and_audit_tables',
    sql: `
      CREATE EXTENSION IF NOT EXISTS "pgcrypto";
      BEGIN;

      CREATE TABLE IF NOT EXISTS audit_logs (
        id uuid PRIMARY KEY DEFAULT gen_random_uuid(),
        entity_type varchar(50) NOT NULL,
        entity_id varchar(255) NOT NULL,
        action varchar(50) NOT NULL,
        actor varchar(120),
        actor_ip inet,
        user_agent text,
        changes jsonb,
        metadata jsonb NOT NULL DEFAULT '{}'::jsonb,
        created_at timestamptz NOT NULL DEFAULT now()
      );

      DO $$
      BEGIN
        IF NOT EXISTS (SELECT 1 FROM pg_constraint WHERE conname='chk_audit_logs_action') THEN
          ALTER TABLE audit_logs
            ADD CONSTRAINT chk_audit_logs_action
            CHECK (action IN ('CREATE','UPDATE','DELETE','EXECUTE','ACCESS','LOGIN','LOGOUT'));
        END IF;
      END $$;

      CREATE TABLE IF NOT EXISTS rate_limit_buckets (
        key varchar(255) PRIMARY KEY,
        tokens integer NOT NULL DEFAULT 0,
        last_refill timestamptz NOT NULL DEFAULT now()
      );
      DO $$
      BEGIN
        IF NOT EXISTS (SELECT 1 FROM pg_constraint WHERE conname='chk_rate_limit_tokens') THEN
          ALTER TABLE rate_limit_buckets
            ADD CONSTRAINT chk_rate_limit_tokens CHECK (tokens >= 0);
        END IF;
      END $$;

      CREATE TABLE IF NOT EXISTS system_config (
        key varchar(100) PRIMARY KEY,
        value jsonb NOT NULL,
        description text,
        is_sensitive boolean NOT NULL DEFAULT false,
        updated_by varchar(100),
        updated_at timestamptz NOT NULL DEFAULT now()
      );

      CREATE INDEX IF NOT EXISTS idx_audit_logs_entity      ON audit_logs(entity_type, entity_id);
      CREATE INDEX IF NOT EXISTS idx_audit_logs_actor       ON audit_logs(actor);
      CREATE INDEX IF NOT EXISTS idx_audit_logs_created_at  ON audit_logs(created_at DESC);
      CREATE INDEX IF NOT EXISTS idx_audit_logs_action      ON audit_logs(action);
      CREATE INDEX IF NOT EXISTS idx_rate_limit_last_refill ON rate_limit_buckets(last_refill);

      -- Seed default config (won't overwrite)
      INSERT INTO system_config (key, value, description)
      VALUES
        ('max_query_execution_time', '300000', 'Maximum query execution time in milliseconds'),
        ('enable_audit_logging', 'true', 'Whether to enable comprehensive audit logging'),
        ('data_retention_days', '365', 'Default data retention period in days'),
        ('max_file_upload_size', '10485760', 'Maximum file upload size in bytes (10MB)')
      ON CONFLICT (key) DO NOTHING;

      -- Maintenance function
      CREATE OR REPLACE FUNCTION cleanup_old_audit_logs()
      RETURNS integer AS $$
      DECLARE
        deleted_count integer;
      BEGIN
        DELETE FROM audit_logs
         WHERE created_at < now() - interval '1 year'
           AND action NOT IN ('DELETE','LOGIN');
        GET DIAGNOSTICS deleted_count = ROW_COUNT;
        RETURN deleted_count;
      END;
      $$ LANGUAGE plpgsql;

      COMMIT;
    `,
  },
  {
    id: 104,
    name: '104_data_lineage_and_relationships',
    sql: `
      CREATE EXTENSION IF NOT EXISTS "pgcrypto";
      BEGIN;

      CREATE TABLE IF NOT EXISTS assets (
        id uuid PRIMARY KEY DEFAULT gen_random_uuid(),
        name varchar(255) NOT NULL,
        type varchar(50) NOT NULL,
        data_source_id uuid REFERENCES data_sources(id) ON DELETE CASCADE,
        schema_name varchar(100),
        table_name varchar(100),
        column_name varchar(100),
        description text,
        data_type varchar(100),
        is_nullable boolean,
        is_primary_key boolean NOT NULL DEFAULT false,
        classification varchar(50) NOT NULL DEFAULT 'public',
        tags text[] NOT NULL DEFAULT '{}'::text[],
        metadata jsonb NOT NULL DEFAULT '{}'::jsonb,
        created_at timestamptz NOT NULL DEFAULT now(),
        updated_at timestamptz NOT NULL DEFAULT now(),
        last_scanned_at timestamptz
      );

      DO $$
      BEGIN
        IF NOT EXISTS (SELECT 1 FROM pg_constraint WHERE conname='chk_assets_type') THEN
          ALTER TABLE assets
            ADD CONSTRAINT chk_assets_type
            CHECK (type IN ('database','schema','table','column','view','procedure','function'));
        END IF;

        IF NOT EXISTS (SELECT 1 FROM pg_constraint WHERE conname='chk_assets_classification') THEN
          ALTER TABLE assets
            ADD CONSTRAINT chk_assets_classification
            CHECK (classification IN ('public','internal','confidential','restricted'));
        END IF;
      END $$;

      CREATE TABLE IF NOT EXISTS data_lineage (
        id uuid PRIMARY KEY DEFAULT gen_random_uuid(),
        source_asset_id uuid NOT NULL REFERENCES assets(id) ON DELETE CASCADE,
        target_asset_id uuid NOT NULL REFERENCES assets(id) ON DELETE CASCADE,
        relationship_type varchar(50) NOT NULL,
        transformation_logic text,
        confidence_score numeric(3,2) DEFAULT 1.0,
        discovered_by varchar(50) DEFAULT 'manual',
        discovered_at timestamptz DEFAULT now(),
        validated_by varchar(100),
        validated_at timestamptz
      );

      DO $$
      BEGIN
        IF NOT EXISTS (SELECT 1 FROM pg_constraint WHERE conname='chk_lineage_relationship_type') THEN
          ALTER TABLE data_lineage
            ADD CONSTRAINT chk_lineage_relationship_type
            CHECK (relationship_type IN ('derives_from','feeds_into','depends_on','similar_to'));
        END IF;

        IF NOT EXISTS (SELECT 1 FROM pg_constraint WHERE conname='chk_lineage_confidence') THEN
          ALTER TABLE data_lineage
            ADD CONSTRAINT chk_lineage_confidence
            CHECK (confidence_score >= 0.0 AND confidence_score <= 1.0);
        END IF;

        IF NOT EXISTS (SELECT 1 FROM pg_constraint WHERE conname='chk_lineage_no_self_reference') THEN
          ALTER TABLE data_lineage
            ADD CONSTRAINT chk_lineage_no_self_reference
            CHECK (source_asset_id <> target_asset_id);
        END IF;
      END $$;

      CREATE TABLE IF NOT EXISTS asset_usage_stats (
        id uuid PRIMARY KEY DEFAULT gen_random_uuid(),
        asset_id uuid NOT NULL REFERENCES assets(id) ON DELETE CASCADE,
        date date NOT NULL,
        query_count integer NOT NULL DEFAULT 0,
        user_count integer NOT NULL DEFAULT 0,
        bytes_read bigint NOT NULL DEFAULT 0,
        bytes_written bigint NOT NULL DEFAULT 0,
        UNIQUE(asset_id, date)
      );

      DO $$
      BEGIN
        IF NOT EXISTS (SELECT 1 FROM pg_constraint WHERE conname='chk_usage_stats_non_negative') THEN
          ALTER TABLE asset_usage_stats
            ADD CONSTRAINT chk_usage_stats_non_negative
            CHECK (query_count >= 0 AND user_count >= 0 AND bytes_read >= 0 AND bytes_written >= 0);
        END IF;
      END $$;

      CREATE INDEX IF NOT EXISTS idx_assets_data_source_id    ON assets(data_source_id);
      CREATE INDEX IF NOT EXISTS idx_assets_type              ON assets(type);
      CREATE INDEX IF NOT EXISTS idx_assets_classification    ON assets(classification);
      CREATE INDEX IF NOT EXISTS idx_assets_updated_at        ON assets(updated_at DESC);
      CREATE INDEX IF NOT EXISTS idx_assets_name_search       ON assets USING gin(to_tsvector('english', name || ' ' || COALESCE(description,'')));
      CREATE INDEX IF NOT EXISTS idx_lineage_source           ON data_lineage(source_asset_id);
      CREATE INDEX IF NOT EXISTS idx_lineage_target           ON data_lineage(target_asset_id);
      CREATE INDEX IF NOT EXISTS idx_lineage_type             ON data_lineage(relationship_type);
      CREATE INDEX IF NOT EXISTS idx_usage_stats_asset_date   ON asset_usage_stats(asset_id, date DESC);
      CREATE INDEX IF NOT EXISTS idx_usage_stats_date         ON asset_usage_stats(date DESC);

      -- Helper to traverse lineage around an asset
      CREATE OR REPLACE FUNCTION get_asset_lineage(
        asset_uuid uuid,
        max_depth integer DEFAULT 3,
        direction  varchar(10) DEFAULT 'both'
      )
      RETURNS TABLE(
        source_id uuid,
        target_id uuid,
        relationship_type varchar,
        depth integer
      ) AS $$
      WITH RECURSIVE lineage_tree AS (
        SELECT 
          dl.source_asset_id AS source_id,
          dl.target_asset_id AS target_id,
          dl.relationship_type,
          1 AS depth
        FROM data_lineage dl
        WHERE (direction IN ('upstream','both') AND dl.target_asset_id = asset_uuid)
           OR (direction IN ('downstream','both') AND dl.source_asset_id = asset_uuid)

        UNION ALL

        SELECT
          dl.source_asset_id,
          dl.target_asset_id,
          dl.relationship_type,
          lt.depth + 1
        FROM data_lineage dl
        JOIN lineage_tree lt ON (
          (direction IN ('upstream','both')   AND dl.target_asset_id = lt.source_id) OR
          (direction IN ('downstream','both') AND dl.source_asset_id = lt.target_id)
        )
        WHERE lt.depth < max_depth
      )
      SELECT DISTINCT * FROM lineage_tree;
      $$ LANGUAGE sql STABLE;

      COMMIT;
    `,
  },
];



------------------------------------------------------------
FILE: backend\data-service\src\services\DatabaseService.ts
------------------------------------------------------------
// backend/data-service/src/services/DatabaseService.ts
import { Pool, PoolClient, QueryResult } from 'pg';
import { config } from '../config/env';
import { logger, loggerUtils } from '../utils/logger';
import { extraMigrations } from './DatabaseService.migrations.additions';

export interface DatabaseConfig {
  host: string;
  port: number;
  database: string;
  user: string;
  password: string;
  ssl?: boolean | object;
  max?: number;
  min?: number;
  idleTimeoutMillis?: number;
  connectionTimeoutMillis?: number;
}

export interface QueryOptions { 
  timeout?: number; 
  retries?: number; 
  retryDelay?: number; 
}

export interface TransactionOptions {
  timeout?: number;
  isolationLevel?: 'READ_UNCOMMITTED'|'READ_COMMITTED'|'REPEATABLE_READ'|'SERIALIZABLE';
}

export interface HealthCheckResult {
  status: 'healthy' | 'unhealthy';
  latency?: number;
  connections?: { total: number; idle: number; waiting: number; };
  error?: string;
  timestamp: string;
}

export interface PoolStats { 
  total: number; 
  idle: number; 
  waiting: number; 
  max: number; 
  min: number; 
}

export interface Migration { 
  id: number; 
  name: string; 
  sql: string; 
  executedAt?: Date; 
}

export class DatabaseService {
  private pool!: Pool;
  private isInitialized = false;
  private migrations: Migration[] = [];

  constructor() {
    this.setupMigrations();
    this.initializePool();
  }

  private initializePool(): void {
    const dbConfig: DatabaseConfig = {
      host: config.database.host,
      port: config.database.port,
      database: config.database.name,
      user: config.database.user,
      password: config.database.password,
      ssl: config.database.ssl ? { rejectUnauthorized: false } : false,
      max: config.database.poolMax,
      min: config.database.poolMin,
      idleTimeoutMillis: config.database.idleTimeout,
      connectionTimeoutMillis: config.database.connectionTimeout,
    };

    this.pool = new Pool(dbConfig);

    // Enhanced error handling
    this.pool.on('error', (err: Error, client?: PoolClient) => {
      logger.error('Database pool error:', { 
        error: err.message, 
        stack: err.stack,
        clientProcessID: (client as any)?.processID 
      });
    });

    this.pool.on('connect', (client: PoolClient) => {
      loggerUtils.logDbOperation('connect', 'pool', 0, true);
    });

    this.pool.on('remove', (client: PoolClient) => {
      loggerUtils.logDbOperation('disconnect', 'pool', 0, true);
    });

    logger.info('Database pool initialized', {
      host: dbConfig.host, 
      port: dbConfig.port, 
      database: dbConfig.database,
      maxConnections: dbConfig.max, 
      minConnections: dbConfig.min, 
      ssl: !!dbConfig.ssl,
    });

    this.isInitialized = true;
  }

  private setupMigrations(): void {
    this.migrations = [
      {
        id: 0,
        name: '000_enable_pgcrypto',
        sql: `CREATE EXTENSION IF NOT EXISTS pgcrypto;`
      },
      {
        id: 1,
        name: '001_create_data_sources_table',
        sql: `
          CREATE TABLE IF NOT EXISTS data_sources (
            id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
            name VARCHAR(100) NOT NULL,
            type VARCHAR(50) NOT NULL,
            host VARCHAR(255),
            port INTEGER CHECK (port > 0 AND port <= 65535),
            database_name VARCHAR(100),
            username VARCHAR(100),
            password_encrypted TEXT,
            ssl BOOLEAN DEFAULT FALSE,
            connection_string TEXT,
            description TEXT,
            tags TEXT[] DEFAULT '{}',
            status VARCHAR(20) DEFAULT 'active',
            metadata JSONB DEFAULT '{}',
            created_at TIMESTAMPTZ DEFAULT NOW(),
            updated_at TIMESTAMPTZ DEFAULT NOW(),
            last_tested_at TIMESTAMPTZ,
            last_sync_at TIMESTAMPTZ
          );

          CREATE OR REPLACE FUNCTION update_updated_at_column()
          RETURNS TRIGGER AS $$
          BEGIN
            NEW.updated_at = NOW();
            RETURN NEW;
          END;
          $$ LANGUAGE plpgsql;

          DROP TRIGGER IF EXISTS update_data_sources_updated_at ON data_sources;
          CREATE TRIGGER update_data_sources_updated_at
            BEFORE UPDATE ON data_sources
            FOR EACH ROW
            EXECUTE FUNCTION update_updated_at_column();

          CREATE INDEX IF NOT EXISTS idx_data_sources_type ON data_sources(type);
          CREATE INDEX IF NOT EXISTS idx_data_sources_status ON data_sources(status);
          CREATE INDEX IF NOT EXISTS idx_data_sources_name ON data_sources(name);
          CREATE INDEX IF NOT EXISTS idx_data_sources_tags ON data_sources USING GIN(tags);
        `
      },
      {
        id: 6,
        name: '006_align_data_sources_schema',
        sql: `
          -- Add missing columns from your connection test requirements
          ALTER TABLE data_sources
            ADD COLUMN IF NOT EXISTS connection_config JSONB DEFAULT '{}'::jsonb,
            ADD COLUMN IF NOT EXISTS created_by VARCHAR(100),
            ADD COLUMN IF NOT EXISTS updated_by VARCHAR(100),
            ADD COLUMN IF NOT EXISTS last_error TEXT,
            ADD COLUMN IF NOT EXISTS public_id VARCHAR(100),
            ADD COLUMN IF NOT EXISTS deleted_at TIMESTAMPTZ,
            ADD COLUMN IF NOT EXISTS last_test_at TIMESTAMPTZ;

          -- Backfill new last_test_at from legacy last_tested_at if present
          UPDATE data_sources
            SET last_test_at = COALESCE(last_test_at, last_tested_at)
            WHERE last_tested_at IS NOT NULL;

          -- Create unique index for public_id
          DO $$
          BEGIN
            IF NOT EXISTS (
              SELECT 1 FROM pg_indexes
              WHERE schemaname = 'public' AND indexname = 'uq_data_sources_public_id'
            ) THEN
              CREATE UNIQUE INDEX uq_data_sources_public_id
                ON data_sources ((public_id)) WHERE public_id IS NOT NULL;
            END IF;
          END $$;

          CREATE INDEX IF NOT EXISTS idx_data_sources_updated_at ON data_sources(updated_at);
          CREATE INDEX IF NOT EXISTS idx_data_sources_deleted_at ON data_sources(deleted_at);

          -- Drop and recreate constraints safely
          DO $$
          BEGIN
            IF EXISTS (SELECT 1 FROM pg_constraint WHERE conname = 'data_sources_type_check' AND conrelid = 'data_sources'::regclass) THEN
              ALTER TABLE data_sources DROP CONSTRAINT data_sources_type_check;
            END IF;
            IF EXISTS (SELECT 1 FROM pg_constraint WHERE conname = 'data_sources_status_check' AND conrelid = 'data_sources'::regclass) THEN
              ALTER TABLE data_sources DROP CONSTRAINT data_sources_status_check;
            END IF;
          END $$;

          -- Add comprehensive constraints
          ALTER TABLE data_sources
            ADD CONSTRAINT chk_data_sources_type CHECK (type IN (
              'postgresql','mysql','mssql','oracle','mongodb','redis',
              's3','azure-blob','gcs','snowflake','bigquery','redshift',
              'databricks','api','file','kafka','elasticsearch'
            ));

          ALTER TABLE data_sources
            ADD CONSTRAINT chk_data_sources_status CHECK (status IN (
              'active','inactive','pending','error','testing',
              'connected','disconnected','warning','syncing'
            ));
        `
      }
    ];
    
    // Add extra migrations if they exist
    if (extraMigrations && Array.isArray(extraMigrations)) {
      this.migrations.push(...extraMigrations);
    }
  }

  /** Enhanced query method with better error handling */
  public async query(text: string, params?: any[], options: QueryOptions = {}): Promise<QueryResult> {
    const { timeout = 30000, retries = 0, retryDelay = 1000 } = options;
    const start = Date.now();
    const queryId = Math.random().toString(36).substring(7);
    let lastError: Error;

    if (!this.isInitialized) {
      throw new Error('Database service not initialized');
    }

    loggerUtils.logDbOperation('query_start', 'general', 0, true);

    for (let attempt = 0; attempt <= retries; attempt++) {
      try {
        const queryPromise = this.pool.query({ text, values: params });
        const timeoutPromise = new Promise<never>((_, reject) => 
          setTimeout(() => reject(new Error(`Query timeout after ${timeout}ms`)), timeout)
        );

        const result = await Promise.race([queryPromise, timeoutPromise]);
        const duration = Date.now() - start;
        
        loggerUtils.logDbOperation('query_success', 'general', duration, true);
        logger.debug('Database query completed', { queryId, duration, rows: result.rowCount });
        
        return result;
      } catch (err) {
        lastError = err as Error;
        const duration = Date.now() - start;
        
        logger.error('Database query failed', { 
          queryId, 
          attempt: attempt + 1, 
          duration,
          error: lastError.message,
          query: text.substring(0, 100) + (text.length > 100 ? '...' : '')
        });

        if (attempt === retries) {
          loggerUtils.logDbOperation('query_failed', 'general', duration, false);
          throw lastError;
        }

        // Exponential backoff
        await new Promise(r => setTimeout(r, retryDelay * Math.pow(2, attempt)));
      }
    }
    throw lastError!;
  }

  /** Enhanced transaction method */
  public async transaction<T>(
    callback: (client: PoolClient) => Promise<T>, 
    options: TransactionOptions = {}
  ): Promise<T> {
    const { timeout = 30000, isolationLevel } = options;
    let client: PoolClient | null = null;
    
    try {
      client = await this.pool.connect();
      await client.query('BEGIN');
      
      if (isolationLevel) {
        await client.query(`SET TRANSACTION ISOLATION LEVEL ${isolationLevel}`);
      }

      const timeoutPromise = new Promise<never>((_, reject) => 
        setTimeout(() => reject(new Error(`Transaction timeout after ${timeout}ms`)), timeout)
      );

      const result = await Promise.race([
        callback(client),
        timeoutPromise
      ]);

      await client.query('COMMIT');
      return result;
    } catch (err) {
      if (client) {
        try {
          await client.query('ROLLBACK');
        } catch (rollbackErr) {
          logger.error('Failed to rollback transaction', { error: (rollbackErr as Error).message });
        }
      }
      throw err;
    } finally {
      if (client) {
        client.release();
      }
    }
  }

  /** Enhanced health check */
  public async healthCheck(): Promise<HealthCheckResult> {
    const started = Date.now();
    try {
      if (!this.isInitialized) {
        throw new Error('Database service not initialized');
      }

      await this.pool.query('SELECT 1 as health_check');
      
      const poolStats = this.getPoolStats();
      
      return {
        status: 'healthy',
        latency: Date.now() - started,
        connections: {
          total: poolStats.total,
          idle: poolStats.idle,
          waiting: poolStats.waiting,
        },
        timestamp: new Date().toISOString(),
      };
    } catch (e: any) {
      logger.error('Database health check failed', { error: e.message });
      return {
        status: 'unhealthy',
        latency: Date.now() - started,
        error: e?.message || String(e),
        timestamp: new Date().toISOString(),
      };
    }
  }

  public getPoolStats(): PoolStats {
    return {
      total: (this.pool as any).totalCount ?? 0,
      idle: (this.pool as any).idleCount ?? 0,
      waiting: (this.pool as any).waitingCount ?? 0,
      max: config.database.poolMax,
      min: config.database.poolMin,
    };
  }

  /** Enhanced migration runner with better error handling */
  public async runMigrations(): Promise<void> {
    logger.info('Running database migrations...');
    
    try {
      // Create migrations table if it doesn't exist
      await this.query(`
        CREATE TABLE IF NOT EXISTS migrations (
          id SERIAL PRIMARY KEY,
          name VARCHAR(255) NOT NULL UNIQUE,
          executed_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
        )
      `);

      // Get already executed migrations
      const executedMigrations = await this.query('SELECT name FROM migrations ORDER BY id');
      const executedNames = new Set(executedMigrations.rows.map(row => row.name));

      let migrationsRun = 0;
      
      for (const migration of this.migrations) {
        if (executedNames.has(migration.name)) {
          logger.debug(`Migration already applied: ${migration.name}`);
          continue;
        }

        logger.info(`Running migration: ${migration.name}`);
        
        try {
          await this.transaction(async (client) => {
            // Execute the migration SQL
            await client.query(migration.sql);
            // Record the migration as completed
            await client.query(
              'INSERT INTO migrations (name) VALUES ($1)', 
              [migration.name]
            );
          });
          
          migrationsRun++;
          logger.info(`Migration completed: ${migration.name}`);
        } catch (migrationError) {
          logger.error(`Migration failed: ${migration.name}`, { 
            error: (migrationError as Error).message 
          });
          throw new Error(`Migration ${migration.name} failed: ${(migrationError as Error).message}`);
        }
      }

      logger.info(`All migrations completed successfully. ${migrationsRun} migrations executed.`);
    } catch (error) {
      logger.error('Migration process failed', { error: (error as Error).message });
      throw error;
    }
  }

  /** Graceful shutdown */
  public async close(): Promise<void> {
    if (this.pool && this.isInitialized) {
      logger.info('Closing database pool...');
      await this.pool.end();
      this.isInitialized = false;
      logger.info('Database pool closed');
    }
  }

  public isReady(): boolean { 
    return this.isInitialized && this.pool !== null; 
  }

  /** Utility method to check if a table exists */
  public async tableExists(tableName: string): Promise<boolean> {
    const result = await this.query(`
      SELECT EXISTS (
        SELECT FROM information_schema.tables 
        WHERE table_schema = 'public' 
        AND table_name = $1
      )
    `, [tableName]);
    
    return result.rows[0]?.exists || false;
  }

  /** Utility method to check if a column exists */
  public async columnExists(tableName: string, columnName: string): Promise<boolean> {
    const result = await this.query(`
      SELECT EXISTS (
        SELECT FROM information_schema.columns 
        WHERE table_schema = 'public' 
        AND table_name = $1 
        AND column_name = $2
      )
    `, [tableName, columnName]);
    
    return result.rows[0]?.exists || false;
  }
}


------------------------------------------------------------
FILE: backend\data-service\src\services\DataSourceService.ts
------------------------------------------------------------
import { randomUUID } from 'node:crypto';
import {
  ConnectionConfig,
  DataSource,
  DataSourceFilters,
  DataSourceStatus,
  DataSourceType,
} from '../models/DataSource';
import { logger } from '../utils/logger';
import { ConnectionTestService } from './ConnectionTestService';
import { DatabaseService } from './DatabaseService';

export interface PaginatedDataSources {
  dataSources: DataSource[];
  total: number;
  page: number;
  limit: number;
  totalPages: number;
}

export interface DataSourceListOptions {
  page: number;
  limit: number;
  filters: DataSourceFilters;
  sortBy?: 'updatedAt' | 'createdAt' | 'name' | 'status' | 'type';
  sortOrder?: 'asc' | 'desc';
}

export interface HealthSummary {
  total: number;
  healthy: number;
  warning: number;
  error: number;
  lastUpdated: Date;
}

export interface SchemaInfo {
  tables: TableInfo[];
  views: ViewInfo[];
  totalTables: number;
  totalColumns: number;
  estimatedSize: string;
}

export interface TableInfo {
  name: string;
  schema?: string;
  rowCount?: number;
  columns: ColumnInfo[];
  indexes: IndexInfo[];
  constraints: ConstraintInfo[];
}

export interface ColumnInfo {
  name: string;
  type: string;
  nullable: boolean;
  primaryKey: boolean;
  foreignKey?: { table: string; column: string };
  defaultValue?: string;
}

export interface ViewInfo { name: string; schema?: string; definition: string; }
export interface IndexInfo { name: string; columns: string[]; unique: boolean; type: string; }

export interface ConstraintInfo {
  name: string;
  type: 'PRIMARY_KEY' | 'FOREIGN_KEY' | 'UNIQUE' | 'CHECK';
  columns: string[];
  referencedTable?: string;
  referencedColumns?: string[];
}

export interface SyncResult {
  syncId: string;
  status: 'started' | 'completed' | 'failed';
  tablesScanned: number;
  newTables: number;
  updatedTables: number;
  errors: string[];
  startedAt: Date;
  completedAt?: Date;
}

const SORT_MAP: Record<NonNullable<DataSourceListOptions['sortBy']>, string> = {
  updatedAt: 'updated_at',
  createdAt: 'created_at',
  name: 'name',
  status: 'status',
  type: 'type',
};

const normalizeType = (t?: string): DataSourceType | undefined => {
  if (!t) return undefined;
  const x = String(t).toLowerCase();
  if (x === 'postgres') return 'postgresql';
  if (['azure_sql', 'azure-sql', 'sqlserver', 'sql-server'].includes(x)) return 'mssql' as DataSourceType;
  return x as DataSourceType;
};

export class DataSourceService {
  private db = new DatabaseService();
  private tester = new ConnectionTestService();

  private makePublicId(): string {
    return `ds_${Date.now()}_${randomUUID().slice(0, 8)}`;
  }

  private coerceJSON<T>(val: any, fallback: T): T {
    if (val === null || val === undefined) return fallback;
    if (typeof val === 'string') {
      try { return JSON.parse(val) as T; } catch { return fallback; }
    }
    return (typeof val === 'object') ? (val as T) : fallback;
  }

  private coerceStringArray(val: any): string[] {
    if (Array.isArray(val)) return val.map(String);
    if (typeof val === 'string') {
      try {
        const parsed = JSON.parse(val);
        if (Array.isArray(parsed)) return parsed.map(String);
      } catch {
        if (/^\{.*\}$/.test(val)) {
          return val
            .slice(1, -1)
            .split(',')
            .map((s) => s.replace(/^"(.*)"$/, '$1'))
            .filter(Boolean);
        }
      }
    }
    return [];
  }

  private toConnectionConfig(raw: any, fallbackType?: DataSourceType): ConnectionConfig {
    try {
      const obj = raw == null ? {} : (typeof raw === 'string' ? JSON.parse(raw) : raw);
      if (obj && typeof obj === 'object') {
        return obj as ConnectionConfig;
      }
    } catch { /* ignore */ }
    return { type: (fallbackType as any) ?? 'api' } as ConnectionConfig;
  }

  private mapRowToDataSource(row: any): DataSource {
    return {
      id: row.id,
      name: row.name,
      description: row.description ?? null,
      type: row.type,
      status: row.status,
      connectionConfig: this.toConnectionConfig(row.connection_config, row.type),
      tags: this.coerceStringArray(row.tags),
      metadata: this.coerceJSON(row.metadata, {}),
      createdAt: row.created_at,
      updatedAt: row.updated_at,
      createdBy: row.created_by ?? null,
      updatedBy: row.updated_by ?? null,
      lastTestAt: row.last_test_at ?? row.last_tested_at ?? null,
      lastSyncAt: row.last_sync_at ?? null,
      lastError: row.last_error ?? null,
      publicId: row.public_id ?? null,
    } as DataSource;
  }

  /* ============================== CRUD + List ============================== */

  async getAllDataSources(options: DataSourceListOptions): Promise<PaginatedDataSources> {
    try {
      const { page, limit, filters, sortBy = 'updatedAt', sortOrder = 'desc' } = options;
      const offset = (page - 1) * limit;

      let where = 'WHERE deleted_at IS NULL';
      const params: any[] = [];
      let i = 1;

      if (filters.status) { where += ` AND status = $${i++}`; params.push(filters.status); }
      if (filters.type)   { where += ` AND type = $${i++}`; params.push(filters.type); }
      if (filters.createdBy) { where += ` AND created_by = $${i++}`; params.push(filters.createdBy); }
      if (filters.search) {
        where += ` AND (name ILIKE $${i} OR description ILIKE $${i})`;
        params.push(`%${filters.search}%`); i++;
      }

      const countSQL = `SELECT COUNT(*)::int AS total FROM data_sources ${where}`;
      const { rows: countRows } = await this.db.query(countSQL, params);
      const total = countRows[0]?.total ?? 0;

      const orderBy = SORT_MAP[sortBy] ?? 'updated_at';
      const orderDir = sortOrder.toLowerCase() === 'asc' ? 'ASC' : 'DESC';

      const dataSQL = `
        SELECT
          id, name, description, type, status,
          connection_config, tags, metadata,
          created_at, updated_at, created_by, updated_by,
          COALESCE(last_test_at, last_tested_at) AS last_test_at,
          last_sync_at, last_error, public_id
        FROM data_sources
        ${where}
        ORDER BY ${orderBy} ${orderDir}
        LIMIT $${i++} OFFSET $${i++}
      `;
      const { rows } = await this.db.query(dataSQL, [...params, limit, offset]);
      const dataSources = rows.map((r) => this.mapRowToDataSource(r));

      return { dataSources, total, page, limit, totalPages: Math.ceil(total / limit) };
    } catch (error) {
      logger.error('DataSourceService.getAllDataSources failed:', error);
      throw error;
    }
  }

  async getDataSourceById(id: string): Promise<DataSource | null> {
    try {
      const sql = `
        SELECT
          id, name, description, type, status,
          connection_config, tags, metadata,
          created_at, updated_at, created_by, updated_by,
          COALESCE(last_test_at, last_tested_at) AS last_test_at,
          last_sync_at, last_error, public_id
        FROM data_sources
        WHERE id = $1 AND deleted_at IS NULL
      `;
      const { rows } = await this.db.query(sql, [id]);
      if (rows.length === 0) return null;
      return this.mapRowToDataSource(rows[0]);
    } catch (error) {
      logger.error('DataSourceService.getDataSourceById failed:', error);
      throw error;
    }
  }

  async createDataSource(data: Partial<DataSource>): Promise<DataSource> {
    try {
      const now = new Date();
      const publicId = this.makePublicId();

      const connectionCfg: ConnectionConfig =
        data.connectionConfig && typeof (data.connectionConfig as any) === 'object'
          ? (data.connectionConfig as ConnectionConfig)
          : this.toConnectionConfig(null, data.type as DataSourceType);

      const sql = `
        INSERT INTO data_sources (
          name, description, type, status,
          connection_config, tags, metadata,
          created_at, updated_at, created_by, public_id,
          last_test_at, last_sync_at, last_error
        )
        VALUES (
          $1, $2, $3, $4,
          $5::jsonb, $6::text[], $7::jsonb,
          $8, $9, $10, $11,
          $12, $13, $14
        )
        RETURNING
          id, name, description, type, status,
          connection_config, tags, metadata,
          created_at, updated_at, created_by, updated_by,
          COALESCE(last_test_at, last_tested_at) AS last_test_at,
          last_sync_at, last_error, public_id
      `;

      const params: any[] = [
        data.name!,
        data.description ?? null,
        normalizeType(data.type) ?? data.type!,
        data.status ?? ('pending' as DataSourceStatus),
        JSON.stringify(connectionCfg),
        Array.isArray(data.tags) ? data.tags : [],
        JSON.stringify(data.metadata ?? {}),
        now,
        now,
        data.createdBy ?? null,
        publicId,
        data.lastTestAt ?? null,
        data.lastSyncAt ?? null,
        data.lastError ?? null,
      ];

      const { rows } = await this.db.query(sql, params);
      return this.mapRowToDataSource(rows[0]);
    } catch (error) {
      logger.error('DataSourceService.createDataSource failed:', error);
      throw error;
    }
  }

  async updateDataSource(id: string, patch: Partial<DataSource>): Promise<DataSource | null> {
    try {
      const existing = await this.getDataSourceById(id);
      if (!existing) return null;

      const sets: string[] = [];
      const params: any[] = [];
      let i = 1;
      const push = (frag: string, val: any) => { sets.push(frag); params.push(val); };

      if (patch.name !== undefined)        push(`name = $${i++}`, patch.name);
      if (patch.description !== undefined) push(`description = $${i++}`, patch.description);
      if (patch.type !== undefined)        push(`type = $${i++}`, normalizeType(patch.type) ?? patch.type);
      if (patch.status !== undefined)      push(`status = $${i++}`, patch.status);
      if (patch.connectionConfig !== undefined) {
        const cfg = this.toConnectionConfig(patch.connectionConfig, (patch.type as any) ?? existing.type);
        push(`connection_config = $${i++}::jsonb`, JSON.stringify(cfg));
      }
      if (patch.tags !== undefined)        push(`tags = $${i++}::text[]`, Array.isArray(patch.tags) ? patch.tags : []);
      if (patch.metadata !== undefined)    push(`metadata = $${i++}::jsonb`, JSON.stringify(patch.metadata ?? {}));
      if (patch.lastTestAt !== undefined)  push(`last_test_at = $${i++}`, patch.lastTestAt);
      if (patch.lastSyncAt !== undefined)  push(`last_sync_at = $${i++}`, patch.lastSyncAt);
      if (patch.lastError !== undefined)   push(`last_error = $${i++}`, patch.lastError);
      if ((patch as any).updatedBy !== undefined)   push(`updated_by = $${i++}`, (patch as any).updatedBy ?? null);

      push(`updated_at = $${i++}`, new Date());
      params.push(id);

      const sql = `
        UPDATE data_sources
        SET ${sets.join(', ')}
        WHERE id = $${i} AND deleted_at IS NULL
        RETURNING
          id, name, description, type, status,
          connection_config, tags, metadata,
          created_at, updated_at, created_by, updated_by,
          COALESCE(last_test_at, last_tested_at) AS last_test_at,
          last_sync_at, last_error, public_id
      `;
      const { rows } = await this.db.query(sql, params);
      if (rows.length === 0) return null;
      return this.mapRowToDataSource(rows[0]);
    } catch (error) {
      logger.error('DataSourceService.updateDataSource failed:', error);
      throw error;
    }
  }

  async deleteDataSource(id: string): Promise<boolean> {
    try {
      const sql = `UPDATE data_sources SET deleted_at = $1 WHERE id = $2 AND deleted_at IS NULL`;
      const { rowCount } = await this.db.query(sql, [new Date(), id]);
      return (rowCount ?? 0) > 0;
    } catch (error) {
      logger.error('DataSourceService.deleteDataSource failed:', error);
      throw error;
    }
  }

  /* ============================== Health & Schema ============================== */

  async getHealthSummary(): Promise<HealthSummary> {
    try {
      const sql = `
        SELECT
          COUNT(*)::int AS total,
          COUNT(CASE WHEN status IN ('active','connected') THEN 1 END)::int AS healthy,
          COUNT(CASE WHEN status IN ('warning','pending','testing','syncing') THEN 1 END)::int AS warning,
          COUNT(CASE WHEN status IN ('error','inactive','disconnected') THEN 1 END)::int AS error
        FROM data_sources
        WHERE deleted_at IS NULL
      `;
      const { rows } = await this.db.query(sql);
      const row = rows[0] || { total: 0, healthy: 0, warning: 0, error: 0 };
      return { ...row, lastUpdated: new Date() } as HealthSummary;
    } catch (error) {
      logger.error('DataSourceService.getHealthSummary failed:', error);
      throw error;
    }
  }

  async getDataSourceSchema(_id: string): Promise<SchemaInfo> {
    // Keep your sample; wire to connector-specific logic later
    return {
      tables: [{
        name: 'users',
        schema: 'public',
        rowCount: 10000,
        columns: [
          { name: 'id', type: 'bigint', nullable: false, primaryKey: true },
          { name: 'email', type: 'varchar', nullable: false, primaryKey: false },
          { name: 'created_at', type: 'timestamp', nullable: false, primaryKey: false },
        ],
        indexes: [
          { name: 'users_pkey', columns: ['id'], unique: true, type: 'btree' },
          { name: 'users_email_idx', columns: ['email'], unique: true, type: 'btree' },
        ],
        constraints: [{ name: 'users_pkey', type: 'PRIMARY_KEY', columns: ['id'] }],
      }],
      views: [],
      totalTables: 1,
      totalColumns: 3,
      estimatedSize: '125MB',
    };
  }

  /* ============================== Sync & Status ============================== */

  async syncDataSource(id: string, _options: { force?: boolean } = {}): Promise<SyncResult> {
    const syncId = `sync_${Date.now()}_${Math.random().toString(36).slice(2, 10)}`;
    await this.updateDataSource(id, { lastSyncAt: new Date(), status: 'connected' as any });
    return {
      syncId,
      status: 'completed',
      tablesScanned: 15,
      newTables: 2,
      updatedTables: 3,
      errors: [],
      startedAt: new Date(),
      completedAt: new Date(),
    };
  }

  /**
   * Optional status poller. If you later persist sync runs, fetch the actual
   * row here. For now, return a simple completed status.
   */
  async getSyncStatus(_id: string): Promise<Partial<SyncResult>> {
    return {
      syncId: `sync_${Date.now()}`,
      status: 'completed',
      startedAt: new Date(),
      completedAt: new Date(),
    };
  }

  /* ============================== Databases listing ============================== */

  /**
   * List databases for an existing data source (server-level discovery).
   * Uses the same discovery engine as the controllerâ€™s preview endpoint,
   * but with the persisted config.
   */
  async listDatabases(id: string): Promise<Array<{ name: string }>> {
    const ds = await this.getDataSourceById(id);
    if (!ds) return [];
    const type = normalizeType(ds.type) ?? ds.type;
    try {
      return await this.tester.discoverDatabasesFromConfig(type, ds.connectionConfig);
    } catch (err) {
      logger.warn(`listDatabases failed for ${id}: ${(err as Error)?.message}`);
      return [];
    }
  }
}



------------------------------------------------------------
FILE: backend\data-service\src\services\GovernanceService.ts
------------------------------------------------------------
import { DatabaseService } from './DatabaseService';

export class GovernanceService {
  private db = new DatabaseService();

  async listPolicies(status?: string) {
    const where = status ? `WHERE status=$1` : '';
    const params = status ? [status] : [];
    const { rows } = await this.db.query(`
      SELECT * FROM governance_policies ${where} ORDER BY updated_at DESC LIMIT 200
    `, params);
    return rows;
  }

  async createPolicy(patch: any, userId?: string) {
    const rules = Array.isArray(patch.rules) ? patch.rules : [];
    const { rows } = await this.db.query(`
      INSERT INTO governance_policies (name,description,category,status,rules,created_by,updated_by)
      VALUES ($1,$2,COALESCE($3,'access'),COALESCE($4,'active'),$5::jsonb,$6,$6)
      RETURNING *
    `, [patch.name, patch.description ?? null, patch.category ?? 'access', patch.status ?? 'active', JSON.stringify(rules), userId ?? null]);
    return rows[0];
  }

  async updatePolicy(id: string, patch: any, userId?: string) {
    const sets: string[] = []; const params: any[] = []; let i = 1;
    const push = (frag: string, val: any) => { sets.push(frag); params.push(val); };
    if (patch.name !== undefined)        push(`name=$${i++}`, patch.name);
    if (patch.description !== undefined) push(`description=$${i++}`, patch.description);
    if (patch.category !== undefined)    push(`category=$${i++}`, patch.category);
    if (patch.status !== undefined)      push(`status=$${i++}`, patch.status);
    if (patch.rules !== undefined)       push(`rules=$${i++}::jsonb`, JSON.stringify(Array.isArray(patch.rules) ? patch.rules : []));
    push(`updated_by=$${i++}`, userId ?? null);
    push(`updated_at=NOW()`, null);
    params.push(id);

    const { rows } = await this.db.query(`
      UPDATE governance_policies SET ${sets.join(', ')} WHERE id=$${i} RETURNING *
    `, params);
    return rows[0] ?? null;
  }

  async deletePolicy(id: string) {
    const { rowCount } = await this.db.query(`DELETE FROM governance_policies WHERE id=$1`, [id]);
    return (rowCount ?? 0) > 0;
  }
}



------------------------------------------------------------
FILE: backend\data-service\src\services\LineageService.ts
------------------------------------------------------------
// src/services/LineageService.ts
import { withTransaction } from '@/config/database';
import { logger } from '@/utils/logger';
import { createHash } from 'crypto';
import { performance } from 'perf_hooks';
import { z } from 'zod';
import { DatabaseService } from './DatabaseService';

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * Schemas & Types
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */

const LineageNodeSchema = z.object({
  id: z.string().uuid(),
  label: z.string().min(1).max(255),
  type: z.enum(['source', 'bronze', 'silver', 'gold', 'transformation', 'sink']),
  data_source_id: z.string().uuid().optional(),
  schema_name: z.string().max(100).optional(),
  table_name: z.string().max(100).optional(),
  description: z.string().max(1000).optional(),
  metadata: z.record(z.any()).optional(),
  created_at: z.date().optional(),
  updated_at: z.date().optional(),
  created_by: z.string().uuid().optional(),
});

const LineageEdgeSchema = z.object({
  id: z.string().uuid(),
  from_id: z.string().uuid(),
  to_id: z.string().uuid(),
  relationship_type: z.enum(['derives_from', 'transforms_to', 'copies_from', 'aggregates_from']),
  transformation_logic: z.string().max(2000).optional(),
  confidence_score: z.number().min(0).max(1).optional(),
  metadata: z.record(z.any()).optional(),
  created_at: z.date().optional(),
  updated_at: z.date().optional(),
  created_by: z.string().uuid().optional(),
});

const GraphFiltersSchema = z.object({
  dataSourceId: z.string().uuid().optional(),
  nodeTypes: z.array(z.enum(['source', 'bronze', 'silver', 'gold', 'transformation', 'sink'])).optional(),
  maxDepth: z.number().min(1).max(10).default(5),
  includeMetadata: z.boolean().default(false),
  relationshipTypes: z.array(z.enum(['derives_from', 'transforms_to', 'copies_from', 'aggregates_from'])).optional(),
  fromNodeId: z.string().uuid().optional(),
  toNodeId: z.string().uuid().optional(),
  limit: z.number().min(1).max(10000).default(1000),
});

const LineagePathSchema = z.object({
  startNodeId: z.string().uuid(),
  endNodeId: z.string().uuid(),
  maxDepth: z.number().min(1).max(20).default(10),
  direction: z.enum(['upstream', 'downstream', 'both']).default('both'),
});

export type LineageNode = z.infer<typeof LineageNodeSchema>;
export type LineageEdge = z.infer<typeof LineageEdgeSchema>;
export type GraphFilters = z.infer<typeof GraphFiltersSchema>;
export type LineagePath = z.infer<typeof LineagePathSchema>;

export interface LineageGraph {
  nodes: LineageNode[];
  edges: LineageEdge[];
  metadata: {
    totalNodes: number;
    totalEdges: number;
    nodeTypeDistribution: Record<string, number>;
    maxDepthReached: number;
    queryDuration: number;
    cacheHit: boolean;
  };
}

export interface LineagePathResult {
  paths: Array<{
    nodes: LineageNode[];
    edges: LineageEdge[];
    pathLength: number;
    confidence: number;
  }>;
  shortestPath?: {
    nodes: LineageNode[];
    edges: LineageEdge[];
    pathLength: number;
  };
  metadata: {
    totalPaths: number;
    maxDepthSearched: number;
    queryDuration: number;
  };
}

export interface LineageImpactAnalysis {
  affectedNodes: LineageNode[];
  impactRadius: number;
  criticalPaths: Array<{
    path: LineageNode[];
    criticality: 'high' | 'medium' | 'low';
    reason: string;
  }>;
  recommendations: string[];
}

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * Errors & Helpers
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */

class LineageError extends Error {
  constructor(
    message: string,
    public code: string = 'LINEAGE_ERROR',
    public statusCode: number = 500
  ) {
    super(message);
    this.name = 'LineageError';
  }
}
class LineageValidationError extends LineageError {
  constructor(message: string, public field?: string) {
    super(message, 'VALIDATION_ERROR', 400);
    this.name = 'LineageValidationError';
  }
}
class LineageNotFoundError extends LineageError {
  constructor(resource: string, id?: string) {
    super(id ? `${resource} with ID ${id} not found` : `${resource} not found`, 'NOT_FOUND', 404);
    this.name = 'LineageNotFoundError';
  }
}

const toError = (e: unknown): Error => (e instanceof Error ? e : new Error(String(e)));
const toInt = (v: unknown, fallback = 0): number => {
  const n = typeof v === 'string' ? Number(v) : (v as number);
  return Number.isFinite(n) ? (n as number) : fallback;
};

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * Service
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */

export class LineageService {
  private db = new DatabaseService();

  private queryCache: Map<string, { data: any; timestamp: number; ttl: number }> = new Map();
  private readonly cacheTTL = 300000; // 5 minutes
  private readonly maxCacheSize = 1000;

  constructor() {
    this.setupCacheCleanup();
  }

  /* â”€â”€ Graph retrieval â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */

  async getGraph(
    filters: Partial<GraphFilters> = {},
    requestContext: { userId?: string; requestId?: string } = {}
  ): Promise<LineageGraph> {
    const start = performance.now();
    const validated = GraphFiltersSchema.parse(filters);
    const cacheKey = this.generateCacheKey('graph', validated);

    // Cache lookup
    const cached = this.getCachedResult(cacheKey);
    if (cached) {
      const meta = {
        ...cached.metadata,
        cacheHit: true,
        queryDuration: Math.round(performance.now() - start),
      };
      logger.info('Lineage graph cache hit', {
        requestId: requestContext.requestId,
        userId: requestContext.userId,
        cacheKey: cacheKey.slice(0, 16),
      });
      return { ...cached, metadata: meta };
    }

    try {
      // No need for explicit transaction: two read-only queries
      const { nodesQuery, nodesParams } = this.buildNodesQuery(validated);
      const { edgesQuery, edgesParams } = this.buildEdgesQuery(validated);

      const nodesRes = (await this.db.query(nodesQuery, nodesParams)) as any;
      const edgesRes = (await this.db.query(edgesQuery, edgesParams)) as any;

      const nodes = this.processNodes(nodesRes.rows ?? [], validated.includeMetadata);
      const edges = this.processEdges(edgesRes.rows ?? []);

      const baseMeta = this.generateGraphMetadata(nodes, edges, performance.now() - start);
      const result: LineageGraph = { nodes, edges, metadata: { ...baseMeta, cacheHit: false } };

      this.setCachedResult(cacheKey, result, this.cacheTTL);

      logger.info('Lineage graph retrieved', {
        requestId: requestContext.requestId,
        userId: requestContext.userId,
        nodeCount: nodes.length,
        edgeCount: edges.length,
        queryDuration: baseMeta.queryDuration,
      });

      return result;
    } catch (e: unknown) {
      const err = toError(e);
      logger.error('Failed to retrieve lineage graph', {
        error: err.message,
        stack: err.stack,
        filters: validated,
        requestId: requestContext.requestId,
        userId: requestContext.userId,
      });
      throw new LineageError('Failed to retrieve lineage graph', 'GRAPH_RETRIEVAL_FAILED', 500);
    }
  }

  /* â”€â”€ Path finding â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */

  async findLineagePaths(
    pathConfig: LineagePath,
    requestContext: { userId?: string; requestId?: string } = {}
  ): Promise<LineagePathResult> {
    const start = performance.now();
    const cfg = LineagePathSchema.parse(pathConfig);

    try {
      await this.validateNodesExist([cfg.startNodeId, cfg.endNodeId]);

      const { query, params } = this.buildPathQuery(cfg);
      const res = (await this.db.query(query, params)) as any;

      const paths = this.processPaths(res.rows ?? []);
      const shortestPath = this.findShortestPath(paths);

      const meta = {
        totalPaths: paths.length,
        maxDepthSearched: cfg.maxDepth,
        queryDuration: Math.round(performance.now() - start),
      };

      logger.info('Lineage paths found', {
        requestId: requestContext.requestId,
        userId: requestContext.userId,
        startNode: cfg.startNodeId,
        endNode: cfg.endNodeId,
        pathsFound: paths.length,
        queryDuration: meta.queryDuration,
      });

      return { paths, shortestPath, metadata: meta };
    } catch (e: unknown) {
      const err = toError(e);
      logger.error('Failed to find lineage paths', {
        error: err.message,
        pathConfig: cfg,
        requestId: requestContext.requestId,
        userId: requestContext.userId,
      });
      if (err instanceof LineageError) throw err;
      throw new LineageError('Failed to find lineage paths', 'PATH_FINDING_FAILED', 500);
    }
  }

  /* â”€â”€ Impact analysis â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */

  async analyzeImpact(
    nodeId: string,
    analysisDepth = 5,
    requestContext: { userId?: string; requestId?: string } = {}
  ): Promise<LineageImpactAnalysis> {
    if (!z.string().uuid().safeParse(nodeId).success) {
      throw new LineageValidationError('Invalid node ID format');
    }

    try {
      await this.validateNodesExist([nodeId]);

      const downstreamQuery = `
        WITH RECURSIVE downstream_impact AS (
          SELECT ln.*, 0 as depth, ARRAY[ln.id] as path
          FROM lineage_nodes ln
          WHERE ln.id = $1 AND ln.deleted_at IS NULL
          UNION ALL
          SELECT ln.*, di.depth + 1, di.path || ln.id
          FROM lineage_nodes ln
          JOIN lineage_edges le ON ln.id = le.to_id
          JOIN downstream_impact di ON le.from_id = di.id
          WHERE di.depth < $2 
            AND ln.deleted_at IS NULL 
            AND le.deleted_at IS NULL
            AND NOT (ln.id = ANY(di.path))
        )
        SELECT DISTINCT id, label, type, schema_name, table_name, depth
        FROM downstream_impact
        WHERE depth > 0
        ORDER BY depth, type, label;
      `;

      const res = (await this.db.query(downstreamQuery, [nodeId, analysisDepth])) as any;

      const affectedNodes: LineageNode[] = (res.rows ?? []).map((row: any) => ({
        id: row.id,
        label: row.label,
        type: row.type,
        schema_name: row.schema_name,
        table_name: row.table_name,
      }));

      const criticalPaths = this.analyzeCriticality(affectedNodes);
      const recommendations = this.generateRecommendations(affectedNodes, criticalPaths);

      const impactRadius = (res.rows ?? []).reduce((m: number, r: any) => Math.max(m, toInt(r.depth, 0)), 0);

      logger.info('Impact analysis completed', {
        requestId: requestContext.requestId,
        userId: requestContext.userId,
        nodeId,
        affectedCount: affectedNodes.length,
        impactRadius,
      });

      return {
        affectedNodes,
        impactRadius,
        criticalPaths,
        recommendations,
      };
    } catch (e: unknown) {
      const err = toError(e);
      logger.error('Failed to analyze impact', {
        error: err.message,
        nodeId,
        requestId: requestContext.requestId,
        userId: requestContext.userId,
      });
      if (err instanceof LineageError) throw err;
      throw new LineageError('Failed to analyze impact', 'IMPACT_ANALYSIS_FAILED', 500);
    }
  }

  /* â”€â”€ Mutations â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */

  async createNode(
    nodeData: Omit<LineageNode, 'id' | 'created_at' | 'updated_at'>,
    userId: string,
    requestContext: { requestId?: string } = {}
  ): Promise<LineageNode> {
    const data = LineageNodeSchema.omit({ id: true, created_at: true, updated_at: true }).parse(nodeData);

    try {
      const inserted = await withTransaction(async (client) => {
        // duplicate check
        if (data.schema_name && data.table_name) {
          const dup = await client.query(
            `SELECT id FROM lineage_nodes 
             WHERE schema_name = $1 AND table_name = $2 AND data_source_id = $3 AND deleted_at IS NULL`,
            [data.schema_name, data.table_name, data.data_source_id]
          );
          if ((dup.rows ?? []).length > 0) {
            throw new LineageValidationError(`Node already exists for ${data.schema_name}.${data.table_name}`);
          }
        }

        const ins = await client.query(
          `
          INSERT INTO lineage_nodes (
            label, type, data_source_id, schema_name, table_name,
            description, metadata, created_by, created_at, updated_at
          ) VALUES ($1,$2,$3,$4,$5,$6,$7,$8,NOW(),NOW())
          RETURNING id, label, type, data_source_id, schema_name, table_name,
                    description, metadata, created_at, updated_at, created_by
          `,
          [
            data.label,
            data.type,
            data.data_source_id ?? null,
            data.schema_name ?? null,
            data.table_name ?? null,
            data.description ?? null,
            JSON.stringify(data.metadata ?? {}),
            userId,
          ]
        );
        return ins.rows[0] as LineageNode;
      });

      this.invalidateGraphCache();

      logger.info('Lineage node created', {
        nodeId: inserted.id,
        label: inserted.label,
        type: inserted.type,
        userId,
        requestId: requestContext.requestId,
      });

      return inserted;
    } catch (e: unknown) {
      const err = toError(e);
      if (err instanceof LineageError) throw err;
      logger.error('Failed to create lineage node', {
        error: err.message,
        nodeData: data,
        userId,
        requestId: requestContext.requestId,
      });
      throw new LineageError('Failed to create lineage node', 'NODE_CREATION_FAILED', 500);
    }
  }

  async createEdge(
    edgeData: Omit<LineageEdge, 'id' | 'created_at' | 'updated_at'>,
    userId: string,
    requestContext: { requestId?: string } = {}
  ): Promise<LineageEdge> {
    const data = LineageEdgeSchema.omit({ id: true, created_at: true, updated_at: true }).parse(edgeData);

    if (data.from_id === data.to_id) {
      throw new LineageValidationError('Self-referencing edges are not allowed');
    }
    await this.validateNodesExist([data.from_id, data.to_id]);

    try {
      const inserted = await withTransaction(async (client) => {
        // duplicate edge check
        const dup = await client.query(
          `SELECT id FROM lineage_edges 
           WHERE from_id = $1 AND to_id = $2 AND relationship_type = $3 AND deleted_at IS NULL`,
          [data.from_id, data.to_id, data.relationship_type]
        );
        if ((dup.rows ?? []).length > 0) {
          throw new LineageValidationError('Edge with this relationship already exists between these nodes');
        }

        // cycle check (simple downstream reachability)
        const cycleQ = `
          WITH RECURSIVE path_check AS (
            SELECT id, 0 as depth FROM lineage_nodes WHERE id = $1
            UNION ALL
            SELECT ln.id, pc.depth + 1
            FROM path_check pc
            JOIN lineage_edges le ON pc.id = le.from_id
            JOIN lineage_nodes ln ON le.to_id = ln.id
            WHERE pc.depth < 20 AND ln.deleted_at IS NULL AND le.deleted_at IS NULL
          )
          SELECT EXISTS(SELECT 1 FROM path_check WHERE id = $2 AND depth > 0) as has_cycle;
        `;
        const cyc = await client.query(cycleQ, [data.to_id, data.from_id]);
        if (cyc.rows?.[0]?.has_cycle === true) {
          throw new LineageValidationError('Creating this edge would introduce a cycle in the lineage graph');
        }

        const ins = await client.query(
          `
          INSERT INTO lineage_edges (
            from_id, to_id, relationship_type, transformation_logic,
            confidence_score, metadata, created_by, created_at, updated_at
          ) VALUES ($1,$2,$3,$4,$5,$6,$7,NOW(),NOW())
          RETURNING id, from_id, to_id, relationship_type, transformation_logic,
                    confidence_score, metadata, created_at, updated_at, created_by
          `,
          [
            data.from_id,
            data.to_id,
            data.relationship_type,
            data.transformation_logic ?? null,
            data.confidence_score ?? null,
            JSON.stringify(data.metadata ?? {}),
            userId,
          ]
        );
        return ins.rows[0] as LineageEdge;
      });

      this.invalidateGraphCache();

      logger.info('Lineage edge created', {
        edgeId: inserted.id,
        fromId: inserted.from_id,
        toId: inserted.to_id,
        relationshipType: inserted.relationship_type,
        userId,
        requestId: requestContext.requestId,
      });

      return inserted;
    } catch (e: unknown) {
      const err = toError(e);
      if (err instanceof LineageError) throw err;
      logger.error('Failed to create lineage edge', {
        error: err.message,
        edgeData: data,
        userId,
        requestId: requestContext.requestId,
      });
      throw new LineageError('Failed to create lineage edge', 'EDGE_CREATION_FAILED', 500);
    }
  }

  async deleteNode(
    nodeId: string,
    userId: string,
    requestContext: { requestId?: string } = {}
  ): Promise<void> {
    if (!z.string().uuid().safeParse(nodeId).success) throw new LineageValidationError('Invalid node ID format');
    await this.validateNodesExist([nodeId]);

    try {
      await withTransaction(async (client) => {
        await client.query(
          `UPDATE lineage_nodes SET deleted_at = NOW(), deleted_by = $2, updated_at = NOW()
           WHERE id = $1 AND deleted_at IS NULL`,
          [nodeId, userId]
        );
        await client.query(
          `UPDATE lineage_edges SET deleted_at = NOW(), deleted_by = $2, updated_at = NOW()
           WHERE (from_id = $1 OR to_id = $1) AND deleted_at IS NULL`,
          [nodeId, userId]
        );
      });

      this.invalidateGraphCache();

      logger.warn('Lineage node deleted', { nodeId, userId, requestId: requestContext.requestId });
    } catch (e: unknown) {
      const err = toError(e);
      logger.error('Failed to delete lineage node', { error: err.message, nodeId, userId, requestId: requestContext.requestId });
      throw new LineageError('Failed to delete lineage node', 'NODE_DELETION_FAILED', 500);
    }
  }

  async deleteEdge(
    edgeId: string,
    userId: string,
    requestContext: { requestId?: string } = {}
  ): Promise<void> {
    if (!z.string().uuid().safeParse(edgeId).success) throw new LineageValidationError('Invalid edge ID format');

    try {
      const res = (await this.db.query(
        `UPDATE lineage_edges 
         SET deleted_at = NOW(), deleted_by = $2, updated_at = NOW()
         WHERE id = $1 AND deleted_at IS NULL
         RETURNING id`,
        [edgeId, userId]
      )) as any;

      if ((res.rows ?? []).length === 0) throw new LineageNotFoundError('Lineage edge', edgeId);

      this.invalidateGraphCache();

      logger.warn('Lineage edge deleted', { edgeId, userId, requestId: requestContext.requestId });
    } catch (e: unknown) {
      const err = toError(e);
      if (err instanceof LineageError) throw err;
      logger.error('Failed to delete lineage edge', { error: err.message, edgeId, userId, requestId: requestContext.requestId });
      throw new LineageError('Failed to delete lineage edge', 'EDGE_DELETION_FAILED', 500);
    }
  }

  async bulkCreateNodes(
    nodesData: Array<Omit<LineageNode, 'id' | 'created_at' | 'updated_at'>>,
    userId: string,
    requestContext: { requestId?: string } = {}
  ): Promise<{ created: LineageNode[]; errors: Array<{ index: number; error: string }> }> {
    if (nodesData.length > 1000) throw new LineageValidationError('Maximum 1000 nodes allowed in bulk operation');

    const created: LineageNode[] = [];
    const errors: Array<{ index: number; error: string }> = [];

    try {
      await withTransaction(async (client) => {
        for (let i = 0; i < nodesData.length; i++) {
          try {
            const data = LineageNodeSchema.omit({ id: true, created_at: true, updated_at: true }).parse(nodesData[i]);

            const dup = await client.query(
              `SELECT id FROM lineage_nodes 
               WHERE schema_name = $1 AND table_name = $2 AND data_source_id = $3 AND deleted_at IS NULL`,
              [data.schema_name ?? null, data.table_name ?? null, data.data_source_id ?? null]
            );
            if ((dup.rows ?? []).length > 0) {
              errors.push({ index: i, error: `Duplicate node: ${data.schema_name}.${data.table_name}` });
              continue;
            }

            const ins = await client.query(
              `
              INSERT INTO lineage_nodes (
                label, type, data_source_id, schema_name, table_name,
                description, metadata, created_by, created_at, updated_at
              ) VALUES ($1,$2,$3,$4,$5,$6,$7,$8,NOW(),NOW())
              RETURNING id, label, type, data_source_id, schema_name, table_name,
                        description, metadata, created_at, updated_at, created_by
              `,
              [
                data.label,
                data.type,
                data.data_source_id ?? null,
                data.schema_name ?? null,
                data.table_name ?? null,
                data.description ?? null,
                JSON.stringify(data.metadata ?? {}),
                userId,
              ]
            );
            created.push(ins.rows[0] as LineageNode);
          } catch (e: unknown) {
            const err = toError(e);
            errors.push({ index: i, error: err.message || 'Unknown validation error' });
          }
        }
      });

      this.invalidateGraphCache();

      logger.info('Bulk node creation completed', {
        totalNodes: nodesData.length,
        created: created.length,
        errors: errors.length,
        userId,
        requestId: requestContext.requestId,
      });

      return { created, errors };
    } catch (e: unknown) {
      const err = toError(e);
      logger.error('Failed to bulk create lineage nodes', {
        error: err.message,
        totalNodes: nodesData.length,
        userId,
        requestId: requestContext.requestId,
      });
      throw new LineageError('Failed to bulk create lineage nodes', 'BULK_NODE_CREATION_FAILED', 500);
    }
  }

  /* â”€â”€ Stats â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */

  async getLineageStats(
    dataSourceId?: string,
    requestContext: { userId?: string; requestId?: string } = {}
  ): Promise<{
    totalNodes: number;
    totalEdges: number;
    nodesByType: Record<string, number>;
    edgesByType: Record<string, number>;
    orphanedNodes: number;
    cyclicalReferences: number;
    dataQualityScore: number;
    lastUpdated: Date;
  }> {
    // Where/params
    const whereClause = dataSourceId ? 'WHERE ln.data_source_id = $1 AND ln.deleted_at IS NULL' : 'WHERE ln.deleted_at IS NULL';
    const params = dataSourceId ? [dataSourceId] : [];

    try {
      const [nodeStats, edgeStats, orphanStats] = (await Promise.all([
        this.db.query(
          `
          SELECT type, COUNT(*)::int as count_by_type
          FROM lineage_nodes ln
          ${whereClause}
          GROUP BY type
          ORDER BY count_by_type DESC
          `,
          params
        ) as any,
        this.db.query(
          `
          SELECT le.relationship_type, COUNT(*)::int as count_by_type, AVG(le.confidence_score)::float as avg_confidence
          FROM lineage_edges le
          JOIN lineage_nodes ln_from ON le.from_id = ln_from.id
          JOIN lineage_nodes ln_to   ON le.to_id   = ln_to.id
          WHERE le.deleted_at IS NULL 
            AND ln_from.deleted_at IS NULL 
            AND ln_to.deleted_at IS NULL
            ${dataSourceId ? 'AND (ln_from.data_source_id = $1 OR ln_to.data_source_id = $1)' : ''}
          GROUP BY le.relationship_type
          `,
          params
        ) as any,
        this.db.query(
          `
          SELECT COUNT(*)::int as orphaned_count
          FROM lineage_nodes ln
          ${whereClause}
            AND NOT EXISTS (
              SELECT 1 FROM lineage_edges le 
              WHERE (le.from_id = ln.id OR le.to_id = ln.id) 
                AND le.deleted_at IS NULL
            )
          `,
          params
        ) as any,
      ])) as [any, any, any];

      const totalNodes = (nodeStats.rows ?? []).reduce((sum: number, row: any) => sum + toInt(row.count_by_type, 0), 0);
      const totalEdges = (edgeStats.rows ?? []).reduce((sum: number, row: any) => sum + toInt(row.count_by_type, 0), 0);

      const nodesByType = (nodeStats.rows ?? []).reduce((acc: Record<string, number>, row: any) => {
        acc[row.type] = toInt(row.count_by_type, 0);
        return acc;
      }, {});

      const edgesByType = (edgeStats.rows ?? []).reduce((acc: Record<string, number>, row: any) => {
        acc[row.relationship_type] = toInt(row.count_by_type, 0);
        return acc;
      }, {});

      const avgConfidence =
        (edgeStats.rows ?? []).reduce((sum: number, row: any) => sum + (Number(row.avg_confidence ?? 0.8) || 0.8), 0) /
        Math.max((edgeStats.rows ?? []).length, 1);

      const orphanedCount = toInt(orphanStats.rows?.[0]?.orphaned_count, 0);
      const orphanedRatio = totalNodes > 0 ? orphanedCount / totalNodes : 0;

      const dataQualityScore = Math.round((avgConfidence * 0.6 + (1 - orphanedRatio) * 0.4) * 100);

      logger.info('Lineage statistics retrieved', {
        totalNodes,
        totalEdges,
        dataQualityScore,
        dataSourceId,
        requestId: requestContext.requestId,
        userId: requestContext.userId,
      });

      return {
        totalNodes,
        totalEdges,
        nodesByType,
        edgesByType,
        orphanedNodes: orphanedCount,
        cyclicalReferences: 0, // detecting cycles requires a dedicated algorithm/query
        dataQualityScore,
        lastUpdated: new Date(),
      };
    } catch (e: unknown) {
      const err = toError(e);
      logger.error('Failed to retrieve lineage statistics', {
        error: err.message,
        dataSourceId,
        requestId: requestContext.requestId,
        userId: requestContext.userId,
      });
      throw new LineageError('Failed to retrieve lineage statistics', 'STATS_RETRIEVAL_FAILED', 500);
    }
  }

  /* â”€â”€ Private helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */

  private buildNodesQuery(filters: GraphFilters): { nodesQuery: string; nodesParams: any[] } {
    const where: string[] = ['ln.deleted_at IS NULL'];
    const params: any[] = [];
    let i = 1;

    if (filters.dataSourceId) {
      where.push(`ln.data_source_id = $${i++}`);
      params.push(filters.dataSourceId);
    }

    if (filters.nodeTypes && filters.nodeTypes.length > 0) {
      where.push(`ln.type = ANY($${i++})`);
      params.push(filters.nodeTypes);
    }

    const selectFields = filters.includeMetadata
      ? 'ln.id, ln.label, ln.type, ln.data_source_id, ln.schema_name, ln.table_name, ln.description, ln.metadata, ln.created_at, ln.updated_at'
      : 'ln.id, ln.label, ln.type, ln.data_source_id, ln.schema_name, ln.table_name';

    const nodesQuery = `
      SELECT ${selectFields}
      FROM lineage_nodes ln
      WHERE ${where.join(' AND ')}
      ORDER BY ln.type, ln.label
      LIMIT $${i++}
    `;
    params.push(filters.limit);

    return { nodesQuery, nodesParams: params };
  }

  private buildEdgesQuery(filters: GraphFilters): { edgesQuery: string; edgesParams: any[] } {
    const where: string[] = ['le.deleted_at IS NULL'];
    const params: any[] = [];
    let i = 1;

    if (filters.relationshipTypes && filters.relationshipTypes.length > 0) {
      where.push(`le.relationship_type = ANY($${i++})`);
      params.push(filters.relationshipTypes);
    }

    if (filters.dataSourceId) {
      where.push(`(
        EXISTS(SELECT 1 FROM lineage_nodes ln WHERE ln.id = le.from_id AND ln.data_source_id = $${i}) OR
        EXISTS(SELECT 1 FROM lineage_nodes ln WHERE ln.id = le.to_id   AND ln.data_source_id = $${i})
      )`);
      params.push(filters.dataSourceId);
      i++;
    }

    const selectFields = filters.includeMetadata
      ? 'le.id, le.from_id, le.to_id, le.relationship_type, le.transformation_logic, le.confidence_score, le.metadata, le.created_at, le.updated_at'
      : 'le.id, le.from_id, le.to_id, le.relationship_type';

    const edgesQuery = `
      SELECT ${selectFields}
      FROM lineage_edges le
      WHERE ${where.join(' AND ')}
      ORDER BY le.from_id, le.to_id
      LIMIT $${i++}
    `;
    params.push(filters.limit);

    return { edgesQuery, edgesParams: params };
  }

  private buildPathQuery(config: LineagePath): { query: string; params: any[] } {
    const join = this.getDirectionClause(config.direction);
    const nodeJoin = this.getNodeJoinCondition(config.direction);

    const query = `
      WITH RECURSIVE lineage_paths AS (
        SELECT 
          ln.id, ln.label, ln.type,
          ARRAY[ln.id] as path_nodes,
          ARRAY[]::uuid[] as path_edges,
          0 as depth,
          1.0 as confidence
        FROM lineage_nodes ln
        WHERE ln.id = $1 AND ln.deleted_at IS NULL
        UNION ALL
        SELECT 
          ln.id, ln.label, ln.type,
          lp.path_nodes || ln.id,
          lp.path_edges || le.id,
          lp.depth + 1,
          lp.confidence * COALESCE(le.confidence_score, 0.8)
        FROM lineage_paths lp
        JOIN lineage_edges le ${join}
        JOIN lineage_nodes ln ON ${nodeJoin}
        WHERE lp.depth < $3
          AND ln.deleted_at IS NULL
          AND le.deleted_at IS NULL
          AND NOT (ln.id = ANY(lp.path_nodes))
      )
      SELECT * FROM lineage_paths 
      WHERE id = $2 AND depth > 0
      ORDER BY depth, confidence DESC;
    `;

    return { query, params: [config.startNodeId, config.endNodeId, config.maxDepth] };
  }

  private getDirectionClause(direction: string): string {
    switch (direction) {
      case 'upstream':
        return 'ON le.to_id = lp.id';
      case 'downstream':
        return 'ON le.from_id = lp.id';
      case 'both':
      default:
        return 'ON (le.from_id = lp.id OR le.to_id = lp.id)';
    }
  }

  private getNodeJoinCondition(direction: string): string {
    switch (direction) {
      case 'upstream':
        return 'ln.id = le.from_id';
      case 'downstream':
        return 'ln.id = le.to_id';
      case 'both':
      default:
        return '(ln.id = le.to_id OR ln.id = le.from_id) AND ln.id != lp.id';
    }
  }

  private async validateNodesExist(nodeIds: string[]): Promise<void> {
    const res = (await this.db.query(
      'SELECT id FROM lineage_nodes WHERE id = ANY($1) AND deleted_at IS NULL',
      [nodeIds]
    )) as any;

    const found = new Set<string>((res.rows ?? []).map((r: any) => r.id as string));
    const missing = nodeIds.filter((id) => !found.has(id));
    if (missing.length > 0) throw new LineageNotFoundError('Lineage nodes', missing.join(', '));
  }

  private processNodes(rows: any[], includeMetadata: boolean): LineageNode[] {
    return rows.map((row: any) => ({
      id: row.id,
      label: row.label,
      type: row.type,
      data_source_id: row.data_source_id ?? undefined,
      schema_name: row.schema_name ?? undefined,
      table_name: row.table_name ?? undefined,
      ...(includeMetadata
        ? {
            description: row.description ?? undefined,
            metadata: row.metadata ?? undefined,
            created_at: row.created_at ?? undefined,
            updated_at: row.updated_at ?? undefined,
          }
        : {}),
    }));
  }

  private processEdges(rows: any[]): LineageEdge[] {
    return rows.map((row: any) => ({
      id: row.id,
      from_id: row.from_id,
      to_id: row.to_id,
      relationship_type: row.relationship_type,
      transformation_logic: row.transformation_logic ?? undefined,
      confidence_score: typeof row.confidence_score === 'number' ? row.confidence_score : undefined,
      metadata: row.metadata ?? undefined,
      created_at: row.created_at ?? undefined,
      updated_at: row.updated_at ?? undefined,
    }));
  }

  private processPaths(rows: any[]): Array<{ nodes: LineageNode[]; edges: LineageEdge[]; pathLength: number; confidence: number }> {
    return rows.map((row: any) => ({
      // If you need full nodes/edges, fetch by ids in row.path_nodes / row.path_edges
      nodes: [],
      edges: [],
      pathLength: toInt(row.depth, 0),
      confidence: Number(row.confidence ?? 0),
    }));
  }

  private findShortestPath<T extends { pathLength: number }>(paths: T[]): T | undefined {
    return paths.reduce<T | undefined>((shortest, current) => {
      if (!shortest) return current;
      return current.pathLength < shortest.pathLength ? current : shortest;
    }, undefined);
  }

  private analyzeCriticality(nodes: LineageNode[]): Array<{ path: LineageNode[]; criticality: 'high' | 'medium' | 'low'; reason: string }> {
    return nodes
      .filter((n) => n.type === 'gold')
      .map((n) => ({ path: [n], criticality: 'high' as const, reason: 'Production gold-tier data asset' }));
  }

  private generateRecommendations(affectedNodes: LineageNode[], criticalPaths: Array<{ path: LineageNode[] }>): string[] {
    const rec: string[] = [];
    if (affectedNodes.length > 50) rec.push('High impact change detected. Consider phased deployment approach.');
    if (criticalPaths.length > 0) rec.push('Critical production assets affected. Coordinate with data consumers before deployment.');
    const goldCount = affectedNodes.filter((n) => n.type === 'gold').length;
    if (goldCount > 0) rec.push(`${goldCount} gold-tier assets affected. Ensure data quality validation.`);
    rec.push('Review and update documentation for affected assets.');
    rec.push('Schedule stakeholder notifications before implementing changes.');
    return rec;
    }

  private generateGraphMetadata(nodes: LineageNode[], edges: LineageEdge[], queryDurationMs: number): Omit<LineageGraph['metadata'], 'cacheHit'> {
    const nodeTypeDistribution = nodes.reduce<Record<string, number>>((acc, n) => {
      acc[n.type] = (acc[n.type] ?? 0) + 1;
      return acc;
    }, {});
    return {
      totalNodes: nodes.length,
      totalEdges: edges.length,
      nodeTypeDistribution,
      maxDepthReached: this.calculateMaxDepth(nodes, edges),
      queryDuration: Math.round(queryDurationMs),
    };
  }

  private calculateMaxDepth(nodes: LineageNode[], edges: LineageEdge[]): number {
    if (nodes.length === 0 || edges.length === 0) return 0;

    const incoming = new Set<string>(edges.map((e) => e.to_id));
    const sources = nodes.filter((n) => !incoming.has(n.id));
    if (sources.length === 0) return 0;

    let maxDepth = 0;
    const visited = new Set<string>();
    const queue: Array<{ nodeId: string; depth: number }> = sources.map((s) => ({ nodeId: s.id, depth: 0 }));

    while (queue.length) {
      const current = queue.shift()!;
      if (visited.has(current.nodeId)) continue;
      visited.add(current.nodeId);
      maxDepth = Math.max(maxDepth, current.depth);

      const children = edges.filter((e) => e.from_id === current.nodeId).map((e) => e.to_id);
      for (const nextId of children) {
        if (!visited.has(nextId)) queue.push({ nodeId: nextId, depth: current.depth + 1 });
      }
    }
    return maxDepth;
  }

  /* â”€â”€ Cache â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */

  private generateCacheKey(operation: string, filters: any): string {
    const filterString = JSON.stringify(filters, Object.keys(filters).sort());
    return createHash('md5').update(`${operation}:${filterString}`).digest('hex');
  }

  private getCachedResult(key: string): any | null {
    const cached = this.queryCache.get(key);
    if (!cached) return null;
    const now = Date.now();
    if (now - cached.timestamp > cached.ttl) {
      this.queryCache.delete(key);
      return null;
    }
    return cached.data;
  }

  private setCachedResult(key: string, data: any, ttl: number): void {
    if (this.queryCache.size >= this.maxCacheSize) {
      const oldestKey: string | undefined = this.queryCache.keys().next().value;
      if (typeof oldestKey === 'string') this.queryCache.delete(oldestKey);
    }
    this.queryCache.set(key, { data, timestamp: Date.now(), ttl });
  }

  private invalidateGraphCache(): void {
    for (const k of Array.from(this.queryCache.keys())) {
      if (k.startsWith('graph:')) this.queryCache.delete(k);
    }
  }

  private setupCacheCleanup(): void {
    setInterval(() => {
      const now = Date.now();
      for (const [key, entry] of this.queryCache) {
        if (now - entry.timestamp > entry.ttl) this.queryCache.delete(key);
      }
    }, 300000).unref();
  }
}

/** Optional singleton export if you prefer DI */
export const lineageService = new LineageService();



------------------------------------------------------------
FILE: backend\data-service\src\services\QualityService.ts
------------------------------------------------------------
// backend/data-service/src/services/QualityService.ts
import { createHash } from 'crypto';
import { performance } from 'perf_hooks';
import { Pool, PoolClient, PoolConfig } from 'pg';
import { z } from 'zod';
import { logger } from '../utils/logger';
import { DatabaseService } from './DatabaseService';

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * Zod Schemas & Types
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */

const QualityRuleSchema = z.object({
  name: z.string().min(2).max(255).trim(),
  description: z.string().max(1000).optional(),
  severity: z.enum(['low', 'medium', 'high', 'critical']).default('medium'),
  type: z.enum(['sql', 'metric']).default('sql'),
  dialect: z.enum(['postgres', 'generic']).default('postgres'),
  expression: z.string().min(3).max(10_000),
  tags: z.array(z.string().max(50)).max(20).default([]),
  enabled: z.boolean().default(true),
});

const QueryExecutionSchema = z.object({
  ruleId: z.string().uuid(),
  dataSourceId: z.string().uuid().optional(),
  timeout: z.number().min(1_000).max(300_000).default(30_000),
});

export type QualityRule = z.infer<typeof QualityRuleSchema> & {
  id: string;
  created_by: string | null;
  updated_by: string | null;
  created_at: Date;
  updated_at: Date;
};

export type QualityResult = {
  id: string;
  rule_id: string;
  data_source_id: string | null;
  status: 'passed' | 'failed' | 'error' | 'skipped' | 'timeout';
  run_at: Date;
  execution_time_ms: number;
  metrics: Record<string, any>;
  error: string | null;
  query_hash: string;
};

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * SQL Safety Validator
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */

class QueryValidator {
  private static readonly FORBIDDEN = [
    'DROP','DELETE','INSERT','UPDATE','ALTER','CREATE','TRUNCATE',
    'GRANT','REVOKE','EXEC','EXECUTE','CALL','MERGE','REPLACE',
  ];

  static validateSQLQuery(query: string): { isValid: boolean; errors: string[] } {
    const errors: string[] = [];
    const upper = query.toUpperCase();

    // SELECT-only & no multi-statement
    if (!upper.trim().startsWith('SELECT')) errors.push('Query must start with SELECT.');
    if (upper.includes(';')) errors.push('Multiple statements are not allowed.');

    // DDL/DML
    for (const kw of this.FORBIDDEN) {
      if (upper.includes(kw)) errors.push(`Forbidden keyword detected: ${kw}`);
    }

    // Dangerous patterns
    const bad = [
      /UNION\s+ALL?\s+SELECT.*INFORMATION_SCHEMA/i,
      /pg_sleep\(/i,
      /waitfor\s+delay/i,
      /xp_cmdshell/i,
      /sp_configure/i,
    ];
    for (const pat of bad) {
      if (pat.test(query)) errors.push('Potentially dangerous SQL pattern detected.');
    }

    // Complexity guard
    const selectCount = (upper.match(/\bSELECT\b/g) || []).length;
    if (selectCount > 5) errors.push('Query too complex: >5 nested SELECTs.');

    return { isValid: errors.length === 0, errors };
  }
}

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * External Data Source Pool Manager (Postgres)
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */

type ExternalPgConfig = { connectionString: string; ssl?: boolean };

class DataSourcePoolManager {
  private pools = new Map<string, Pool>();
  private readonly maxPools = 5;

  getPool(cfg: ExternalPgConfig): Pool {
    const key = this.hashCfg(cfg);
    const found = this.pools.get(key);
    if (found) return found;

    if (this.pools.size >= this.maxPools) {
      throw new Error('Maximum external connection pool limit reached.');
    }

    const poolCfg: PoolConfig = {
      connectionString: cfg.connectionString,
      max: 2,
      idleTimeoutMillis: 30_000,
      connectionTimeoutMillis: 10_000,
      ssl: cfg.ssl ? { rejectUnauthorized: false } : undefined,
    };
    const pool = new Pool(poolCfg);
    pool.on('error', (err) => logger.error('External pool idle client error', { err: String(err) }));
    this.pools.set(key, pool);
    return pool;
  }

  async cleanup(): Promise<void> {
    for (const [key, pool] of this.pools) {
      try {
        await pool.end();
      } catch (err) {
        logger.error('Error closing external pool', { key, err: String(err) });
      }
      this.pools.delete(key);
    }
  }

  private hashCfg(cfg: ExternalPgConfig): string {
    const redacted = cfg.connectionString.replace(/:(?:[^@]+)@/, ':***@');
    return createHash('sha256').update(JSON.stringify({ connectionString: redacted, ssl: !!cfg.ssl }))
      .digest('hex').slice(0, 16);
  }
}

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * Helpers
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */

function toInt(x: unknown, fallback = 0): number {
  const n = typeof x === 'string' ? Number(x) : (x as number);
  return Number.isFinite(n) ? (n as number) : fallback;
}

function hashQuery(sql: string): string {
  return createHash('sha256').update(sql).digest('hex').slice(0, 16);
}

async function withStatementTimeout(client: PoolClient, timeoutMs: number, fn: () => Promise<any>) {
  await client.query('SET LOCAL statement_timeout = $1', [timeoutMs]);
  return fn();
}

async function withConnectTimeout(pool: Pool, timeoutMs: number): Promise<PoolClient> {
  let timer: NodeJS.Timeout | null = null;
  try {
    const connectPromise = pool.connect();
    const timeoutPromise = new Promise<never>((_, reject) => {
      timer = setTimeout(() => reject(new Error('Connection timeout')), timeoutMs);
    });
    const client = (await Promise.race([connectPromise, timeoutPromise])) as PoolClient;
    if (timer) clearTimeout(timer);
    return client;
  } catch (e) {
    if (timer) clearTimeout(timer);
    throw e;
  }
}

function safeJsonParse(s: string): any {
  try { return JSON.parse(s); } catch { return undefined; }
}

function redactError(msg: string): string {
  return msg.replace(/(password|pwd)=([^;\s]+)/gi, 'password=***');
}

function timeframeToMs(tf: '24h' | '7d' | '30d' | '90d'): number {
  switch (tf) {
    case '24h': return 24 * 60 * 60 * 1000;
    case '7d':  return 7  * 24 * 60 * 60 * 1000;
    case '30d': return 30 * 24 * 60 * 60 * 1000;
    case '90d': return 90 * 24 * 60 * 60 * 1000;
    default:    return 7  * 24 * 60 * 60 * 1000;
  }
}

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * Quality Service
 * (no generics at call sites â†’ avoids TS2558 if DatabaseService isn't generic)
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */

export class QualityService {
  private readonly db = new DatabaseService();          // internal metadata DB wrapper
  private readonly pools = new DataSourcePoolManager();  // external DS pools

  /* â”€â”€ Rules: list/get/create/update/delete â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */

  async listRules(filters: {
    q?: string;
    severity?: string;
    enabled?: boolean;
    limit?: number;
    offset?: number;
  } = {}): Promise<{ rules: QualityRule[]; total: number }> {
    const { q = '', severity, enabled, limit = 50, offset = 0 } = filters;

    const conds: string[] = [];
    const params: any[] = [];
    let i = 1;

    if (q) { conds.push(`(name ILIKE $${i} OR description ILIKE $${i})`); params.push(`%${q}%`); i++; }
    if (severity) { conds.push(`severity = $${i}`); params.push(severity); i++; }
    if (typeof enabled === 'boolean') { conds.push(`enabled = $${i}`); params.push(enabled); i++; }

    const where = conds.length ? `WHERE ${conds.join(' AND ')}` : '';

    const countRes = await this.db.query(`SELECT COUNT(*) AS total FROM quality_rules ${where}`, params) as any;
    const total = toInt(countRes.rows?.[0]?.total, 0);

    const pageLimit = Math.min(Math.max(limit, 1), 100);
    const pageOffset = Math.max(offset, 0);

    const rulesRes = await this.db.query(
      `
      SELECT id, name, description, severity, type, dialect, expression, tags,
             enabled, created_by, updated_by, created_at, updated_at
      FROM quality_rules
      ${where}
      ORDER BY updated_at DESC
      LIMIT $${i} OFFSET $${i + 1}
      `,
      [...params, pageLimit, pageOffset],
    ) as any;

    const rules = ((rulesRes.rows ?? []) as QualityRule[]).map((r) => ({
      ...r,
      tags: Array.isArray(r.tags) ? r.tags : [],
    }));

    return { rules, total };
  }

  async getRule(id: string): Promise<QualityRule | null> {
    const res = await this.db.query(`SELECT * FROM quality_rules WHERE id = $1`, [id]) as any;
    return (res.rows?.[0] as QualityRule) ?? null;
  }

  async createRule(data: z.infer<typeof QualityRuleSchema>, userId?: string): Promise<QualityRule> {
    const validated = QualityRuleSchema.parse(data);
    if (validated.type === 'sql') {
      const v = QueryValidator.validateSQLQuery(validated.expression);
      if (!v.isValid) throw new Error(`Invalid SQL query: ${v.errors.join(', ')}`);
    }

    const res = await this.db.query(
      `
      INSERT INTO quality_rules (
        name, description, severity, type, dialect, expression, tags, enabled,
        created_by, updated_by
      ) VALUES ($1,$2,$3,$4,$5,$6,$7,$8,$9,$9)
      RETURNING *
      `,
      [
        validated.name,
        validated.description ?? null,
        validated.severity,
        validated.type,
        validated.dialect,
        validated.expression,
        validated.tags,
        validated.enabled,
        userId ?? null,
      ],
    ) as any;

    const rule = res.rows[0] as QualityRule;
    logger.info('Quality rule created', { ruleId: rule.id, name: rule.name });
    return rule;
  }

  async updateRule(id: string, updates: Partial<z.infer<typeof QualityRuleSchema>>, userId?: string): Promise<QualityRule | null> {
    const validated = QualityRuleSchema.partial().parse(updates);

    if (validated.expression && (validated.type ?? 'sql') === 'sql') {
      const v = QueryValidator.validateSQLQuery(validated.expression);
      if (!v.isValid) throw new Error(`Invalid SQL query: ${v.errors.join(', ')}`);
    }

    const fields: Array<keyof typeof validated> = [
      'name','description','severity','type','dialect','expression','tags','enabled',
    ];
    const sets: string[] = [];
    const params: any[] = [];
    let i = 1;

    for (const f of fields) {
      if (validated[f] !== undefined) {
        sets.push(`${f} = $${i}`);
        params.push(validated[f] as any);
        i++;
      }
    }
    if (!sets.length) throw new Error('No valid fields to update');

    sets.push(`updated_by = $${i}`, `updated_at = NOW()`);
    params.push(userId ?? null);
    i++;
    params.push(id);

    const res = await this.db.query(
      `
      UPDATE quality_rules
      SET ${sets.join(', ')}
      WHERE id = $${i}
      RETURNING *
      `,
      params,
    ) as any;

    if ((res.rows?.length ?? 0) > 0) {
      logger.info('Quality rule updated', { ruleId: id, fieldsUpdated: Object.keys(validated) });
      return res.rows[0] as QualityRule;
    }
    return null;
  }

  async deleteRule(id: string, userId?: string): Promise<boolean> {
    const res = await this.db.query(
      `UPDATE quality_rules SET enabled = false, updated_by = $1, updated_at = NOW() WHERE id = $2`,
      [userId ?? null, id],
    ) as any;
    const ok = (res.rowCount || 0) > 0;
    if (ok) logger.info('Quality rule disabled', { ruleId: id });
    return ok;
  }

  /* â”€â”€ Results listing â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */

  async listResults(filters: {
    ruleId?: string;
    dataSourceId?: string;
    status?: string;
    limit?: number;
    offset?: number;
  } = {}): Promise<{ results: (QualityResult & { rule_name: string | null })[]; total: number }> {
    const { ruleId, dataSourceId, status, limit = 50, offset = 0 } = filters;

    const conds: string[] = [];
    const params: any[] = [];
    let i = 1;

    if (ruleId) { conds.push(`qr.rule_id = $${i}`); params.push(ruleId); i++; }
    if (dataSourceId) { conds.push(`qr.data_source_id = $${i}`); params.push(dataSourceId); i++; }
    if (status) { conds.push(`qr.status = $${i}`); params.push(status); i++; }

    const where = conds.length ? `WHERE ${conds.join(' AND ')}` : '';

    const countRes = await this.db.query(`SELECT COUNT(*) AS total FROM quality_results qr ${where}`, params) as any;
    const total = toInt(countRes.rows?.[0]?.total, 0);

    const pageLimit = Math.min(Math.max(limit, 1), 100);
    const pageOffset = Math.max(offset, 0);

    const res = await this.db.query(
      `
      SELECT qr.*, r.name AS rule_name
      FROM quality_results qr
      LEFT JOIN quality_rules r ON r.id = qr.rule_id
      ${where}
      ORDER BY qr.run_at DESC
      LIMIT $${i} OFFSET $${i + 1}
      `,
      [...params, pageLimit, pageOffset],
    ) as any;

    return { results: (res.rows ?? []) as (QualityResult & { rule_name: string | null })[], total };
  }

  /* â”€â”€ Rule execution â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */

  async executeRule(
    ruleId: string,
    dataSourceId?: string,
    options: { timeout?: number; userId?: string } = {},
  ): Promise<QualityResult> {
    const { timeout = 30_000, userId } = options;
    const startedAt = performance.now();

    const input = QueryExecutionSchema.parse({ ruleId, dataSourceId, timeout });

    const ruleRes = await this.db.query(
      `SELECT * FROM quality_rules WHERE id = $1 AND enabled = true`,
      [input.ruleId],
    ) as any;
    if (!ruleRes.rows?.length) throw new Error('Rule not found or disabled');

    const rule = ruleRes.rows[0] as QualityRule;

    let status: QualityResult['status'] = 'skipped';
    let metrics: Record<string, any> = {};
    let error: string | null = null;
    let qhash = '';

    if (rule.type === 'sql' && rule.dialect === 'postgres') {
      const v = QueryValidator.validateSQLQuery(rule.expression);
      if (!v.isValid) throw new Error(`Invalid SQL query: ${v.errors.join(', ')}`);

      qhash = hashQuery(rule.expression);

      // Resolve target connection (default to primary DB)
      let connectionString = process.env.DATABASE_URL as string | undefined;
      let ssl = false;

      if (input.dataSourceId) {
        const ds = await this.db.query(
          `SELECT connection_config FROM data_sources WHERE id = $1`,
          [input.dataSourceId],
        ) as any;

        if (ds.rows?.length) {
          const cfgRaw = (ds.rows[0] as { connection_config: any }).connection_config;
          const cfg = typeof cfgRaw === 'string' ? safeJsonParse(cfgRaw) : cfgRaw;
          if (cfg?.connectionString) connectionString = String(cfg.connectionString);
          if (typeof cfg?.ssl === 'boolean') ssl = !!cfg.ssl;
        }
      }

      if (!connectionString) throw new Error('No connection string available for rule execution.');

      const pool = this.pools.getPool({ connectionString, ssl });

      let client: PoolClient | null = null;
      try {
        client = await withConnectTimeout(pool, 10_000);

        const exec = async () => {
          const result = await client!.query(rule.expression);
          const first = result.rows?.[0] ?? {};
          const passed =
            typeof first.passed === 'boolean'
              ? (first.passed as boolean)
              : ((result.rowCount ?? 0) > 0);

          status = passed ? 'passed' : 'failed';
          metrics = {
            rowCount: result.rowCount ?? 0,
            sampleRows: (result.rows ?? []).slice(0, 3),
            queryHash: qhash,
          };
        };

        await withStatementTimeout(client, timeout, exec);
      } catch (e: any) {
        const msg = String(e?.message || e);
        status = /timeout/i.test(msg) ? 'timeout' : 'error';
        error = redactError(msg);
        logger.error('Quality rule execution failed', {
          ruleId: input.ruleId,
          dataSourceId: input.dataSourceId ?? null,
          error,
        });
      } finally {
        if (client) {
          try { client.release(); } catch (releaseErr) {
            logger.warn('Failed to release PG client', { err: String(releaseErr) });
          }
        }
      }
    } else {
      status = 'skipped';
    }

    const execMs = Math.round(performance.now() - startedAt);

    const insert = await this.db.query(
      `
      INSERT INTO quality_results (
        rule_id, data_source_id, status, execution_time_ms, metrics, error, query_hash
      ) VALUES ($1, $2, $3, $4, $5::jsonb, $6, $7)
      RETURNING *
      `,
      [input.ruleId, input.dataSourceId ?? null, status, execMs, JSON.stringify(metrics), error, qhash],
    ) as any;

    logger.info('Quality rule executed', { ruleId: input.ruleId, status, executionTimeMs: execMs });

    return insert.rows[0] as QualityResult;
  }

  /* â”€â”€ Stats & Health â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */

  // Lightweight DB health for /api/quality/health
  async healthCheck(): Promise<boolean> {
    try {
      const pong = await this.db.query('SELECT 1 as ok') as any;
      return pong.rows?.[0]?.ok === 1;
    } catch {
      return false;
    }
  }

  /**
   * Aggregated stats for dashboards.
   * timeframe: '24h' | '7d' | '30d' | '90d' (default '7d')
   * groupBy:   'severity' | 'status' | 'data_source' (default 'status')
   */
  async getStats(params: {
    timeframe?: '24h' | '7d' | '30d' | '90d';
    groupBy?: 'severity' | 'status' | 'data_source';
  }): Promise<{
    from: string;
    to: string;
    timeframe: '24h' | '7d' | '30d' | '90d';
    groupBy: 'severity' | 'status' | 'data_source';
    buckets: Array<{ key: string; count: number }>;
  }> {
    const timeframe = params.timeframe ?? '7d';
    const groupBy = params.groupBy ?? 'status';

    const now = new Date();
    const fromIso = new Date(now.getTime() - timeframeToMs(timeframe)).toISOString();

    let sql: string;
    const values: any[] = [fromIso];

    if (groupBy === 'severity') {
      sql = `
        SELECT r.severity AS key, COUNT(*)::int AS count
        FROM quality_results qr
        JOIN quality_rules r ON r.id = qr.rule_id
        WHERE qr.run_at >= $1
        GROUP BY 1
        ORDER BY 2 DESC, 1 ASC
      `;
    } else if (groupBy === 'data_source') {
      sql = `
        SELECT COALESCE(qr.data_source_id::text, 'none') AS key, COUNT(*)::int AS count
        FROM quality_results qr
        WHERE qr.run_at >= $1
        GROUP BY 1
        ORDER BY 2 DESC, 1 ASC
      `;
    } else {
      // status (default)
      sql = `
        SELECT qr.status AS key, COUNT(*)::int AS count
        FROM quality_results qr
        WHERE qr.run_at >= $1
        GROUP BY 1
        ORDER BY 2 DESC, 1 ASC
      `;
    }

    const res = await this.db.query(sql, values) as any;

    return {
      from: fromIso,
      to: now.toISOString(),
      timeframe,
      groupBy,
      buckets: (res.rows ?? []) as Array<{ key: string; count: number }>,
    };
  }

  /* â”€â”€ Lifecycle â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */

  async cleanup(): Promise<void> {
    await this.pools.cleanup();
  }
}



------------------------------------------------------------
FILE: backend\data-service\src\services\RequestsService.ts
------------------------------------------------------------
import { DatabaseService } from './DatabaseService';

export class RequestsService {
  private db = new DatabaseService();

  async list(status?: string, type?: string) {
    const clauses: string[] = [];
    const params: any[] = [];
    let i = 1;
    if (status) { clauses.push(`status=$${i++}`); params.push(status); }
    if (type)   { clauses.push(`type=$${i++}`);   params.push(type); }
    const where = clauses.length ? `WHERE ${clauses.join(' AND ')}` : '';
    const { rows } = await this.db.query(`
      SELECT * FROM workflow_requests ${where} ORDER BY updated_at DESC LIMIT 200
    `, params);
    return rows;
  }

  async create(data: any, userId?: string) {
    const { rows } = await this.db.query(`
      INSERT INTO workflow_requests (title,type,status,requester,payload,updated_by)
      VALUES ($1,COALESCE($2,'access'),COALESCE($3,'open'),$4,$5::jsonb,$6)
      RETURNING *
    `, [data.title, data.type ?? 'access', data.status ?? 'open', data.requester ?? userId ?? null, JSON.stringify(data.payload ?? {}), userId ?? null]);
    return rows[0];
  }

  async update(id: string, patch: any, userId?: string) {
    const sets: string[] = []; const params: any[] = []; let i = 1;
    const push = (f: string, v: any) => { sets.push(f); params.push(v); };
    if (patch.title !== undefined)   push(`title=$${i++}`, patch.title);
    if (patch.type !== undefined)    push(`type=$${i++}`, patch.type);
    if (patch.status !== undefined)  push(`status=$${i++}`, patch.status);
    if (patch.assignee !== undefined)push(`assignee=$${i++}`, patch.assignee);
    if (patch.payload !== undefined) push(`payload=$${i++}::jsonb`, JSON.stringify(patch.payload ?? {}));
    push(`updated_by=$${i++}`, userId ?? null);
    push(`updated_at=NOW()`, null);
    params.push(id);
    const { rows } = await this.db.query(`UPDATE workflow_requests SET ${sets.join(', ')} WHERE id=$${i} RETURNING *`, params);
    return rows[0] ?? null;
  }
}



------------------------------------------------------------
FILE: backend\data-service\src\services\StatsService.ts
------------------------------------------------------------
// backend/data-service/src/services/StatsService.ts
import { DatabaseService } from './DatabaseService';

/** Public types your controller/routers can use */
export type KpiRow = { key: string; value: number; updated_at: Date };
export type StatusBucket = { key: string; count: number };
export type SeriesPoint = { ts: string; count: number; status?: string };

function timeframeToInterval(timeframe: '24h'|'7d'|'30d'|'90d'): { fromIso: string; dateTrunc: 'hour'|'day' } {
  const now = new Date();
  let ms = 7 * 24 * 60 * 60 * 1000;
  let trunc: 'hour'|'day' = 'day';
  switch (timeframe) {
    case '24h': ms = 24 * 60 * 60 * 1000; trunc = 'hour'; break;
    case '7d':  ms = 7  * 24 * 60 * 60 * 1000; trunc = 'day'; break;
    case '30d': ms = 30 * 24 * 60 * 60 * 1000; trunc = 'day'; break;
    case '90d': ms = 90 * 24 * 60 * 60 * 1000; trunc = 'day'; break;
  }
  const from = new Date(now.getTime() - ms).toISOString();
  return { fromIso: from, dateTrunc: trunc };
}

export class StatsService {
  private readonly db = new DatabaseService();

  /** Health ping for /stats/health or readiness checks */
  async healthCheck(): Promise<boolean> {
    try {
      const res = await this.db.query('SELECT 1 AS ok') as any;
      return res.rows?.[0]?.ok === 1;
    } catch {
      return false;
    }
  }

  /** Simple KPIs table -> UI cards */
  async getKpis(): Promise<KpiRow[]> {
    const res = await this.db.query(
      `SELECT key, value, updated_at FROM kpi_stats ORDER BY key`
    ) as any;
    return (res.rows ?? []) as KpiRow[];
  }

  /** Quality summary (counts by status + pass rate + avg exec time) */
  async getQualitySummary(timeframe: '24h'|'7d'|'30d'|'90d' = '7d'): Promise<{
    timeframe: typeof timeframe;
    from: string;
    to: string;
    byStatus: StatusBucket[];
    totals: { total: number; passed: number; failed: number; error: number; skipped: number; timeout: number; passRate: number; avgExecMs: number };
  }> {
    const { fromIso } = timeframeToInterval(timeframe);
    const nowIso = new Date().toISOString();

    const byStatusRes = await this.db.query(
      `
      SELECT status AS key, COUNT(*)::int AS count
      FROM quality_results
      WHERE run_at >= $1
      GROUP BY 1
      ORDER BY 2 DESC, 1 ASC
      `,
      [fromIso]
    ) as any;

    const aggRes = await this.db.query(
      `
      SELECT
        COUNT(*)::int                                  AS total,
        SUM(CASE WHEN status = 'passed'  THEN 1 ELSE 0 END)::int AS passed,
        SUM(CASE WHEN status = 'failed'  THEN 1 ELSE 0 END)::int AS failed,
        SUM(CASE WHEN status = 'error'   THEN 1 ELSE 0 END)::int AS error,
        SUM(CASE WHEN status = 'skipped' THEN 1 ELSE 0 END)::int AS skipped,
        SUM(CASE WHEN status = 'timeout' THEN 1 ELSE 0 END)::int AS timeout,
        COALESCE(AVG(execution_time_ms), 0)::float                AS avg_exec_ms
      FROM quality_results
      WHERE run_at >= $1
      `,
      [fromIso]
    ) as any;

    const a = aggRes.rows?.[0] ?? { total: 0, passed: 0, failed: 0, error: 0, skipped: 0, timeout: 0, avg_exec_ms: 0 };
    const passRate = a.total ? Math.round((a.passed / a.total) * 1000) / 10 : 0;

    return {
      timeframe,
      from: fromIso,
      to: nowIso,
      byStatus: (byStatusRes.rows ?? []) as StatusBucket[],
      totals: {
        total: a.total,
        passed: a.passed,
        failed: a.failed,
        error: a.error,
        skipped: a.skipped,
        timeout: a.timeout,
        passRate,
        avgExecMs: Math.round(a.avg_exec_ms),
      }
    };
  }

  /** Time-series of results count; optionally split by status */
  async getQualitySeries(params: { timeframe?: '24h'|'7d'|'30d'|'90d'; splitByStatus?: boolean } = {}): Promise<{
    timeframe: NonNullable<typeof params['timeframe']> extends never ? '7d' : NonNullable<typeof params['timeframe']>;
    from: string;
    to: string;
    series: SeriesPoint[];
  }> {
    const timeframe = (params.timeframe ?? '7d') as any;
    const split = !!params.splitByStatus;
    const { fromIso, dateTrunc } = timeframeToInterval(timeframe);
    const nowIso = new Date().toISOString();

    const sql = split
      ? `
        SELECT
          to_char(date_trunc('${dateTrunc}', run_at), 'YYYY-MM-DD"T"HH24:00:00Z') AS ts,
          status,
          COUNT(*)::int AS count
        FROM quality_results
        WHERE run_at >= $1
        GROUP BY 1, 2
        ORDER BY 1 ASC, 2 ASC
      `
      : `
        SELECT
          to_char(date_trunc('${dateTrunc}', run_at), 'YYYY-MM-DD"T"HH24:00:00Z') AS ts,
          COUNT(*)::int AS count
        FROM quality_results
        WHERE run_at >= $1
        GROUP BY 1
        ORDER BY 1 ASC
      `;

    const res = await this.db.query(sql, [fromIso]) as any;

    const series = (res.rows ?? []).map((r: any) =>
      split ? ({ ts: r.ts, count: r.count, status: r.status }) : ({ ts: r.ts, count: r.count })
    ) as SeriesPoint[];

    return { timeframe, from: fromIso, to: nowIso, series };
  }
}



------------------------------------------------------------
FILE: backend\data-service\src\utils\logger.ts
------------------------------------------------------------
// backend/data-service/src/utils/logger.ts
import fs from 'fs';
import path from 'path';
import winston from 'winston';
import { env } from '../config/env';

function bool(val: any, def = true) {
  if (val === undefined || val === null) return def;
  const s = String(val).toLowerCase();
  return s === '1' || s === 'true' || s === 'yes' || s === 'on';
}

const LOG_DIR = process.env.LOG_DIR || path.join(process.cwd(), 'logs'); // default ./logs
const LOG_TO_FILES = bool(process.env.LOG_TO_FILES, true);
const LOG_LEVEL = env.LOG_LEVEL || process.env.LOG_LEVEL || 'info';

function ensureWritable(dir: string): boolean {
  try {
    fs.mkdirSync(dir, { recursive: true });
    const testFile = path.join(dir, `.writable-${Date.now()}`);
    fs.writeFileSync(testFile, 'ok');
    fs.unlinkSync(testFile);
    return true;
  } catch {
    return false;
  }
}

const canWriteFiles = LOG_TO_FILES && ensureWritable(LOG_DIR);

// common formats
const human = winston.format.combine(
  winston.format.timestamp({ format: 'YYYY-MM-DD HH:mm:ss:ms' }),
  winston.format.colorize({ all: true }),
  winston.format.printf(info => `${info.timestamp} ${info.level}: ${info.message}`)
);

const jsonFmt = winston.format.combine(
  winston.format.timestamp(),
  winston.format.errors({ stack: true }),
  winston.format.json()
);

// base transports: always console
const baseTransports: winston.transport[] = [
  new winston.transports.Console({ level: LOG_LEVEL, format: human }),
];

// add file transports only if writable
if (canWriteFiles) {
  baseTransports.push(
    new winston.transports.File({
      filename: path.join(LOG_DIR, 'combined.log'),
      level: LOG_LEVEL,
      format: jsonFmt,
      maxsize: 10 * 1024 * 1024,
      maxFiles: 5,
      tailable: true,
    }),
    new winston.transports.File({
      filename: path.join(LOG_DIR, 'error.log'),
      level: 'error',
      format: jsonFmt,
      maxsize: 10 * 1024 * 1024,
      maxFiles: 3,
      tailable: true,
    })
  );
} else {
  // visible, but non-fatal notice
  // eslint-disable-next-line no-console
  console.warn(`[logger] File logging disabled. LOG_DIR=${LOG_DIR} not writable. Using console only.`);
}

export const logger = winston.createLogger({
  level: LOG_LEVEL,
  format: jsonFmt,
  transports: baseTransports,
  exitOnError: false,
});

export const httpLogger = winston.createLogger({
  level: 'http',
  format: human,
  transports: canWriteFiles
    ? [
        new winston.transports.Console({ level: 'http', format: human }),
        new winston.transports.File({
          filename: path.join(LOG_DIR, 'http.log'),
          level: 'http',
          format: jsonFmt,
        }),
      ]
    : [new winston.transports.Console({ level: 'http', format: human })],
});

export const performanceLogger = winston.createLogger({
  level: 'info',
  format: jsonFmt,
  transports: canWriteFiles
    ? [new winston.transports.File({ filename: path.join(LOG_DIR, 'performance.log'), format: jsonFmt })]
    : [new winston.transports.Console({ level: 'info', format: human })],
});

export const securityLogger = winston.createLogger({
  level: 'warn',
  format: jsonFmt,
  transports: canWriteFiles
    ? [new winston.transports.File({ filename: path.join(LOG_DIR, 'security.log'), format: jsonFmt })]
    : [new winston.transports.Console({ level: 'warn', format: human })],
});

// Structured helpers (unchanged API, but now safe)
export const loggerUtils = {
  logRequest: (req: any, res: any, duration: number) => {
    httpLogger.http(`${req.method} ${req.url} - ${res.statusCode} - ${duration}ms`);
  },
  logDbOperation: (operation: string, table: string, duration: number, success: boolean) => {
    performanceLogger.info({ type: 'database', operation, table, duration, success, ts: new Date().toISOString() });
  },
  logAuth: (event: string, userId?: string, ip?: string, userAgent?: string) => {
    securityLogger.warn({ type: 'authentication', event, userId, ip, userAgent, ts: new Date().toISOString() });
  },
  logApiCall: (service: string, endpoint: string, method: string, duration: number, statusCode: number) => {
    performanceLogger.info({ type: 'external_api', service, endpoint, method, duration, statusCode, ts: new Date().toISOString() });
  },
  logDataSource: (operation: string, dataSourceId: string, status: string, details?: any) => {
    logger.info({ type: 'data_source', operation, dataSourceId, status, details, ts: new Date().toISOString() });
  },
  logConnectionTest: (dataSourceId: string, type: string, success: boolean, duration: number, error?: string) => {
    logger.info({ type: 'connection_test', dataSourceId, connectionType: type, success, duration, error, ts: new Date().toISOString() });
  },
  logError: (error: Error, context?: any) => {
    logger.error({ message: error.message, stack: error.stack, context, ts: new Date().toISOString() });
  },
};

// Crash guards (optional)
process.on('uncaughtException', (error) => {
  logger.error('Uncaught Exception', { message: error.message, stack: error.stack });
  // Donâ€™t exit here; let orchestrator handle restarts based on health checks.
});
process.on('unhandledRejection', (reason: any, promise) => {
  logger.error('Unhandled Rejection', { reason: reason?.message || String(reason), promise: String(promise) });
});



------------------------------------------------------------
FILE: backend\data-service\src\utils\normalizeType.ts
------------------------------------------------------------
// Normalize external aliases to canonical internal types
export type KnownType =
  | 'postgres' | 'postgresql' | 'mysql' | 'mssql' | 'mongodb' | 'redis'
  | 'snowflake' | 'bigquery' | 'redshift' | 'databricks' | 's3' | 'azure-blob'
  | 'gcs' | 'kafka' | 'api' | 'file' | 'ftp' | 'elasticsearch' | 'oracle';

export function normalizeDataSourceType(t?: string): KnownType | undefined {
  if (!t) return undefined;
  const lower = t.toLowerCase();
  switch (lower) {
    case 'postgres': return 'postgresql';
    default: return lower as KnownType;
  }
}



------------------------------------------------------------
FILE: backend\data-service\src\utils\pagination.ts
------------------------------------------------------------
export type PageQuery = { page?: any; pageSize?: any; sort?: any; dir?: any };

export function pageParams(q: PageQuery, allowedSort: string[] = ['created_at']) {
  const page = Math.max(1, Number(q.page) || 1);
  const pageSize = Math.min(100, Math.max(1, Number(q.pageSize) || 20));
  const sort = allowedSort.includes(String(q.sort || '')) ? String(q.sort) : allowedSort[0];
  const dir = (String(q.dir).toLowerCase() === 'desc' ? 'desc' : 'asc') as 'asc'|'desc';
  const offset = (page - 1) * pageSize;
  return { page, pageSize, sort, dir, offset };
}



------------------------------------------------------------
FILE: backend\data-service\src\worker.ts
------------------------------------------------------------
import { Worker } from 'bullmq';
import 'dotenv/config';
import mssql from 'mssql';
import { Client as PgClient, Pool } from 'pg';

const cpdb = new Pool({ connectionString: process.env.DATABASE_URL });
const connection = { connection: { url: process.env.REDIS_URL || 'redis://redis:6379' } };

// Helpers to fetch DS config
async function getAssetAndDS(assetId: string) {
  const { rows } = await cpdb.query(`
    SELECT a.id, a.schema_name, a.table_name, a.datasource_id, ds.type, COALESCE(ds.config, ds.connection_config) AS cfg
    FROM catalog_assets a JOIN data_sources ds ON ds.id = a.datasource_id
    WHERE a.id = $1
  `, [assetId]);
  return rows[0];
}

// PII heuristics by name/value
const piiNameMatchers = [
  { type: 'email', re: /(email|e[-_ ]?mail)/i },
  { type: 'ssn',   re: /(ssn|social[_-]?security)/i },
  { type: 'cc',    re: /(card|cc|credit)/i },
  { type: 'phone', re: /(phone|mobile|cell|tel)/i },
  { type: 'iban',  re: /(iban)/i },
];

const piiValueMatchers = [
  { type: 'email', re: /^[^\s@]+@[^\s@]+\.[^\s@]+$/i },
  { type: 'cc',    re: /^(?:\d[ -]*?){13,19}$/ },
  { type: 'ssn',   re: /^\d{3}-?\d{2}-?\d{4}$/ },
  { type: 'phone', re: /^\+?\d[\d -]{7,}$/ },
  { type: 'iban',  re: /^[A-Z]{2}\d{2}[A-Z0-9]{11,30}$/i }
];

function inferPIIByName(col: string): string | null {
  const m = piiNameMatchers.find(m => m.re.test(col));
  return m?.type || null;
}
function inferPIIByValues(samples: any[]): string | null {
  const s = String(samples?.find(v => v != null) ?? '');
  const m = piiValueMatchers.find(m => m.re.test(s));
  return m?.type || null;
}

// ------- Profile Worker -------
new Worker('catalog:profile', async job => {
  const { assetId } = job.data as { assetId: string };
  const asset = await getAssetAndDS(assetId);
  if (!asset) throw new Error('Asset not found');

  const { type, cfg, schema_name, table_name } = asset;
  let columns: Array<{ name: string, data_type: string }> = [];
  let rowsCount = 0;

  const runIdRes = await cpdb.query(`INSERT INTO catalog_profile_runs (asset_id, status) VALUES ($1,'running') RETURNING id`, [assetId]);
  const runId = runIdRes.rows[0].id;

  try {
    if (type === 'postgresql') {
      const cli = new PgClient({
        host: cfg.host, port: Number(cfg.port ?? 5432),
        database: cfg.database, user: cfg.username, password: cfg.password,
        ssl: cfg.ssl === false || cfg.ssl?.mode === 'disable' ? undefined : cfg.ssl
      });
      await cli.connect();

      const cols = await cli.query(`
        SELECT column_name as name, data_type
        FROM information_schema.columns
        WHERE table_schema=$1 AND table_name=$2
        ORDER BY ordinal_position`, [schema_name, table_name]);
      columns = cols.rows;

      const rc = await cli.query(`SELECT reltuples::bigint AS row_est FROM pg_class WHERE oid = $1::regclass`, [`"${schema_name}"."${table_name}"`]);
      rowsCount = Number(rc.rows?.[0]?.row_est || 0);

      for (const col of columns) {
        // sample 1% or up to 10k rows
        const sample = await cli.query(`
          SELECT ${JSON.stringify(col.name).replace(/"/g,'')} as name FROM "${schema_name}"."${table_name}"
          TABLESAMPLE SYSTEM (1) LIMIT 10000
        `).catch(() => ({ rows: [] as any[] }));

        const vals = sample.rows.map(r => r[col.name]).filter(v => v !== undefined);
        const total = Math.max(vals.length, 1);
        const nulls = vals.filter(v => v === null).length;
        const nonNull = vals.filter(v => v !== null).map(v => String(v));

        const distinct = new Set(nonNull.map(v => v)).size;
        const lengths = nonNull.map(s => s.length);
        const minv = nonNull.length ? nonNull.reduce((a,b)=> a < b ? a : b) : null;
        const maxv = nonNull.length ? nonNull.reduce((a,b)=> a > b ? a : b) : null;
        const avgl = nonNull.length ? (lengths.reduce((a,b)=>a+b,0) / nonNull.length) : null;

        const piiByName = inferPIIByName(col.name);
        const piiByValues = inferPIIByValues(nonNull.slice(0,50));
        const pii = piiByValues || piiByName;

        await cpdb.query(`
          INSERT INTO catalog_column_profiles (asset_id, column_name, null_frac, distinct_frac, min_value, max_value, avg_length, sample_values, inferred_type, pii_type, pattern, updated_at)
          VALUES ($1,$2,$3,$4,$5,$6,$7,$8,$9,$10,$11, now())
          ON CONFLICT (asset_id, column_name) DO UPDATE SET
            null_frac = EXCLUDED.null_frac,
            distinct_frac = EXCLUDED.distinct_frac,
            min_value = EXCLUDED.min_value,
            max_value = EXCLUDED.max_value,
            avg_length = EXCLUDED.avg_length,
            sample_values = EXCLUDED.sample_values,
            inferred_type = EXCLUDED.inferred_type,
            pii_type = EXCLUDED.pii_type,
            pattern = EXCLUDED.pattern,
            updated_at = now()
        `, [
          assetId, col.name,
          total ? nulls / total : null,
          total ? distinct / total : null,
          minv, maxv, avgl,
          JSON.stringify(nonNull.slice(0,10)),
          col.data_type, pii || null, null
        ]);
      }
      await cli.end();
    } else if (type === 'mssql') {
      const pool = await mssql.connect({
        server: cfg.host,
        port: Number(cfg.port ?? 1433),
        database: cfg.database,
        user: cfg.username,
        password: cfg.password,
        options: { encrypt: true, trustServerCertificate: true, ...(cfg.options || {}) }
      });

      const cols = await pool.request().query(`
        SELECT c.name AS name, ty.name AS data_type
        FROM sys.columns c
        JOIN sys.types ty ON c.user_type_id = ty.user_type_id
        JOIN sys.objects o ON c.object_id = o.object_id
        JOIN sys.schemas s ON s.schema_id = o.schema_id
        WHERE s.name=@schema AND o.name=@table
        ORDER BY c.column_id
      `).then(r => r.recordset);
      columns = cols;

      const rc = await pool.request().query(`
        SELECT SUM(row_count) as rows
        FROM sys.dm_db_partition_stats
        WHERE object_id = OBJECT_ID(QUOTENAME(@schema)+'.'+QUOTENAME(@table)) AND (index_id=0 OR index_id=1)
      `).then(r => Number(r.recordset?.[0]?.rows || 0));
      rowsCount = rc;

      for (const col of columns) {
        const sample = await pool.request().query(`
          SELECT TOP 10000 [${col.name}] AS v FROM QUOTENAME('${schema_name}').${table_name} TABLESAMPLE (1 PERCENT)
        `).then(r => r.recordset).catch(() => [] as any[]);

        const vals = sample.map(r => r.v);
        const total = Math.max(vals.length, 1);
        const nulls = vals.filter(v => v == null).length;
        const nonNull = vals.filter(v => v != null).map(v => String(v));

        const distinct = new Set(nonNull).size;
        const lengths = nonNull.map(s => s.length);
        const minv = nonNull.length ? nonNull.reduce((a,b)=> a < b ? a : b) : null;
        const maxv = nonNull.length ? nonNull.reduce((a,b)=> a > b ? a : b) : null;
        const avgl = nonNull.length ? (lengths.reduce((a,b)=>a+b,0) / nonNull.length) : null;

        const piiByName = inferPIIByName(col.name);
        const piiByValues = inferPIIByValues(nonNull.slice(0,50));
        const pii = piiByValues || piiByName;

        await cpdb.query(`
          INSERT INTO catalog_column_profiles (asset_id, column_name, null_frac, distinct_frac, min_value, max_value, avg_length, sample_values, inferred_type, pii_type, pattern, updated_at)
          VALUES ($1,$2,$3,$4,$5,$6,$7,$8,$9,$10,$11, now())
          ON CONFLICT (asset_id, column_name) DO UPDATE SET
            null_frac = EXCLUDED.null_frac,
            distinct_frac = EXCLUDED.distinct_frac,
            min_value = EXCLUDED.min_value,
            max_value = EXCLUDED.max_value,
            avg_length = EXCLUDED.avg_length,
            sample_values = EXCLUDED.sample_values,
            inferred_type = EXCLUDED.inferred_type,
            pii_type = EXCLUDED.pii_type,
            pattern = EXCLUDED.pattern,
            updated_at = now()
        `, [
          assetId, col.name,
          total ? nulls / total : null,
          total ? distinct / total : null,
          minv, maxv, avgl,
          JSON.stringify(nonNull.slice(0,10)),
          col.data_type, pii || null, null
        ]);
      }

      await pool.close();
    } else {
      throw new Error(`Unsupported type: ${type}`);
    }

    // Simple asset quality heuristic
    const { rows: colpii } = await cpdb.query(`SELECT count(*)::int AS pii FROM catalog_column_profiles WHERE asset_id=$1 AND pii_type IS NOT NULL`, [assetId]);
    const piiCount = colpii[0].pii || 0;
    const quality = piiCount > 0 ? 'medium' : 'high';

    await cpdb.query(`UPDATE catalog_assets SET quality=$2, updated_at=now() WHERE id=$1`, [assetId, quality]);
    await cpdb.query(`UPDATE catalog_profile_runs SET status='completed', completed_at=now() WHERE id=$1`, [runId]);

  } catch (e: any) {
    await cpdb.query(`UPDATE catalog_profile_runs SET status='failed', completed_at=now(), error=$2 WHERE id=$1`, [runId, e?.message || String(e)]);
    throw e;
  }
}, connection);

// ------- Sync Worker (optional parallelization) -------
new Worker('catalog:sync', async job => {
  // you can call your existing ingestPostgres/ingestMSSQL here
  // keeping empty for brevity since you already sync via route
  return;
}, connection);



====================================================================================================
  AI SERVICE - SRC
====================================================================================================


------------------------------------------------------------
FILE: backend\ai-service\src\app.ts
------------------------------------------------------------
// src/app.ts
import compression from 'compression';
import cors from 'cors';
import express, { Application, NextFunction, Request, RequestHandler, Response } from 'express';
import helmet from 'helmet';
import morgan from 'morgan';


class App {
  public app: Application;

  constructor() {
    this.app = express();
    console.log('ðŸ”„ Creating Express app...');
    this.initializeMiddlewares();
    console.log('âœ… Express app created');
    this.initializeRoutes();
    console.log('ðŸ”„ Initializing basic middlewares...');
    this.initializeErrorHandling();
    console.log('âœ… Basic middlewares initialized');
  }

  private initializeMiddlewares(): void {
    // Security middleware
    this.app.use(helmet({
      contentSecurityPolicy: {
        directives: {
          defaultSrc: ["'self'"],
          styleSrc: ["'self'", "'unsafe-inline'"],
          scriptSrc: ["'self'"],
          imgSrc: ["'self'", "data:", "https:"],
        },
      },
      crossOriginEmbedderPolicy: false
    }) as RequestHandler);

    // CORS configuration
    const corsOptions = {
      origin: process.env.NODE_ENV === 'production' 
        ? process.env.CORS_ORIGINS?.split(',') || ['https://your-frontend-domain.com']
        : ['http://localhost:3000', 'http://127.0.0.1:3000', 'http://localhost:5173'],
      credentials: true,
      optionsSuccessStatus: 200
    };
    this.app.use(cors(corsOptions) as RequestHandler);

    // Compression
    this.app.use(compression() as RequestHandler);

    // Body parsing
    this.app.use(express.json({ limit: '10mb' }) as RequestHandler);
    this.app.use(express.urlencoded({ extended: true, limit: '10mb' }) as RequestHandler);

    // Logging
    const morganFormat = process.env.NODE_ENV === 'production' ? 'combined' : 'dev';
    this.app.use(morgan(morganFormat) as RequestHandler);

    // Request ID middleware
    this.app.use((req: Request, _res: Response, next: NextFunction) => {
      (req as any).id = `req_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
      next();
    });

    // Security headers
    this.app.use((_req: Request, res: Response, next: NextFunction) => {
      res.setHeader('X-Content-Type-Options', 'nosniff');
      res.setHeader('X-Frame-Options', 'DENY');
      res.setHeader('X-XSS-Protection', '1; mode=block');
      res.setHeader('Referrer-Policy', 'strict-origin-when-cross-origin');
      res.removeHeader('X-Powered-By');
      next();
    });
  }

  private initializeRoutes(): void {
    console.log('ðŸ”„ Initializing basic routes...');
    
    // Health check (before any middleware that might block it)
    this.app.get('/health', (_req: Request, res: Response) => {
      const memoryUsage = process.memoryUsage();
      res.status(200).json({
        status: 'healthy',
        service: 'ai-service',
        timestamp: new Date().toISOString(),
        version: process.env.APP_VERSION || '1.0.0',
        uptime: Math.floor(process.uptime()),
        environment: process.env.NODE_ENV || 'development',
        memory: {
          used: Math.round(memoryUsage.heapUsed / 1024 / 1024),
          total: Math.round(memoryUsage.heapTotal / 1024 / 1024),
          usage: Math.round((memoryUsage.heapUsed / memoryUsage.heapTotal) * 100)
        }
      });
    });

    // Root endpoint
    this.app.get('/', (_req: Request, res: Response) => {
      res.status(200).json({
        message: 'CWIC AI Service',
        version: process.env.APP_VERSION || '1.0.0',
        status: 'running',
        endpoints: {
          health: '/health',
          api: '/api',
          docs: '/api/docs'
        },
        timestamp: new Date().toISOString()
      });
    });

    // API documentation endpoint
    this.app.get('/api/docs', (_req: Request, res: Response) => {
      res.status(200).json({
        service: 'CWIC AI Service',
        version: process.env.APP_VERSION || '1.0.0',
        description: 'AI-powered data governance and discovery service',
        endpoints: {
          discovery: {
            'POST /api/discovery': 'Start data discovery session',
            'GET /api/discovery/:sessionId': 'Get discovery status',
            'POST /api/discovery/query': 'Natural language queries',
            'POST /api/discovery/quality-rules': 'Generate quality rules'
          },
          analysis: {
            'POST /api/analysis/schema': 'Analyze database schema',
            'POST /api/analysis/quality': 'Data quality analysis'
          },
          health: {
            'GET /health': 'Service health check',
            'GET /health/ready': 'Readiness probe',
            'GET /health/live': 'Liveness probe'
          }
        }
      });
    });

    // API status endpoint (fallback)
    this.app.get('/api/status', (_req: Request, res: Response) => {
      res.status(200).json({
        status: 'AI Service API Ready',
        timestamp: new Date().toISOString(),
        routes: 'Basic routes loaded'
      });
    });

    // Try to load API routes (gracefully handle if not available)
   try {
  // IMPORTANT: prefer require here because ts-node is already running with tsconfig-paths/register
  // If this throws, you'll see the exact error below.
    const routes = require('./routes');
    this.app.use('/api', routes.default || routes);
    console.log('âœ… API routes loaded successfully');
  } catch (routeError: any) {
    console.error('âŒ Failed to load API routes:', {
      message: routeError?.message,
      stack: routeError?.stack,
    });

    // Fallback API route (keep this so app still runs)
    this.app.use('/api', (_req: Request, res: Response) => {
      res.status(503).json({
        error: 'API routes failed to load',
        message: routeError?.message || 'Service is starting up',
        retry: 'Fix the routes import error shown in server logs',
      });
    });
  }

    console.log('âœ… Basic routes initialized');
  }

  private initializeErrorHandling(): void {
    // 404 handler
    this.app.use((_req: Request, res: Response) => {
      res.status(404).json({
        success: false,
        error: {
          code: 'NOT_FOUND',
          message: 'The requested resource was not found',
          path: _req.path
        },
        timestamp: new Date().toISOString()
      });
    });

    // Global error handler
    this.app.use((error: unknown, _req: Request, res: Response, _next: NextFunction) => {
      // Type guard to check if error is an Error object
      const isError = error instanceof Error;
      const errorMessage = isError ? error.message : 'Unknown error occurred';
      const errorStack = isError ? error.stack : undefined;

      // Log error safely
      if (typeof console !== 'undefined') {
        console.error('âŒ Application Error:', {
          message: errorMessage,
          stack: errorStack,
          url: _req.url,
          method: _req.method
        });
      }

      // Determine status code
      let statusCode = 500;
      if (isError && 'statusCode' in error) {
        statusCode = (error as any).statusCode || 500;
      }

      // Send error response
      const response: any = {
        success: false,
        error: {
          code: 'INTERNAL_SERVER_ERROR',
          message: process.env.NODE_ENV === 'development' 
            ? errorMessage 
            : 'An internal server error occurred'
        },
        timestamp: new Date().toISOString()
      };

      // Include stack trace in development
      if (process.env.NODE_ENV === 'development' && errorStack) {
        response.error.stack = errorStack;
      }

      if (!res.headersSent) {
        res.status(statusCode).json(response);
      }
    });
  }

  public getApp(): Application {
    return this.app;
  }

  public async shutdown(): Promise<void> {
    console.log('ðŸ”„ Shutting down application...');
    // Add cleanup logic here if needed
    console.log('âœ… Application shutdown complete');
  }
}

export default App;


------------------------------------------------------------
FILE: backend\ai-service\src\config\database.ts
------------------------------------------------------------
import { logger } from '@utils/logger';
import { Pool } from 'pg';

class DatabaseConfig {
  private pool: Pool | null = null;

  constructor() {
    this.initializePool();
  }

  private initializePool(): void {
    try {
      this.pool = new Pool({
        connectionString: process.env.DATABASE_URL,
        min: parseInt(process.env.DATABASE_POOL_MIN || '2'),
        max: parseInt(process.env.DATABASE_POOL_MAX || '10'),
        idleTimeoutMillis: 30000,
        connectionTimeoutMillis: 2000,
        ssl: process.env.NODE_ENV === 'production' ? { rejectUnauthorized: false } : false
      });

      // Handle pool errors
      this.pool.on('error', (err) => {
        logger.error('Database pool error:', err);
      });

      // Handle client connection errors
      this.pool.on('connect', () => {
        logger.debug('New database client connected');
      });

    } catch (error) {
      logger.error('Failed to initialize database pool:', error);
      throw error;
    }
  }

  public getPool(): Pool {
    if (!this.pool) {
      throw new Error('Database pool not initialized');
    }
    return this.pool;
  }

  public async query(text: string, params?: any[]): Promise<any> {
    const client = await this.getPool().connect();
    try {
      const start = Date.now();
      const result = await client.query(text, params);
      const duration = Date.now() - start;
      
      logger.debug('Query executed', {
        query: text,
        duration: `${duration}ms`,
        rows: result.rowCount
      });
      
      return result;
    } catch (error) {
      logger.error('Database query error:', { query: text, error });
      throw error;
    } finally {
      client.release();
    }
  }

  public async transaction(callback: (client: any) => Promise<any>): Promise<any> {
    const client = await this.getPool().connect();
    try {
      await client.query('BEGIN');
      const result = await callback(client);
      await client.query('COMMIT');
      return result;
    } catch (error) {
      await client.query('ROLLBACK');
      logger.error('Transaction error:', error);
      throw error;
    } finally {
      client.release();
    }
  }

  public async close(): Promise<void> {
    if (this.pool) {
      await this.pool.end();
      this.pool = null;
      logger.info('Database pool closed');
    }
  }
}

export const db = new DatabaseConfig();

export async function connectDatabase(): Promise<void> {
  try {
    await db.query('SELECT 1');
    logger.info('Database connection verified');
  } catch (error) {
    logger.error('Database connection failed:', error);
    throw error;
  }
}


------------------------------------------------------------
FILE: backend\ai-service\src\config\openai.ts
------------------------------------------------------------
// src/config/openai.ts
import { logger } from '@utils/logger';
import OpenAI from 'openai';

type ChatRole = 'system' | 'user' | 'assistant';

export interface ChatMessage {
  role: ChatRole;
  content: string;
}

export interface ChatArgs {
  model?: string;
  messages: ChatMessage[];
  max_tokens?: number;
  temperature?: number;
  response_format?: { type: 'json_object' | 'text' };
}

export interface ChatResponse {
  choices: Array<{ message: { content: string } }>;
}

class OpenAIAdapter {
  private client: OpenAI | null = null;
  private enabled = false;

  constructor() {
    const apiKey = process.env.OPENAI_API_KEY?.trim();
    if (apiKey) {
      try {
        this.client = new OpenAI({ apiKey });
        this.enabled = true;
        logger.info('OpenAI client initialized');
      } catch (err) {
        this.client = null;
        this.enabled = false;
        logger.error('Failed to initialize OpenAI client (using stub):', err as any);
      }
    } else {
      logger.warn('OPENAI_API_KEY not set. Using stub OpenAI client.');
      this.enabled = false;
    }
  }

  public isAvailable(): boolean {
    return this.enabled && !!this.client;
  }

  /**
   * Mirrors the shape your AIService expects:
   * await openai.createChatCompletion({...})
   * -> returns { choices: [{ message: { content: string } }] }
   */
  public async createChatCompletion(args: ChatArgs): Promise<ChatResponse> {
    // Real client path
    if (this.isAvailable() && this.client) {
      const model = args.model || process.env.OPENAI_MODEL || 'gpt-4o-mini';
      const res = await this.client.chat.completions.create({
        model,
        messages: args.messages,
        max_tokens: args.max_tokens,
        temperature: args.temperature,
        // The SDK accepts response_format on chat.completions
        response_format: args.response_format as any,
      });

      // Conform to your expected return type
      return {
        choices: [
          {
            message: {
              content: res.choices?.[0]?.message?.content ?? '',
            },
          },
        ],
      };
    }

    // Stubbed fallback (no API key): return a JSON-ish payload so your services can parse it.
    const stubJson = JSON.stringify({
      // field discovery defaults
      fields: [],
      recommendations: { governance: [], quality: [], compliance: [] },
      confidence: 0.5,
      // nlq defaults
      sql: 'SELECT 1;',
      explanation: 'OpenAI disabled; returning stubbed content.',
      tables: [],
      fieldsUsed: [],
      warnings: ['OpenAI disabled (stub)'],
    });

    logger.warn('OpenAI call intercepted by stub. Set OPENAI_API_KEY to enable real calls.');
    return { choices: [{ message: { content: stubJson } }] };
  }
}

export const openai = new OpenAIAdapter();



------------------------------------------------------------
FILE: backend\ai-service\src\config\redis.ts
------------------------------------------------------------
import { logger } from '@utils/logger';
import { createClient, RedisClientType } from 'redis';

class RedisConfig {
  private client: RedisClientType | null = null;

  constructor() {
    this.initializeClient();
  }

  private initializeClient(): void {
    try {
      this.client = createClient({
        url: process.env.REDIS_URL || 'redis://localhost:6379',
        socket: {
          reconnectStrategy: (retries) => Math.min(retries * 50, 1000)
        }
      });

      this.client.on('error', (err) => {
        logger.error('Redis client error:', err);
      });

      this.client.on('connect', () => {
        logger.info('Redis client connected');
      });

      this.client.on('ready', () => {
        logger.info('Redis client ready');
      });

      this.client.on('end', () => {
        logger.info('Redis client disconnected');
      });

    } catch (error) {
      logger.error('Failed to initialize Redis client:', error);
      throw error;
    }
  }

  public getClient(): RedisClientType {
    if (!this.client) {
      throw new Error('Redis client not initialized');
    }
    return this.client;
  }

  public async set(key: string, value: string, ttl?: number): Promise<void> {
    try {
      if (ttl) {
        await this.getClient().setEx(key, ttl, value);
      } else {
        await this.getClient().set(key, value);
      }
    } catch (error) {
      logger.error('Redis SET error:', { key, error });
      throw error;
    }
  }

  public async get(key: string): Promise<string | null> {
    try {
      return await this.getClient().get(key);
    } catch (error) {
      logger.error('Redis GET error:', { key, error });
      throw error;
    }
  }

  public async del(key: string): Promise<void> {
    try {
      await this.getClient().del(key);
    } catch (error) {
      logger.error('Redis DEL error:', { key, error });
      throw error;
    }
  }

  public async exists(key: string): Promise<boolean> {
    try {
      const result = await this.getClient().exists(key);
      return result === 1;
    } catch (error) {
      logger.error('Redis EXISTS error:', { key, error });
      throw error;
    }
  }

  public async close(): Promise<void> {
    if (this.client) {
      await this.client.quit();
      this.client = null;
      logger.info('Redis client closed');
    }
  }
}

export const redis = new RedisConfig();

export async function connectRedis(): Promise<void> {
  try {
    await redis.getClient().connect();
    logger.info('Redis connection established');
  } catch (error) {
    logger.error('Redis connection failed:', error);
    throw error;
  }
}


------------------------------------------------------------
FILE: backend\ai-service\src\controllers\AnalysisController.ts
------------------------------------------------------------
import { AnalysisService } from '@/services/AnalysisService';
import { APIError } from '@/utils/errors';
import { logger } from '@/utils/logger';
import { successResponse } from '@/utils/responses';
import { NextFunction, Request, Response } from 'express';

export class AnalysisController {
  private analysisService: AnalysisService;

  constructor() {
    this.analysisService = new AnalysisService();
  }

  public analyzeSchema = async (req: Request, res: Response, next: NextFunction): Promise<void> => {
    try {
      const { schema } = req.body;
      const userId = (req as any).user.id;

      if (!schema) {
        throw new APIError('Schema information is required', 400);
      }

      const analysis = await this.analysisService.analyzeSchema(schema, userId);

      logger.info('Schema analysis completed', { 
        userId, 
        schema: schema.name,
        tables: schema.tables?.length || 0
      });

      res.json(successResponse(analysis, 'Schema analysis completed'));

    } catch (error) {
      next(error);
    }
  };

  public analyzeDataSample = async (req: Request, res: Response, next: NextFunction): Promise<void> => {
    try {
      const { samples } = req.body;
      const userId = (req as any).user.id;

      if (!samples || !Array.isArray(samples)) {
        throw new APIError('Data samples are required', 400);
      }

      const analysis = await this.analysisService.analyzeDataSample(samples, userId);

      logger.info('Data sample analysis completed', { 
        userId,
        samplesAnalyzed: samples.length
      });

      res.json(successResponse(analysis, 'Data sample analysis completed'));

    } catch (error) {
      next(error);
    }
  };

  public performQualityCheck = async (req: Request, res: Response, next: NextFunction): Promise<void> => {
    try {
      const { dataSourceId, rules } = req.body;
      const userId = (req as any).user.id;

      if (!dataSourceId) {
        throw new APIError('Data source ID is required', 400);
      }

      const qualityReport = await this.analysisService.performQualityCheck(dataSourceId, rules, userId);

      logger.info('Quality check completed', { 
        userId,
        dataSourceId,
        rulesChecked: rules?.length || 0
      });

      res.json(successResponse(qualityReport, 'Quality check completed'));

    } catch (error) {
      next(error);
    }
  };
}


------------------------------------------------------------
FILE: backend\ai-service\src\controllers\DiscoveryController.ts
------------------------------------------------------------
import { AIService, NaturalLanguageQuery } from '@services/AIService';
import { DiscoveryService, StartDiscoveryRequest } from '@services/DiscoveryService';
import { APIError } from '@utils/errors';
import { logger } from '@utils/logger';
import { successResponse } from '@utils/responses';
import { NextFunction, Request, Response } from 'express';

export class DiscoveryController {
  private discoveryService: DiscoveryService;
  private aiService: AIService;

  constructor() {
    this.discoveryService = new DiscoveryService();
    this.aiService = new AIService();
  }

  public startDiscovery = async (req: Request, res: Response, next: NextFunction): Promise<void> => {
    try {
      const { dataSourceId, schemas, tables, options } = req.body;
      const userId = (req as any).user.id;

      if (!dataSourceId) {
        throw new APIError('Data source ID is required', 400);
      }

      const request: StartDiscoveryRequest = {
        userId,
        dataSourceId,
        schemas,
        tables,
        options
      };

      const session = await this.discoveryService.startDiscovery(request);

      logger.info('Discovery started', { sessionId: session.sessionId, userId });

      res.status(201).json(successResponse(session, 'Discovery session started'));

    } catch (error) {
      next(error);
    }
  };

  public getDiscoveryStatus = async (req: Request, res: Response, next: NextFunction): Promise<void> => {
    try {
      const { sessionId } = req.params;
      const userId = (req as any).user.id;

      const session = await this.discoveryService.getSession(sessionId);

      if (!session) {
        throw new APIError('Discovery session not found', 404);
      }

      if (session.userId !== userId) {
        throw new APIError('Access denied', 403);
      }

      res.json(successResponse(session));

    } catch (error) {
      next(error);
    }
  };

  public listDiscoverySessions = async (req: Request, res: Response, next: NextFunction): Promise<void> => {
    try {
      const userId = (req as any).user.id;
      const limit = parseInt(req.query.limit as string) || 20;
      const offset = parseInt(req.query.offset as string) || 0;

      const sessions = await this.discoveryService.listSessions(userId, limit, offset);

      res.json(successResponse({
        sessions,
        pagination: {
          limit,
          offset,
          total: sessions.length
        }
      }));

    } catch (error) {
      next(error);
    }
  };

  public deleteDiscoverySession = async (req: Request, res: Response, next: NextFunction): Promise<void> => {
    try {
      const { sessionId } = req.params;
      const userId = (req as any).user.id;

      await this.discoveryService.deleteSession(sessionId, userId);

      logger.info('Discovery session deleted', { sessionId, userId });

      res.json(successResponse(null, 'Discovery session deleted'));

    } catch (error) {
      next(error);
    }
  };

  public processNaturalLanguageQuery = async (req: Request, res: Response, next: NextFunction): Promise<void> => {
  try {
    const { query, context } = req.body;
    if (!query) throw new APIError('Query is required', 400);

    const nlQuery: NaturalLanguageQuery = { query, context };
    const result = await this.aiService.processNaturalLanguageQuery(nlQuery);

    // ðŸ”§ Normalize to the frontendâ€™s expected AIResponse.data shape
    const payload = {
      message: "Hereâ€™s the SQL Iâ€™d run based on your request.",
      type: 'query' as const,
      results: {
        sql:          result.sql,
        explanation:  result.explanation,
        tables:       result.tables,
        fields:       result.fields,
        confidence:   result.confidence,
        warnings:     result.warnings,
        isAiGenerated: result.isAiGenerated
      },
      suggestions: [
        'Add a date range filter',
        'Group results by day',
        'Limit to the last 1,000 rows',
        'Explain this query step-by-step'
      ],
      actions: [
        { type: 'view_details', label: 'Copy SQL', payload: { sql: result.sql } },
        { type: 'export_data',  label: 'Export as CSV' }
      ]
    };

    res.json(successResponse(payload, 'Natural language query processed'));
  } catch (error) {
    next(error);
  }
};

  public generateQualityRules = async (req: Request, res: Response, next: NextFunction): Promise<void> => {
    try {
      const { fieldInfo } = req.body;

      if (!fieldInfo) {
        throw new APIError('Field information is required', 400);
      }

      const rules = await this.aiService.generateQualityRules(fieldInfo);

      res.json(successResponse({ rules }));

    } catch (error) {
      next(error);
    }
  };

  public explainViolation = async (req: Request, res: Response, next: NextFunction): Promise<void> => {
    try {
      const { violation } = req.body;

      if (!violation) {
        throw new APIError('Violation information is required', 400);
      }

      const explanation = await this.aiService.explainViolation(violation);

      res.json(successResponse({ explanation }));

    } catch (error) {
      next(error);
    }
  };
}


------------------------------------------------------------
FILE: backend\ai-service\src\controllers\HealthController.ts
------------------------------------------------------------
// src/controllers/HealthController.ts
import type { NextFunction, Request, Response } from 'express';
import { unlink, writeFile } from 'fs/promises';
import os from 'os';
import path from 'path';

import { db } from '@config/database';
import { openai } from '@config/openai';
import { redis } from '@config/redis';
import { APIError } from '@utils/errors';
import { logger } from '@utils/logger';
import { errorResponse, successResponse } from '@utils/responses';

type Status = 'healthy' | 'degraded' | 'unhealthy';

interface HealthCheck {
  name: string;
  status: Status;
  responseTime: number; // ms
  details?: unknown;
  error?: string;
}

interface SystemHealth {
  status: Status;
  service: string;
  version: string;
  timestamp: string;
  uptime: number;
  environment: string;
  checks: HealthCheck[];
  summary: { total: number; healthy: number; degraded: number; unhealthy: number };
  system: {
    memory: NodeJS.MemoryUsage;
    cpu: { loadAverage: number[]; usageMicros: number };
    process: { pid: number; platform: string; nodeVersion: string };
  };
}

// --- bounded timeouts to avoid crazy env values
const clamp = (n: number, min: number, max: number) => Math.max(min, Math.min(max, n));
const DEFAULT_CHECK_TIMEOUT_MS = clamp(Number(process.env.HEALTH_CHECK_TIMEOUT_MS || 2000), 250, 10_000);

// Mask detailed dependency errors in production
const mask = (msg: string) => (process.env.NODE_ENV === 'development' ? msg : 'dependency error');

export class HealthController {
  private healthChecks: Map<string, () => Promise<HealthCheck>> = new Map();

  constructor() {
    this.initializeHealthChecks();
  }

  private initializeHealthChecks(): void {
    this.healthChecks.set('database', this.checkDatabase.bind(this));
    this.healthChecks.set('redis', this.checkRedis.bind(this));
    this.healthChecks.set('openai', this.checkOpenAI.bind(this));
    this.healthChecks.set('memory', this.checkMemory.bind(this));
    this.healthChecks.set('storage', this.checkStorage.bind(this));
  }

  public checkHealth = async (_req: Request, res: Response): Promise<void> => {
    const started = Date.now();
    logger.debug('Health: starting');

    const entries = Array.from(this.healthChecks.entries());
    const checks = await Promise.all(
      entries.map(([name, fn]) => this.runWithTimeout(name, fn, DEFAULT_CHECK_TIMEOUT_MS))
    );

    const summary = {
      total: checks.length,
      healthy: checks.filter(c => c.status === 'healthy').length,
      degraded: checks.filter(c => c.status === 'degraded').length,
      unhealthy: checks.filter(c => c.status === 'unhealthy').length
    };

    const overall: Status =
      summary.unhealthy > 0 ? 'unhealthy' : summary.degraded > 0 ? 'degraded' : 'healthy';

    const system = this.getSystemInfo();
    const payload: SystemHealth = {
      status: overall,
      service: 'ai-service',
      version: process.env.APP_VERSION || '1.0.0',
      timestamp: new Date().toISOString(),
      uptime: process.uptime(),
      environment: process.env.NODE_ENV || 'development',
      checks,
      summary,
      system
    };

    logger.info('Health: completed', { status: overall, durationMs: Date.now() - started, summary });

    // prevent caches from serving stale health
    res.setHeader('Cache-Control', 'no-store, no-cache, must-revalidate, proxy-revalidate');
    res
      .status(overall === 'unhealthy' ? 503 : 200)
      .json(successResponse(payload, 'Health check completed'));
  };

  public checkReadiness = async (_req: Request, res: Response, next: NextFunction): Promise<void> => {
    try {
      logger.debug('Readiness: starting');
      const critical: Array<[string, () => Promise<HealthCheck>]> = [
        ['database', this.checkDatabase.bind(this)],
        ['redis', this.checkRedis.bind(this)],
        ['openai', this.checkOpenAI.bind(this)]
      ];

      const results = await Promise.all(
        critical.map(([name, fn]) => this.runWithTimeout(name, fn, DEFAULT_CHECK_TIMEOUT_MS))
      );

      const failures = results.filter(r => r.status === 'unhealthy');

      if (failures.length) {
        logger.warn('Readiness: failed', { failures });
        res
          .status(503)
          .json(
            errorResponse('Service not ready', 503, {
              status: 'not ready',
              service: 'ai-service',
              timestamp: new Date().toISOString(),
              failures
            })
          );
        return;
      }

      logger.info('Readiness: passed');
      res.setHeader('Cache-Control', 'no-store');
      res.json(
        successResponse(
          { status: 'ready', service: 'ai-service', timestamp: new Date().toISOString(), message: 'Service is ready to accept requests' },
          'Readiness check passed'
        )
      );
    } catch (err) {
      logger.error('Readiness: error', { err });
      next(new APIError('Readiness check failed', 503, err));
    }
  };

  public checkLiveness = async (_req: Request, res: Response): Promise<void> => {
    const status = {
      status: 'alive',
      service: 'ai-service',
      timestamp: new Date().toISOString(),
      uptime: Math.floor(process.uptime()),
      pid: process.pid,
      memory: process.memoryUsage()
    };
    logger.debug('Liveness: ok', status);
    res.setHeader('Cache-Control', 'no-store');
    res.json(successResponse(status, 'Service is alive'));
  };

  public getMetrics = async (_req: Request, res: Response): Promise<void> => {
    try {
      // short sampling window to compute delta CPU
      const snap = process.cpuUsage();
      await new Promise(r => setTimeout(r, 50));
      const delta = process.cpuUsage(snap);
      const usageMicros = delta.user + delta.system;

      const metrics = {
        service: 'ai-service',
        timestamp: new Date().toISOString(),
        uptime: process.uptime(),
        memory: process.memoryUsage(),
        cpu: { loadAverage: os.loadavg(), usageMicros },
        requests: { total: 0, active: 0, errors: 0 }, // wire your counters via middleware
        cache: await this.getCacheMetrics(),
        database: await this.getDatabaseMetrics()
      };

      res.setHeader('Cache-Control', 'no-store');
      res.json(successResponse(metrics, 'Metrics retrieved'));
    } catch (err) {
      logger.error('Metrics: failed', { err });
      res.status(500).json(errorResponse('Failed to retrieve metrics', 500));
    }
  };

  // ----- Individual checks

  private async checkDatabase(): Promise<HealthCheck> {
    const t0 = Date.now();
    try {
      await db.query('SELECT 1');
      return { name: 'database', status: 'healthy', responseTime: Date.now() - t0, details: { type: 'PostgreSQL', connection: 'active' } };
    } catch (err: any) {
      return { name: 'database', status: 'unhealthy', responseTime: Date.now() - t0, error: mask(err?.message || 'db error') };
    }
  }

  private async checkRedis(): Promise<HealthCheck> {
    const t0 = Date.now();
    try {
      const key = `health:check:${Date.now()}`;
      // Redis v4: { EX: seconds }
      await (redis as any).set?.(key, 'ok', { EX: 10 });
      const val = await (redis as any).get?.(key);
      await (redis as any).del?.(key);
      if (val !== 'ok') throw new Error('Redis read/write test failed');
      return { name: 'redis', status: 'healthy', responseTime: Date.now() - t0, details: { type: 'Redis', operation: 'read/write passed' } };
    } catch (err: any) {
      return { name: 'redis', status: 'unhealthy', responseTime: Date.now() - t0, error: mask(err?.message || 'redis error') };
    }
  }

  private async checkOpenAI(): Promise<HealthCheck> {
    const t0 = Date.now();
    try {
      let ok = false;
      if (typeof (openai as any)?.testConnection === 'function') {
        ok = await (openai as any).testConnection();
      } else if ((openai as any)?.models?.list) {
        const models = await (openai as any).models.list();
        ok = Boolean(models);
      }
      return {
        name: 'openai',
        status: ok ? 'healthy' : 'degraded',
        responseTime: Date.now() - t0,
        details: { type: 'OpenAI API', available: ok },
        ...(ok ? {} : { error: 'OpenAI API not verified' })
      };
    } catch (err: any) {
      return { name: 'openai', status: 'degraded', responseTime: Date.now() - t0, error: mask(err?.message || 'OpenAI check failed') };
    }
  }

  private async checkMemory(): Promise<HealthCheck> {
    const t0 = Date.now();
    try {
      const m = process.memoryUsage();
      const pct = (m.heapUsed / Math.max(m.heapTotal, 1)) * 100;
      let status: Status = 'healthy';
      let message = 'Memory usage normal';
      if (pct > 90) { status = 'unhealthy'; message = 'Critical memory usage'; }
      else if (pct > 75) { status = 'degraded'; message = 'High memory usage'; }

      return {
        name: 'memory',
        status,
        responseTime: Date.now() - t0,
        details: {
          usagePercent: Math.round(pct * 100) / 100,
          heapUsedMB: Math.round((m.heapUsed / 1024 / 1024) * 100) / 100,
          heapTotalMB: Math.round((m.heapTotal / 1024 / 1024) * 100) / 100,
          message
        }
      };
    } catch {
      return { name: 'memory', status: 'unhealthy', responseTime: Date.now() - t0, error: 'Failed to evaluate memory' };
    }
  }

  private async checkStorage(): Promise<HealthCheck> {
    const t0 = Date.now();
    const base = process.env.HEALTH_TMP_DIR || os.tmpdir(); // configurable for read-only FS
    const file = path.join(base, `ai-service-health-${process.pid}-${Date.now()}.tmp`);
    try {
      await writeFile(file, 'health check');
      await unlink(file);
      return { name: 'storage', status: 'healthy', responseTime: Date.now() - t0, details: { type: 'filesystem', dir: base, writable: true } };
    } catch (err: any) {
      return { name: 'storage', status: 'degraded', responseTime: Date.now() - t0, error: mask(err?.message || 'Storage write test failed') };
    }
  }

  // ----- Helpers

  private getSystemInfo() {
    const mem = process.memoryUsage();
    const cpu0 = process.cpuUsage();
    const load = os.loadavg();
    return {
      memory: mem,
      cpu: { loadAverage: load, usageMicros: cpu0.user + cpu0.system },
      process: { pid: process.pid, platform: process.platform, nodeVersion: process.version }
    };
  }

  private async getCacheMetrics() {
    try {
      if (typeof (redis as any)?.getStats === 'function') {
        const stats = await (redis as any).getStats();
        return { connected: true, stats };
      }
      const pong = await (redis as any).ping?.();
      return { connected: pong === 'PONG' || pong === true };
    } catch (err: any) {
      return { connected: false, error: mask(err?.message || 'Failed to get Redis stats') };
    }
  }

  private async getDatabaseMetrics() {
    try {
      const result = await db.query(`
        SELECT 
          pg_database_size(current_database()) as database_size,
          (SELECT count(*) FROM pg_stat_activity WHERE state = 'active') as active_connections
      `);
      const row = (result as any).rows?.[0] || {};
      return {
        connected: true,
        size: Number(row.database_size ?? 0),
        activeConnections: Number(row.active_connections ?? 0)
      };
    } catch (err: any) {
      return { connected: false, error: mask(err?.message || 'Failed to get database metrics') };
    }
  }

  private async runWithTimeout(name: string, fn: () => Promise<HealthCheck>, timeoutMs: number): Promise<HealthCheck> {
    const started = Date.now();
    try {
      const result = await Promise.race<Promise<HealthCheck>>([
        fn(),
        new Promise<HealthCheck>((_resolve, reject) => setTimeout(() => reject(new Error(`${name} check timed out after ${timeoutMs}ms`)), timeoutMs))
      ]);
      return result;
    } catch (err: any) {
      logger.warn('Health: check failed', { name, error: err?.message });
      return { name, status: 'unhealthy', responseTime: Date.now() - started, error: mask(err?.message || 'Unknown error') };
    }
  }
}



------------------------------------------------------------
FILE: backend\ai-service\src\interfaces\analysis.interface.ts
------------------------------------------------------------
export interface AnalysisRequest {
  dataSourceId: string;
  analysisType: 'schema' | 'data_quality' | 'compliance' | 'performance';
  options?: AnalysisOptions;
  userId: string;
}

export interface AnalysisOptions {
  includeMetadata?: boolean;
  includeSampleData?: boolean;
  sampleSize?: number;
  analysisDepth?: 'basic' | 'detailed' | 'comprehensive';
  targetTables?: string[];
  targetSchemas?: string[];
  complianceFrameworks?: ComplianceFramework[];
}

export interface AnalysisResult {
  analysisId: string;
  dataSourceId: string;
  analysisType: string;
  status: AnalysisStatus;
  progress: number;
  startedAt: Date;
  completedAt?: Date;
  results?: AnalysisData;
  error?: string;
  userId: string;
}

export interface AnalysisData {
  schemaAnalysis?: SchemaAnalysisResult;
  qualityAnalysis?: QualityAnalysisResult;
  complianceAnalysis?: ComplianceAnalysisResult;
  performanceAnalysis?: PerformanceAnalysisResult;
  summary: AnalysisSummary;
}

export interface SchemaAnalysisResult {
  totalTables: number;
  totalColumns: number;
  tableAnalysis: TableAnalysis[];
  relationshipMap: RelationshipAnalysis[];
  dataClassification: DataClassificationSummary;
  recommendations: string[];
}

export interface TableAnalysis {
  schemaName: string;
  tableName: string;
  columnCount: number;
  estimatedRowCount?: number;
  columns: ColumnAnalysis[];
  governance: TableGovernance;
  dataQuality: TableQualityMetrics;
  relationships: TableRelationship[];
}

export interface ColumnAnalysis {
  name: string;
  dataType: string;
  nullable: boolean;
  isPrimaryKey: boolean;
  isForeignKey: boolean;
  classification: DataClassification;
  sensitivity: SensitivityLevel;
  qualityScore: number;
  patterns: DataPattern[];
  statistics?: ColumnStatistics;
  recommendations: string[];
}

export interface TableGovernance {
  classification: DataClassification;
  sensitivity: SensitivityLevel;
  complianceRequirements: ComplianceFramework[];
  accessLevel: AccessLevel;
  retentionPolicy?: RetentionPolicy;
  encryptionRequired: boolean;
  auditRequired: boolean;
}

export interface TableQualityMetrics {
  completeness: number;
  validity: number;
  consistency: number;
  accuracy: number;
  uniqueness: number;
  overallScore: number;
  issues: QualityIssue[];
}

export interface QualityAnalysisResult {
  overallScore: number;
  dimensionScores: QualityDimensionScores;
  issues: QualityIssue[];
  trends: QualityTrend[];
  recommendations: QualityRecommendation[];
}

export interface QualityDimensionScores {
  completeness: number;
  validity: number;
  consistency: number;
  accuracy: number;
  uniqueness: number;
  timeliness: number;
}

export interface QualityIssue {
  id: string;
  type: QualityIssueType;
  severity: 'Critical' | 'High' | 'Medium' | 'Low';
  table: string;
  column?: string;
  description: string;
  affectedRows: number;
  suggestion: string;
  detectedAt: Date;
  status: 'Open' | 'Acknowledged' | 'Resolved' | 'Ignored';
}

export interface ComplianceAnalysisResult {
  overallScore: number;
  frameworkResults: FrameworkComplianceResult[];
  violations: ComplianceViolation[];
  recommendations: ComplianceRecommendation[];
  riskAssessment: RiskAssessment;
}

export interface FrameworkComplianceResult {
  framework: ComplianceFramework;
  score: number;
  status: 'Compliant' | 'Partially Compliant' | 'Non-Compliant';
  requirements: RequirementResult[];
  lastAssessed: Date;
}

export interface PerformanceAnalysisResult {
  queryPerformance: QueryPerformanceMetrics;
  indexAnalysis: IndexAnalysis[];
  storageAnalysis: StorageMetrics;
  recommendations: PerformanceRecommendation[];
}

export interface AnalysisSummary {
  totalTables: number;
  totalColumns: number;
  sensitiveDataTables: number;
  qualityScore: number;
  complianceScore: number;
  criticalIssues: number;
  highPriorityRecommendations: string[];
  estimatedImprovementEffort: 'Low' | 'Medium' | 'High';
}

// Supporting Enums and Types
export enum AnalysisStatus {
  PENDING = 'pending',
  IN_PROGRESS = 'in_progress',
  COMPLETED = 'completed',
  FAILED = 'failed',
  CANCELLED = 'cancelled'
}

export enum DataClassification {
  PUBLIC = 'Public',
  INTERNAL = 'Internal',
  CONFIDENTIAL = 'Confidential',
  RESTRICTED = 'Restricted',
  PII = 'PII',
  PHI = 'PHI',
  FINANCIAL = 'Financial'
}

export enum SensitivityLevel {
  LOW = 'Low',
  MEDIUM = 'Medium',
  HIGH = 'High',
  CRITICAL = 'Critical'
}

export enum ComplianceFramework {
  GDPR = 'GDPR',
  HIPAA = 'HIPAA',
  CCPA = 'CCPA',
  SOX = 'SOX',
  PCI_DSS = 'PCI-DSS',
  ISO_27001 = 'ISO-27001',
  NIST = 'NIST'
}

export enum AccessLevel {
  PUBLIC = 'Public',
  INTERNAL = 'Internal',
  RESTRICTED = 'Restricted',
  CONFIDENTIAL = 'Confidential'
}

export enum QualityIssueType {
  NULL_VALUES = 'null_values',
  DUPLICATES = 'duplicates',
  FORMAT_INCONSISTENCY = 'format_inconsistency',
  OUTLIERS = 'outliers',
  REFERENTIAL_INTEGRITY = 'referential_integrity',
  BUSINESS_RULE_VIOLATION = 'business_rule_violation'
}

// Supporting Interfaces
export interface DataPattern {
  type: string;
  pattern: string;
  confidence: number;
  examples: string[];
}

export interface ColumnStatistics {
  nullCount: number;
  uniqueCount: number;
  minValue?: any;
  maxValue?: any;
  avgValue?: number;
  standardDeviation?: number;
  distribution?: ValueDistribution[];
}

export interface ValueDistribution {
  value: any;
  count: number;
  percentage: number;
}

export interface RelationshipAnalysis {
  sourceTable: string;
  targetTable: string;
  relationshipType: 'one-to-one' | 'one-to-many' | 'many-to-many';
  foreignKeys: ForeignKeyRelation[];
  strength: number;
}

export interface ForeignKeyRelation {
  sourceColumn: string;
  targetColumn: string;
  constraintName?: string;
}

export interface TableRelationship {
  relatedTable: string;
  relationshipType: string;
  foreignKeyColumns: string[];
  isStrong: boolean;
}

export interface DataClassificationSummary {
  byClassification: Record<DataClassification, number>;
  bySensitivity: Record<SensitivityLevel, number>;
  byCompliance: Record<ComplianceFramework, number>;
  totalSensitiveFields: number;
}

export interface RetentionPolicy {
  retentionPeriod: number;
  retentionUnit: 'days' | 'months' | 'years';
  archiveAfter?: number;
  deleteAfter?: number;
  policy: string;
}

export interface QualityTrend {
  date: Date;
  dimension: string;
  score: number;
  change: number;
}

export interface QualityRecommendation {
  id: string;
  priority: 'High' | 'Medium' | 'Low';
  category: 'Data Quality' | 'Governance' | 'Compliance' | 'Performance';
  title: string;
  description: string;
  impact: string;
  effort: 'Low' | 'Medium' | 'High';
  estimatedImprovement: number;
  implementation: string[];
}

export interface ComplianceViolation {
  id: string;
  framework: ComplianceFramework;
  requirement: string;
  severity: 'Critical' | 'High' | 'Medium' | 'Low';
  table: string;
  column?: string;
  description: string;
  remediation: string;
  dueDate?: Date;
  status: 'Open' | 'In Progress' | 'Resolved';
}

export interface ComplianceRecommendation {
  framework: ComplianceFramework;
  requirement: string;
  description: string;
  priority: 'High' | 'Medium' | 'Low';
  implementation: string[];
  timeline: string;
}

export interface RiskAssessment {
  overallRisk: 'Low' | 'Medium' | 'High' | 'Critical';
  riskFactors: RiskFactor[];
  mitigationStrategies: string[];
  businessImpact: string;
}

export interface RiskFactor {
  factor: string;
  level: 'Low' | 'Medium' | 'High' | 'Critical';
  description: string;
  likelihood: number;
  impact: number;
}

export interface RequirementResult {
  requirement: string;
  status: 'Met' | 'Partially Met' | 'Not Met';
  description: string;
  evidence?: string[];
  gaps?: string[];
}

export interface QueryPerformanceMetrics {
  avgQueryTime: number;
  slowQueries: SlowQuery[];
  queryPatterns: QueryPattern[];
  resourceUtilization: ResourceUtilization;
}

export interface SlowQuery {
  query: string;
  executionTime: number;
  frequency: number;
  table: string;
  recommendation: string;
}

export interface QueryPattern {
  pattern: string;
  frequency: number;
  avgExecutionTime: number;
  optimization: string;
}

export interface ResourceUtilization {
  cpuUsage: number;
  memoryUsage: number;
  ioWait: number;
  connectionCount: number;
}

export interface IndexAnalysis {
  table: string;
  existingIndexes: IndexInfo[];
  suggestedIndexes: SuggestedIndex[];
  unusedIndexes: string[];
}

export interface IndexInfo {
  name: string;
  columns: string[];
  type: string;
  size: number;
  usage: number;
}

export interface SuggestedIndex {
  columns: string[];
  type: string;
  rationale: string;
  estimatedImprovement: number;
}

export interface StorageMetrics {
  totalSize: number;
  tablesSizes: TableSize[];
  growthRate: number;
  projectedSize: number;
  optimization: string[];
}

export interface TableSize {
  table: string;
  size: number;
  rowCount: number;
  avgRowSize: number;
}

export interface PerformanceRecommendation {
  type: 'Index' | 'Query' | 'Schema' | 'Configuration';
  description: string;
  impact: 'High' | 'Medium' | 'Low';
  effort: 'Low' | 'Medium' | 'High';
  implementation: string;
}


------------------------------------------------------------
FILE: backend\ai-service\src\interfaces\discovery.interface.ts
------------------------------------------------------------
/* eslint-disable @typescript-eslint/consistent-type-definitions */

/**
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * Utility & Brand Types
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 */
export type Brand<K, T extends string> = K & { readonly __brand: T };

export type UUID = Brand<string, 'uuid'>;               // e.g., '2f1a2c1e-...'
export type ISODateTime = Brand<string, 'iso-datetime'>; // e.g., new Date().toISOString()
export type ByteSize = Brand<number, 'bytes'>;
export type Percentage = Brand<number, '0..100'>;

export type NonEmptyArray<T> = readonly [T, ...T[]];
export type PositiveInt = Brand<number, 'positive-int'>;

/**
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * Shared Enums / Unions
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 */
export type DiscoveryType = 'full' | 'incremental' | 'targeted';

export enum DiscoveryStatus {
  PENDING = 'pending',
  INITIALIZING = 'initializing',
  SCANNING_METADATA = 'scanning_metadata',
  SAMPLING_DATA = 'sampling_data',
  CLASSIFYING = 'classifying',
  AI_ANALYSIS = 'ai_analysis',
  QUALITY_ASSESSMENT = 'quality_assessment',
  GENERATING_INSIGHTS = 'generating_insights',
  RUNNING = 'running',
  COMPLETED = 'completed',
  FAILED = 'failed',
  CANCELLED = 'cancelled',
}

export enum PatternType {
  EMAIL = 'email',
  PHONE = 'phone',
  SSN = 'ssn',
  CREDIT_CARD = 'credit_card',
  IP_ADDRESS = 'ip_address',
  UUID = 'uuid',
  DATE = 'date',
  URL = 'url',
  CUSTOM = 'custom',
}

export type ConstraintKind = 'PRIMARY KEY' | 'FOREIGN KEY' | 'UNIQUE' | 'CHECK' | 'NOT NULL';
export type IndexMethod = 'btree' | 'hash' | 'gist' | 'gin' | 'brin' | 'spgist' | string;
export type TableLike = 'table' | 'view' | 'materialized_view';

export type DBType =
  | 'postgres'
  | 'mysql'
  | 'mariadb'
  | 'mssql'
  | 'oracle'
  | 'snowflake'
  | 'bigquery'
  | 'sqlite'
  | 'redshift'
  | string;

export type QualityDimension = 'Completeness' | 'Validity' | 'Consistency' | 'Accuracy' | 'Uniqueness';
export type DataVolume = 'Small' | 'Medium' | 'Large' | 'Very Large';
export type Criticality = 'Low' | 'Medium' | 'High' | 'Critical';
export type RiskLevel = Criticality;
export type Priority = 'Critical' | 'High' | 'Medium' | 'Low';
export type Timeline = 'Immediate' | 'Short Term' | 'Long Term';

export type GovernanceCategory = 'Access Control' | 'Data Classification' | 'Retention' | 'Compliance';

export type DataClassification =
  | 'PII'
  | 'PHI'
  | 'PCI'
  | 'Confidential'
  | 'Restricted'
  | 'Internal'
  | 'Public'
  | 'Custom';

export type SensitivityLevel = 'Low' | 'Medium' | 'High' | 'Very High';

export type ComplianceFramework =
  | 'GDPR'
  | 'HIPAA'
  | 'PCI-DSS'
  | 'SOX'
  | 'CCPA'
  | 'ISO27001'
  | 'NIST'
  | 'SOC2'
  | 'Custom';

export type ClassificationScope = 'column_name' | 'data_type' | 'data_pattern';

/**
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * Request Models
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 */

export interface DiscoveryOptions {
  readonly schemas?: readonly string[];
  readonly tables?: readonly string[];
  readonly includeSystemTables?: boolean;
  readonly includeSampleData?: boolean;
  readonly sampleSize?: PositiveInt; // rows per table when sampling
  readonly analysisDepth?: 'basic' | 'detailed' | 'comprehensive';
  readonly aiAnalysis?: boolean;
  readonly classificationRules?: readonly ClassificationRule[];
  readonly customPatterns?: readonly CustomPattern[];
}

/**
 * Discriminated DiscoveryRequest:
 * - full / incremental: options optional
 * - targeted: requires at least one of schemas/tables, and they cannot be empty
 */
interface BaseDiscoveryRequest {
  readonly dataSourceId: UUID | string;
  readonly userId: UUID | string;
}

export type DiscoveryRequest =
  | (BaseDiscoveryRequest & {
      readonly discoveryType: 'full';
      readonly options?: DiscoveryOptions;
    })
  | (BaseDiscoveryRequest & {
      readonly discoveryType: 'incremental';
      readonly options?: DiscoveryOptions & { readonly since?: ISODateTime };
    })
  | (BaseDiscoveryRequest & {
      readonly discoveryType: 'targeted';
      readonly options: DiscoveryOptions & {
        readonly schemas?: NonEmptyArray<string>;
        readonly tables?: NonEmptyArray<string>;
      };
    });

/**
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * Session / Results
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 */

export interface DiscoverySession {
  readonly sessionId: UUID | string;
  readonly userId: UUID | string;
  readonly dataSourceId: UUID | string;
  readonly discoveryType: DiscoveryType;
  readonly status: DiscoveryStatus;
  readonly progress: Percentage; // 0..100
  readonly currentStep?: string;
  readonly results?: DiscoveryResults;
  readonly error?: string;
  readonly startedAt: Date;
  readonly completedAt?: Date;
  readonly estimatedCompletion?: Date;
  readonly options: DiscoveryOptions;
}

export interface DiscoveryResults {
  readonly metadata: DataSourceMetadata;
  readonly classification: ClassificationResults;
  readonly aiInsights: AIInsights;
  readonly qualityAssessment: QualityAssessment;
  readonly summary: DiscoverySummary;
  readonly recommendations: readonly DiscoveryRecommendation[];
}

/**
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * Metadata Shapes
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 */

export interface DataSourceMetadata {
  readonly dataSourceId: UUID | string;
  readonly connectionInfo: ConnectionInfo;
  readonly schemas: readonly SchemaMetadata[];
  readonly totalTables: number;
  readonly totalColumns: number;
  readonly totalRows?: number;
  readonly dataSize?: ByteSize;
  readonly lastUpdated: Date;
}

export interface ConnectionInfo {
  readonly type: DBType;
  readonly host?: string;
  readonly port?: number;
  readonly database?: string;
  readonly version?: string;
  readonly charset?: string;
  readonly collation?: string;
}

export interface SchemaMetadata {
  readonly name: string;
  readonly tables: readonly TableMetadata[];
  readonly views: readonly ViewMetadata[];
  readonly procedures?: readonly ProcedureMetadata[];
  readonly functions?: readonly FunctionMetadata[];
}

export interface TableMetadata {
  readonly schema: string;
  readonly name: string;
  readonly type: TableLike;
  readonly columns: readonly ColumnMetadata[];
  readonly primaryKeys: readonly string[];
  readonly foreignKeys: readonly ForeignKeyMetadata[];
  readonly indexes: readonly IndexMetadata[];
  readonly constraints: readonly ConstraintMetadata[];
  readonly rowCount?: number;
  readonly sizeBytes?: ByteSize;
  readonly lastModified?: Date;
  readonly sampleData?: readonly unknown[];
}

export interface ColumnMetadata {
  readonly name: string;
  readonly dataType: string;
  readonly length?: number;
  readonly precision?: number;
  readonly scale?: number;
  readonly nullable: boolean;
  readonly defaultValue?: unknown;
  readonly autoIncrement?: boolean;
  readonly description?: string;
  readonly position: number;
}

export interface ViewMetadata {
  readonly schema: string;
  readonly name: string;
  readonly definition: string;
  readonly columns: readonly ColumnMetadata[];
  readonly dependencies: readonly string[];
}

export interface ProcedureMetadata {
  readonly schema: string;
  readonly name: string;
  readonly parameters: readonly ParameterMetadata[];
  readonly returnType?: string;
  readonly language?: string;
}

export interface FunctionMetadata {
  readonly schema: string;
  readonly name: string;
  readonly parameters: readonly ParameterMetadata[];
  readonly returnType: string;
  readonly language?: string;
}

export interface ParameterMetadata {
  readonly name: string;
  readonly dataType: string;
  readonly direction: 'IN' | 'OUT' | 'INOUT';
  readonly defaultValue?: unknown;
}

export interface ForeignKeyMetadata {
  readonly name: string;
  readonly columns: readonly string[];
  readonly referencedTable: string; // consider "schema.table"
  readonly referencedColumns: readonly string[];
  readonly onDelete?: 'NO ACTION' | 'RESTRICT' | 'CASCADE' | 'SET NULL' | 'SET DEFAULT' | string;
  readonly onUpdate?: 'NO ACTION' | 'RESTRICT' | 'CASCADE' | 'SET NULL' | 'SET DEFAULT' | string;
}

export interface IndexMetadata {
  readonly name: string;
  readonly columns: readonly string[];
  readonly unique: boolean;
  readonly type?: string;   // btree, hash... (engine-specific)
  readonly method?: IndexMethod;
}

export interface ConstraintMetadata {
  readonly name: string;
  readonly type: ConstraintKind;
  readonly columns: readonly string[];
  readonly definition?: string;
}

/**
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * Classification / Compliance
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 */

export interface ClassificationResults {
  readonly fieldClassifications: readonly FieldClassification[];
  readonly tableClassifications: readonly TableClassification[];
  readonly sensitivityMap: SensitivityMap;
  readonly complianceMapping: ComplianceMapping;
  readonly riskAssessment: DataRiskAssessment;
}

export interface FieldClassification {
  readonly schema: string;
  readonly table: string;
  readonly column: string;
  readonly dataType: string;
  readonly classification: DataClassification;
  readonly sensitivity: SensitivityLevel;
  readonly confidence: Percentage;
  readonly patterns: readonly DetectedPattern[];
  readonly tags: readonly string[];
  readonly businessContext?: string;
  readonly complianceFlags: readonly ComplianceFlag[];
}

export interface TableClassification {
  readonly schema: string;
  readonly table: string;
  readonly overallClassification: DataClassification;
  readonly overallSensitivity: SensitivityLevel;
  readonly dataVolume: DataVolume;
  readonly businessCriticality: Criticality;
  readonly accessFrequency: 'Rare' | 'Occasional' | 'Regular' | 'High';
  readonly retentionCategory: string;
  readonly complianceScope: readonly ComplianceFramework[];
}

export interface DetectedPattern {
  readonly type: PatternType;
  readonly pattern: string; // e.g., regex or named rule
  readonly confidence: Percentage;
  readonly examples: readonly string[];
  readonly description: string;
}

export interface SensitivityMap {
  readonly bySensitivity: Record<SensitivityLevel, readonly FieldClassification[]>;
  readonly byClassification: Record<DataClassification, readonly FieldClassification[]>;
  readonly sensitiveTableCount: number;
  readonly highRiskFields: readonly FieldClassification[];
}

export interface ComplianceMapping {
  readonly byFramework: Record<ComplianceFramework, ComplianceScope>;
  readonly overallComplexity: 'Low' | 'Medium' | 'High' | 'Very High';
  readonly requiredActions: readonly ComplianceAction[];
}

export interface ComplianceScope {
  readonly applicableTables: readonly string[]; // consider using "schema.table" naming
  readonly applicableFields: readonly FieldClassification[];
  readonly requirements: readonly string[];
  readonly riskLevel: RiskLevel;
}

export interface ComplianceAction {
  readonly framework: ComplianceFramework;
  readonly action: string;
  readonly priority: 'High' | 'Medium' | 'Low';
  readonly timeline: string;
  readonly effort: 'Low' | 'Medium' | 'High';
}

export interface ComplianceFlag {
  readonly framework: ComplianceFramework;
  readonly requirement: string;
  readonly severity: 'Info' | 'Warning' | 'Error';
  readonly description: string;
}

/**
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * Risk / Quality / AI Insights
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 */

export interface DataRiskAssessment {
  readonly overallRisk: RiskLevel;
  readonly riskFactors: readonly DataRiskFactor[];
  readonly mitigationPriorities: readonly string[];
  readonly businessImpact: BusinessImpact;
}

export interface DataRiskFactor {
  readonly factor: string;
  readonly level: RiskLevel;
  readonly description: string;
  readonly affectedTables: readonly string[];
  readonly mitigationStrategy: string;
}

export interface BusinessImpact {
  readonly reputational: RiskLevel;
  readonly financial: RiskLevel;
  readonly operational: RiskLevel;
  readonly regulatory: RiskLevel;
}

export interface AIInsights {
  readonly fieldRecommendations: readonly AIFieldRecommendation[];
  readonly schemaInsights: readonly SchemaInsight[];
  readonly qualityPredictions: readonly QualityPrediction[];
  readonly governanceRecommendations: readonly GovernanceRecommendation[];
  readonly anomalies: readonly DataAnomaly[];
}

export interface AIFieldRecommendation {
  readonly schema: string;
  readonly table: string;
  readonly column: string;
  readonly recommendation: string;
  readonly reasoning: string;
  readonly confidence: Percentage;
  readonly impact: 'Low' | 'Medium' | 'High';
  readonly category: 'Classification' | 'Quality' | 'Governance' | 'Security';
}

export interface SchemaInsight {
  readonly type: 'Pattern' | 'Relationship' | 'Optimization' | 'Risk';
  readonly insight: string;
  readonly confidence: Percentage;
  readonly tables: readonly string[];
  readonly recommendation: string;
  readonly priority: 'Low' | 'Medium' | 'High';
}

export interface QualityPrediction {
  readonly table: string;
  readonly column?: string;
  readonly qualityDimension: QualityDimension;
  readonly predictedScore: Percentage; // 0..100
  readonly confidence: Percentage;     // 0..100
  readonly factors: readonly string[];
  readonly recommendations: readonly string[];
}

export interface GovernanceRecommendation {
  readonly scope: 'Field' | 'Table' | 'Schema' | 'Database';
  readonly target: string; // e.g., "schema.table.column"
  readonly recommendation: string;
  readonly category: GovernanceCategory;
  readonly priority: 'High' | 'Medium' | 'Low';
  readonly effort: 'Low' | 'Medium' | 'High';
  readonly benefit: string;
}

export interface DataAnomaly {
  readonly type: 'Statistical' | 'Pattern' | 'Relationship' | 'Quality';
  readonly table: string;
  readonly column?: string;
  readonly description: string;
  readonly severity: 'Info' | 'Warning' | 'Error';
  readonly confidence: Percentage;
  readonly suggestion: string;
}

export interface QualityAssessment {
  readonly overallScore: Percentage;
  readonly tableScores: readonly TableQualityScore[];
  readonly dimensionScores: QualityDimensionScores;
  readonly issues: readonly QualityIssue[];
  readonly trends?: readonly QualityTrend[];
}

export interface TableQualityScore {
  readonly schema: string;
  readonly table: string;
  readonly overallScore: Percentage;
  readonly completeness: Percentage;
  readonly validity: Percentage;
  readonly consistency: Percentage;
  readonly accuracy: Percentage;
  readonly uniqueness: Percentage;
  readonly issueCount: number;
  readonly recommendation: string;
}

export interface QualityDimensionScores {
  readonly [dimension: string]: Percentage | number; // allow dynamic dimensions
}

export interface QualityIssue {
  readonly id?: UUID | string;
  readonly schema: string;
  readonly table: string;
  readonly column?: string;
  readonly dimension: QualityDimension;
  readonly severity: 'Low' | 'Medium' | 'High';
  readonly description: string;
  readonly recommendation: string;
}

export interface QualityTrend {
  readonly timestamp: ISODateTime | string;
  readonly dimension: QualityDimension;
  readonly score: Percentage;
}

export interface DiscoverySummary {
  readonly totalTablesAnalyzed: number;
  readonly totalColumnsAnalyzed: number;
  readonly classificationsApplied: number;
  readonly sensitiveDataFound: number;
  readonly complianceFlags: number;
  readonly qualityIssues: number;
  readonly aiRecommendations: number;
  readonly executionTime: number; // ms
  readonly dataVolumeProcessed: ByteSize | number;
}

export interface DiscoveryRecommendation {
  readonly id: UUID | string;
  readonly category: Timeline;
  readonly priority: Priority;
  readonly type: 'Security' | 'Compliance' | 'Quality' | 'Governance' | 'Performance';
  readonly title: string;
  readonly description: string;
  readonly affectedTables: readonly string[];
  readonly businessImpact: string;
  readonly effort: 'Low' | 'Medium' | 'High';
  readonly timeline: string;
  readonly implementation: readonly ImplementationStep[];
}

export interface ImplementationStep {
  readonly step: number;
  readonly description: string;
  readonly estimatedTime: string;
  readonly dependencies?: readonly string[];
  readonly tools?: readonly string[];
}

export interface ClassificationRule {
  readonly name: string;
  readonly pattern: string; // regex or named rule
  readonly classification: DataClassification;
  readonly sensitivity: SensitivityLevel;
  readonly scope: ClassificationScope;
  readonly priority: number;
}

export interface CustomPattern {
  readonly name: string;
  readonly regex: string; // serialized regex
  readonly classification: DataClassification;
  readonly description: string;
  readonly examples: readonly string[];
}



------------------------------------------------------------
FILE: backend\ai-service\src\interfaces\index.ts
------------------------------------------------------------
// src/interfaces/index.ts

// Namespace-style re-exports (import as `Analysis.*` or `Discovery.*`)
export * as Analysis from './analysis.interface';
export * as Discovery from './discovery.interface';

// Flatten specific items so you can `import { DiscoveryStatus } from '@/interfaces'`
export { DiscoveryStatus, DiscoveryType } from './discovery.interface';

// NOTE: Removed this because we define JobStatus/JobPriority below.
// export { JobStatus, JobPriority } from './job.interface';

// Import only for typing
import type { Request as ExpressRequest } from 'express';

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * Utility & Brand Types
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
export type Brand<K, T extends string> = K & { readonly __brand: T };

export type UUID = Brand<string, 'uuid'>;
export type ISODateTime = Brand<string, 'iso-datetime'>;

export type Maybe<T> = T | null | undefined;
export type Result<T, E = ServiceError> =
  | Readonly<{ ok: true; value: T }>
  | Readonly<{ ok: false; error: E }>;
export type NonEmptyArray<T> = readonly [T, ...T[]];

export type DeepReadonly<T> =
  T extends (...args: any[]) => any ? T :
  T extends Array<infer U> ? ReadonlyArray<DeepReadonly<U>> :
  T extends object ? { readonly [K in keyof T]: DeepReadonly<T[K]> } :
  T;

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * Shared entities & pagination
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
export interface BaseEntity {
  readonly id: UUID | string;
  readonly createdAt: Date;
  readonly updatedAt: Date;
  readonly createdBy?: UUID | string;
  readonly updatedBy?: UUID | string;
}

export type SortOrder = 'ASC' | 'DESC';

export interface PaginationParams {
  readonly page?: number;
  readonly limit?: number;
  readonly offset?: number; // (page-1)*limit (server-calculated preferred)
  readonly sortBy?: string;
  readonly sortOrder?: SortOrder;
}

export interface PaginationInfo {
  readonly page: number;
  readonly limit: number;
  readonly total: number;
  readonly totalPages: number;
  readonly hasNext: boolean;
  readonly hasPrev: boolean;
}

export interface PaginationResult<T> {
  readonly data: readonly T[];
  readonly pagination: PaginationInfo;
}

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * Filtering / query params
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
export interface DateRange {
  readonly from: Date | ISODateTime | string;
  readonly to: Date | ISODateTime | string;
}

export interface FilterParams<F extends Record<string, unknown> = Record<string, unknown>> {
  readonly search?: string;
  readonly filters?: F;
  readonly dateRange?: DateRange;
}

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * ApiRequest & Auth
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
export enum UserRole {
  SUPER_ADMIN = 'super_admin',
  ADMIN = 'admin',
  DATA_STEWARD = 'data_steward',
  ANALYST = 'analyst',
  VIEWER = 'viewer'
}

export enum Permission {
  // Discovery
  DISCOVERY_READ = 'discovery:read',
  DISCOVERY_WRITE = 'discovery:write',
  DISCOVERY_DELETE = 'discovery:delete',
  // Analysis
  ANALYSIS_READ = 'analysis:read',
  ANALYSIS_WRITE = 'analysis:write',
  ANALYSIS_DELETE = 'analysis:delete',
  // Data source
  DATASOURCE_READ = 'datasource:read',
  DATASOURCE_WRITE = 'datasource:write',
  DATASOURCE_DELETE = 'datasource:delete',
  DATASOURCE_CONNECT = 'datasource:connect',
  // Admin
  USER_MANAGEMENT = 'user:management',
  SYSTEM_CONFIG = 'system:config',
  AUDIT_LOGS = 'audit:logs',
  // AI
  AI_QUERY = 'ai:query',
  AI_TRAINING = 'ai:training'
}

export interface NotificationSettings {
  readonly email: boolean;
  readonly inApp: boolean;
  readonly sms: boolean;
  readonly slack: boolean;
  readonly webhooks: boolean;
}

export interface UserPreferences {
  readonly timezone: string;
  readonly language: string;
  readonly dateFormat: string;
  readonly notifications: NotificationSettings;
}

export interface AuthenticatedUser {
  readonly id: UUID | string;
  readonly email: string;
  readonly role: UserRole;
  readonly permissions: readonly Permission[];
  readonly organizationId?: UUID | string;
  readonly preferences?: UserPreferences;
}

/** Express Request typed with body/params/query plus user */
export type ApiRequest<
  B = unknown,
  P extends Record<string, string> = Record<string, string>,
  Q extends Record<string, unknown> = Record<string, unknown>
> = ExpressRequest<P, any, B, Q> & { user?: AuthenticatedUser };

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * Service response envelopes
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
export interface ServiceError {
  readonly code: string; // e.g., 'VALIDATION_ERROR', 'DB_TIMEOUT'
  readonly message: string;
  readonly details?: unknown;
  readonly stack?: string; // do not expose in prod
}

export interface ResponseMeta {
  readonly timestamp: ISODateTime | string;
  readonly requestId?: string;
  readonly version: string;
  readonly processingTime?: number; // ms
}

export interface ServiceResponse<T = unknown> {
  readonly success: boolean;
  readonly data?: T;
  readonly message?: string;
  readonly error?: ServiceError;
  readonly meta?: ResponseMeta;
}

/** Generic pagination wrapper using ApiResponse pattern */
export type PaginatedResponse<T> =
  | Readonly<{
      success: true;
      data: { items: readonly T[]; pagination: PaginationInfo };
      message?: string;
      meta?: ResponseMeta;
    }>
  | Readonly<{
      success: false;
      error: ServiceError;
      meta?: ResponseMeta;
    }>;

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * Health & system info
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
export type HealthState = 'healthy' | 'degraded' | 'unhealthy';

export interface HealthCheck {
  readonly name: string;
  readonly status: HealthState;
  readonly responseTime: number;
  readonly details?: unknown;
  readonly error?: string;
}

export interface SystemInfo {
  readonly memory: NodeJS.MemoryUsage;
  readonly cpu: {
    readonly loadAverage: readonly number[];
    readonly usage: number; // your implementation units
  };
  readonly process: {
    readonly pid: number;
    readonly platform: string;
    readonly nodeVersion: string;
  };
}

export interface HealthStatus {
  readonly status: HealthState;
  readonly service: string;
  readonly version: string;
  readonly timestamp: ISODateTime | string;
  readonly uptime: number;
  readonly checks: readonly HealthCheck[];
  readonly system: SystemInfo;
}

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * Data sources & connection
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
export enum DataSourceType {
  POSTGRESQL = 'postgresql',
  MYSQL = 'mysql',
  SQL_SERVER = 'sql_server',
  ORACLE = 'oracle',
  SNOWFLAKE = 'snowflake',
  BIGQUERY = 'bigquery',
  REDSHIFT = 'redshift',
  MONGODB = 'mongodb',
  CASSANDRA = 'cassandra',
  ELASTICSEARCH = 'elasticsearch'
}

export enum ConnectionStatus {
  CONNECTED = 'connected',
  DISCONNECTED = 'disconnected',
  ERROR = 'error',
  TESTING = 'testing',
  PENDING = 'pending',
  TIMEOUT = 'timeout'
}

export interface ConnectionConfig {
  readonly host?: string;
  readonly port?: number;
  readonly database?: string;
  readonly username?: string;
  readonly password?: string; // encrypted at rest
  readonly ssl?: boolean;
  readonly connectionTimeout?: number;
  readonly queryTimeout?: number;
  readonly poolSize?: number;
  readonly additionalProperties?: Record<string, unknown>;
}

export interface DataSource {
  readonly id: UUID | string;
  readonly name: string;
  readonly type: DataSourceType;
  readonly connectionConfig: ConnectionConfig;
  readonly status: ConnectionStatus;
  readonly lastConnected?: Date;
  readonly tags?: readonly string[];
  readonly description?: string;
}

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * Logging / audit / notifications
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
export type LogLevel = 'error' | 'warn' | 'info' | 'debug';

export interface LogEntry {
  readonly level: LogLevel;
  readonly message: string;
  readonly timestamp: Date;
  readonly service: string;
  readonly requestId?: string;
  readonly userId?: UUID | string;
  readonly metadata?: Record<string, unknown>;
  readonly stack?: string;
}

export interface AuditLog extends BaseEntity {
  readonly action: string;
  readonly resource: string;
  readonly resourceId?: string;
  readonly userId: UUID | string;
  readonly ipAddress?: string;
  readonly userAgent?: string;
  readonly details?: Record<string, unknown>;
  readonly result: 'success' | 'failure';
}

export enum NotificationType {
  DISCOVERY_COMPLETED = 'discovery_completed',
  ANALYSIS_COMPLETED = 'analysis_completed',
  QUALITY_ALERT = 'quality_alert',
  COMPLIANCE_VIOLATION = 'compliance_violation',
  SYSTEM_ALERT = 'system_alert',
  SECURITY_ALERT = 'security_alert',
  DATA_BREACH = 'data_breach',
  MAINTENANCE = 'maintenance'
}

export enum NotificationChannel {
  EMAIL = 'email',
  IN_APP = 'in_app',
  SMS = 'sms',
  SLACK = 'slack',
  TEAMS = 'teams',
  WEBHOOK = 'webhook',
  PUSH = 'push'
}

export enum NotificationStatus {
  PENDING = 'pending',
  SENT = 'sent',
  DELIVERED = 'delivered',
  READ = 'read',
  FAILED = 'failed',
  CANCELLED = 'cancelled'
}

export interface Notification extends BaseEntity {
  readonly type: NotificationType;
  readonly title: string;
  readonly message: string;
  readonly userId?: UUID | string;
  readonly organizationId?: UUID | string;
  readonly channel: NotificationChannel;
  readonly status: NotificationStatus;
  readonly scheduledAt?: Date;
  readonly sentAt?: Date;
  readonly metadata?: Record<string, unknown>;
}

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * Jobs (defined here; no external file needed)
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
export enum JobStatus {
  PENDING = 'pending',
  RUNNING = 'running',
  COMPLETED = 'completed',
  FAILED = 'failed',
  CANCELLED = 'cancelled',
  TIMEOUT = 'timeout'
}

export enum JobPriority {
  LOW = 'low',
  NORMAL = 'normal',
  HIGH = 'high',
  CRITICAL = 'critical'
}

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * Events
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
export enum EventType {
  USER_LOGIN = 'user_login',
  USER_LOGOUT = 'user_logout',
  DATA_ACCESS = 'data_access',
  DISCOVERY_START = 'discovery_start',
  DISCOVERY_COMPLETE = 'discovery_complete',
  ANALYSIS_START = 'analysis_start',
  ANALYSIS_COMPLETE = 'analysis_complete',
  COMPLIANCE_CHECK = 'compliance_check',
  QUALITY_CHECK = 'quality_check',
  SYSTEM_ERROR = 'system_error',
  SECURITY_EVENT = 'security_event'
}

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * JSON types
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
export type JSONValue = string | number | boolean | null | JSONObject | JSONArray;
export type JSONObject = { readonly [key: string]: JSONValue };
export type JSONArray = readonly JSONValue[];

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * Forms (UI helpers)
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
export interface ValidationRule {
  readonly required?: boolean;
  readonly minLength?: number;
  readonly maxLength?: number;
  readonly pattern?: RegExp;
  readonly custom?: (value: unknown) => boolean | string;
}

export interface FormField {
  readonly name: string;
  readonly label: string;
  readonly type: 'text' | 'email' | 'password' | 'number' | 'select' | 'checkbox' | 'textarea';
  readonly placeholder?: string;
  readonly defaultValue?: unknown;
  readonly options?: ReadonlyArray<{ label: string; value: unknown }>;
  readonly validation?: ValidationRule;
  readonly disabled?: boolean;
  readonly required?: boolean;
}

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * Configuration
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
export interface DatabaseConfig {
  readonly host: string;
  readonly port: number;
  readonly database: string;
  readonly username: string;
  readonly password: string;
  readonly ssl: boolean;
  readonly poolMin: number;
  readonly poolMax: number;
  readonly timeout: number;
}

export interface RedisConfig {
  readonly host: string;
  readonly port: number;
  readonly password?: string;
  readonly db: number;
  readonly ttl: number;
}

export interface AIConfig {
  readonly provider: 'openai' | 'azure' | 'anthropic';
  readonly apiKey: string;
  readonly model: string;
  readonly maxTokens: number;
  readonly temperature: number;
  readonly timeout: number;
}

export interface SecurityConfig {
  readonly jwtSecret: string;
  readonly jwtExpiry: string;
  readonly bcryptRounds: number;
  readonly rateLimitWindow: number;
  readonly rateLimitMax: number;
  readonly corsOrigins: readonly string[];
}

export interface MonitoringConfig {
  readonly enabled: boolean;
  readonly metricsPort: number;
  readonly healthCheckInterval: number;
  readonly logLevel: LogLevel;
  readonly logRetention: number;
}

export interface ServiceConfig {
  readonly name: string;
  readonly version: string;
  readonly environment: string;
  readonly port: number;
  readonly database: DatabaseConfig;
  readonly redis: RedisConfig;
  readonly ai: AIConfig;
  readonly security: SecurityConfig;
  readonly monitoring: MonitoringConfig;
}

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * Friendly named export aliases
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
export type {
  AIConfig as TAIConfig,
  DatabaseConfig as TDatabaseConfig,
  FormField as TFormField,
  ISODateTime as TISODateTime,
  JSONArray as TJSONArray,
  JSONObject as TJSONObject,
  JSONValue as TJSONValue,
  MonitoringConfig as TMonitoringConfig,
  PaginatedResponse as TPaginatedResponse,
  RedisConfig as TRedisConfig,
  SecurityConfig as TSecurityConfig,
  ServiceConfig as TServiceConfig,
  UUID as TUUID
};

// Re-export ApiResponse type from utils (type-only to avoid runtime deps)
  export type { ApiResponse } from '../utils/responses';




------------------------------------------------------------
FILE: backend\ai-service\src\jobs\analysisJob.ts
------------------------------------------------------------
// src/jobs/analysisJob.ts
import { db } from '@/config/database';
import { redis } from '@/config/redis';
import { JobPriority, JobStatus } from '@/interfaces';
import { AnalysisService } from '@/services/AnalysisService';
import { APIError } from '@/utils/errors';
import { logger } from '@/utils/logger';

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * Types
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */

type AnalysisKind = 'schema' | 'data_quality' | 'compliance' | 'performance';

export interface AnalysisJobData {
  analysisId: string;
  userId: string;
  dataSourceId: string;
  analysisType: AnalysisKind;
  options?: SchemaOptions | QualityOptions | ComplianceOptions | PerformanceOptions;
  priority: JobPriority;
  retryCount?: number;
  maxRetries?: number;
}

export interface AnalysisJobResult {
  analysisId: string;
  status: JobStatus;
  result?: SchemaResult | QualityResult | ComplianceResult | PerformanceResult;
  error?: string;
  duration: number;
  completedAt: Date;
}

/** Per-type options */
export interface SchemaOptions {
  schemas?: string[];
  includeSystem?: boolean;
}
export interface QualityOptions {
  sampleSize?: number; // rows per column/table
}
export interface ComplianceOptions {
  frameworks?: Array<'GDPR' | 'HIPAA' | 'PCI-DSS' | 'SOX' | 'CCPA' | 'ISO27001' | 'NIST' | 'SOC2'>;
}
export interface PerformanceOptions {
  timeWindowMinutes?: number;
}

/** Public result contracts (mutable arrays) */
export interface SchemaResult {
  name: string;
  tables: Array<{
    schema: string;
    name: string;
    columns: Array<{ name: string; type: string; nullable: boolean }>;
  }>;
}
export interface QualityResult {
  issues: Array<{ columnName: string; type: 'format' | 'range' | 'nulls'; count: number }>;
  scores: Record<string, number>;
}
export interface ComplianceResult {
  passed: boolean;
  violations: Array<{ id: string; framework: string; description: string }>;
}
export interface PerformanceResult {
  windowMinutes: number;
  queryPerformance: {
    avgQueryTime: number;
    slowQueries: string[];
    queryPatterns: string[];
    resourceUtilization: {
      cpuUsage: number;
      memoryUsage: number;
      ioWait: number;
      connectionCount: number;
    };
  };
  recommendations: Array<{
    type: string;
    description: string;
    impact: 'Low' | 'Medium' | 'High';
    effort: 'Low' | 'Medium' | 'High';
    implementation?: string;
  }>;
}

/** DataSource rows we actually use */
interface DataSource {
  id: string;
  name: string;
  type?: string;
  config?: unknown;
}

/* Shapes coming back from services (loose, then normalized) */
type SchemaAnalysisResult = {
  name?: unknown;
  tables?: ReadonlyArray<{
    schema?: unknown;
    name?: unknown;
    columns?: ReadonlyArray<{
      name?: unknown;
      type?: unknown;
      nullable?: unknown;
    }>;
  }>;
};

type AnalyzeDataSampleResponse = {
  qualityIssues?: ReadonlyArray<{ columnName?: unknown; type?: unknown; count?: unknown }>;
  analysis?: Record<string, unknown> | ReadonlyArray<Record<string, unknown>>;
};

type QualityCheckResult = {
  results?: ReadonlyArray<{
    ruleId?: unknown;
    ruleName?: unknown;
    status?: unknown;
  }>;
};

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * Config
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */

const DEFAULT_MAX_RETRIES = 3;
const BASE_RETRY_DELAY_MS = 5_000; // 5s
const MAX_RETRY_DELAY_MS = 60_000; // 60s cap
const REDIS_STATUS_TTL_SEC = 300; // 5m

/** Where we check for a cancel flag (optional) */
const CANCEL_KEY = (analysisId: string) => `analysis:cancel:${analysisId}`;
const STATUS_KEY = (analysisId: string) => `analysis:status:${analysisId}`;

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * Utility helpers
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */

function assertNever(x: never): never {
  throw new APIError(`Unsupported analysis type: ${String(x)}`, 400);
}

const backoffWithJitter = (attempt: number) => {
  const exp = Math.min(BASE_RETRY_DELAY_MS * Math.pow(2, attempt - 1), MAX_RETRY_DELAY_MS);
  const jitter = Math.floor(Math.random() * Math.min(1000, Math.floor(exp * 0.1))); // up to 10% jitter, max 1s
  return exp + jitter;
};

/** Keep log payloads small to avoid huge log lines */
const safeLogSize = (value: unknown, max = 4_096) => {
  try {
    const s = JSON.stringify(value);
    return s.length <= max ? s : s.slice(0, max) + `â€¦ (truncated ${s.length - max} chars)`;
  } catch {
    return '[unserializable]';
  }
};

/** Heuristic transient error classifier for retries */
const isTransientError = (err: unknown): boolean => {
  const anyErr = err as { message?: string; code?: string } | undefined;
  const msg = (anyErr?.message ?? '').toLowerCase();
  const code = anyErr?.code ?? '';
  return (
    code === 'ETIMEDOUT' ||
    code === 'ECONNRESET' ||
    code === 'ECONNREFUSED' ||
    msg.includes('timeout') ||
    msg.includes('deadlock') ||
    msg.includes('connection') ||
    msg.includes('too many connections') ||
    msg.includes('rate limit') ||
    msg.includes('temporarily') ||
    msg.includes('try again')
  );
};

/** Build a parameterized UPDATE statement dynamically and safely */
const buildUpdateQuery = (
  table: string,
  whereClause: string,
  whereParams: unknown[],
  data: Record<string, unknown>
) => {
  const keys = Object.keys(data);
  const setFragments = keys.map((k, i) => `${k} = $${i + whereParams.length + 1}`);
  const values = [...whereParams, ...keys.map((k) => data[k])];
  const text = `UPDATE ${table} SET ${setFragments.join(', ')} ${whereClause}`;
  return { text, values };
};

/** Deep clone a readonly schema array to a mutable one */
function cloneTablesToMutable(
  tables: ReadonlyArray<{
    schema?: unknown;
    name?: unknown;
    columns?: ReadonlyArray<{ name?: unknown; type?: unknown; nullable?: unknown }>;
  }>
): SchemaResult['tables'] {
  return tables.map((t) => ({
    schema: typeof t?.schema === 'string' ? t.schema : 'public',
    name: typeof t?.name === 'string' ? t.name : 'unknown',
    columns: Array.isArray(t?.columns)
      ? t.columns.map((c) => ({
          name: typeof c?.name === 'string' ? c.name : 'unknown',
          type: typeof c?.type === 'string' ? c.type : 'text',
          nullable: typeof c?.nullable === 'boolean' ? c.nullable : true
        }))
      : []
  }));
}

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * Job executor
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */

export class AnalysisJob {
  private readonly analysisService: AnalysisService;
  private readonly maxRetries = DEFAULT_MAX_RETRIES;

  constructor() {
    this.analysisService = new AnalysisService();
  }

  public async execute(data: AnalysisJobData): Promise<AnalysisJobResult> {
    const start = Date.now();
    const { analysisId, userId, dataSourceId, analysisType, options } = data;

    try {
      logger.info('Analysis job: start', {
        analysisId,
        userId,
        dataSourceId,
        analysisType,
        priority: data.priority,
        retryCount: data.retryCount ?? 0
      });

      await this.updateJobStatus(analysisId, JobStatus.RUNNING);
      await this.validateJobData(data);

      if (await this.isCancelled(analysisId)) {
        throw new APIError('Job cancelled', 499);
      }

      let result: SchemaResult | QualityResult | ComplianceResult | PerformanceResult;

      switch (analysisType) {
        case 'schema':
          result = await this.executeSchemaAnalysis(
            dataSourceId,
            (options as SchemaOptions | undefined) ?? undefined,
            userId
          );
          break;
        case 'data_quality':
          result = await this.executeQualityAnalysis(
            dataSourceId,
            (options as QualityOptions | undefined) ?? undefined,
            userId
          );
          break;
        case 'compliance':
          result = await this.executeComplianceAnalysis(
            dataSourceId,
            (options as ComplianceOptions | undefined) ?? undefined,
            userId
          );
          break;
        case 'performance':
          result = await this.executePerformanceAnalysis(
            dataSourceId,
            (options as PerformanceOptions | undefined) ?? undefined,
            userId
          );
          break;
        default:
          return assertNever(analysisType as never);
      }

      await this.updateJobStatus(analysisId, JobStatus.COMPLETED, result);
      await this.storeAnalysisResult(analysisId, result);
      await this.sendCompletionNotification(userId, analysisId, analysisType, true);

      const duration = Date.now() - start;
      logger.info('Analysis job: completed', {
        analysisId,
        durationMs: duration,
        resultPreview: safeLogSize(result)
      });

      return { analysisId, status: JobStatus.COMPLETED, result, duration, completedAt: new Date() };
    } catch (err) {
      const anyErr = err as { message?: string } | undefined;
      const duration = Date.now() - start;

      logger.error('Analysis job: failed', {
        analysisId,
        durationMs: duration,
        error: anyErr?.message,
        retryCount: data.retryCount ?? 0
      });

      if (await this.shouldRetryJob(data, err)) {
        return this.scheduleRetry(data);
      }

      await this.updateJobStatus(analysisId, JobStatus.FAILED, undefined, anyErr?.message);
      await this.sendCompletionNotification(userId, analysisId, analysisType, false, anyErr?.message);

      return { analysisId, status: JobStatus.FAILED, error: anyErr?.message ?? 'failed', duration, completedAt: new Date() };
    }
  }

  /* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Per-type handlers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */

  private async executeSchemaAnalysis(
    dataSourceId: string,
    _options: SchemaOptions | undefined,
    userId: string
  ): Promise<SchemaResult> {
    try {
      const dataSource = await this.getDataSource(dataSourceId);
      if (!dataSource) throw new APIError('Data source not found', 404);

      // Baseline candidate
      const schemaCandidate = {
        name: String(dataSource.name ?? 'unknown'),
        tables: [
          {
            schema: 'public',
            name: 'users',
            columns: [
              { name: 'id', type: 'integer', nullable: false },
              { name: 'email', type: 'varchar', nullable: false },
              { name: 'first_name', type: 'varchar', nullable: true },
              { name: 'last_name', type: 'varchar', nullable: true },
              { name: 'created_at', type: 'timestamp', nullable: false }
            ]
          }
        ] as const
      } as const;

      // Call service; cast via unknown first (TS suggestion) then narrow with our loose type
      const analyzed = (await this.analysisService.analyzeSchema(
        { name: schemaCandidate.name, tables: schemaCandidate.tables },
        userId
      )) as unknown as SchemaAnalysisResult;

      const name =
        typeof analyzed?.name === 'string' ? analyzed.name : schemaCandidate.name;

      let tables: SchemaResult['tables'];
      if (Array.isArray(analyzed?.tables)) {
        tables = cloneTablesToMutable(analyzed.tables);
      } else {
        // clone readonly candidate â†’ mutable
        tables = cloneTablesToMutable(schemaCandidate.tables);
      }

      return { name, tables };
    } catch (err) {
      logger.error('Schema analysis failed', {
        dataSourceId,
        error: (err as { message?: string } | undefined)?.message
      });
      throw err;
    }
  }

  private async executeQualityAnalysis(
    _dataSourceId: string,
    options: QualityOptions | undefined,
    userId: string
  ): Promise<QualityResult> {
    try {
      const sampleSize = Math.max(1, Math.min(options?.sampleSize ?? 100, 10_000));

      const dataSamples = [
        { columnName: 'email', values: ['user1@example.com', 'user2@example.com', 'invalid-email', null] },
        { columnName: 'age', values: [25, 30, -5, 150, null, 28] }
      ].map((c) => ({ ...c, values: c.values.slice(0, sampleSize) }));

      const serviceRes = (await this.analysisService.analyzeDataSample(
        dataSamples,
        userId
      )) as unknown as AnalyzeDataSampleResponse;

      const issues: QualityResult['issues'] = Array.isArray(serviceRes?.qualityIssues)
        ? serviceRes.qualityIssues.map((q) => ({
            columnName: typeof q?.columnName === 'string' ? q.columnName : 'unknown',
            type:
              q?.type === 'format' || q?.type === 'range' || q?.type === 'nulls'
                ? q.type
                : ('format' as const),
            count: Number.isFinite(q?.count as number) ? Number(q!.count) : 0
          }))
        : [];

      const scores: Record<string, number> = {};
      const a = serviceRes?.analysis;

      if (a && !Array.isArray(a)) {
        for (const [k, v] of Object.entries(a)) {
          scores[k] = typeof v === 'number' && Number.isFinite(v) ? v : 0;
        }
      } else if (Array.isArray(a)) {
        a.forEach((row, idx) => {
          for (const [k, v] of Object.entries(row)) {
            const key = `${k}#${idx}`;
            scores[key] = typeof v === 'number' && Number.isFinite(v) ? v : 0;
          }
        });
      }

      return { issues, scores };
    } catch (err) {
      logger.error('Quality analysis failed', { error: (err as { message?: string } | undefined)?.message });
      throw err;
    }
  }

  private async executeComplianceAnalysis(
    dataSourceId: string,
    options: ComplianceOptions | undefined,
    userId: string
  ): Promise<ComplianceResult> {
    try {
      const frameworks = (options?.frameworks?.length ? options.frameworks : ['GDPR', 'HIPAA']) as readonly string[];

      const rules = [
        { id: 'gdpr_1', name: 'PII Data Encryption', framework: 'GDPR' },
        { id: 'hipaa_1', name: 'PHI Access Controls', framework: 'HIPAA' }
      ].filter((r) => frameworks.includes(r.framework));

      const serviceRes = (await this.analysisService.performQualityCheck(
        dataSourceId,
        rules,
        userId
      )) as unknown as QualityCheckResult;

      const violations: ComplianceResult['violations'] = Array.isArray(serviceRes?.results)
        ? serviceRes.results
            .filter((r) => r?.status === 'failed')
            .map((r) => ({
              id: typeof r?.ruleId === 'string' ? r.ruleId : 'unknown',
              framework: String(rules.find((x) => x.id === r?.ruleId)?.framework ?? 'Unknown'),
              description: typeof r?.ruleName === 'string' ? r.ruleName : 'Violation detected'
            }))
        : [];

      const passed = violations.length === 0;
      return { passed, violations };
    } catch (err) {
      logger.error('Compliance analysis failed', {
        dataSourceId,
        error: (err as { message?: string } | undefined)?.message
      });
      throw err;
    }
  }

  private async executePerformanceAnalysis(
    _dataSourceId: string,
    options: PerformanceOptions | undefined,
    _userId: string
  ): Promise<PerformanceResult> {
    try {
      const windowMins = Math.max(1, Math.min(options?.timeWindowMinutes ?? 15, 1440));

      const result: PerformanceResult = {
        windowMinutes: windowMins,
        queryPerformance: {
          avgQueryTime: 250,
          slowQueries: [],
          queryPatterns: [],
          resourceUtilization: { cpuUsage: 45, memoryUsage: 60, ioWait: 5, connectionCount: 15 }
        },
        recommendations: [
          {
            type: 'Index',
            description: 'Add index on frequently queried columns',
            impact: 'High',
            effort: 'Low',
            implementation: 'CREATE INDEX idx_user_email ON users(email);'
          }
        ]
      };

      return result;
    } catch (err) {
      logger.error('Performance analysis failed', { error: (err as { message?: string } | undefined)?.message });
      throw err;
    }
  }

  /* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Validation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */

  private async validateJobData(d: AnalysisJobData): Promise<void> {
    if (!d.analysisId) throw new APIError('Analysis ID is required', 400);
    if (!d.userId) throw new APIError('User ID is required', 400);
    if (!d.dataSourceId) throw new APIError('Data source ID is required', 400);

    const validTypes: AnalysisKind[] = ['schema', 'data_quality', 'compliance', 'performance'];
    if (!validTypes.includes(d.analysisType)) throw new APIError('Invalid analysis type', 400);

    const ds = await this.getDataSource(d.dataSourceId);
    if (!ds) throw new APIError('Data source not found', 404);
  }

  /* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Persistence â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */

  private async updateJobStatus(
    analysisId: string,
    status: JobStatus,
    result?: unknown,
    error?: string
  ): Promise<void> {
    try {
      const data: Record<string, unknown> = { status, updated_at: new Date() };
      if (result !== undefined) data.results = JSON.stringify(result);
      if (error !== undefined) data.error = error;
      if (status === JobStatus.COMPLETED || status === JobStatus.FAILED) data.completed_at = new Date();

      const { text, values } = buildUpdateQuery('analysis_jobs', 'WHERE analysis_id = $1', [analysisId], data);
      await db.query(text, values);

      await (redis as any).set?.(
        STATUS_KEY(analysisId),
        JSON.stringify({ status, updated_at: Date.now() }),
        { EX: REDIS_STATUS_TTL_SEC }
      );
    } catch (err) {
      logger.error('Job status update failed', {
        analysisId,
        status,
        error: (err as { message?: string } | undefined)?.message
      });
    }
  }

  private async storeAnalysisResult(analysisId: string, result: unknown): Promise<void> {
    try {
      const resultStr = JSON.stringify(result);
      await db.query(
        `UPDATE analysis_jobs 
           SET results = $2, result_size = $3, completed_at = NOW()
         WHERE analysis_id = $1`,
        [analysisId, resultStr, resultStr.length]
      );

      await db.query(
        `INSERT INTO analysis_results (analysis_id, result_data, created_at)
         VALUES ($1, $2, NOW())
         ON CONFLICT (analysis_id) DO UPDATE SET
           result_data = EXCLUDED.result_data,
           updated_at = NOW()`,
        [analysisId, resultStr]
      );
    } catch (err) {
      logger.error('Persisting result failed', {
        analysisId,
        error: (err as { message?: string } | undefined)?.message
      });
      throw err;
    }
  }

  /* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Retry & Cancel â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */

  private async shouldRetryJob(data: AnalysisJobData, err: unknown): Promise<boolean> {
    const retryCount = data.retryCount ?? 0;
    const maxRetries = data.maxRetries ?? this.maxRetries;

    if (err instanceof APIError && err.statusCode >= 400 && err.statusCode < 500) return false;

    const anyErr = err as { statusCode?: number } | undefined;
    if (anyErr?.statusCode === 499 || (await this.isCancelled(data.analysisId))) return false;

    if (retryCount >= maxRetries) return false;

    return isTransientError(err);
  }

  private async scheduleRetry(data: AnalysisJobData): Promise<AnalysisJobResult> {
    const retryCount = (data.retryCount ?? 0) + 1;
    const delay = backoffWithJitter(retryCount);

    logger.info('Analysis job: scheduling retry', {
      analysisId: data.analysisId,
      retryCount,
      delayMs: delay
    });

    const retryData: AnalysisJobData = { ...data, retryCount };

    setTimeout(async () => {
      try {
        if (await this.isCancelled(retryData.analysisId)) {
          await this.updateJobStatus(retryData.analysisId, JobStatus.FAILED, undefined, 'Job cancelled');
          return;
        }
        await this.execute(retryData);
      } catch (err) {
        logger.error('Retry execution failed', {
          analysisId: retryData.analysisId,
          error: (err as { message?: string } | undefined)?.message
        });
      }
    }, delay);

    return {
      analysisId: data.analysisId,
      status: JobStatus.PENDING,
      duration: 0,
      completedAt: new Date()
    };
  }

  private async isCancelled(analysisId: string): Promise<boolean> {
    try {
      const val = await (redis as any).get?.(CANCEL_KEY(analysisId));
      return val === '1' || val === 'true';
    } catch {
      return false;
    }
  }

  /* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Notifications â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */

  private async sendCompletionNotification(
    userId: string,
    analysisId: string,
    analysisType: string,
    success: boolean,
    error?: string
  ): Promise<void> {
    try {
      const metadata = { analysisId, analysisType, success };
      const type = success ? 'analysis_completed' : 'analysis_failed';
      const title = success ? 'Analysis Completed' : 'Analysis Failed';
      const message = success
        ? `Your ${analysisType} analysis has completed successfully.`
        : `Your ${analysisType} analysis failed: ${error ?? 'unknown error'}`;

      await db.query(
        `INSERT INTO notifications (user_id, type, title, message, metadata, created_at)
         VALUES ($1, $2, $3, $4, $5, NOW())`,
        [userId, type, title, message, JSON.stringify(metadata)]
      );
    } catch (err) {
      logger.error('Notification emit failed', {
        userId,
        analysisId,
        error: (err as { message?: string } | undefined)?.message
      });
    }
  }

  /* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Lookups & Cleanup â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */

  private async getDataSource(dataSourceId: string): Promise<DataSource | null> {
    try {
      const result = await db.query(
        'SELECT id, name, type, config FROM data_sources WHERE id = $1',
        [dataSourceId]
      );
      const row = result.rows[0];
      if (!row) return null;

      // exactOptionalPropertyTypes-safe construction
      const dsBase: { id: string; name: string } = {
        id: String(row.id),
        name: String(row.name)
      };
      const ds: DataSource = {
        ...dsBase,
        ...(row.type !== undefined && row.type !== null ? { type: String(row.type) } : {}),
        ...(row.config !== undefined ? { config: row.config } : {})
      };

      return ds;
    } catch (err) {
      logger.error('Data source lookup failed', {
        dataSourceId,
        error: (err as { message?: string } | undefined)?.message
      });
      throw err;
    }
  }

  public async cleanup(analysisId: string): Promise<void> {
    try {
      await (redis as any).del?.(STATUS_KEY(analysisId));
      logger.debug('Job cleanup completed', { analysisId });
    } catch (err) {
      logger.error('Job cleanup failed', {
        analysisId,
        error: (err as { message?: string } | undefined)?.message
      });
    }
  }
}

/* Singleton export */
export const analysisJob = new AnalysisJob();



------------------------------------------------------------
FILE: backend\ai-service\src\jobs\discoveryJob.ts
------------------------------------------------------------
import { db } from '@/config/database';
import { redis } from '@/config/redis';
import { DiscoveryStatus, JobPriority, JobStatus } from '@/interfaces';
import { APIError } from '@/utils/errors';
import { logger } from '@/utils/logger';

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * Types
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */

type DiscoveryKind = 'full' | 'incremental' | 'targeted';

export interface DiscoveryJobData {
  sessionId: string;
  userId: string;
  dataSourceId: string;
  discoveryType: DiscoveryKind;
  options?: DiscoveryOptions;
  priority: JobPriority;
  retryCount?: number;
  maxRetries?: number;
}

export interface DiscoveryJobResult {
  sessionId: string;
  status: JobStatus;
  result?: DiscoveryResults;
  error?: string;
  duration: number;
  completedAt: Date;
}

/** Tighten options you actually use */
export interface DiscoveryOptions {
  includeSampleData?: boolean;
  sampleSize?: number;
  aiAnalysis?: boolean; // default true
  schemas?: string[];
  tables?: string[];
}

/** Minimal result shape; swap with your domain interfaces if you prefer */
export interface DiscoveryResults {
  metadata: any;         // replace with Discovery.DataSourceMetadata if wired
  classification: any;   // replace with Discovery.ClassificationResults
  aiInsights?: any;      // replace with Discovery.AIInsights
  summary: any;          // replace with Discovery.DiscoverySummary
}

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * Config & Keys
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */

const DEFAULT_MAX_RETRIES = 3;
const BASE_RETRY_DELAY_MS = 5_000;
const MAX_RETRY_DELAY_MS = 60_000;
const REDIS_STATUS_TTL_SEC = 300;

const STATUS_KEY = (sessionId: string) => `discovery:status:${sessionId}`;
const CANCEL_KEY = (sessionId: string) => `discovery:cancel:${sessionId}`;

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * Utils
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */

const backoffWithJitter = (attempt: number) => {
  const exp = Math.min(BASE_RETRY_DELAY_MS * Math.pow(2, attempt - 1), MAX_RETRY_DELAY_MS);
  const jitter = Math.floor(Math.random() * Math.min(1000, exp * 0.1));
  return exp + jitter;
};

const safeLogSize = (val: unknown, max = 4096) => {
  try {
    const s = JSON.stringify(val);
    return s.length <= max ? s : s.slice(0, max) + `â€¦ (truncated ${s.length - max} chars)`;
  } catch {
    return '[unserializable]';
  }
};

const isTransientError = (err: unknown): boolean => {
  const msg = (err as any)?.message?.toLowerCase?.() || '';
  const code = (err as any)?.code || '';
  return (
    code === 'ETIMEDOUT' ||
    code === 'ECONNRESET' ||
    code === 'ECONNREFUSED' ||
    msg.includes('timeout') ||
    msg.includes('connection') ||
    msg.includes('deadlock') ||
    msg.includes('too many connections') ||
    msg.includes('rate limit') ||
    msg.includes('temporarily') ||
    msg.includes('try again')
  );
};

/** Parameterized UPDATE builder to avoid index mistakes */
const buildUpdateQuery = (table: string, whereClause: string, whereParams: unknown[], data: Record<string, unknown>) => {
  const keys = Object.keys(data);
  const setFragments = keys.map((k, i) => `${k} = $${i + whereParams.length + 1}`);
  const values = [...whereParams, ...keys.map(k => data[k])];
  const text = `UPDATE ${table} SET ${setFragments.join(', ')} ${whereClause}`;
  return { text, values };
};

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * Job
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */

export class DiscoveryJob {
  private maxRetries = DEFAULT_MAX_RETRIES;

  constructor() {}

  public async execute(data: DiscoveryJobData): Promise<DiscoveryJobResult> {
    const started = Date.now();
    const { sessionId, userId, dataSourceId, discoveryType, options } = data;

    try {
      logger.info('Discovery job: start', {
        sessionId, userId, dataSourceId, discoveryType, priority: data.priority, retryCount: data.retryCount ?? 0,
      });

      await this.updateJobStatus(sessionId, DiscoveryStatus.INITIALIZING, 0);

      await this.validateJobData(data);

      // Respect cancellation early
      if (await this.isCancelled(sessionId)) {
        throw new APIError('Job cancelled', 499);
      }

      const result = await this.executeDiscoveryPhases(data);

      await this.updateJobStatus(sessionId, DiscoveryStatus.COMPLETED, 100, result);

      await this.sendCompletionNotification(userId, sessionId, discoveryType, true);

      const duration = Date.now() - started;
      logger.info('Discovery job: completed', {
        sessionId,
        durationMs: duration,
        resultPreview: safeLogSize({
          summary: result?.summary,
          metadata: { totalTables: result?.metadata?.totalTables, totalColumns: result?.metadata?.totalColumns },
        })
      });

      return {
        sessionId,
        status: JobStatus.COMPLETED,
        result,
        duration,
        completedAt: new Date(),
      };
    } catch (err: any) {
      const duration = Date.now() - started;
      logger.error('Discovery job: failed', {
        sessionId,
        durationMs: duration,
        error: err?.message,
        retryCount: data.retryCount ?? 0,
      });

      if (await this.shouldRetryJob(data, err)) {
        return this.scheduleRetry(data);
      }

      await this.updateJobStatus(sessionId, DiscoveryStatus.FAILED, 0, undefined, err?.message);
      await this.sendCompletionNotification(userId, sessionId, discoveryType, false, err?.message);

      return {
        sessionId,
        status: JobStatus.FAILED,
        error: err?.message ?? 'failed',
        duration,
        completedAt: new Date(),
      };
    }
  }

  /* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Phases â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */

  private async executeDiscoveryPhases(data: DiscoveryJobData): Promise<DiscoveryResults> {
    const { sessionId, dataSourceId, options } = data;
    let progress = 0;

    try {
      // Phase 1: metadata
      await this.updateJobStatus(sessionId, DiscoveryStatus.SCANNING_METADATA, 10);
      const metadata = await this.scanMetadata(dataSourceId, options);
      progress = 20;
      await this.updateJobStatus(sessionId, DiscoveryStatus.SCANNING_METADATA, progress);

      // Phase 2: sampling
      if (options?.includeSampleData) {
        await this.updateJobStatus(sessionId, DiscoveryStatus.SAMPLING_DATA, progress);
        const sampleData = await this.sampleData(dataSourceId, metadata, options);
        (metadata as any).sampleData = sampleData;
        progress = 40;
        await this.updateJobStatus(sessionId, DiscoveryStatus.SAMPLING_DATA, progress);
      }

      // Phase 3: classification
      await this.updateJobStatus(sessionId, DiscoveryStatus.CLASSIFYING, progress);
      const classification = await this.classifyData(metadata, options);
      progress = 60;
      await this.updateJobStatus(sessionId, DiscoveryStatus.CLASSIFYING, progress);

      // Phase 4: AI analysis (default on)
      let aiInsights: unknown | undefined;
      if (options?.aiAnalysis !== false) {
        await this.updateJobStatus(sessionId, DiscoveryStatus.AI_ANALYSIS, progress);
        aiInsights = await this.performAIAnalysis(metadata, classification);
        progress = 80;
        await this.updateJobStatus(sessionId, DiscoveryStatus.AI_ANALYSIS, progress);
      }

      const summary = this.generateSummary(metadata, classification, aiInsights);

      return { metadata, classification, aiInsights, summary };
    } catch (err) {
      logger.error('Discovery phases: error', { sessionId, progress, error: (err as any)?.message });
      throw err;
    }
  }

  /* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Implementations (mocked) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */

  private async scanMetadata(dataSourceId: string, _options?: DiscoveryOptions): Promise<any> {
    void _options;
    const dataSource = await this.getDataSource(dataSourceId);
    if (!dataSource) throw new APIError('Data source not found', 404);

    // Replace this mock with real extractor when ready
    const metadata = {
      dataSourceId,
      connectionInfo: {
        type: (dataSource as any).type,
        host: (dataSource as any).connectionConfig?.host,
        database: (dataSource as any).connectionConfig?.database,
        version: '14.5',
      },
      schemas: [
        {
          name: 'public',
          tables: [
            {
              schema: 'public',
              name: 'users',
              type: 'table',
              columns: [
                { name: 'id', dataType: 'integer', nullable: false, isPrimaryKey: true },
                { name: 'email', dataType: 'varchar', nullable: false },
                { name: 'first_name', dataType: 'varchar', nullable: true },
                { name: 'last_name', dataType: 'varchar', nullable: true },
                { name: 'phone', dataType: 'varchar', nullable: true },
                { name: 'date_of_birth', dataType: 'date', nullable: true },
                { name: 'created_at', dataType: 'timestamp', nullable: false },
              ],
              primaryKeys: ['id'],
              foreignKeys: [],
              indexes: [
                { name: 'users_pkey', columns: ['id'], unique: true },
                { name: 'users_email_idx', columns: ['email'], unique: true },
              ],
              rowCount: 15_000,
              sizeBytes: 2_048_000,
            },
            {
              schema: 'public',
              name: 'orders',
              type: 'table',
              columns: [
                { name: 'id', dataType: 'integer', nullable: false, isPrimaryKey: true },
                { name: 'user_id', dataType: 'integer', nullable: false, isForeignKey: true },
                { name: 'total_amount', dataType: 'decimal', nullable: false },
                { name: 'status', dataType: 'varchar', nullable: false },
                { name: 'created_at', dataType: 'timestamp', nullable: false },
              ],
              primaryKeys: ['id'],
              foreignKeys: [
                { name: 'fk_orders_user', columns: ['user_id'], referencedTable: 'users', referencedColumns: ['id'] },
              ],
              indexes: [
                { name: 'orders_pkey', columns: ['id'], unique: true },
                { name: 'orders_user_id_idx', columns: ['user_id'], unique: false },
              ],
              rowCount: 45_000,
              sizeBytes: 3_072_000,
            },
          ],
          views: [],
          procedures: [],
        },
      ],
      totalTables: 2,
      totalColumns: 12,
      totalRows: 60_000,
      dataSize: 5_120_000,
      lastUpdated: new Date(),
    };

    return metadata;
  }

  private async sampleData(_dataSourceId: string, _metadata: any, options?: DiscoveryOptions): Promise<any> {
    void _metadata;
    const size = Math.max(1, Math.min(options?.sampleSize ?? 100, 10_000));
    void size; // for now
    return {
      'public.users': [
        { id: 1, email: 'john.doe@example.com', first_name: 'John', last_name: 'Doe', phone: '+1-555-0123', date_of_birth: '1990-05-15' },
        { id: 2, email: 'jane.smith@example.com', first_name: 'Jane', last_name: 'Smith', phone: '+1-555-0124', date_of_birth: '1985-12-08' },
        { id: 3, email: 'invalid-email', first_name: 'Bob', last_name: 'Johnson', phone: '555-0125', date_of_birth: '1992-03-22' },
      ],
      'public.orders': [
        { id: 1, user_id: 1, total_amount: 99.99, status: 'completed', created_at: '2024-01-15T10:30:00Z' },
        { id: 2, user_id: 2, total_amount: 149.50, status: 'pending', created_at: '2024-01-16T14:20:00Z' },
        { id: 3, user_id: 1, total_amount: -10.00, status: 'refunded', created_at: '2024-01-17T09:15:00Z' },
      ],
    };
  }

  private async classifyData(metadata: any, _options?: DiscoveryOptions): Promise<any> {
    void _options;
    const fieldClassifications: any[] = [];
    const tableClassifications: any[] = [];

    const piiPatterns = ['email', 'phone', 'ssn', 'social_security', 'first_name', 'last_name', 'full_name'];
    const phiPatterns = ['medical', 'health', 'diagnosis', 'patient', 'dob', 'date_of_birth'];
    const finPatterns = ['credit_card', 'bank_account', 'salary', 'income', 'total_amount', 'price'];

    for (const schema of metadata.schemas) {
      for (const table of schema.tables) {
        let hasPII = false; let hasPHI = false; let hasFIN = false;

        for (const col of table.columns) {
          const name = String(col.name).toLowerCase();
          let classification = 'General';
          let sensitivity = 'Low';
          let confidence = 0.7;
          const patterns: string[] = [];
          const tags: string[] = [];
          const complianceFlags: any[] = [];

          if (piiPatterns.some(p => name.includes(p))) {
            classification = 'PII';
            sensitivity = name.includes('ssn') ? 'High' : 'Medium';
            confidence = 0.9;
            patterns.push('PII identifier pattern');
            tags.push('personal_data');
            complianceFlags.push({ framework: 'GDPR', requirement: 'Data subject rights', severity: 'Warning' });
            hasPII = true;
          } else if (phiPatterns.some(p => name.includes(p))) {
            classification = 'PHI';
            sensitivity = 'High';
            confidence = 0.9;
            patterns.push('PHI identifier pattern');
            tags.push('health_data');
            complianceFlags.push({ framework: 'HIPAA', requirement: 'PHI protection', severity: 'Error' });
            hasPHI = true;
          } else if (finPatterns.some(p => name.includes(p))) {
            classification = 'Financial';
            sensitivity = 'Medium';
            confidence = 0.8;
            patterns.push('Financial data pattern');
            tags.push('financial_data');
            complianceFlags.push({ framework: 'PCI-DSS', requirement: 'Payment data security', severity: 'Warning' });
            hasFIN = true;
          }

          fieldClassifications.push({
            schema: schema.name,
            table: table.name,
            column: col.name,
            dataType: col.dataType,
            classification,
            sensitivity,
            confidence,
            patterns,
            tags,
            complianceFlags,
          });
        }

        let overallClassification = 'General';
        let overallSensitivity = 'Low';
        if (hasPHI) { overallClassification = 'PHI'; overallSensitivity = 'High'; }
        else if (hasPII) { overallClassification = 'PII'; overallSensitivity = 'Medium'; }
        else if (hasFIN) { overallClassification = 'Financial'; overallSensitivity = 'Medium'; }

        tableClassifications.push({
          schema: schema.name,
          table: table.name,
          overallClassification,
          overallSensitivity,
          dataVolume: table.rowCount > 100_000 ? 'Large' : table.rowCount > 10_000 ? 'Medium' : 'Small',
          businessCriticality: 'Medium',
          accessFrequency: 'Regular',
          retentionCategory: 'Standard',
          complianceScope: this.getComplianceScope(overallClassification),
        });
      }
    }

    return {
      fieldClassifications,
      tableClassifications,
      sensitivityMap: this.createSensitivityMap(fieldClassifications),
      complianceMapping: this.createComplianceMapping(fieldClassifications),
      riskAssessment: this.assessRisk(fieldClassifications, tableClassifications),
    };
  }

  private async performAIAnalysis(metadata: any, classification: any): Promise<any> {
    // Stubbed AI; integrate your AIService usage once ready
    const aiInsights = {
      fieldRecommendations: [] as any[],
      schemaInsights: [] as any[],
      qualityPredictions: [] as any[],
      governanceRecommendations: [] as any[],
      anomalies: [] as any[],
    };

    for (const f of classification.fieldClassifications) {
      if (f.sensitivity === 'High' || f.classification !== 'General') {
        aiInsights.fieldRecommendations.push({
          schema: f.schema,
          table: f.table,
          column: f.column,
          recommendation: `Encrypt and restrict access to ${f.classification} field`,
          reasoning: `Contains ${f.classification} with ${f.sensitivity} sensitivity`,
          confidence: 0.9,
          impact: f.sensitivity === 'High' ? 'High' : 'Medium',
          category: 'Security',
        });
      }
    }

    aiInsights.schemaInsights.push({
      type: 'Pattern',
      insight: 'Detected user-order relationship; consider normalization/indexing',
      confidence: 0.8,
      tables: ['users', 'orders'],
      recommendation: 'Add FKs and composite indexes for key joins',
      priority: 'Medium',
    });

    aiInsights.qualityPredictions.push({
      table: 'users',
      column: 'email',
      qualityDimension: 'Validity',
      predictedScore: 85,
      confidence: 0.9,
      factors: ['Invalid format occurrences'],
      recommendations: ['Add email validation', 'Clean existing invalids'],
    });

    aiInsights.governanceRecommendations.push({
      scope: 'Table',
      target: 'users',
      recommendation: 'Adopt data retention for PII',
      category: 'Retention',
      priority: 'High',
      effort: 'Medium',
      benefit: 'Compliance & cost control',
    });

    aiInsights.anomalies.push({
      type: 'Quality',
      table: 'orders',
      column: 'total_amount',
      description: 'Negative amounts detected',
      severity: 'Warning',
      confidence: 0.95,
      suggestion: 'Review refund logic; add validation',
    });

    return aiInsights;
  }

  private generateSummary(metadata: any, classification: any, aiInsights?: any): any {
    const summary = {
      totalTablesAnalyzed: metadata.totalTables,
      totalColumnsAnalyzed: metadata.totalColumns,
      classificationsApplied: classification.fieldClassifications.length,
      sensitiveDataFound: classification.fieldClassifications.filter((f: any) => f.sensitivity !== 'Low').length,
      complianceFlags: classification.fieldClassifications.reduce((sum: number, f: any) => sum + f.complianceFlags.length, 0),
      qualityIssues: 0,
      aiRecommendations: 0,
      executionTime: 0,
      dataVolumeProcessed: metadata.totalRows || 0,
    };

    if (aiInsights) {
      summary.qualityIssues = aiInsights.anomalies.length;
      summary.aiRecommendations = aiInsights.fieldRecommendations.length + aiInsights.governanceRecommendations.length;
    }
    return summary;
  }

  private createSensitivityMap(fieldClassifications: any[]) {
    const bySensitivity: Record<string, any[]> = {
      Low: fieldClassifications.filter(f => f.sensitivity === 'Low'),
      Medium: fieldClassifications.filter(f => f.sensitivity === 'Medium'),
      High: fieldClassifications.filter(f => f.sensitivity === 'High'),
      Critical: fieldClassifications.filter(f => f.sensitivity === 'Critical'),
    };

    const byClassification: Record<string, any[]> = {
      General: fieldClassifications.filter(f => f.classification === 'General'),
      PII: fieldClassifications.filter(f => f.classification === 'PII'),
      PHI: fieldClassifications.filter(f => f.classification === 'PHI'),
      Financial: fieldClassifications.filter(f => f.classification === 'Financial'),
    };

    return {
      bySensitivity,
      byClassification,
      sensitiveTableCount: new Set(
        fieldClassifications.filter(f => f.sensitivity !== 'Low').map(f => `${f.schema}.${f.table}`)
      ).size,
      highRiskFields: fieldClassifications.filter(f => f.sensitivity === 'High' || f.sensitivity === 'Critical'),
    };
  }

  private createComplianceMapping(fieldClassifications: any[]) {
    const frameworkMap: Record<string, { applicableTables: Set<string>; applicableFields: any[]; requirements: Set<string>; riskLevel: 'Low' | 'Medium' | 'High' }> = {};

    fieldClassifications.forEach(field => {
      field.complianceFlags.forEach((flag: any) => {
        if (!frameworkMap[flag.framework]) {
          frameworkMap[flag.framework] = {
            applicableTables: new Set<string>(),
            applicableFields: [],
            requirements: new Set<string>(),
            riskLevel: 'Low',
          };
        }
        const f = frameworkMap[flag.framework];
        f.applicableTables.add(`${field.schema}.${field.table}`);
        f.applicableFields.push(field);
        f.requirements.add(flag.requirement);
        if (flag.severity === 'Error') f.riskLevel = 'High';
        else if (flag.severity === 'Warning' && f.riskLevel === 'Low') f.riskLevel = 'Medium';
      });
    });

    // Convert Sets
    const byFramework: Record<string, any> = {};
    for (const [fw, data] of Object.entries(frameworkMap)) {
      byFramework[fw] = {
        applicableTables: Array.from(data.applicableTables),
        applicableFields: data.applicableFields,
        requirements: Array.from(data.requirements),
        riskLevel: data.riskLevel,
      };
    }

    return {
      byFramework,
      overallComplexity: Object.keys(byFramework).length > 2 ? 'High' : Object.keys(byFramework).length > 1 ? 'Medium' : 'Low',
      requiredActions: this.generateComplianceActions(byFramework),
    };
  }

  private generateComplianceActions(byFramework: Record<string, any>) {
    const actions: any[] = [];
    for (const [framework, data] of Object.entries(byFramework)) {
      if (data.riskLevel === 'High') {
        actions.push({ framework, action: `Immediate ${framework} compliance review`, priority: 'High', timeline: '30 days', effort: 'High' });
      } else if (data.riskLevel === 'Medium') {
        actions.push({ framework, action: `${framework} compliance assessment`, priority: 'Medium', timeline: '90 days', effort: 'Medium' });
      }
    }
    return actions;
  }

  private assessRisk(fieldClassifications: any[], tableClassifications: any[]) {
    const highRiskFields = fieldClassifications.filter(f => f.sensitivity === 'High' || f.sensitivity === 'Critical');
    const sensitiveTableCount = tableClassifications.filter(t => t.overallSensitivity !== 'Low').length;

    let overallRisk: 'Low' | 'Medium' | 'High' = 'Low';
    if (highRiskFields.length > 10 || sensitiveTableCount > 5) overallRisk = 'High';
    else if (highRiskFields.length > 5 || sensitiveTableCount > 2) overallRisk = 'Medium';

    return {
      overallRisk,
      riskFactors: [
        {
          factor: 'High sensitivity data fields',
          level: highRiskFields.length > 10 ? 'High' : highRiskFields.length > 5 ? 'Medium' : 'Low',
          description: `${highRiskFields.length} fields contain highly sensitive data`,
          affectedTables: [...new Set(highRiskFields.map(f => `${f.schema}.${f.table}`))],
          mitigationStrategy: 'Implement encryption and access controls',
        },
      ],
      mitigationPriorities: [
        'Implement data classification policies',
        'Set up access controls for sensitive data',
        'Regular compliance audits',
      ],
      businessImpact: {
        reputational: overallRisk === 'High' ? 'High' : 'Medium',
        financial: overallRisk === 'High' ? 'High' : 'Low',
        operational: 'Medium',
        regulatory: overallRisk === 'High' ? 'Critical' : 'Medium',
      },
    };
  }

  private getComplianceScope(classification: string): string[] {
    switch (classification) {
      case 'PII': return ['GDPR', 'CCPA'];
      case 'PHI': return ['HIPAA'];
      case 'Financial': return ['PCI-DSS', 'SOX'];
      default: return [];
    }
  }

  /* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Validation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */

  private async validateJobData(d: DiscoveryJobData): Promise<void> {
    if (!d.sessionId) throw new APIError('Session ID is required', 400);
    if (!d.userId) throw new APIError('User ID is required', 400);
    if (!d.dataSourceId) throw new APIError('Data source ID is required', 400);

    const valid: DiscoveryKind[] = ['full', 'incremental', 'targeted'];
    if (!valid.includes(d.discoveryType)) throw new APIError('Invalid discovery type', 400);

    // basic existence
    const ds = await this.getDataSource(d.dataSourceId);
    if (!ds) throw new APIError('Data source not found', 404);

    // Targeted must include at least one target
    if (d.discoveryType === 'targeted') {
      const hasTargets = Boolean(d.options?.schemas?.length || d.options?.tables?.length);
      if (!hasTargets) throw new APIError('Targeted discovery requires schemas or tables', 400);
    }
  }

  /* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Persistence & Status â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */

  private async updateJobStatus(
    sessionId: string,
    status: DiscoveryStatus,
    progress?: number,
    result?: unknown,
    error?: string
  ): Promise<void> {
    try {
      const patch: Record<string, unknown> = {
        status,
        updated_at: new Date(),
      };
      if (progress !== undefined) patch.progress = progress;
      if (result !== undefined) patch.results = JSON.stringify(result);
      if (error !== undefined) patch.error = error;
      if (status === DiscoveryStatus.COMPLETED || status === DiscoveryStatus.FAILED || status === DiscoveryStatus.CANCELLED) {
        patch.completed_at = new Date();
      }

      const { text, values } = buildUpdateQuery('discovery_sessions', 'WHERE session_id = $1', [sessionId], patch);
      await db.query(text, values);

      await (redis as any).set?.(
        STATUS_KEY(sessionId),
        JSON.stringify({ status, progress: progress ?? null, updated_at: Date.now() }),
        { EX: REDIS_STATUS_TTL_SEC }
      );
    } catch (err) {
      logger.error('Discovery status update failed', { sessionId, status, error: (err as any)?.message });
      // non-fatal
    }
  }

  private async getDataSource(dataSourceId: string): Promise<any> {
    try {
      const result = await db.query('SELECT * FROM data_sources WHERE id = $1', [dataSourceId]);
      return result.rows[0] ?? null;
    } catch (err) {
      logger.error('Discovery data source lookup failed', { dataSourceId, error: (err as any)?.message });
      throw err;
    }
  }

  /* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Retry & Cancel â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */

  private async shouldRetryJob(d: DiscoveryJobData, err: unknown): Promise<boolean> {
    const retryCount = d.retryCount ?? 0;
    const maxRetries = d.maxRetries ?? this.maxRetries;

    if (err instanceof APIError && err.statusCode >= 400 && err.statusCode < 500) return false;
    if ((err as any)?.statusCode === 499) return false; // cancelled
    if (await this.isCancelled(d.sessionId)) return false;
    if (retryCount >= maxRetries) return false;

    return isTransientError(err);
  }

  private async scheduleRetry(d: DiscoveryJobData): Promise<DiscoveryJobResult> {
    const retryCount = (d.retryCount ?? 0) + 1;
    const delay = backoffWithJitter(retryCount);

    logger.info('Discovery job: scheduling retry', { sessionId: d.sessionId, retryCount, delayMs: delay });

    const retryData: DiscoveryJobData = { ...d, retryCount };

    setTimeout(async () => {
      try {
        if (await this.isCancelled(retryData.sessionId)) {
          await this.updateJobStatus(retryData.sessionId, DiscoveryStatus.FAILED, 0, undefined, 'Job cancelled');
          return;
        }
        await this.execute(retryData);
      } catch (err) {
        logger.error('Discovery retry execution failed', { sessionId: retryData.sessionId, error: (err as any)?.message });
      }
    }, delay);

    return {
      sessionId: d.sessionId,
      status: JobStatus.PENDING,
      duration: 0,
      completedAt: new Date(),
    };
  }

  private async isCancelled(sessionId: string): Promise<boolean> {
    try {
      const val = await (redis as any).get?.(CANCEL_KEY(sessionId));
      return val === '1' || val === 'true';
    } catch {
      return false;
    }
  }

  /* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Notifications â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */

  private async sendCompletionNotification(
    userId: string,
    sessionId: string,
    discoveryType: string,
    success: boolean,
    error?: string
  ): Promise<void> {
    try {
      const type = success ? 'discovery_completed' : 'discovery_failed';
      const title = success ? 'Discovery Completed' : 'Discovery Failed';
      const message = success
        ? `Your ${discoveryType} discovery completed successfully.`
        : `Your ${discoveryType} discovery failed: ${error ?? 'unknown error'}`;
      const metadata = { sessionId, discoveryType, success };

      await db.query(
        `INSERT INTO notifications (user_id, type, title, message, metadata, created_at)
         VALUES ($1, $2, $3, $4, $5, NOW())`,
        [userId, type, title, message, JSON.stringify(metadata)]
      );
      // push via websocket/event bus as needed
    } catch (err) {
      logger.error('Discovery notification failed', { userId, sessionId, error: (err as any)?.message });
      // swallow
    }
  }

  /* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Lifecycle helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */

  public async cleanup(sessionId: string): Promise<void> {
    try {
      await (redis as any).del?.(STATUS_KEY(sessionId));
      logger.debug('Discovery cleanup completed', { sessionId });
    } catch (err) {
      logger.error('Discovery cleanup failed', { sessionId, error: (err as any)?.message });
    }
  }

  public async cancel(sessionId: string): Promise<void> {
    try {
      // A controller can also set CANCEL_KEY(sessionId) in Redis, if you want
      await this.updateJobStatus(sessionId, DiscoveryStatus.CANCELLED, 0);
      await this.cleanup(sessionId);
      logger.info('Discovery job cancelled', { sessionId });
    } catch (err) {
      logger.error('Discovery cancel failed', { sessionId, error: (err as any)?.message });
      throw err;
    }
  }

  public async getProgress(sessionId: string): Promise<any> {
    try {
      const cached = await (redis as any).get?.(STATUS_KEY(sessionId));
      if (cached) {
        try { return JSON.parse(cached); } catch { /* fall through */ }
      }

      const result = await db.query(
        'SELECT status, progress, updated_at FROM discovery_sessions WHERE session_id = $1',
        [sessionId]
      );
      if (result.rows.length === 0) throw new APIError('Discovery session not found', 404);

      return {
        status: result.rows[0].status,
        progress: result.rows[0].progress,
        updated_at: result.rows[0].updated_at,
      };
    } catch (err) {
      logger.error('Discovery progress fetch failed', { sessionId, error: (err as any)?.message });
      throw err;
    }
  }
}

/** Singleton */
export const discoveryJob = new DiscoveryJob();



------------------------------------------------------------
FILE: backend\ai-service\src\middleware\auth.ts
------------------------------------------------------------
// src/middleware/auth.ts
import { APIError } from '@/utils/errors';
import { logger } from '@/utils/logger';
import { NextFunction, Request, Response } from 'express';
import jwt, { JwtPayload, VerifyOptions } from 'jsonwebtoken';

/** Extend Express Request with an authenticated user */
export interface AuthenticatedRequest extends Request {
  user?: {
    id: string;
    email: string;
    role: string;
    permissions?: string[];
    sub?: string;
    iat?: number;
    exp?: number;
  };
}

/** The JWT claims your system issues/accepts */
interface AppJwtPayload extends JwtPayload {
  id: string;
  email: string;
  role: string;
  permissions?: string[];
}

/* ---------------------------- Helpers & Config ---------------------------- */

const readEnv = () => {
  const {
    JWT_SECRET,
    JWT_ISSUER,
    JWT_AUDIENCE,
    JWT_ALLOWED_ALGS,
    JWT_ALG = 'HS256',
    JWT_CLOCK_TOLERANCE_SEC = '60',
    AUTH_COOKIE = 'auth_token',
  } = process.env;

  if (!JWT_SECRET) {
    // fail closed; this is a deployment/config error
    throw new Error('JWT_SECRET is not configured');
  }

  const allowedAlgs = (JWT_ALLOWED_ALGS?.split(',').map(s => s.trim()).filter(Boolean)) || [JWT_ALG];

  const verifyOptions: VerifyOptions = {
    algorithms: allowedAlgs as jwt.Algorithm[],
    issuer: JWT_ISSUER || undefined,
    audience: JWT_AUDIENCE || undefined,
    clockTolerance: Number.isFinite(+JWT_CLOCK_TOLERANCE_SEC) ? Number(JWT_CLOCK_TOLERANCE_SEC) : 60,
  };

  return { JWT_SECRET, verifyOptions, AUTH_COOKIE };
};

/** Safely extract a token from Authorization header, x-access-token, or a cookie */
const extractToken = (req: Request, cookieName: string): string | null => {
  const hdr = req.headers.authorization || '';
  if (hdr) {
    const [scheme, token] = hdr.split(' ');
    if (scheme?.toLowerCase() === 'bearer' && token) return token.trim();
  }
  const alt = (req.headers['x-access-token'] as string) || '';
  if (alt) return alt.trim();

  // minimal cookie parse (avoid extra deps)
  const cookieHeader = req.headers.cookie || '';
  if (cookieHeader && cookieName) {
    const parts = cookieHeader.split(';').map(c => c.trim());
    for (const p of parts) {
      const [k, v] = p.split('=');
      if (k === cookieName && v) return decodeURIComponent(v);
    }
  }
  return null;
};

/** Central token verification (HMAC secret) */
const verifyToken = (token: string): AppJwtPayload => {
  const { JWT_SECRET, verifyOptions } = readEnv();
  const decoded = jwt.verify(token, JWT_SECRET, verifyOptions);
  if (typeof decoded === 'string') {
    throw new APIError('Invalid token payload', 401);
  }
  const payload = decoded as AppJwtPayload;
  if (!payload.id || !payload.email || !payload.role) {
    throw new APIError('Token missing required claims', 401);
  }
  return payload;
};

/** include optional field only if defined (for exactOptionalPropertyTypes) */
type Defined<T> = Exclude<T, undefined>;
const includeIfDefined = <K extends string, V>(key: K, value: V | undefined) =>
  (value !== undefined ? { [key]: value } as Record<K, Defined<V>> : {});

/** normalize string or string[] input */
const toArray = <T>(v: T | T[]) => (Array.isArray(v) ? v : [v]);

/* -------------------------------- Middlewares ----------------------------- */

/** Strict authentication. Requires a valid token and attaches user to req. */
export const authenticateToken = async (
  req: AuthenticatedRequest,
  _res: Response,
  next: NextFunction
): Promise<void> => {
  try {
    const { AUTH_COOKIE } = readEnv();
    const token = extractToken(req, AUTH_COOKIE);
    if (!token) throw new APIError('Access token required', 401);

    const payload = verifyToken(token);

    // only include optional fields if they exist
    req.user = {
      id: payload.id,
      email: payload.email,
      role: payload.role,
      permissions: payload.permissions ?? [],
      ...includeIfDefined('sub', payload.sub),
      ...includeIfDefined('iat', payload.iat),
      ...includeIfDefined('exp', payload.exp),
    };

    logger.debug('Auth: user authenticated', { userId: payload.id, role: payload.role });
    next();
  } catch (err: any) {
    if (err instanceof APIError) return next(err);
    if (err instanceof jwt.TokenExpiredError) return next(new APIError('Token expired', 401));
    if (err instanceof jwt.NotBeforeError) return next(new APIError('Token not active yet', 401));
    if (err instanceof jwt.JsonWebTokenError) return next(new APIError('Invalid token', 401));
    logger.warn('Auth: unexpected verification error', { message: err?.message });
    next(new APIError('Authentication failed', 401));
  }
};

/** Optional auth. If a valid token is present, attaches user; never blocks. */
export const optionalAuth = async (
  req: AuthenticatedRequest,
  _res: Response,
  next: NextFunction
): Promise<void> => {
  try {
    const { AUTH_COOKIE } = readEnv();
    const token = extractToken(req, AUTH_COOKIE);
    if (!token) return next();

    try {
      const payload = verifyToken(token);
      req.user = {
        id: payload.id,
        email: payload.email,
        role: payload.role,
        permissions: payload.permissions ?? [],
        ...includeIfDefined('sub', payload.sub),
        ...includeIfDefined('iat', payload.iat),
        ...includeIfDefined('exp', payload.exp),
      };
      logger.debug('Auth: optional user attached', { userId: payload.id, role: payload.role });
    } catch (e: any) {
      // Do not block optional routes; just log at debug
      logger.debug('Auth: optional token rejected', { reason: e?.message });
    }
    next();
  } catch {
    next();
  }
};

/** Require one of the given roles. */
export const requireRole = (roles: string[] | string) => {
  const required = new Set(toArray(roles).map(r => r.toLowerCase()));
  return (req: AuthenticatedRequest, _res: Response, next: NextFunction): void => {
    try {
      if (!req.user) throw new APIError('Authentication required', 401);
      const userRole = (req.user.role || '').toLowerCase();
      if (!required.has(userRole)) throw new APIError('Insufficient permissions', 403);
      next();
    } catch (err) {
      next(err);
    }
  };
};

/** Require a specific permission (exact match). */
export const requirePermission = (permission: string) => {
  return (req: AuthenticatedRequest, _res: Response, next: NextFunction): void => {
    try {
      if (!req.user) throw new APIError('Authentication required', 401);
      const perms = new Set(req.user.permissions || []);
      if (!perms.has(permission)) throw new APIError('Insufficient permissions', 403);
      next();
    } catch (err) {
      next(err);
    }
  };
};



------------------------------------------------------------
FILE: backend\ai-service\src\middleware\errorHandler.ts
------------------------------------------------------------
import { APIError } from '@/utils/errors';
import { logger } from '@/utils/logger';
import { NextFunction, Request, Response } from 'express';

// Extended Error interface for database and system errors
interface ExtendedError extends Error {
  code?: string;
  errno?: number;
  sqlState?: string;
  sqlMessage?: string;
  statusCode?: number;
}

export const errorHandler = (
  error: ExtendedError,
  req: Request,
  res: Response,
  next: NextFunction
): void => {
  void next; // keep Express signature, silence TS unused

  // Log the error with full context
  logger.error('Request error:', {
    error: error.message,
    stack: error.stack,
    code: error.code,
    statusCode: error.statusCode,
    url: req.url,
    method: req.method,
    ip: req.ip,
    userAgent: req.get('User-Agent'),
    requestId: (req as any).id,
    body: req.method !== 'GET' ? req.body : undefined,
    query: req.query,
    params: req.params
  });

  // Handle API errors (our custom errors)
  if (error instanceof APIError) {
    res.status(error.statusCode).json({
      success: false,
      error: {
        message: error.message,
        code: error.statusCode,
        type: 'APIError',
        ...(error.details && { details: error.details }),
        ...(process.env.NODE_ENV === 'development' && { stack: error.stack })
      },
      requestId: (req as any).id,
      timestamp: new Date().toISOString()
    });
    return;
  }

  // Handle Joi validation errors
  if (error.name === 'ValidationError') {
    res.status(400).json({
      success: false,
      error: {
        message: 'Validation failed',
        code: 400,
        type: 'ValidationError',
        details: error.message
      },
      requestId: (req as any).id,
      timestamp: new Date().toISOString()
    });
    return;
  }

  // Handle JWT errors
  if (error.name === 'JsonWebTokenError') {
    res.status(401).json({
      success: false,
      error: {
        message: 'Invalid token',
        code: 401,
        type: 'AuthenticationError'
      },
      requestId: (req as any).id,
      timestamp: new Date().toISOString()
    });
    return;
  }

  if (error.name === 'TokenExpiredError') {
    res.status(401).json({
      success: false,
      error: {
        message: 'Token expired',
        code: 401,
        type: 'AuthenticationError'
      },
      requestId: (req as any).id,
      timestamp: new Date().toISOString()
    });
    return;
  }

  // Handle database connection errors
  if (error.message?.includes('connect ECONNREFUSED') || 
      error.code === 'ECONNREFUSED' ||
      error.code === 'ENOTFOUND' ||
      error.code === 'ETIMEDOUT') {
    res.status(503).json({
      success: false,
      error: {
        message: 'Database connection failed',
        code: 503,
        type: 'DatabaseConnectionError'
      },
      requestId: (req as any).id,
      timestamp: new Date().toISOString()
    });
    return;
  }

  // Handle PostgreSQL specific errors
  if (error.code?.startsWith('23')) { // PostgreSQL constraint violations
    let message = 'Database constraint violation';
    let statusCode = 400;

    switch (error.code) {
      case '23505': // unique_violation
        message = 'Duplicate entry - record already exists';
        break;
      case '23503': // foreign_key_violation
        message = 'Referenced record does not exist';
        break;
      case '23502': // not_null_violation
        message = 'Required field cannot be empty';
        break;
      case '23514': // check_violation
        message = 'Data does not meet validation requirements';
        break;
    }

    res.status(statusCode).json({
      success: false,
      error: {
        message,
        code: statusCode,
        type: 'DatabaseConstraintError',
        dbCode: error.code,
        ...(process.env.NODE_ENV === 'development' && { 
          sqlMessage: (error as any).sqlMessage || error.message 
        })
      },
      requestId: (req as any).id,
      timestamp: new Date().toISOString()
    });
    return;
  }

  // Handle Redis connection errors
  if (error.message?.includes('Redis') || error.code === 'ECONNRESET') {
    res.status(503).json({
      success: false,
      error: {
        message: 'Cache service temporarily unavailable',
        code: 503,
        type: 'CacheConnectionError'
      },
      requestId: (req as any).id,
      timestamp: new Date().toISOString()
    });
    return;
  }

  // Handle OpenAI API errors
  if (error.message?.includes('OpenAI') || error.message?.includes('AI service')) {
    res.status(503).json({
      success: false,
      error: {
        message: 'AI service temporarily unavailable',
        code: 503,
        type: 'AIServiceError'
      },
      requestId: (req as any).id,
      timestamp: new Date().toISOString()
    });
    return;
  }

  // Handle rate limiting errors
  if ((error.message?.includes('rate limit') || (error as any).statusCode === 429)) {
    res.status(429).json({
      success: false,
      error: {
        message: 'Too many requests - please try again later',
        code: 429,
        type: 'RateLimitError',
        retryAfter: '15 minutes'
      },
      requestId: (req as any).id,
      timestamp: new Date().toISOString()
    });
    return;
  }

  // Handle file upload errors
  if ((error as any).code === 'LIMIT_FILE_SIZE') {
    res.status(413).json({
      success: false,
      error: {
        message: 'File too large',
        code: 413,
        type: 'FileUploadError'
      },
      requestId: (req as any).id,
      timestamp: new Date().toISOString()
    });
    return;
  }

  if ((error as any).code === 'LIMIT_UNEXPECTED_FILE') {
    res.status(400).json({
      success: false,
      error: {
        message: 'Invalid file upload',
        code: 400,
        type: 'FileUploadError'
      },
      requestId: (req as any).id,
      timestamp: new Date().toISOString()
    });
    return;
  }

  // Handle syntax errors (malformed JSON, etc.)
  if (error instanceof SyntaxError) {
    res.status(400).json({
      success: false,
      error: {
        message: 'Invalid request format',
        code: 400,
        type: 'SyntaxError'
      },
      requestId: (req as any).id,
      timestamp: new Date().toISOString()
    });
    return;
  }

  // Handle timeout errors
  if (error.message?.includes('timeout') || error.code === 'ETIMEDOUT') {
    res.status(408).json({
      success: false,
      error: {
        message: 'Request timeout',
        code: 408,
        type: 'TimeoutError'
      },
      requestId: (req as any).id,
      timestamp: new Date().toISOString()
    });
    return;
  }

  // Handle permission errors
  if (error.code === 'EACCES' || error.code === 'EPERM') {
    res.status(403).json({
      success: false,
      error: {
        message: 'Access denied',
        code: 403,
        type: 'PermissionError'
      },
      requestId: (req as any).id,
      timestamp: new Date().toISOString()
    });
    return;
  }

  // Handle default errors
  const isDevelopment = process.env.NODE_ENV === 'development';
  const statusCode = (error as any).statusCode || 500;

  res.status(statusCode).json({
    success: false,
    error: {
      message: isDevelopment ? error.message : 'Internal server error',
      code: statusCode,
      type: 'InternalServerError',
      ...(isDevelopment && { 
        stack: error.stack,
        originalError: {
          name: error.name,
          message: error.message,
          code: error.code
        }
      })
    },
    requestId: (req as any).id,
    timestamp: new Date().toISOString()
  });
};

export const notFoundHandler = (req: Request, res: Response): void => {
  const error = {
    success: false,
    error: {
      message: `Route ${req.method} ${req.path} not found`,
      code: 404,
      type: 'NotFoundError',
      availableRoutes: [
        'GET /api/health',
        'GET /api/docs',
        'POST /api/discovery',
        'POST /api/analysis/schema'
      ]
    },
    requestId: (req as any).id,
    timestamp: new Date().toISOString()
  };

  logger.warn('Route not found', {
    method: req.method,
    path: req.path,
    ip: req.ip,
    userAgent: req.get('User-Agent')
  });

  res.status(404).json(error);
};

// Async error wrapper utility
export const asyncHandler = (
  fn: (req: Request, res: Response, next: NextFunction) => Promise<any>
) => {
  return (req: Request, res: Response, next: NextFunction): void => {
    Promise.resolve(fn(req, res, next)).catch(next);
  };
};

// Global unhandled error handlers
export const setupGlobalErrorHandlers = (): void => {
  // Handle uncaught exceptions
  process.on('uncaughtException', (error: Error) => {
    logger.error('Uncaught Exception - Server shutting down:', {
      error: error.message,
      stack: error.stack,
      pid: process.pid
    });
    process.exit(1);
  });

  // Handle unhandled promise rejections
  process.on('unhandledRejection', (reason: any, promise: Promise<any>) => {
    logger.error('Unhandled Promise Rejection:', {
      reason: reason?.message || reason,
      stack: reason?.stack,
      promise: promise.toString()
    });
    process.exit(1);
  });

  // Handle SIGTERM (graceful shutdown)
  process.on('SIGTERM', () => {
    logger.info('SIGTERM received - starting graceful shutdown');
    process.exit(0);
  });

  // Handle SIGINT (Ctrl+C)
  process.on('SIGINT', () => {
    logger.info('SIGINT received - starting graceful shutdown');
    process.exit(0);
  });
};

// Error types for better error handling
export enum ErrorTypes {
  API_ERROR = 'APIError',
  VALIDATION_ERROR = 'ValidationError',
  AUTHENTICATION_ERROR = 'AuthenticationError',
  AUTHORIZATION_ERROR = 'AuthorizationError',
  DATABASE_ERROR = 'DatabaseError',
  CACHE_ERROR = 'CacheError',
  AI_SERVICE_ERROR = 'AIServiceError',
  RATE_LIMIT_ERROR = 'RateLimitError',
  FILE_UPLOAD_ERROR = 'FileUploadError',
  TIMEOUT_ERROR = 'TimeoutError',
  NOT_FOUND_ERROR = 'NotFoundError',
  INTERNAL_SERVER_ERROR = 'InternalServerError'
}

// Helper function to create standardized error responses
export const createErrorResponse = (
  message: string,
  code: number,
  type: ErrorTypes,
  details?: any,
  requestId?: string
) => {
  return {
    success: false,
    error: {
      message,
      code,
      type,
      ...(details && { details })
    },
    requestId: requestId || 'unknown',
    timestamp: new Date().toISOString()
  };
};



------------------------------------------------------------
FILE: backend\ai-service\src\middleware\rateLimit.ts
------------------------------------------------------------
// src/middleware/rateLimit.ts
import { redis } from '@/config/redis';
import type { NextFunction, Request, RequestHandler, Response } from 'express';
import rateLimit, {
  type ClientRateLimitInfo,
  type RateLimitRequestHandler,
  type Store as RateLimitStore,
} from 'express-rate-limit';

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * Central config (can move to config/env)
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
const RATE_LIMIT_CONFIG = {
  ai: { windowMs: 15 * 60 * 1000, max: 10, prefix: 'rl:ai:' },         // 10 per 15m
  discovery: { windowMs: 5 * 60 * 1000, max: 3, prefix: 'rl:disc:' },   // 3 per 5m
  api: { windowMs: 15 * 60 * 1000, max: 100, prefix: 'rl:api:' },       // 100 per 15m
};

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * Minimal request shape (avoid importing Express Request types here)
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
type MaybeAuthed = {
  user?: { id?: string | null | undefined; role?: string | null | undefined };
  ip?: string;
  originalUrl?: string;
};

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * Redis-backed store for express-rate-limit v7
 * (Do NOT `implements Store` to avoid cross-package type conflicts)
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
class RateLimitRedisStore {
  private readonly _prefix: string;
  private readonly _windowMs: number;

  constructor(windowMs: number, prefix = 'rl:') {
    this._prefix = prefix;
    this._windowMs = windowMs;
  }

  async increment(key: string): Promise<ClientRateLimitInfo> {
    const redisKey = `${this._prefix}${key}`;
    try {
      const client = redis.getClient();
      const totalHits = await client.incr(redisKey);

      // set expiry on first hit
      if (totalHits === 1) {
        await client.expire(redisKey, Math.ceil(this._windowMs / 1000));
      }

      const ttlSec = await client.ttl(redisKey);
      // resetTime is REQUIRED by ClientRateLimitInfo
      const resetTime =
        ttlSec > 0
          ? new Date(Date.now() + ttlSec * 1000)
          : new Date(Date.now() + this._windowMs);

      return { totalHits, resetTime };
    } catch {
      // If Redis is unavailable, be permissive but still provide a resetTime
      return { totalHits: 1, resetTime: new Date(Date.now() + this._windowMs) };
    }
  }

  async decrement(key: string): Promise<void> {
    try {
      await redis.getClient().decr(`${this._prefix}${key}`);
    } catch {
      // swallow
    }
  }

  async resetKey(key: string): Promise<void> {
    try {
      await redis.getClient().del(`${this._prefix}${key}`);
    } catch {
      // swallow
    }
  }

  // Optional: some versions may call resetAll; implement as no-op
  async resetAll(): Promise<void> {
    // Implement SCAN/DEL by prefix if you need global resets
  }
}

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * Factory (uses `unknown` to avoid type-forks between @types/express trees)
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
export function createRateLimiter(options: {
  windowMs: number;
  max: number | ((req: unknown) => number);
  message?: string;
  skipSuccessfulRequests?: boolean;
  keyGenerator?: (req: unknown, res: unknown) => string;
  prefix?: string;
}): RateLimitRequestHandler {
  const {
    windowMs,
    max,
    message = 'Too many requests',
    skipSuccessfulRequests = false,
    keyGenerator,
    prefix = 'rl:',
  } = options;

  return rateLimit({
    windowMs,

    // ValueDeterminingMiddleware<number> compatible
    max: (req: unknown) => {
      // functional max support
      if (typeof max === 'function') {
        try {
          return max(req);
        } catch {
          return 100;
        }
      }
      // super_admin bypass (unlimited)
      const r = req as MaybeAuthed;
      if (r?.user?.role === 'super_admin') return Number.MAX_SAFE_INTEGER;
      return max;
    },

    standardHeaders: true,
    legacyHeaders: false,

    // Cast through unknown to satisfy possible distinct type trees
    store: new RateLimitRedisStore(windowMs, prefix) as unknown as RateLimitStore,

    keyGenerator: (req: unknown, res: unknown): string => {
      if (keyGenerator) {
        const k = keyGenerator(req, res);
        // Must always return a string
        return (k ?? '').toString() || (req as MaybeAuthed).ip || 'unknown';
      }
      const r = req as MaybeAuthed;
      const id = (r?.user?.id ?? '').toString().trim();
      return id || r?.ip || 'unknown';
    },

    skipSuccessfulRequests,

    handler: (req: unknown, res: unknown): void => {
      const _res = res as {
        setHeader: (k: string, v: string) => void;
        status: (c: number) => { json?: (b: unknown) => void };
      };
      const _req = req as MaybeAuthed;

      _res.setHeader('Retry-After', Math.ceil(windowMs / 1000).toString());
      _res
        .status(429)
        .json?.({
          success: false,
          error: { code: 'RATE_LIMIT_EXCEEDED', message },
          meta: { timestamp: new Date().toISOString(), path: _req?.originalUrl || '' },
        });
    },
  });
}

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * Preconfigured limiters (raw RateLimitRequestHandler)
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
export const aiRateLimit: RateLimitRequestHandler = createRateLimiter({
  ...RATE_LIMIT_CONFIG.ai,
  message: 'AI request limit exceeded',
  prefix: RATE_LIMIT_CONFIG.ai.prefix,
  // Admins can do more AI calls
  max: (req) => ((req as MaybeAuthed).user?.role === 'admin' ? 50 : RATE_LIMIT_CONFIG.ai.max),
  keyGenerator: (req) => {
    const r = req as MaybeAuthed;
    const id = (r?.user?.id ?? '').toString().trim();
    return id || r?.ip || 'unknown';
  },
});

export const discoveryRateLimit: RateLimitRequestHandler = createRateLimiter({
  ...RATE_LIMIT_CONFIG.discovery,
  message: 'Discovery request limit exceeded',
  prefix: RATE_LIMIT_CONFIG.discovery.prefix,
  keyGenerator: (req) => {
    const r = req as MaybeAuthed;
    const id = (r?.user?.id ?? '').toString().trim();
    return id || r?.ip || 'unknown';
  },
});

export const apiRateLimit: RateLimitRequestHandler = createRateLimiter({
  ...RATE_LIMIT_CONFIG.api,
  message: 'API request limit exceeded',
  prefix: RATE_LIMIT_CONFIG.api.prefix,
  skipSuccessfulRequests: true,
  keyGenerator: (req) => {
    const r = req as MaybeAuthed;
    const id = (r?.user?.id ?? '').toString().trim();
    return id || r?.ip || 'unknown';
  },
});

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * Wrappers to plain Express RequestHandler (fix type tree mismatches)
 * Use these in your routers: aiRateLimitMw/discoveryRateLimitMw/apiRateLimitMw
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
const asMiddleware = (rl: RateLimitRequestHandler): RequestHandler =>
  (req: Request, res: Response, next: NextFunction) =>
    (rl as unknown as (req: Request, res: Response, next: NextFunction) => void)(req, res, next);

export const aiRateLimitMw: RequestHandler = asMiddleware(aiRateLimit);
export const discoveryRateLimitMw: RequestHandler = asMiddleware(discoveryRateLimit);
export const apiRateLimitMw: RequestHandler = asMiddleware(apiRateLimit);



------------------------------------------------------------
FILE: backend\ai-service\src\middleware\validation.ts
------------------------------------------------------------
import { APIError } from '@/utils/errors';
import { NextFunction, Request, Response } from 'express';
import Joi from 'joi';

const discoveryRequestSchema = Joi.object({
  dataSourceId: Joi.string().uuid().required(),
  schemas: Joi.array().items(Joi.string()).optional(),
  tables: Joi.array().items(Joi.string()).optional(),
  options: Joi.object({
    sampleSize: Joi.number().min(10).max(10000).default(100),
    includeData: Joi.boolean().default(true),
    analysisDepth: Joi.string().valid('basic', 'detailed', 'comprehensive').default('detailed')
  }).optional()
});

const nlQuerySchema = Joi.object({
  query: Joi.string().min(3).max(500).required(),
  context: Joi.object({
    schemas: Joi.array().items(Joi.string()).optional(),
    tables: Joi.array().items(Joi.string()).optional(),
    fields: Joi.array().items(Joi.string()).optional()
  }).optional()
});

const analysisRequestSchema = Joi.object({
  schema: Joi.object({
    name: Joi.string().required(),
    tables: Joi.array().items(Joi.object({
      schema: Joi.string().required(),
      name: Joi.string().required(),
      columns: Joi.array().items(Joi.object({
        name: Joi.string().required(),
        type: Joi.string().required(),
        nullable: Joi.boolean().required(),
        description: Joi.string().optional()
      })).required()
    })).required()
  }).required()
});

export const validateDiscoveryRequest = (req: Request, res: Response, next: NextFunction): void => {
  void res;
  const { error } = discoveryRequestSchema.validate(req.body);
  if (error) {
    next(new APIError(`Validation error: ${error.details[0].message}`, 400));
    return;
  }
  next();
};

export const validateNLQuery = (req: Request, res: Response, next: NextFunction): void => {
  void res;
  const { error } = nlQuerySchema.validate(req.body);
  if (error) {
    next(new APIError(`Validation error: ${error.details[0].message}`, 400));
    return;
  }
  next();
};

export const validateAnalysisRequest = (req: Request, res: Response, next: NextFunction): void => {
  void res;
  const { error } = analysisRequestSchema.validate(req.body);
  if (error) {
    next(new APIError(`Validation error: ${error.details[0].message}`, 400));
    return;
  }
  next();
};



------------------------------------------------------------
FILE: backend\ai-service\src\models\Analysis.ts
------------------------------------------------------------
# Empty file


------------------------------------------------------------
FILE: backend\ai-service\src\models\DataField.ts
------------------------------------------------------------
# Empty file


------------------------------------------------------------
FILE: backend\ai-service\src\models\Discovery.ts
------------------------------------------------------------
// src/models/Discovery.ts
import { db } from '@/config/database';
import { logger } from '@/utils/logger';

/** Domain model */
export interface DiscoverySession {
  sessionId: string;
  userId: string;
  dataSourceId: string;
  status: 'pending' | 'processing' | 'completed' | 'failed';
  progress: number;
  results?: unknown; // if present, must not be undefined (exactOptionalPropertyTypes)
  error?: string;    // if present, must not be undefined
  createdAt: Date;
  updatedAt: Date;
}

/** Shape returned by Postgres (snake_case) */
interface DbDiscoveryRow {
  session_id: string;
  user_id: string;
  data_source_id: string;
  status: 'pending' | 'processing' | 'completed' | 'failed';
  progress: number;
  results: unknown | null;
  error: string | null;
  created_at: Date;
  updated_at: Date;
}

export class DiscoveryModel {
  static async create(session: Partial<DiscoverySession>): Promise<DiscoverySession> {
    try {
      const result = await db.query(
        `INSERT INTO discovery_sessions 
           (session_id, user_id, data_source_id, status, progress, created_at, updated_at)
         VALUES ($1,        $2,     $3,            $4,    $5,      NOW(),     NOW())
         RETURNING *`,
        [
          session.sessionId,
          session.userId,
          session.dataSourceId,
          session.status,
          session.progress,
        ]
      );

      const row = (result.rows as unknown as DbDiscoveryRow[])[0];
      return this.mapFromDb(row);
    } catch (error) {
      logger.error('Failed to create discovery session:', error);
      throw error;
    }
  }

  static async findById(sessionId: string): Promise<DiscoverySession | null> {
    try {
      const result = await db.query(
        'SELECT * FROM discovery_sessions WHERE session_id = $1',
        [sessionId]
      );

      const rows = result.rows as unknown as DbDiscoveryRow[];
      if (rows.length === 0) return null;
      return this.mapFromDb(rows[0]);
    } catch (error) {
      logger.error('Failed to find discovery session:', error);
      throw error;
    }
  }

  static async findByUserId(
    userId: string,
    limit = 20,
    offset = 0
  ): Promise<DiscoverySession[]> {
    try {
      const result = await db.query(
        `SELECT * FROM discovery_sessions
          WHERE user_id = $1
          ORDER BY created_at DESC
          LIMIT $2 OFFSET $3`,
        [userId, limit, offset]
      );

      const rows = result.rows as unknown as DbDiscoveryRow[];
      return rows.map((row) => this.mapFromDb(row));
    } catch (error) {
      logger.error('Failed to find discovery sessions by user:', error);
      throw error;
    }
  }

  static async update(
    sessionId: string,
    updates: Partial<DiscoverySession>
  ): Promise<DiscoverySession | null> {
    try {
      const setClause: string[] = [];
      const values: unknown[] = [];
      let paramIndex = 1;

      // Build dynamic SET list (convert camelCase -> snake_case)
      for (const [key, value] of Object.entries(updates)) {
        if (key === 'sessionId') continue; // never update PK here
        const dbKey = key.replace(/[A-Z]/g, (ltr) => `_${ltr.toLowerCase()}`);
        setClause.push(`${dbKey} = $${paramIndex}`);
        values.push(value);
        paramIndex++;
      }

      if (setClause.length === 0) return null;

      // always set updated_at
      setClause.push(`updated_at = NOW()`);

      // WHERE param
      values.push(sessionId);

      const result = await db.query(
        `UPDATE discovery_sessions
            SET ${setClause.join(', ')}
          WHERE session_id = $${paramIndex}
          RETURNING *`,
        values
      );

      const rows = result.rows as unknown as DbDiscoveryRow[];
      if (rows.length === 0) return null;
      return this.mapFromDb(rows[0]);
    } catch (error) {
      logger.error('Failed to update discovery session:', error);
      throw error;
    }
  }

  static async delete(sessionId: string, userId: string): Promise<boolean> {
    try {
      const result = await db.query(
        'DELETE FROM discovery_sessions WHERE session_id = $1 AND user_id = $2',
        [sessionId, userId]
      );
      return result.rowCount > 0;
    } catch (error) {
      logger.error('Failed to delete discovery session:', error);
      throw error;
    }
  }

  /** Map DB row -> domain object, respecting exactOptionalPropertyTypes */
  private static mapFromDb(row: DbDiscoveryRow): DiscoverySession {
    const base: DiscoverySession = {
      sessionId: row.session_id,
      userId: row.user_id,
      dataSourceId: row.data_source_id,
      status: row.status,
      progress: row.progress,
      createdAt: row.created_at,
      updatedAt: row.updated_at,
    };

    // Only assign optional fields if they are non-null/defined
    if (row.results !== null && row.results !== undefined) {
      (base as { results: unknown }).results = row.results;
    }
    if (row.error !== null && row.error !== undefined) {
      (base as { error: string }).error = row.error;
    }

    return base;
  }
}



------------------------------------------------------------
FILE: backend\ai-service\src\processors\DataProcessor.ts
------------------------------------------------------------
// src/processors/DataProcessor.ts
import type {
  DataSample,
  IDataProcessor,
  QualityIssue,
} from '@/services/AnalysisService';

export class DataProcessor implements IDataProcessor {
  async analyzeSampleData(
    samples: DataSample[],
  ): Promise<{ analysis: Record<string, unknown>[]; qualityIssues: QualityIssue[] }> {
    const analysis: Record<string, unknown>[] = [];
    const qualityIssues: QualityIssue[] = [];

    for (const s of samples) {
      const values = Array.isArray(s.values) ? s.values : [];
      const nonNull = values.filter((v) => v !== null && v !== undefined);
      const nulls = values.length - nonNull.length;

      const uniqueCount = new Set(nonNull.map((v) => JSON.stringify(v))).size;

      analysis.push({
        column: s.columnName,
        count: values.length,
        nulls,
        nullRate: values.length ? +(nulls / values.length * 100).toFixed(2) : 0,
        uniqueCount,
        sample: nonNull.slice(0, 5),
      });

      if (nulls > 0) {
        qualityIssues.push({
          column: s.columnName,
          type: 'null_values',
          severity: nulls / (values.length || 1) > 0.2 ? 'High' : 'Low',
          count: nulls,
          message: 'Column contains null/undefined values',
          sample: values.slice(0, 5),
        });
      }

      const lower = s.columnName.toLowerCase();

      if (lower.includes('email')) {
        const bad = nonNull.filter(
          (v) => typeof v === 'string' && !/^[^\s@]+@[^\s@]+\.[^\s@]+$/.test(v),
        );
        if (bad.length) {
          qualityIssues.push({
            column: s.columnName,
            type: 'format_inconsistency',
            severity: bad.length / (nonNull.length || 1) > 0.05 ? 'Medium' : 'Low',
            count: bad.length,
            message: 'Invalid email addresses detected',
            sample: bad.slice(0, 5),
          });
        }
      }

      if (lower.includes('phone')) {
        const bad = nonNull.filter(
          (v) => typeof v === 'string' && !/^\+?[0-9().\- ]{7,}$/.test(v),
        );
        if (bad.length) {
          qualityIssues.push({
            column: s.columnName,
            type: 'format_inconsistency',
            severity: bad.length / (nonNull.length || 1) > 0.05 ? 'Medium' : 'Low',
            count: bad.length,
            message: 'Invalid phone numbers detected',
            sample: bad.slice(0, 5),
          });
        }
      }
    }

    return { analysis, qualityIssues };
  }
}

export default DataProcessor;



------------------------------------------------------------
FILE: backend\ai-service\src\processors\FieldProcessor.ts
------------------------------------------------------------
// src/processors/FieldProcessor.ts
export interface FieldInfo {
  name: string;
  type: string;
  nullable: boolean;
  description?: string;
}

export type Classification = 'PII' | 'PHI' | 'Financial' | 'General';
export type Sensitivity = 'Low' | 'Medium' | 'High';

export interface ProcessedField extends FieldInfo {
  classification: Classification;
  sensitivity: Sensitivity;
  patterns: string[];
}

/** Very lightweight field classifier used by SchemaProcessor */
export class FieldProcessor {
  processFields(fields: FieldInfo[]): ProcessedField[] {
    return fields.map((f) => {
      const classification = this.classify(f);
      const sensitivity = this.sensitivityFromClass(classification);
      const patterns = this.detectPatterns(f);

      return { ...f, classification, sensitivity, patterns };
    });
  }

  private classify(f: FieldInfo): Classification {
    const n = f.name.toLowerCase();
    if (/(email|first_?name|last_?name|phone|ssn|address)/.test(n)) return 'PII';
    if (/(health|medical|patient|diagnosis)/.test(n)) return 'PHI';
    if (/(payment|amount|price|card|invoice|billing)/.test(n)) return 'Financial';
    return 'General';
    }

  private sensitivityFromClass(c: Classification): Sensitivity {
    if (c === 'PHI') return 'High';
    if (c === 'PII' || c === 'Financial') return 'Medium';
    return 'Low';
  }

  private detectPatterns(f: FieldInfo): string[] {
    const out: string[] = [];
    const n = f.name.toLowerCase();
    if (n.includes('email')) out.push('email');
    if (n.includes('phone')) out.push('phone');
    if (/(date|timestamp)/.test(f.type.toLowerCase())) out.push('date');
    return out;
  }
}

export default FieldProcessor;



------------------------------------------------------------
FILE: backend\ai-service\src\processors\SchemaProcessor.ts
------------------------------------------------------------
// src/processors/SchemaProcessor.ts
import { logger } from '@utils/logger';
import FieldProcessor, { FieldInfo } from './FieldProcessor';

export interface SchemaInfo {
  name: string;
  tables: TableInfo[];
}

export interface TableInfo {
  schema: string;
  name: string;
  columns: FieldInfo[];
  rowCount?: number;
  relationships?: RelationshipInfo[];
}

export interface RelationshipInfo {
  type: 'foreign_key' | 'one_to_many' | 'many_to_many';
  targetTable: string;
  targetColumn: string;
  sourceColumn: string;
}

export interface ProcessedTable extends TableInfo {
  processedColumns: Array<
    FieldInfo & { classification: string; sensitivity: string; patterns: string[] }
  >;
  governance: {
    classification: string;
    sensitivity: string;
    complianceFrameworks: string[];
    suggestedPolicies: string[];
  };
}

export interface SchemaSummary {
  totalTables: number;
  totalColumns: number;
  sensitiveDataTables: number;
  complianceRequirements: string[];
  recommendations: string[];
}

export interface ProcessedSchema {
  name: string;
  tables: ProcessedTable[];
  summary: SchemaSummary;
}

export class SchemaProcessor {
  private readonly fieldProcessor: FieldProcessor;

  constructor() {
    this.fieldProcessor = new FieldProcessor();
  }

  public async processSchema(schema: SchemaInfo): Promise<ProcessedSchema> {
    try {
      logger.info('Processing schema', { schema: schema.name, tables: schema.tables.length });

      const processedTables = await Promise.all(
        schema.tables.map((table) => this.processTable(table))
      );

      const summary = this.generateSchemaSummary(processedTables);

      return { name: schema.name, tables: processedTables, summary };
    } catch (error) {
      logger.error('Schema processing failed:', error);
      throw error;
    }
  }

  private async processTable(table: TableInfo): Promise<ProcessedTable> {
    try {
      const processedColumns = this.fieldProcessor.processFields(table.columns);
      const governance = this.generateTableGovernance(processedColumns);

      return { ...table, processedColumns, governance };
    } catch (error) {
      logger.error('Table processing failed:', { table: table.name, error });
      throw error;
    }
  }

  private generateTableGovernance(
    processedColumns: ProcessedTable['processedColumns']
  ): ProcessedTable['governance'] {
    const classifications = processedColumns.map((c) => c.classification);
    const sensitivities = processedColumns.map((c) => c.sensitivity);

    const hasPhiData = classifications.includes('PHI');
    const hasPiiData = classifications.includes('PII');
    const hasFinancialData = classifications.includes('Financial');

    let classification = 'General';
    if (hasPhiData) classification = 'PHI';
    else if (hasPiiData) classification = 'PII';
    else if (hasFinancialData) classification = 'Financial';

    let sensitivity = 'Low';
    if (sensitivities.includes('High')) sensitivity = 'High';
    else if (sensitivities.includes('Medium')) sensitivity = 'Medium';

    const complianceFrameworks: string[] = [];
    if (hasPhiData) complianceFrameworks.push('HIPAA');
    if (hasPiiData) complianceFrameworks.push('GDPR', 'CCPA');
    if (hasFinancialData) complianceFrameworks.push('SOX', 'PCI-DSS');

    const suggestedPolicies: string[] = [];
    if (sensitivity === 'High') {
      suggestedPolicies.push('Data encryption required', 'Access approval required', 'Regular access reviews');
    }
    if (hasPiiData || hasPhiData) {
      suggestedPolicies.push('Data retention policy', 'Right to be forgotten procedures');
    }

    return { classification, sensitivity, complianceFrameworks, suggestedPolicies };
  }

  private generateSchemaSummary(tables: ProcessedTable[]): SchemaSummary {
    const totalTables = tables.length;
    const totalColumns = tables.reduce((sum, t) => sum + t.columns.length, 0);
    const sensitiveDataTables = tables.filter(
      (t) => t.governance.sensitivity === 'High' || t.governance.sensitivity === 'Medium'
    ).length;

    const complianceSet = new Set<string>();
    for (const t of tables) {
      for (const f of t.governance.complianceFrameworks) complianceSet.add(f);
    }

    const recommendations: string[] = [
      `${sensitiveDataTables} of ${totalTables} tables contain sensitive data`,
      'Implement role-based access controls',
      'Regular compliance audits recommended',
      'Consider data classification labels',
    ];
    if (complianceSet.has('GDPR')) recommendations.push('GDPR compliance review required');
    if (complianceSet.has('HIPAA')) recommendations.push('HIPAA security controls needed');

    return {
      totalTables,
      totalColumns,
      sensitiveDataTables,
      complianceRequirements: Array.from(complianceSet),
      recommendations,
    };
  }
}

// export both ways so AnalysisService can `new (mod.SchemaProcessor ?? mod.default)()`
export default SchemaProcessor;



------------------------------------------------------------
FILE: backend\ai-service\src\prompts\fieldDiscovery.ts
------------------------------------------------------------
// src/prompts/fieldDiscovery.ts

/* eslint-disable max-lines */
type Sensitivity =
  | 'Low'
  | 'Medium'
  | 'High'
  | 'Critical';

type Classification =
  | 'General'
  | 'PII'
  | 'PHI'
  | 'Financial';

export interface FieldDiscoveryColumn {
  name: string;
  type: string;
  nullable: boolean;
  description?: string | null | undefined;
  /** Optional small set of example values for extra context */
  exampleValues?: readonly unknown[] | null | undefined;
}

export interface FieldDiscoveryResultField {
  name: string;
  type: string;
  classification: Classification;
  sensitivity: Sensitivity;
  description: string;
  suggestedRules: string[];
  dataPatterns: string[];
  businessContext: string;
}

export interface FieldDiscoveryRequest {
  schema: string;
  tableName: string;
  /** Optional business context of the table */
  context?: string | null | undefined;
  /** Table columns */
  columns: readonly FieldDiscoveryColumn[];
  /** Optional sample data (records/rows) */
  sampleData?: readonly Record<string, unknown>[] | null | undefined;
  /** Optional region for compliance nuance */
  region?: 'US' | 'EU' | 'Global';
  /** Optional hint for how deep the analysis should go */
  aiAnalysisDepth?: 'basic' | 'detailed' | 'comprehensive';
}

export const FIELD_DISCOVERY_SYSTEM_PROMPT = `
You are an expert data governance analyst specializing in:
- Field classification and data sensitivity analysis
- Compliance requirements (GDPR, HIPAA, CCPA, SOX, PCI-DSS)
- Data quality and governance best practices
- Business context understanding

GENERAL PRINCIPLES
- Be precise, practical, and implementation-oriented.
- Prefer least-privilege and data minimization.
- Recommend enforceable validation and indexing strategies when useful.

RESPONSE FORMAT (STRICT)
- Respond with STRICT JSON only. Do NOT include markdown, prose, or comments.
- Use these enums exactly:
  classification: "General" | "PII" | "PHI" | "Financial"
  sensitivity: "Low" | "Medium" | "High" | "Critical"
- Confidence is 0..1 (number).
- Recommendations arrays must be concise and actionable.
`.trim();

/**
 * Build a robust user prompt for field discovery.
 * - Strong typing (no implicit any)
 * - Sanitizes and truncates inputs to control token size
 * - Adds light heuristics to give the model helpful hints
 */
export function buildFieldDiscoveryPrompt(
  request: FieldDiscoveryRequest,
  opts?: {
    maxSampleRows?: number;
    maxCharsPerValue?: number;
    maxColumns?: number;
  }
): string {
  const maxSampleRows = Number.isFinite(opts?.maxSampleRows) ? Math.max(0, Number(opts?.maxSampleRows)) : 5;
  const maxCharsPerValue = Number.isFinite(opts?.maxCharsPerValue) ? Math.max(16, Number(opts?.maxCharsPerValue)) : 120;
  const maxColumns = Number.isFinite(opts?.maxColumns) ? Math.max(1, Number(opts?.maxColumns)) : 200;

  const cleanContext = sanitizeText(request.context);
  const cleanRegion = request.region ?? 'Global';
  const depth = request.aiAnalysisDepth ?? 'detailed';

  const columns = (request.columns ?? []).slice(0, maxColumns).map(safeColumn);
  const hints = buildHeuristicHints(columns);

  const sample = pruneSampleData(request.sampleData ?? [], maxSampleRows, maxCharsPerValue);

  const columnsBlock = columns
    .map((col) => {
      const nullable = col.nullable ? 'NULLABLE' : 'NOT NULL';
      const desc = col.description ? ` - ${sanitizeInline(col.description)}` : '';
      const examples = (col.exampleValues && col.exampleValues.length)
        ? ` (examples: ${stringifyInline(col.exampleValues.slice(0, 3), maxCharsPerValue)})`
        : '';
      return `- ${col.name} (${col.type}) ${nullable}${desc}${examples}`;
    })
    .join('\n');

  const sampleBlock = sample.length
    ? `Sample Data (first ${sample.length} rows):
${JSON.stringify(sample, null, 2)}`
    : '';

  const hintsBlock = hints.length
    ? `Heuristic Hints:
${hints.map((h) => `- ${h}`).join('\n')}`
    : '';

  // Final strict instructions to shape output for downstream services
  const strictJsonContract = `
RETURN STRICT JSON ONLY (no markdown, no comments) with this structure:
{
  "fields": [
    {
      "name": "field_name",
      "type": "data_type",
      "classification": "PII|PHI|Financial|General",
      "sensitivity": "High|Medium|Low|Critical",
      "description": "clear business meaning and purpose",
      "suggestedRules": ["specific quality rule 1", "specific quality rule 2"],
      "dataPatterns": ["observed pattern 1", "observed pattern 2"],
      "businessContext": "business context and usage"
    }
  ],
  "recommendations": {
    "governance": ["actionable governance recommendation 1", "recommendation 2"],
    "quality": ["actionable quality recommendation 1", "recommendation 2"],
    "compliance": ["specific compliance requirement 1", "requirement 2"]
  },
  "confidence": 0.0-1.0
}

CONSTRAINTS
- Keep arrays concise (max 5 items each) and prioritize high impact actions.
- Prefer column-specific recommendations over generic advice.
- Match enum values exactly as specified.
- If uncertain about a field, mark classification "General" with lower confidence.
`.trim();

  const userPrompt = `
Analyze the following database table and provide comprehensive field classification.

Context:
- Schema: ${sanitizeInline(request.schema)}
- Table: ${sanitizeInline(request.tableName)}
- Region: ${cleanRegion}
- Depth: ${depth}
${cleanContext ? `- Business Context: ${sanitizeInline(cleanContext)}` : ''}

Columns:
${columnsBlock}

${sampleBlock ? `\n${sampleBlock}\n` : ''}

${hintsBlock ? `\n${hintsBlock}\n` : ''}

${strictJsonContract}

FOCUS AREAS
1) Accurate classification based on names, types, and sample data.
2) Practical quality rules (validation, uniqueness, ranges, referential integrity).
3) Specific compliance requirements (GDPR/HIPAA/PCI-DSS/CCPA/SOX) relevant to the region.
4) Clear business value and usage context for each field.
5) Actionable, high-impact recommendations.
`.trim();

  return userPrompt;
}

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * Helpers
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */

function sanitizeText(input?: string | null | undefined): string | undefined {
  if (!input) return undefined;
  const trimmed = input.trim();
  if (!trimmed) return undefined;
  // very light sanitization to cut obvious prompt-injection vectors
  return trimmed.replace(/[<>]/g, '');
}

function sanitizeInline(input: string): string {
  return sanitizeText(input) ?? '';
}

function safeColumn(col: FieldDiscoveryColumn): FieldDiscoveryColumn {
  return {
    name: String(col.name).trim(),
    type: String(col.type).trim(),
    nullable: Boolean(col.nullable),
    description: col.description ?? undefined,
    exampleValues: col.exampleValues ?? undefined,
  };
}

function stringifyInline(values: readonly unknown[], maxCharsPerValue: number): string {
  return values
    .map((v) => compactValue(v, maxCharsPerValue))
    .join(', ');
}

function compactValue(v: unknown, maxCharsPerValue: number): string {
  try {
    const s = typeof v === 'string' ? v : JSON.stringify(v);
    const trimmed = (s ?? '').toString();
    if (trimmed.length <= maxCharsPerValue) return trimmed;
    return trimmed.slice(0, maxCharsPerValue) + 'â€¦';
  } catch {
    return '[unserializable]';
  }
}

function pruneSampleData(
  rows: readonly Record<string, unknown>[],
  maxRows: number,
  maxCharsPerValue: number
): Record<string, unknown>[] {
  const limited = rows.slice(0, Math.max(0, maxRows));
  return limited.map((row) => {
    const out: Record<string, unknown> = {};
    for (const [k, v] of Object.entries(row)) {
      if (v === null || v === undefined) {
        out[k] = v as null | undefined;
        continue;
      }
      if (typeof v === 'string') {
        out[k] = redactString(v, maxCharsPerValue);
      } else if (typeof v === 'number' || typeof v === 'boolean') {
        out[k] = v;
      } else if (v instanceof Date) {
        out[k] = v.toISOString();
      } else {
        // stringify and truncate complex values
        out[k] = compactValue(v, maxCharsPerValue);
      }
    }
    return out;
  });
}

function redactString(s: string, maxChars: number): string {
  // simple redactions for PII-ish patterns
  const emailRx = /([A-Z0-9._%+-]+)@([A-Z0-9.-]+\.[A-Z]{2,})/gi;
  const phoneRx = /\+?\d{1,3}[-.\s]?\(?\d{2,4}\)?[-.\s]?\d{2,4}[-.\s]?\d{2,6}/g;
  const ssnRx = /\b\d{3}-?\d{2}-?\d{4}\b/g;

  let out = s.replace(emailRx, (_, user, host) => `${user[0]}***@${host}`);
  out = out.replace(phoneRx, (m) => m.slice(0, 3) + '***' + m.slice(-2));
  out = out.replace(ssnRx, '***-**-****');

  if (out.length <= maxChars) return out;
  return out.slice(0, maxChars) + 'â€¦';
}

function buildHeuristicHints(columns: readonly FieldDiscoveryColumn[]): string[] {
  const hints: string[] = [];

  for (const col of columns) {
    const name = col.name.toLowerCase();
    const type = col.type.toLowerCase();

    if (/email/.test(name)) {
      hints.push(`Column "${col.name}" likely contains email addresses â†’ consider "PII" with Medium sensitivity and format validation.`);
    }
    if (/(phone|mobile|cell)/.test(name)) {
      hints.push(`Column "${col.name}" likely contains phone numbers â†’ consider "PII"; recommend E.164 normalization and validation.`);
    }
    if (/(ssn|social[_-]?security)/.test(name)) {
      hints.push(`Column "${col.name}" may be SSN â†’ consider "PII" with High sensitivity; encryption at rest, restricted access.`);
    }
    if (/(dob|date[_-]?of[_-]?birth|birth[_-]?date)/.test(name) || (type.includes('date') && /birth/.test(name))) {
      hints.push(`Column "${col.name}" looks like date of birth â†’ "PII" with Medium/High sensitivity depending on jurisdiction.`);
    }
    if (/(card|cc|credit[_-]?card)/.test(name)) {
      hints.push(`Column "${col.name}" may be card data â†’ classify "Financial" with High sensitivity; tokenize or avoid storing PAN.`);
    }
    if (/(amount|price|salary|income|revenue)/.test(name)) {
      hints.push(`Column "${col.name}" is financial metric â†’ classify "Financial" (usually Medium sensitivity), enforce numeric ranges.`);
    }
    if (/(patient|diagnosis|medical|icd|phi)/.test(name)) {
      hints.push(`Column "${col.name}" suggests PHI â†’ classify "PHI" with High/Critical sensitivity and HIPAA safeguards.`);
    }
    if (/(ip[_-]?address|ipv4|ipv6)/.test(name)) {
      hints.push(`Column "${col.name}" may store IPs â†’ treat as "PII" in some frameworks; consider anonymization/retention policy.`);
    }
    if (/password|secret|token|api[_-]?key/.test(name)) {
      hints.push(`Column "${col.name}" looks like a credential/secret â†’ do not store raw; hash/tokenize and restrict access.`);
    }
  }

  return Array.from(new Set(hints)).slice(0, 12); // cap to keep the prompt lean
}



------------------------------------------------------------
FILE: backend\ai-service\src\prompts\naturalLanguage.ts
------------------------------------------------------------
export const NATURAL_LANGUAGE_SYSTEM_PROMPT = `You are an expert SQL analyst and data translator specializing in:
- Converting natural language to SQL queries
- Database schema understanding
- Query optimization and safety
- Business intelligence and analytics

Convert user queries into safe, efficient SQL statements with detailed explanations.`;

export const buildNaturalLanguagePrompt = (query: any): string => {
  const contextInfo = query.context ? `
Available Database Context:
- Schemas: ${query.context.schemas?.join(', ') || 'None specified'}
- Tables: ${query.context.tables?.join(', ') || 'None specified'}  
- Key Fields: ${query.context.fields?.join(', ') || 'None specified'}
` : '';

  return `Convert this natural language query to SQL:

User Query: "${query.query}"

${contextInfo}

Please provide a comprehensive JSON response:
{
  "sql": "Complete SELECT statement with proper formatting",
  "explanation": "Detailed step-by-step explanation of the query logic",
  "tables": ["table1", "table2"],
  "fields": ["field1", "field2", "field3"],
  "joinTypes": ["INNER", "LEFT", "RIGHT"],
  "aggregations": ["COUNT", "SUM", "AVG"],
  "filters": ["WHERE conditions applied"],
  "orderBy": ["Sorting criteria"],
  "confidence": 0.95,
  "warnings": ["Potential performance issues", "Security considerations"],
  "suggestions": ["Query optimization tips", "Alternative approaches"],
  "estimatedComplexity": "Simple|Medium|Complex",
  "estimatedExecutionTime": "Fast|Medium|Slow"
}

Important considerations:
1. Generate safe, read-only queries (SELECT only)
2. Include proper WHERE clauses to limit results
3. Use appropriate JOINs based on relationships
4. Consider performance implications
5. Flag potential security risks
6. Provide clear explanations for business users
7. Suggest LIMIT clauses for large datasets`;
};


------------------------------------------------------------
FILE: backend\ai-service\src\prompts\qualityRules.ts
------------------------------------------------------------
export const QUALITY_RULES_SYSTEM_PROMPT = `You are a data quality expert specializing in:
- Data validation and quality rules
- Business rule implementation
- Data profiling and anomaly detection
- Quality metrics and monitoring

Generate specific, measurable, and implementable data quality rules.`;

export const buildQualityRulesPrompt = (fieldInfo: any): string => {
  return `Generate specific data quality rules for the following field:

Field Information:
- Name: ${fieldInfo.name}
- Data Type: ${fieldInfo.type}
- Classification: ${fieldInfo.classification}
- Sensitivity: ${fieldInfo.sensitivity}
- Business Context: ${fieldInfo.businessContext}
- Observed Patterns: ${JSON.stringify(fieldInfo.dataPatterns || [])}
- Sample Data: ${JSON.stringify(fieldInfo.sampleData || [])}

Please provide a JSON response with specific, actionable quality rules:
{
  "rules": [
    {
      "name": "Descriptive rule name",
      "type": "validation|format|range|completeness|uniqueness|consistency",
      "description": "Detailed description of what the rule checks",
      "implementation": "Specific implementation details or SQL/logic",
      "severity": "Critical|High|Medium|Low",
      "automated": true|false,
      "frequency": "Real-time|Daily|Weekly|Monthly"
    }
  ]
}

Focus on:
1. Specific, measurable criteria
2. Clear implementation guidance
3. Appropriate severity levels
4. Automation feasibility
5. Business impact consideration`;
};


------------------------------------------------------------
FILE: backend\ai-service\src\routes\analysis.ts
------------------------------------------------------------
import { AnalysisController } from '@/controllers/AnalysisController';
import { authenticateToken } from '@/middleware/auth';
import { validateAnalysisRequest } from '@/middleware/validation';
import { Router } from 'express';

const router = Router();
const analysisController = new AnalysisController();

// All analysis routes require authentication
router.use(authenticateToken);

// Analysis endpoints
router.post('/schema', validateAnalysisRequest, analysisController.analyzeSchema);
router.post('/data-sample', analysisController.analyzeDataSample);
router.post('/quality-check', analysisController.performQualityCheck);

export default router;


------------------------------------------------------------
FILE: backend\ai-service\src\routes\discovery.ts
------------------------------------------------------------
import { DiscoveryController } from '@/controllers/DiscoveryController';
import { authenticateToken } from '@/middleware/auth';
import { aiRateLimitMw, discoveryRateLimitMw } from '@/middleware/rateLimit';
import { validateDiscoveryRequest, validateNLQuery } from '@/middleware/validation';
import { NextFunction, Request, Response, Router } from 'express';

const router = Router();
const controller = new DiscoveryController();

const asyncHandler =
  <T extends (req: Request, res: Response, next: NextFunction) => Promise<any>>(fn: T) =>
  (req: Request, res: Response, next: NextFunction) =>
    Promise.resolve(fn.call(controller, req, res, next)).catch(next);

// In dev weâ€™ll allow requests without a token; see auth middleware below
router.use(authenticateToken);

router.post('/', discoveryRateLimitMw, validateDiscoveryRequest, asyncHandler(controller.startDiscovery));
router.post('/query', aiRateLimitMw, validateNLQuery, asyncHandler(controller.processNaturalLanguageQuery));
router.post('/quality-rules', aiRateLimitMw, asyncHandler(controller.generateQualityRules));
router.post('/explain-violation', aiRateLimitMw, asyncHandler(controller.explainViolation));

router.get('/', asyncHandler(controller.listDiscoverySessions));
router.get('/:sessionId', asyncHandler(controller.getDiscoveryStatus));
router.delete('/:sessionId', asyncHandler(controller.deleteDiscoverySession));

export default router;



------------------------------------------------------------
FILE: backend\ai-service\src\routes\index.ts
------------------------------------------------------------
import { HealthController } from '@/controllers/HealthController';
import { Router } from 'express';
import analysisRoutes from './analysis';
import discoveryRoutes from './discovery';

const router = Router();
const healthController = new HealthController();

// Health check routes
router.get('/health', healthController.checkHealth);
router.get('/health/ready', healthController.checkReadiness);
router.get('/health/live', healthController.checkLiveness);

// Feature routes
router.use('/discovery', discoveryRoutes);
router.use('/analysis', analysisRoutes);

// API documentation endpoint
router.get('/docs', (req, res) => {
  void req;
  res.json({
    service: 'CWIC AI Service',
    version: process.env.APP_VERSION || '1.0.0',
    description: 'AI-powered data discovery and governance service',
    endpoints: {
      discovery: {
        'POST /api/discovery': 'Start field discovery session',
        'GET /api/discovery/:sessionId': 'Get discovery status and results',
        'GET /api/discovery': 'List discovery sessions',
        'DELETE /api/discovery/:sessionId': 'Delete discovery session',
        'POST /api/discovery/query': 'Process natural language query',
        'POST /api/discovery/quality-rules': 'Generate quality rules',
        'POST /api/discovery/explain-violation': 'Explain data quality violation'
      },
      analysis: {
        'POST /api/analysis/schema': 'Analyze database schema',
        'POST /api/analysis/data-sample': 'Analyze data samples',
        'POST /api/analysis/quality-check': 'Perform quality analysis'
      },
      health: {
        'GET /api/health': 'Service health status',
        'GET /api/health/ready': 'Readiness check',
        'GET /api/health/live': 'Liveness check'
      }
    }
  });
});

export default router;



------------------------------------------------------------
FILE: backend\ai-service\src\scripts\cleanup.ts
------------------------------------------------------------
# Empty file


------------------------------------------------------------
FILE: backend\ai-service\src\scripts\migrate.ts
------------------------------------------------------------
# Empty file


------------------------------------------------------------
FILE: backend\ai-service\src\scripts\seed.ts
------------------------------------------------------------
# Empty file


------------------------------------------------------------
FILE: backend\ai-service\src\server.ts
------------------------------------------------------------
// src/server.ts
import { logger } from '@utils/logger';
import App from './app';

const PORT = Number(process.env.PORT ?? 3003);     // << default 3003, not 8003
const HOST = process.env.HOST || '0.0.0.0';

function start() {
  try {
    const expressApp = new App().getApp();

    // Ensure a simple health endpoint exists here (even if App already has one)
    expressApp.get('/health', (_req, res) => {
      res.json({ ok: true, service: 'ai-service', pid: process.pid });
    });

    const server = expressApp.listen(PORT, HOST, () => {
      logger.info(`ðŸš€ AI Service listening on http://${HOST}:${PORT}`);
      logger.info(`ðŸ“ Health: http://${HOST}:${PORT}/health`);
      logger.info(`ðŸ§­ Docs:   http://${HOST}:${PORT}/api/docs`);
      logger.info(`ðŸŒ± NODE_ENV=${process.env.NODE_ENV || 'development'}`);
    });

    server.on('error', (err: any) => {
      logger.error('HTTP server error:', {
        message: err?.message,
        code: err?.code,
        stack: err?.stack,
      });
    });

    const shutdown = (signal: string) => {
      logger.warn(`Received ${signal}. Shutting down...`);
      server.close(() => {
        logger.info('HTTP server closed');
        process.exit(0);
      });
      setTimeout(() => process.exit(1), 5000).unref();
    };

    process.on('SIGINT', () => shutdown('SIGINT'));
    process.on('SIGTERM', () => shutdown('SIGTERM'));

    process.on('uncaughtException', (err) => {
      logger.error('Uncaught exception:', { message: err.message, stack: err.stack });
    });
    process.on('unhandledRejection', (reason: any) => {
      logger.error('Unhandled rejection:', { reason: reason?.message || String(reason), stack: reason?.stack });
    });
  } catch (err: any) {
    logger.error('Fatal startup error:', { message: err.message, stack: err.stack });
  }
}

start();



------------------------------------------------------------
FILE: backend\ai-service\src\services\AIService.ts
------------------------------------------------------------
import { openai } from '@config/openai';
import { logger } from '@utils/logger';
import { CacheService } from './CacheService';

export interface FieldDiscoveryRequest {
  schema: string;
  tableName: string;
  columns: Array<{
    name: string;
    type: string;
    nullable: boolean;
    description?: string;
  }>;
  sampleData?: any[];
  context?: string;
}

export interface FieldDiscoveryResponse {
  fields: Array<{
    name: string;
    type: string;
    classification: 'PII' | 'PHI' | 'Financial' | 'General';
    sensitivity: 'High' | 'Medium' | 'Low';
    description: string;
    suggestedRules: string[];
    dataPatterns: string[];
    businessContext: string;
  }>;
  recommendations: {
    governance: string[];
    quality: string[];
    compliance: string[];
  };
  confidence: number;
  isAiGenerated: boolean; // Track if this came from AI or fallback
}

export interface NaturalLanguageQuery {
  query: string;
  context?: {
    schemas: string[];
    tables: string[];
    fields: string[];
  };
}

export interface QueryResult {
  sql: string;
  explanation: string;
  tables: string[];
  fields: string[];
  confidence: number;
  warnings: string[];
  isAiGenerated: boolean;
}

export class AIService {
  private cacheService: CacheService;

  constructor() {
    this.cacheService = new CacheService();
  }

  public async discoverFields(request: FieldDiscoveryRequest): Promise<FieldDiscoveryResponse> {
    try {
      const cacheKey = `field_discovery:${JSON.stringify(request)}`;
      const cached = await this.cacheService.get(cacheKey);
      
      if (cached) {
        logger.info('Returning cached field discovery result');
        return JSON.parse(cached);
      }

      // Check if OpenAI is available
      if (!openai.isAvailable()) {
        logger.warn('OpenAI not available - using fallback field discovery');
        return this.fallbackFieldDiscovery(request);
      }

      const prompt = this.buildFieldDiscoveryPrompt(request);
      
      const response = await openai.createChatCompletion({
        model: process.env.OPENAI_MODEL || 'gpt-4',
        messages: [
          {
            role: 'system',
            content: `You are an expert data governance analyst specializing in field classification, 
                     data sensitivity analysis, and compliance requirements. Analyze database fields 
                     and provide comprehensive governance recommendations.`
          },
          {
            role: 'user',
            content: prompt
          }
        ],
        max_tokens: parseInt(process.env.OPENAI_MAX_TOKENS || '4000'),
        temperature: parseFloat(process.env.OPENAI_TEMPERATURE || '0.1'),
        response_format: { type: 'json_object' }
      });

      if (!response || !response.choices[0]?.message?.content) {
        logger.warn('No response from OpenAI - using fallback');
        return this.fallbackFieldDiscovery(request);
      }

      const result = JSON.parse(response.choices[0].message.content) as FieldDiscoveryResponse;
      result.isAiGenerated = true;
      
      // Cache the result for 1 hour
      await this.cacheService.set(cacheKey, JSON.stringify(result), 3600);
      
      logger.info('Field discovery completed successfully with AI', {
        schema: request.schema,
        table: request.tableName,
        fieldsAnalyzed: request.columns.length
      });

      return result;

    } catch (error) {
      logger.error('AI field discovery failed, using fallback:', error);
      return this.fallbackFieldDiscovery(request);
    }
  }

  public async processNaturalLanguageQuery(query: NaturalLanguageQuery): Promise<QueryResult> {
    try {
      const cacheKey = `nlq:${JSON.stringify(query)}`;
      const cached = await this.cacheService.get(cacheKey);
      
      if (cached) {
        logger.info('Returning cached natural language query result');
        return JSON.parse(cached);
      }

      // Check if OpenAI is available
      if (!openai.isAvailable()) {
        logger.warn('OpenAI not available - using fallback query processing');
        return this.fallbackNaturalLanguageQuery(query);
      }

      const prompt = this.buildNLQueryPrompt(query);
      
      const response = await openai.createChatCompletion({
        model: process.env.OPENAI_MODEL || 'gpt-4',
        messages: [
          {
            role: 'system',
            content: `You are an expert SQL analyst. Convert natural language queries into 
                     SQL statements with detailed explanations and safety warnings.`
          },
          {
            role: 'user',
            content: prompt
          }
        ],
        max_tokens: parseInt(process.env.OPENAI_MAX_TOKENS || '4000'),
        temperature: parseFloat(process.env.OPENAI_TEMPERATURE || '0.1'),
        response_format: { type: 'json_object' }
      });

      if (!response || !response.choices[0]?.message?.content) {
        logger.warn('No response from OpenAI - using fallback');
        return this.fallbackNaturalLanguageQuery(query);
      }

      const result = JSON.parse(response.choices[0].message.content) as QueryResult;
      result.isAiGenerated = true;
      
      // Cache the result for 30 minutes
      await this.cacheService.set(cacheKey, JSON.stringify(result), 1800);
      
      logger.info('Natural language query processed successfully with AI');
      return result;

    } catch (error) {
      logger.error('AI query processing failed, using fallback:', error);
      return this.fallbackNaturalLanguageQuery(query);
    }
  }

  public async generateQualityRules(fieldInfo: any): Promise<string[]> {
    try {
      if (!openai.isAvailable()) {
        logger.warn('OpenAI not available - using fallback quality rules');
        return this.fallbackQualityRules(fieldInfo);
      }

      const prompt = `Generate data quality rules for the following field:
        Field Name: ${fieldInfo.name}
        Data Type: ${fieldInfo.type}
        Classification: ${fieldInfo.classification}
        Sample Data: ${JSON.stringify(fieldInfo.sampleData || [])}
        
        Return a JSON array of specific, actionable quality rules.`;

      const response = await openai.createChatCompletion({
        model: process.env.OPENAI_MODEL || 'gpt-4',
        messages: [
          {
            role: 'system',
            content: 'You are a data quality expert. Generate specific, measurable quality rules.'
          },
          {
            role: 'user',
            content: prompt
          }
        ],
        max_tokens: 1000,
        temperature: 0.1,
        response_format: { type: 'json_object' }
      });

      if (!response || !response.choices[0]?.message?.content) {
        return this.fallbackQualityRules(fieldInfo);
      }

      const result = JSON.parse(response.choices[0].message.content);
      return result.rules || this.fallbackQualityRules(fieldInfo);

    } catch (error) {
      logger.error('AI quality rule generation failed, using fallback:', error);
      return this.fallbackQualityRules(fieldInfo);
    }
  }

  public async explainViolation(violation: any): Promise<string> {
    try {
      if (!openai.isAvailable()) {
        return this.fallbackViolationExplanation(violation);
      }

      const prompt = `Explain this data quality violation in simple terms:
        Rule: ${violation.rule}
        Field: ${violation.field}
        Value: ${violation.value}
        Error: ${violation.error}
        
        Provide a clear explanation and suggested fix.`;

      const response = await openai.createChatCompletion({
        model: process.env.OPENAI_MODEL || 'gpt-4',
        messages: [
          {
            role: 'system',
            content: 'You are a helpful data analyst explaining quality issues.'
          },
          {
            role: 'user',
            content: prompt
          }
        ],
        max_tokens: 500,
        temperature: 0.3
      });

      if (!response || !response.choices[0]?.message?.content) {
        return this.fallbackViolationExplanation(violation);
      }

      return response.choices[0].message.content;

    } catch (error) {
      logger.error('AI violation explanation failed, using fallback:', error);
      return this.fallbackViolationExplanation(violation);
    }
  }

  // Fallback methods for when AI is not available
  private fallbackFieldDiscovery(request: FieldDiscoveryRequest): FieldDiscoveryResponse {
    const fields = request.columns.map(col => {
      const classification = this.classifyFieldBasic(col.name, col.type);
      const sensitivity = this.determineSensitivityBasic(classification);
      
      return {
        name: col.name,
        type: col.type,
        classification,
        sensitivity,
        description: `${col.type} field containing ${classification.toLowerCase()} data`,
        suggestedRules: this.getBasicQualityRules(col.type, classification),
        dataPatterns: this.detectBasicPatterns(col.name, col.type),
        businessContext: `Data field in ${request.tableName} table`
      };
    });

    return {
      fields,
      recommendations: {
        governance: ['Implement data classification policy', 'Set up access controls'],
        quality: ['Add data validation rules', 'Monitor data quality metrics'],
        compliance: ['Review compliance requirements', 'Implement audit logging']
      },
      confidence: 0.7, // Lower confidence for rule-based classification
      isAiGenerated: false
    };
  }

  private fallbackNaturalLanguageQuery(query: NaturalLanguageQuery): QueryResult {
    // Simple keyword-based SQL generation
    const lowerQuery = query.query.toLowerCase();
    let sql = 'SELECT ';
    
    if (lowerQuery.includes('count') || lowerQuery.includes('how many')) {
      sql += 'COUNT(*) ';
    } else {
      sql += '* ';
    }
    
    sql += 'FROM ';
    
    // Try to detect table names from context or query
    if (query.context?.tables && query.context.tables.length > 0) {
      sql += query.context.tables[0];
    } else if (lowerQuery.includes('user')) {
      sql += 'users';
    } else if (lowerQuery.includes('order')) {
      sql += 'orders';
    } else {
      sql += 'table_name';
    }

    return {
      sql,
      explanation: 'Basic SQL query generated using keyword matching (AI not available)',
      tables: query.context?.tables || ['table_name'],
      fields: query.context?.fields || ['*'],
      confidence: 0.3, // Low confidence for keyword-based generation
      warnings: ['AI service not available - this is a basic keyword-based query'],
      isAiGenerated: false
    };
  }

  private fallbackQualityRules(fieldInfo: any): string[] {
    const rules = [];
    
    if (fieldInfo.type?.includes('varchar') || fieldInfo.type?.includes('text')) {
      rules.push('Validate string length');
      rules.push('Check for null values');
    }
    
    if (fieldInfo.type?.includes('int') || fieldInfo.type?.includes('number')) {
      rules.push('Validate numeric range');
      rules.push('Check for negative values');
    }
    
    if (fieldInfo.name?.toLowerCase().includes('email')) {
      rules.push('Validate email format');
    }
    
    if (fieldInfo.name?.toLowerCase().includes('phone')) {
      rules.push('Validate phone number format');
    }
    
    return rules.length > 0 ? rules : ['Basic data validation required'];
  }

  private fallbackViolationExplanation(violation: any): string {
    return `Data quality issue detected in field "${violation.field}". The rule "${violation.rule}" failed because: ${violation.error}. Please review the data and apply appropriate corrections.`;
  }

  // Helper methods for basic classification
  private classifyFieldBasic(name: string, type: string): 'PII' | 'PHI' | 'Financial' | 'General' {
    const lowerName = name.toLowerCase();
    
    if (lowerName.includes('email') || lowerName.includes('phone') || lowerName.includes('name')) {
      return 'PII';
    }
    if (lowerName.includes('medical') || lowerName.includes('health')) {
      return 'PHI';
    }
    if (lowerName.includes('payment') || lowerName.includes('amount') || lowerName.includes('price')) {
      return 'Financial';
    }
    
    return 'General';
  }

  private determineSensitivityBasic(classification: string): 'High' | 'Medium' | 'Low' {
    switch (classification) {
      case 'PHI': return 'High';
      case 'PII': case 'Financial': return 'Medium';
      default: return 'Low';
    }
  }

  private getBasicQualityRules(type: string, classification: string): string[] {
    const rules = ['Not null validation'];
    
    if (type.includes('varchar')) {
      rules.push('String length validation');
    }
    
    if (classification === 'PII' || classification === 'PHI') {
      rules.push('Data encryption required');
    }
    
    return rules;
  }

  private detectBasicPatterns(name: string, type: string): string[] {
    const patterns = [];
    
    if (name.toLowerCase().includes('email')) {
      patterns.push('Email format');
    }
    if (name.toLowerCase().includes('phone')) {
      patterns.push('Phone number format');
    }
    if (type.includes('date') || type.includes('timestamp')) {
      patterns.push('Date format');
    }
    
    return patterns;
  }

  // Existing helper methods...
  private buildFieldDiscoveryPrompt(request: FieldDiscoveryRequest): string {
    return `Analyze the following database table and provide comprehensive field classification:

Schema: ${request.schema}
Table: ${request.tableName}
Context: ${request.context || 'Not provided'}

Columns:
${request.columns.map(col => 
  `- ${col.name} (${col.type}) ${col.nullable ? 'NULLABLE' : 'NOT NULL'} ${col.description ? '- ' + col.description : ''}`
).join('\n')}

${request.sampleData ? `Sample Data (first 5 rows):
${JSON.stringify(request.sampleData.slice(0, 5), null, 2)}` : ''}

Please provide a JSON response with comprehensive field analysis.`;
  }

  private buildNLQueryPrompt(query: NaturalLanguageQuery): string {
    const contextInfo = query.context ? `
Available Context:
- Schemas: ${query.context.schemas?.join(', ') || 'None'}
- Tables: ${query.context.tables?.join(', ') || 'None'}
- Fields: ${query.context.fields?.join(', ') || 'None'}
` : '';

    return `Convert this natural language query to SQL:
"${query.query}"

${contextInfo}

Please provide a JSON response with SQL and explanation.`;
  }
}


------------------------------------------------------------
FILE: backend\ai-service\src\services\AnalysisService.ts
------------------------------------------------------------
// src/services/AnalysisService.ts
import { APIError } from '@/utils/errors';
import { logger } from '@/utils/logger';

// Import concrete classes but DO NOT rely on their exported types
// (your current module doesn't export DataProcessor/DataSample types)
import * as DataProcessorMod from '@/processors/DataProcessor';
import * as SchemaProcessorMod from '@/processors/SchemaProcessor';
import { AIService } from './AIService';

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * Minimal contracts (kept small to avoid coupling & missing exports)
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */

export type Severity = 'Low' | 'Medium' | 'High' | 'Critical';
export type RuleStatus = 'passed' | 'warning' | 'failed';

export interface DataSample {
  columnName: string;
  values: unknown[];
}

export interface QualityIssue {
  column: string;
  type:
    | 'null_values'
    | 'format_inconsistency'
    | 'out_of_range'
    | 'uniqueness'
    | 'referential'
    | 'custom';
  severity: Severity;
  count: number;
  sample?: unknown[];
  message?: string;
}

export interface IDataProcessor {
  analyzeSampleData(
    samples: DataSample[],
  ): Promise<{ analysis: Record<string, unknown>[]; qualityIssues: QualityIssue[] }>;
}

export interface SchemaInfo {
  name: string;
  // optional extra fields your processor might use
  [k: string]: unknown;
}

export interface ISchemaProcessor {
  processSchema(schema: SchemaInfo): Promise<unknown>;
}

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * Result types
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */

export interface QualityRuleResult {
  ruleId: string;
  ruleName: string;
  status: RuleStatus;
  testedRecords: number;
  passedRecords: number;
  failedRecords: number;
  successRate: number; // 0..100
  aiExplanation?: string;
  recommendations?: string[];
}

export interface AnalysisSummary {
  totalColumns: number;
  qualityIssues: number;
  highSeverityIssues: number;
}

export interface DataSampleAnalysisResult {
  analysis: ReadonlyArray<Record<string, unknown>>;
  qualityIssues: ReadonlyArray<QualityIssue>;
  recommendations: ReadonlyArray<string>;
  summary: AnalysisSummary;
  analysisMetadata: {
    analyzedAt: string;
    analyzedBy: string;
    version: string;
  };
}

export interface SchemaAIInsights {
  overallAssessment: string;
  riskAreas: string[];
  complianceGaps: string[];
  optimizationOpportunities: string[];
}

export interface SchemaAnalysisResult {
  processed: unknown;
  aiInsights: SchemaAIInsights;
  analysisMetadata: {
    analyzedAt: string;
    analyzedBy: string;
    version: string;
  };
}

export interface QualityCheckResult {
  dataSourceId: string;
  results: ReadonlyArray<QualityRuleResult>;
  summary: {
    totalRules: number;
    passed: number;
    failed: number;
    warnings: number;
  };
  analysisMetadata: {
    analyzedAt: string;
    analyzedBy: string;
    version: string;
  };
}

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * Utils
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */

const SERVICE_VERSION = '1.0';

function asApiError(err: unknown, fallback: string, status = 500): APIError {
  if (err instanceof APIError) return err;
  const msg = err instanceof Error ? err.message : fallback;
  return new APIError(msg, status, err);
}

async function withTimeout<T>(p: Promise<T>, ms: number, label: string): Promise<T> {
  let t: NodeJS.Timeout | undefined;
  try {
    const timeout = new Promise<never>((_, rej) =>
      (t = setTimeout(() => rej(new APIError(`${label} timed out after ${ms}ms`, 504)), ms)),
    );
    return await Promise.race([p, timeout]);
  } finally {
    if (t) clearTimeout(t);
  }
}

function isHigh(sev: Severity): boolean {
  return sev === 'High' || sev === 'Critical';
}

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * Service
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */

export class AnalysisService {
  private readonly schemaProcessor: ISchemaProcessor;
  private readonly dataProcessor: IDataProcessor;
  private readonly ai: AIService;
  private readonly aiTimeoutMs: number;

  constructor(deps?: {
    schemaProcessor?: ISchemaProcessor;
    dataProcessor?: IDataProcessor;
    aiService?: AIService;
    aiTimeoutMs?: number;
  }) {
    // Instantiate from modules if not injected
    const DefaultSchemaProcessor =
    ( SchemaProcessorMod as any).SchemaProcessor ?? (SchemaProcessorMod as any).default;
    const DefaultDataProcessor =
    (DataProcessorMod as any).DataProcessor ?? (DataProcessorMod as any).default;


    this.schemaProcessor = deps?.schemaProcessor ?? new DefaultSchemaProcessor();
    this.dataProcessor = deps?.dataProcessor ?? new DefaultDataProcessor();
    this.ai = deps?.aiService ?? new AIService();
    this.aiTimeoutMs = deps?.aiTimeoutMs ?? Number(process.env.AI_TIMEOUT_MS ?? 8000);
  }

  /* â”€â”€â”€â”€â”€â”€â”€â”€â”€ Schema Analysis â”€â”€â”€â”€â”€â”€â”€â”€â”€ */

  public async analyzeSchema(schema: SchemaInfo, userId: string): Promise<SchemaAnalysisResult> {
    try {
      this.assertUser(userId);
      this.assertSchema(schema);

      logger.info('AnalysisService: schema analysis start', { userId, schema: schema.name });
      const processed = await this.schemaProcessor.processSchema(schema);

      const aiInsights = await this.safeSchemaInsights(processed);

      const res: SchemaAnalysisResult = {
        processed,
        aiInsights,
        analysisMetadata: {
          analyzedAt: new Date().toISOString(),
          analyzedBy: userId,
          version: SERVICE_VERSION,
        },
      };

      logger.info('AnalysisService: schema analysis complete', { userId, schema: schema.name });
      return res;
    } catch (err) {
      logger.error('AnalysisService: schema analysis error', { error: err });
      throw asApiError(err, 'Schema analysis failed', 500);
    }
  }

  /* â”€â”€â”€â”€â”€â”€â”€â”€â”€ Data Sample Analysis â”€â”€â”€â”€â”€â”€â”€â”€â”€ */

  public async analyzeDataSample(samples: DataSample[], userId: string): Promise<DataSampleAnalysisResult> {
    try {
      this.assertUser(userId);
      this.assertSamples(samples);

      logger.info('AnalysisService: data sample analysis start', { userId, samples: samples.length });

      const { analysis, qualityIssues } = await this.dataProcessor.analyzeSampleData(samples);

      const recommendations = await this.buildDataRecommendations(analysis, qualityIssues);

      const res: DataSampleAnalysisResult = {
        analysis,
        qualityIssues,
        recommendations,
        summary: {
          totalColumns: samples.length,
          qualityIssues: qualityIssues.length,
          highSeverityIssues: qualityIssues.filter((q) => isHigh(q.severity)).length,
        },
        analysisMetadata: {
          analyzedAt: new Date().toISOString(),
          analyzedBy: userId,
          version: SERVICE_VERSION,
        },
      };

      logger.info('AnalysisService: data sample analysis complete', {
        userId,
        samplesAnalyzed: samples.length,
        issuesFound: qualityIssues.length,
      });
      return res;
    } catch (err) {
      logger.error('AnalysisService: data sample analysis error', { error: err });
      throw asApiError(err, 'Data sample analysis failed', 500);
    }
  }

  /* â”€â”€â”€â”€â”€â”€â”€â”€â”€ Quality Check (mocked engine) â”€â”€â”€â”€â”€â”€â”€â”€â”€ */

  public async performQualityCheck(
    dataSourceId: string,
    rules: ReadonlyArray<Record<string, unknown>> | undefined,
    userId: string,
  ): Promise<QualityCheckResult> {
    try {
      this.assertUser(userId);
      if (!dataSourceId) throw new APIError('dataSourceId is required', 400);

      logger.info('AnalysisService: quality check start', {
        userId,
        dataSourceId,
        rules: rules?.length ?? 0,
      });

      const base = this.mockQualityResults(rules ?? []);
      const enhanced = await this.enhanceRuleResults(base);

      const summary = {
        totalRules: rules?.length ?? 0,
        passed: enhanced.filter((r) => r.status === 'passed').length,
        failed: enhanced.filter((r) => r.status === 'failed').length,
        warnings: enhanced.filter((r) => r.status === 'warning').length,
      };

      const res: QualityCheckResult = {
        dataSourceId,
        results: enhanced,
        summary,
        analysisMetadata: {
          analyzedAt: new Date().toISOString(),
          analyzedBy: userId,
          version: SERVICE_VERSION,
        },
      };

      logger.info('AnalysisService: quality check complete', {
        userId,
        dataSourceId,
        rulesChecked: rules?.length ?? 0,
      });
      return res;
    } catch (err) {
      logger.error('AnalysisService: quality check error', { error: err });
      throw asApiError(err, 'Quality check failed', 500);
    }
  }

  /* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   * Private: AI insights for schema
   * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */

  private async safeSchemaInsights(processed: unknown): Promise<SchemaAIInsights> {
    type TableGov = {
      sensitivity?: Severity | string;
      classification?: 'General' | 'PII' | 'PHI' | 'Financial' | string;
      complianceFrameworks?: string[];
      suggestedPolicies?: string[];
    };
    type MinimalProcessed = { name?: string; tables?: { governance?: TableGov }[] };

    const schema = (processed as MinimalProcessed) ?? {};
    const tables: { governance?: TableGov }[] = Array.isArray(schema.tables) ? [...schema.tables] : [];

    // Safety: ensure mutable arrays (avoid readonly assignment issues)
    const snapshot = tables.slice(0, 100).map((t) => ({
      sensitivity: (t.governance?.sensitivity ?? 'Low').toString(),
      classification: (t.governance?.classification ?? 'General').toString(),
      frameworks: Array.isArray(t.governance?.complianceFrameworks)
        ? [...t.governance!.complianceFrameworks!]
        : ([] as string[]),
      policyCount: Array.isArray(t.governance?.suggestedPolicies) ? t.governance!.suggestedPolicies!.length : 0,
    }));

    // If AI service exposes a summarization helper, call it. Otherwise, fall back.
    const hasSummarize =
      this.ai && (typeof (this.ai as any).safeSummarize === 'function' || typeof (this.ai as any).summarize === 'function');

    let overallAssessment = this.fallbackOverallAssessment(tables);
    if (hasSummarize) {
      try {
        const fn = (this.ai as any).safeSummarize ?? (this.ai as any).summarize;
        const out = await withTimeout(
          Promise.resolve(fn.call(this.ai, { topic: 'schema-assessment', payload: { tableCount: tables.length, snapshot } })),
          this.aiTimeoutMs,
          'AI schema assessment',
        );
        if (typeof out === 'string' && out.trim()) overallAssessment = out.trim();
      } catch {
        // keep fallback
      }
    }

    return {
      overallAssessment,
      riskAreas: this.deriveRiskAreas(tables),
      complianceGaps: this.deriveComplianceGaps(tables),
      optimizationOpportunities: this.deriveOptimizations(tables),
    };
  }

  private fallbackOverallAssessment(
    tables: ReadonlyArray<{ governance?: { sensitivity?: string; classification?: string; complianceFrameworks?: string[] } }>,
  ): string {
    const total = tables.length || 1;
    const sensitive = tables.filter((t) => (t.governance?.sensitivity ?? 'Low') !== 'Low').length;
    const frameworks = new Set<string>();
    for (const t of tables) {
      const list = t.governance?.complianceFrameworks ?? [];
      for (let i = 0; i < list.length; i++) frameworks.add(list[i] as string);
    }
    if (sensitive / total > 0.5) {
      return `High-risk schema: ${sensitive}/${total} tables contain non-low sensitivity data. ${frameworks.size} compliance frameworks detected. Prioritize governance.`;
    }
    if (sensitive > 0) {
      return `Moderate-risk schema: ${sensitive} sensitive tables. Frameworks: ${[...frameworks].join(', ') || 'None'}. Maintain standard governance.`;
    }
    return 'Low-risk schema: mostly general data. Basic governance practices are sufficient.';
  }

  private deriveRiskAreas(tables: ReadonlyArray<{ governance?: { sensitivity?: string; classification?: string } }>): string[] {
    const risks: string[] = [];
    const hi = tables.filter(
      (t) => (t.governance?.sensitivity ?? 'Low') === 'High' || (t.governance?.sensitivity ?? 'Low') === 'Critical',
    ).length;
    if (hi) risks.push(`${hi} table(s) contain highly sensitive data (strict access & encryption).`);

    const pii = tables.filter((t) => t.governance?.classification === 'PII').length;
    if (pii) risks.push(`${pii} table(s) contain PII; ensure privacy controls & minimization.`);

    const phi = tables.filter((t) => t.governance?.classification === 'PHI').length;
    if (phi) risks.push(`${phi} table(s) contain PHI; HIPAA safeguards required.`);

    return risks;
  }

  private deriveComplianceGaps(tables: ReadonlyArray<{ governance?: { complianceFrameworks?: string[] } }>): string[] {
    const frameworks = new Set<string>();
    for (const t of tables) {
      const list = t.governance?.complianceFrameworks ?? [];
      for (let i = 0; i < list.length; i++) frameworks.add(list[i] as string);
    }
    const gaps: string[] = [];
    if (frameworks.has('GDPR')) gaps.push('Validate GDPR data subject rights, retention, and DPIA for high-risk processing.');
    if (frameworks.has('HIPAA')) gaps.push('Perform HIPAA security risk analysis and enforce PHI audit controls.');
    if (frameworks.has('PCI-DSS')) gaps.push('Confirm segmentation & encryption for cardholder data.');
    return gaps;
  }

  private deriveOptimizations(
    tables: ReadonlyArray<{ governance?: { suggestedPolicies?: string[]; classification?: string } }>,
  ): string[] {
    const out: string[] = [];
    let noPolicy = 0;
    let general = 0;
    for (let i = 0; i < tables.length; i++) {
      const g = tables[i]?.governance;
      if (!g) continue;
      if (!Array.isArray(g.suggestedPolicies) || g.suggestedPolicies.length === 0) noPolicy++;
      if (g.classification === 'General') general++;
    }
    if (noPolicy) out.push(`${noPolicy} table(s) lack governance policies; define baseline classification and retention.`);
    if (tables.length && general / tables.length > 0.8) {
      out.push('Large share of tables classified as General; consider targeted reclassification review.');
    }
    out.push('Automate periodic discovery and policy drift detection.');
    out.push('Schedule quarterly compliance checks for sensitive domains.');
    return out;
  }

  /* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   * Private: Data recommendations
   * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */

  private async buildDataRecommendations(
    analysis: ReadonlyArray<Record<string, unknown>>,
    issues: ReadonlyArray<QualityIssue>,
  ): Promise<string[]> {
    const recs = new Set<string>();
    const hi = issues.filter((q) => isHigh(q.severity)).length;
    if (hi) recs.add(`Address ${hi} high/critical quality issues immediately.`);

    if (issues.some((q) => q.type === 'null_values')) recs.add('Add NOT NULL/CHECK constraints or upstream validation.');
    if (issues.some((q) => q.type === 'format_inconsistency')) recs.add('Standardize formats with validation/canonicalization.');

    // Optional AI tip if method exists
    const hasSummarize =
      this.ai && (typeof (this.ai as any).safeSummarize === 'function' || typeof (this.ai as any).summarize === 'function');
    if (hasSummarize) {
      try {
        const fn = (this.ai as any).safeSummarize ?? (this.ai as any).summarize;
        const maybe = await withTimeout(
          Promise.resolve(fn.call(this.ai, { topic: 'data-quality-highlights', payload: { issues: issues.slice(0, 50) } })),
          Math.min(this.aiTimeoutMs, 3000),
          'AI data tip',
        );
        if (typeof maybe === 'string' && maybe.trim()) recs.add(maybe.trim());
      } catch {
        // ignore AI failure
      }
    }

    recs.add('Enable continuous monitoring & alerting for key quality dimensions.');
    recs.add('Publish a data quality dashboard with issue backlog & owners.');

    return Array.from(recs);
  }

  private mockQualityResults(_rules: ReadonlyArray<Record<string, unknown>>): QualityRuleResult[] {
    return [
      {
        ruleId: 'email_format',
        ruleName: 'Email Format Validation',
        status: 'passed',
        testedRecords: 1000,
        passedRecords: 998,
        failedRecords: 2,
        successRate: 99.8,
      },
      {
        ruleId: 'phone_format',
        ruleName: 'Phone Number Format',
        status: 'warning',
        testedRecords: 1000,
        passedRecords: 950,
        failedRecords: 50,
        successRate: 95.0,
      },
      {
        ruleId: 'null_check',
        ruleName: 'Required Field Validation',
        status: 'failed',
        testedRecords: 1000,
        passedRecords: 800,
        failedRecords: 200,
        successRate: 80.0,
      },
    ];
  }

  private async enhanceRuleResults(results: ReadonlyArray<QualityRuleResult>): Promise<QualityRuleResult[]> {
    const out: QualityRuleResult[] = [];
    const hasSummarize =
      this.ai && (typeof (this.ai as any).safeSummarize === 'function' || typeof (this.ai as any).summarize === 'function');
    for (let i = 0; i < results.length; i++) {
      const r = results[i];
      const baseExp = this.baseRuleExplanation(r);
      const baseRecs = this.baseRuleRecommendations(r);

      let aiNote: string | undefined;
      if (hasSummarize) {
        try {
          const fn = (this.ai as any).safeSummarize ?? (this.ai as any).summarize;
          const maybe = await withTimeout(
            Promise.resolve(fn.call(this.ai, { topic: 'quality-rule-explanation', payload: { id: r.ruleId, status: r.status, rate: r.successRate } })),
            Math.min(this.aiTimeoutMs, 3000),
            `AI note for ${r.ruleId}`,
          );
          if (typeof maybe === 'string' && maybe.trim()) aiNote = maybe.trim();
        } catch {
          // ignore
        }
      }

      out.push({
        ...r,
        aiExplanation: aiNote ?? baseExp,
        recommendations: Array.from(new Set([...(r.recommendations ?? []), ...baseRecs])),
      });
    }
    return out;
  }

  private baseRuleExplanation(r: QualityRuleResult): string {
    if (r.status === 'passed') return `Rule "${r.ruleName}" performing well (${r.successRate}% success).`;
    if (r.status === 'warning')
      return `Rule "${r.ruleName}" shows moderate issues (${r.failedRecords} failures). Investigate upstream validation.`;
    return `Rule "${r.ruleName}" failing (${r.failedRecords} failures). Immediate remediation required.`;
  }

  private baseRuleRecommendations(r: QualityRuleResult): string[] {
    const recs: string[] = [];
    if (r.status === 'failed') {
      recs.push('Identify root cause and add upstream validation.');
      recs.push('Cleanse/backfill existing bad records.');
      recs.push('Add tests & monitoring to prevent regressions.');
    } else if (r.status === 'warning') {
      recs.push('Track trend; tighten validation where safe.');
      recs.push('Add sampling-based alerts.');
    }
    return recs;
  }

  /* â”€â”€â”€â”€â”€â”€â”€â”€â”€ Guards â”€â”€â”€â”€â”€â”€â”€â”€â”€ */

  private assertUser(userId: string): void {
    if (!userId || typeof userId !== 'string') throw new APIError('Invalid userId', 400);
  }

  private assertSchema(schema: unknown): asserts schema is SchemaInfo {
    if (!schema || typeof (schema as SchemaInfo).name !== 'string') {
      throw new APIError('Invalid schema payload', 400);
    }
  }

  private assertSamples(samples: unknown): asserts samples is DataSample[] {
    if (!Array.isArray(samples)) throw new APIError('samples must be an array', 400);
    if (samples.length === 0) throw new APIError('At least one sample is required', 400);
    for (let i = 0; i < samples.length; i++) {
      const s = samples[i] as Partial<DataSample>;
      if (!s || typeof s.columnName !== 'string' || !Array.isArray(s.values)) {
        throw new APIError(`Invalid sample at index ${i}`, 400);
      }
    }
  }
}



------------------------------------------------------------
FILE: backend\ai-service\src\services\CacheService.ts
------------------------------------------------------------
// src/services/CacheService.ts
import { redis } from '@/config/redis';
import { logger } from '@/utils/logger';

function toSeconds(ms: number): number {
  return Math.max(1, Math.floor(ms / 1000));
}

export class CacheService {
  private readonly defaultTTLSeconds: number;

  constructor() {
    const raw = process.env.REDIS_TTL ?? '3600';
    const ttlNum = Number(raw);
    // If someone passed milliseconds (very large), normalize to seconds.
    this.defaultTTLSeconds = ttlNum > 7 * 24 * 3600 ? toSeconds(ttlNum) : (ttlNum || 3600);
  }

  /* ----------------------- Basic primitives ----------------------- */

  public async get(key: string): Promise<string | null> {
    try {
      return await redis.get(key);
    } catch (error) {
      logger.error('Cache GET error', { key, error });
      return null;
    }
  }

  public async getJSON<T = unknown>(key: string): Promise<T | null> {
    const v = await this.get(key);
    if (v == null) return null;
    try {
      return JSON.parse(v) as T;
    } catch {
      return null;
    }
  }

  /**
   * Set a value with TTL (seconds). Accepts string or any JSON-serializable value.
   * Works with both:
   *  - node-redis v4: client.set(key, value, { EX: ttl })
   *  - custom wrappers: redis.set(key, value, ttl)
   */
  public async set(key: string, value: unknown, ttlSeconds?: number): Promise<void> {
    const ttl = ttlSeconds ?? this.defaultTTLSeconds;
    const toStore = typeof value === 'string' ? value : JSON.stringify(value);

    try {
      // Prefer modern API via underlying client (node-redis v4)
      const client: any = redis.getClient?.() ?? null;
      if (client && typeof client.set === 'function') {
        try {
          await client.set(key, toStore, { EX: ttl });
          return;
        } catch {
          // fall through to wrapper style
        }
      }

      // Fallback to wrapper style: redis.set(key, value, ttl)
      const maybe = (redis as any).set;
      if (typeof maybe === 'function') {
        if (maybe.length >= 3) {
          await maybe.call(redis, key, toStore, ttl);
        } else {
          await maybe.call(redis, key, toStore);
          // If wrapper ignores TTL, try to set it via EXPIRE
          if (client && typeof client.expire === 'function') {
            await client.expire(key, ttl);
          }
        }
      }
    } catch (error) {
      logger.error('Cache SET error', { key, error });
      // don't throw â€” cache is best effort
    }
  }

  public async del(key: string): Promise<void> {
    try {
      await redis.del(key);
    } catch (error) {
      logger.error('Cache DEL error', { key, error });
    }
  }

  /**
   * Normalize EXISTS return to boolean whether itâ€™s number or boolean.
   */
  public async exists(key: string): Promise<boolean> {
    try {
      const raw = await (redis as any).exists?.(key);
      const n = typeof raw === 'number' ? raw : raw ? 1 : 0;
      return n > 0;
    } catch (error) {
      logger.error('Cache EXISTS error', { key, error });
      return false;
    }
  }

  /* ----------------------- Bulk helpers ----------------------- */

  /**
   * Flush keys by pattern safely. Uses scanIterator (node-redis v4),
   * falls back to SCAN or KEYS if needed.
   */
  public async flushPattern(pattern: string): Promise<void> {
    try {
      const client: any = redis.getClient?.() ?? null;
      if (!client) return;

      const batch: string[] = [];
      const flushBatch = async () => {
        if (batch.length) {
          await client.del(batch.splice(0, batch.length));
        }
      };

      if (typeof client.scanIterator === 'function') {
        // Best path: async iterator with MATCH/COUNT
        for await (const key of client.scanIterator({ MATCH: pattern, COUNT: 1000 })) {
          batch.push(key as string);
          if (batch.length >= 1000) await flushBatch();
        }
        await flushBatch();
        return;
      }

      if (typeof client.scan === 'function') {
        // Fallback: manual SCAN loop
        let cursor = '0';
        do {
          const [next, keys]: [string, string[]] = await client.scan(cursor, {
            MATCH: pattern,
            COUNT: 1000,
          });
          cursor = next;
          if (keys?.length) {
            batch.push(...keys);
            if (batch.length >= 1000) await flushBatch();
          }
        } while (cursor !== '0');
        await flushBatch();
        return;
      }

      if (typeof client.keys === 'function') {
        // Last resort: KEYS (blocking)
        const keys: string[] = await client.keys(pattern);
        if (keys.length) await client.del(keys);
      }
    } catch (error) {
      logger.error('Cache FLUSH PATTERN error', { pattern, error });
    }
  }

  /* ----------------------- Stats & diagnostics ----------------------- */

  public async getStats(): Promise<Record<string, string | number>> {
    try {
      const client: any = redis.getClient?.() ?? null;
      if (!client || typeof client.info !== 'function') return {};
      const info: string = await client.info('stats');
      return this.parseRedisInfo(info);
    } catch (error) {
      logger.error('Cache STATS error', { error });
      return {};
    }
  }

  private parseRedisInfo(info: string): Record<string, string | number> {
    const stats: Record<string, string | number> = {};
    const lines = info.split(/\r?\n/);

    for (const line of lines) {
      if (!line || line.startsWith('#')) continue; // skip comments / blanks
      const idx = line.indexOf(':');
      if (idx <= 0) continue;

      const key = line.slice(0, idx).trim();
      const raw = line.slice(idx + 1).trim();

      const n = Number(raw);
      stats[key] = Number.isFinite(n) && raw !== '' ? n : raw;
    }
    return stats;
    }
}

// Optional singleton export
export const cacheService = new CacheService();



------------------------------------------------------------
FILE: backend\ai-service\src\services\DefaultDataProcessor.ts
------------------------------------------------------------
// src/services/DefaultDataProcessor.ts
import type { DataSample, IDataProcessor, QualityIssue } from '@/services/AnalysisService';

export class DefaultDataProcessor implements IDataProcessor {
  constructor(private readonly log: (msg: string, meta?: unknown) => void = () => {}) {}

  async analyzeSampleData(
    samples: DataSample[],
  ): Promise<{ analysis: Record<string, unknown>[]; qualityIssues: QualityIssue[] }> {
    this.log('DefaultDataProcessor.analyzeSampleData', { columns: samples.length });

    const analysis: Record<string, unknown>[] = [];
    const qualityIssues: QualityIssue[] = [];

    for (const s of samples) {
      const values = Array.isArray(s.values) ? s.values : [];
      const nonNull = values.filter(v => v !== null && v !== undefined);
      const nulls = values.length - nonNull.length;
      const uniqueCount = new Set(nonNull.map(v => JSON.stringify(v))).size;

      analysis.push({
        column: s.columnName,
        count: values.length,
        nulls,
        nullRate: values.length ? +(nulls / values.length * 100).toFixed(2) : 0,
        uniqueCount,
        sample: nonNull.slice(0, 5),
      });

      if (nulls > 0) {
        qualityIssues.push({
          column: s.columnName,
          type: 'null_values',
          severity: nulls / Math.max(values.length, 1) > 0.2 ? 'High' : 'Low',
          count: nulls,
          message: 'Column contains null/undefined values',
          sample: values.slice(0, 5),
        });
      }

      const lower = s.columnName.toLowerCase();
      if (lower.includes('email')) {
        const bad = nonNull.filter(v => typeof v === 'string' && !/^[^\s@]+@[^\s@]+\.[^\s@]+$/.test(v));
        if (bad.length) {
          qualityIssues.push({
            column: s.columnName,
            type: 'format_inconsistency',
            severity: bad.length / Math.max(nonNull.length, 1) > 0.05 ? 'Medium' : 'Low',
            count: bad.length,
            message: 'Invalid email addresses detected',
            sample: bad.slice(0, 5),
          });
        }
      }
    }

    return { analysis, qualityIssues };
  }
}

export default DefaultDataProcessor;



------------------------------------------------------------
FILE: backend\ai-service\src\services\DiscoveryService.ts
------------------------------------------------------------
// src/services/DiscoveryService.ts
import { db } from '@/config/database';
import { APIError } from '@/utils/errors';
import { logger } from '@/utils/logger';
import { v4 as uuidv4 } from 'uuid';
import { AIService, type FieldDiscoveryRequest } from './AIService';

export interface DiscoverySession {
  sessionId: string;
  userId: string;
  dataSourceId: string;
  status: 'pending' | 'processing' | 'completed' | 'failed';
  progress: number;
  results?: unknown;
  error?: string;
  createdAt: Date;
  updatedAt: Date;
}

export interface StartDiscoveryRequest {
  userId: string;
  dataSourceId: string;
  schemas?: string[];
  tables?: string[];
  options?: {
    sampleSize?: number;
    includeData?: boolean;
    analysisDepth?: 'basic' | 'detailed' | 'comprehensive';
  };
}

// shape as returned from DB
type DbSessionRow = {
  session_id: string;
  user_id: string;
  data_source_id: string;
  status: DiscoverySession['status'];
  progress: number;
  results: unknown | null;
  error: string | null;
  created_at: Date;
  updated_at: Date;
};

// local helper type for metadata
type ColumnDef = { name: string; type: string; nullable: boolean; description?: string };
type TableMeta = { schema: string; name: string; columns: ColumnDef[] };

export class DiscoveryService {
  private readonly aiService = new AIService();

  public async startDiscovery(request: StartDiscoveryRequest): Promise<DiscoverySession> {
    try {
      const sessionId = uuidv4();

      // Create discovery session
      const session = await this.createSession({
        sessionId,
        userId: request.userId,
        dataSourceId: request.dataSourceId,
        status: 'pending',
        progress: 0,
      });

      // Kick off async processing
      setImmediate(() =>
        this.processDiscovery(session, request).catch((err) => {
          const msg = err instanceof Error ? err.message : String(err);
          logger.error('Discovery background task fatal error', { sessionId, error: msg });
        })
      );

      logger.info('Discovery session started', { sessionId, dataSourceId: request.dataSourceId });
      return session;
    } catch (err: unknown) {
      const msg = err instanceof Error ? err.message : 'Unknown error';
      logger.error('Failed to start discovery', { error: msg });
      throw new APIError('Failed to start discovery', 500, err);
    }
  }

  public async getSession(sessionId: string): Promise<DiscoverySession | null> {
    try {
      const result = await db.query('SELECT * FROM discovery_sessions WHERE session_id = $1', [sessionId]);
      if (result.rows.length === 0) return null;
      return this.mapSessionFromDb(result.rows[0] as DbSessionRow);
    } catch (err: unknown) {
      const msg = err instanceof Error ? err.message : 'Unknown error';
      logger.error('Failed to get discovery session', { sessionId, error: msg });
      throw new APIError('Failed to get session', 500, err);
    }
  }

  public async listSessions(userId: string, limit = 20, offset = 0): Promise<DiscoverySession[]> {
    try {
      const result = await db.query(
        `SELECT * FROM discovery_sessions 
         WHERE user_id = $1 
         ORDER BY created_at DESC 
         LIMIT $2 OFFSET $3`,
        [userId, limit, offset]
      );

      return (result.rows as DbSessionRow[]).map((row) => this.mapSessionFromDb(row));
    } catch (err: unknown) {
      const msg = err instanceof Error ? err.message : 'Unknown error';
      logger.error('Failed to list discovery sessions', { userId, error: msg });
      throw new APIError('Failed to list sessions', 500, err);
    }
  }

  public async deleteSession(sessionId: string, userId: string): Promise<void> {
    try {
      const result = await db.query('DELETE FROM discovery_sessions WHERE session_id = $1 AND user_id = $2', [
        sessionId,
        userId,
      ]);

      if (result.rowCount === 0) {
        throw new APIError('Session not found', 404);
      }

      logger.info('Discovery session deleted', { sessionId });
    } catch (err: unknown) {
      const msg = err instanceof Error ? err.message : 'Unknown error';
      logger.error('Failed to delete discovery session', { sessionId, error: msg });
      throw err instanceof APIError ? err : new APIError('Failed to delete session', 500, err);
    }
  }

  /* --------------------------- Internals --------------------------- */

  private async createSession(session: Partial<DiscoverySession>): Promise<DiscoverySession> {
    const result = await db.query(
      `INSERT INTO discovery_sessions 
       (session_id, user_id, data_source_id, status, progress, created_at, updated_at)
       VALUES ($1, $2, $3, $4, $5, NOW(), NOW())
       RETURNING *`,
      [session.sessionId, session.userId, session.dataSourceId, session.status, session.progress]
    );
    return this.mapSessionFromDb(result.rows[0] as DbSessionRow);
  }

  private async updateSession(sessionId: string, updates: Partial<DiscoverySession>): Promise<void> {
    const setClause: string[] = [];
    const values: unknown[] = [];
    let i = 1;

    for (const [key, value] of Object.entries(updates)) {
      if (key === 'sessionId') continue;
      // convert camelCase to snake_case
      const dbKey = key.replace(/[A-Z]/g, (m) => `_${m.toLowerCase()}`);
      setClause.push(`${dbKey} = $${i++}`);
      values.push(value);
    }

    if (setClause.length === 0) return;

    setClause.push(`updated_at = NOW()`);
    values.push(sessionId);

    await db.query(`UPDATE discovery_sessions SET ${setClause.join(', ')} WHERE session_id = $${i}`, values);
  }

  private async processDiscovery(session: DiscoverySession, request: StartDiscoveryRequest): Promise<void> {
    try {
      await this.updateSession(session.sessionId, { status: 'processing', progress: 10 });

      const dataSource = await this.getDataSource(request.dataSourceId);
      if (!dataSource) throw new Error('Data source not found');

      await this.updateSession(session.sessionId, { progress: 20 });

      // Retrieve metadata
      const metadata = await this.getSchemaMetadata(dataSource, request.schemas, request.tables);
      await this.updateSession(session.sessionId, { progress: 40 });

      const results: Array<{ schema: string; table: string; analysis: unknown }> = [];
      const totalTables = metadata.length || 1;

      for (let idx = 0; idx < metadata.length; idx++) {
        const table = metadata[idx];

        // Optional sample data
        let sampleData: unknown[] = [];
        if (request.options?.includeData) {
          sampleData = await this.getSampleData(
            dataSource,
            table.schema,
            table.name,
            request.options.sampleSize ?? 100
          );
        }

        // IMPORTANT: make columns mutable (clone), not readonly
        const columns: ColumnDef[] = table.columns.map((c) => ({ ...c }));

        const discoveryRequest: FieldDiscoveryRequest = {
          schema: table.schema,
          tableName: table.name,
          columns,            // mutable array now
          sampleData,         // always an array
          context: `Discovery session for ${String(dataSource.name ?? dataSource.id)}`,
        };

        const analysis = await this.aiService.discoverFields(discoveryRequest);

        results.push({ schema: table.schema, table: table.name, analysis });

        // progress: 40 â†’ 90 during table loop
        const progress = 40 + Math.floor(((idx + 1) / totalTables) * 50);
        await this.updateSession(session.sessionId, { progress });
      }

      await this.updateSession(session.sessionId, {
        status: 'completed',
        progress: 100,
        results: { tables: results, summary: this.generateSummary(results) },
      });

      logger.info('Discovery completed successfully', {
        sessionId: session.sessionId,
        tablesProcessed: results.length,
      });
    } catch (err: unknown) {
      const msg = err instanceof Error ? err.message : 'Unknown error';
      logger.error('Discovery processing failed', { sessionId: session.sessionId, error: msg });

      await this.updateSession(session.sessionId, { status: 'failed', error: msg });
    }
  }

  private async getDataSource(dataSourceId: string): Promise<any | null> {
    const result = await db.query('SELECT * FROM data_sources WHERE id = $1', [dataSourceId]);
    return result.rows[0] ?? null;
  }

  // eslint-disable-next-line @typescript-eslint/no-unused-vars
  private async getSchemaMetadata(
    _dataSource: any,
    _schemas?: string[],
    _tables?: string[]
  ): Promise<TableMeta[]> {
    // TODO: replace with real connector fetch
    return [
      {
        schema: 'public',
        name: 'users',
        columns: [
          { name: 'id', type: 'integer', nullable: false },
          { name: 'email', type: 'varchar', nullable: false },
          { name: 'first_name', type: 'varchar', nullable: true },
          { name: 'last_name', type: 'varchar', nullable: true },
          { name: 'phone', type: 'varchar', nullable: true },
          { name: 'created_at', type: 'timestamp', nullable: false },
        ],
      },
    ];
  }

  private async getSampleData(
    _dataSource: any,
    _schema: string,
    _table: string,
    _limit: number
  ): Promise<unknown[]> {
    // TODO: replace with actual sampling query
    return [
      { id: 1, email: 'john@example.com', first_name: 'John', last_name: 'Doe', phone: '+1234567890' },
      { id: 2, email: 'jane@example.com', first_name: 'Jane', last_name: 'Smith', phone: '+1987654321' },
    ];
  }

  private generateSummary(results: ReadonlyArray<{ analysis: any }>): {
    totalTables: number;
    totalFields: number;
    classifications: Record<string, number>;
    sensitivities: Record<string, number>;
    recommendations: string[];
  } {
    let totalFields = 0;
    const classifications: Record<string, number> = Object.create(null);
    const sensitivities: Record<string, number> = Object.create(null);

    for (const t of results) {
      const fields: ReadonlyArray<any> = Array.isArray(t.analysis?.fields) ? t.analysis.fields : [];
      totalFields += fields.length;

      for (const f of fields) {
        const cls = String(f.classification ?? 'Unknown');
        const sen = String(f.sensitivity ?? 'Unknown');
        classifications[cls] = (classifications[cls] ?? 0) + 1;
        sensitivities[sen] = (sensitivities[sen] ?? 0) + 1;
      }
    }

    const recommendations = results
      .flatMap((t) => {
        const gov: unknown = t.analysis?.recommendations?.governance;
        return Array.isArray(gov) ? gov : [];
      })
      .slice(0, 10);

    return {
      totalTables: results.length,
      totalFields,
      classifications,
      sensitivities,
      recommendations,
    };
  }

  private mapSessionFromDb(row: DbSessionRow): DiscoverySession {
    // Build with conditional spreads to satisfy exactOptionalPropertyTypes:
    const base: Omit<DiscoverySession, 'results' | 'error'> = {
      sessionId: row.session_id,
      userId: row.user_id,
      dataSourceId: row.data_source_id,
      status: row.status,
      progress: row.progress,
      createdAt: row.created_at,
      updatedAt: row.updated_at,
    };

    return {
      ...base,
      ...(row.results !== null ? { results: row.results } : {}),
      ...(row.error !== null ? { error: row.error } : {}),
    };
  }
}



------------------------------------------------------------
FILE: backend\ai-service\src\utils\errors.ts
------------------------------------------------------------
export class APIError extends Error {
  public statusCode: number;
  public isOperational: boolean;
  public details?: any;

  constructor(message: string, statusCode = 500, details?: any) {
    super(message);
    this.name = 'APIError';
    this.statusCode = statusCode;
    this.isOperational = true;
    this.details = details;

    // Ensure proper prototype chain
    Object.setPrototypeOf(this, APIError.prototype);

    // Capture stack trace
    Error.captureStackTrace(this, this.constructor);
  }
}

export class ValidationError extends APIError {
  constructor(message: string, details?: any) {
    super(message, 400, details);
    this.name = 'ValidationError';
  }
}

export class AuthenticationError extends APIError {
  constructor(message = 'Authentication required') {
    super(message, 401);
    this.name = 'AuthenticationError';
  }
}

export class AuthorizationError extends APIError {
  constructor(message = 'Insufficient permissions') {
    super(message, 403);
    this.name = 'AuthorizationError';
  }
}

export class NotFoundError extends APIError {
  constructor(resource = 'Resource') {
    super(`${resource} not found`, 404);
    this.name = 'NotFoundError';
  }
}

export class ConflictError extends APIError {
  constructor(message = 'Resource conflict') {
    super(message, 409);
    this.name = 'ConflictError';
  }
}

export class RateLimitError extends APIError {
  constructor(message = 'Rate limit exceeded') {
    super(message, 429);
    this.name = 'RateLimitError';
  }
}

export class ExternalServiceError extends APIError {
  constructor(service: string, message?: string) {
    super(message || `External service ${service} is unavailable`, 503);
    this.name = 'ExternalServiceError';
  }
}


------------------------------------------------------------
FILE: backend\ai-service\src\utils\gracefulShutdown.ts
------------------------------------------------------------
// src/utils/gracefulShutdown.ts
import { Server } from 'http';
import { logger } from './logger';

interface ShutdownOptions {
  timeout?: number; // Timeout in milliseconds
  signals?: string[]; // Signals to listen for
  forceExitDelay?: number; // Delay before force exit
}

/**
 * Production-ready graceful shutdown handler
 */
export class GracefulShutdown {
  private server: Server;
  private isShuttingDown: boolean = false;
  private connections: Set<any> = new Set();
  private options: Required<ShutdownOptions>;
  private shutdownTimeout: NodeJS.Timeout | null = null;
  private forceExitTimeout: NodeJS.Timeout | null = null;

  constructor(server: Server, options: ShutdownOptions = {}) {
    this.server = server;
    this.options = {
      timeout: options.timeout || 30000, // 30 seconds default
      signals: options.signals || ['SIGTERM', 'SIGINT', 'SIGUSR2'],
      forceExitDelay: options.forceExitDelay || 5000 // 5 seconds before force exit
    };

    this.setupConnectionTracking();
    this.setupSignalHandlers();
  }

  /**
   * Track active connections
   */
  private setupConnectionTracking(): void {
    this.server.on('connection', (connection) => {
      this.connections.add(connection);
      
      connection.on('close', () => {
        this.connections.delete(connection);
      });

      // Handle connection errors
      connection.on('error', (error) => {
        logger.warn('Connection error during shutdown:', error);
        this.connections.delete(connection);
      });
    });
  }

  /**
   * Setup signal handlers for graceful shutdown
   */
  private setupSignalHandlers(): void {
    this.options.signals.forEach((signal) => {
      process.on(signal, () => {
        logger.info(`Received ${signal} signal, starting graceful shutdown...`);
        this.initiateShutdown(signal);
      });
    });

    // Handle uncaught exceptions during shutdown
    process.on('uncaughtException', (error) => {
      logger.error('Uncaught exception during shutdown:', error);
      if (this.isShuttingDown) {
        this.forceExit(1);
      }
    });

    // Handle unhandled promise rejections during shutdown
    process.on('unhandledRejection', (reason, promise) => {
      logger.error('Unhandled promise rejection during shutdown:', { reason, promise });
      if (this.isShuttingDown) {
        this.forceExit(1);
      }
    });
  }

  /**
   * Initiate graceful shutdown process
   */
  private async initiateShutdown(signal: string): Promise<void> {
    if (this.isShuttingDown) {
      logger.warn('Shutdown already in progress, ignoring signal');
      return;
    }

    this.isShuttingDown = true;
    const startTime = Date.now();

    logger.info('Starting graceful shutdown process...', {
      signal,
      activeConnections: this.connections.size,
      timeout: this.options.timeout
    });

    // Set timeout for forced shutdown
    this.shutdownTimeout = setTimeout(() => {
      logger.warn('Graceful shutdown timeout reached, forcing shutdown');
      this.forceShutdown();
    }, this.options.timeout);

    // Set force exit timeout
    this.forceExitTimeout = setTimeout(() => {
      logger.error('Force exit timeout reached, terminating process');
      this.forceExit(1);
    }, this.options.timeout + this.options.forceExitDelay);

    try {
      // Step 1: Stop accepting new connections
      await this.stopAcceptingConnections();

      // Step 2: Close existing connections gracefully
      await this.closeExistingConnections();

      // Step 3: Cleanup resources
      await this.cleanupResources();

      // Step 4: Exit gracefully
      const duration = Date.now() - startTime;
      logger.info(`Graceful shutdown completed successfully in ${duration}ms`);
      
      this.clearTimeouts();
      process.exit(0);

    } catch (error) {
      logger.error('Error during graceful shutdown:', error);
      this.forceExit(1);
    }
  }

  /**
   * Stop accepting new connections
   */
  private async stopAcceptingConnections(): Promise<void> {
    return new Promise((resolve, reject) => {
      if (!this.server.listening) {
        logger.info('Server not listening, skipping connection stop');
        return resolve();
      }

      logger.info('Stopping server from accepting new connections...');
      
      this.server.close((error) => {
        if (error) {
          logger.error('Error stopping server:', error);
          return reject(error);
        }
        
        logger.info('Server stopped accepting new connections');
        resolve();
      });
    });
  }

  /**
   * Close existing connections gracefully
   */
  private async closeExistingConnections(): Promise<void> {
    if (this.connections.size === 0) {
      logger.info('No active connections to close');
      return;
    }

    logger.info(`Closing ${this.connections.size} active connections...`);

    // Give connections time to finish naturally
    await this.waitForConnectionsToClose(5000);

    // Force close remaining connections
    if (this.connections.size > 0) {
      logger.warn(`Force closing ${this.connections.size} remaining connections`);
      this.connections.forEach((connection) => {
        try {
          connection.destroy();
        } catch (error) {
          logger.warn('Error destroying connection:', error);
        }
      });
      this.connections.clear();
    }

    logger.info('All connections closed');
  }

  /**
   * Wait for connections to close naturally
   */
  private async waitForConnectionsToClose(timeout: number): Promise<void> {
    const startTime = Date.now();
    
    while (this.connections.size > 0 && (Date.now() - startTime) < timeout) {
      await new Promise(resolve => setTimeout(resolve, 100));
    }
  }

  /**
   * Cleanup application resources
   */
  private async cleanupResources(): Promise<void> {
    logger.info('Cleaning up application resources...');

    try {
      // Import and close database connections
      const { db } = await import('@/config/database');
      if (db && typeof db.close === 'function') {
        await db.close();
        logger.info('Database connections closed');
      }
    } catch (error) {
      logger.warn('Error closing database connections:', error);
    }

    try {
      // Import and close Redis connections
      const { redis } = await import('@/config/redis');
      if (redis && typeof redis.close === 'function') {
        await redis.close();
        logger.info('Redis connections closed');
      }
    } catch (error) {
      logger.warn('Error closing Redis connections:', error);
    }

    // Clear any intervals or timeouts
    this.clearApplicationTimers();

    logger.info('Resource cleanup completed');
  }

  /**
   * Clear application timers and intervals
   */
  private clearApplicationTimers(): void {
    // Clear any global intervals or timeouts
    // This is a placeholder - you can add specific timer cleanup here
    logger.debug('Application timers cleared');
  }

  /**
   * Force shutdown when graceful shutdown fails
   */
  private forceShutdown(): void {
    logger.warn('Forcing immediate shutdown...');

    // Destroy all connections immediately
    this.connections.forEach((connection) => {
      try {
        connection.destroy();
      } catch (error) {
        logger.warn('Error destroying connection during force shutdown:', error);
      }
    });

    this.connections.clear();
    
    // Force close server
    try {
      this.server.close();
    } catch (error) {
      logger.warn('Error force closing server:', error);
    }

    this.clearTimeouts();
    this.forceExit(1);
  }

  /**
   * Force exit the process
   */
  private forceExit(code: number): void {
    logger.error(`Force exiting with code ${code}`);
    this.clearTimeouts();
    process.exit(code);
  }

  /**
   * Clear shutdown timeouts
   */
  private clearTimeouts(): void {
    if (this.shutdownTimeout) {
      clearTimeout(this.shutdownTimeout);
      this.shutdownTimeout = null;
    }

    if (this.forceExitTimeout) {
      clearTimeout(this.forceExitTimeout);
      this.forceExitTimeout = null;
    }
  }

  /**
   * Get shutdown status
   */
  public isShutdownInProgress(): boolean {
    return this.isShuttingDown;
  }

  /**
   * Get active connections count
   */
  public getActiveConnectionsCount(): number {
    return this.connections.size;
  }
}

/**
 * Simple graceful shutdown function (backwards compatible)
 */
export function gracefulShutdown(server: Server, options?: ShutdownOptions): GracefulShutdown {
  return new GracefulShutdown(server, options);
}

/**
 * Enhanced graceful shutdown with custom cleanup
 */
export function createGracefulShutdown(
  server: Server, 
  options: ShutdownOptions = {},
  customCleanup?: () => Promise<void>
): GracefulShutdown {
  const shutdown = new GracefulShutdown(server, options);

  // Add custom cleanup if provided
  if (customCleanup) {
    const originalCleanup = (shutdown as any).cleanupResources;
    (shutdown as any).cleanupResources = async function() {
      await originalCleanup.call(this);
      try {
        await customCleanup();
        logger.info('Custom cleanup completed');
      } catch (error) {
        logger.error('Error in custom cleanup:', error);
      }
    };
  }

  return shutdown;
}

// Export default
export default gracefulShutdown;


------------------------------------------------------------
FILE: backend\ai-service\src\utils\logger.ts
------------------------------------------------------------
import winston from 'winston';
import DailyRotateFile from 'winston-daily-rotate-file';

const logFormat = winston.format.combine(
  winston.format.timestamp(),
  winston.format.errors({ stack: true }),
  winston.format.json()
);

const consoleFormat = winston.format.combine(
  winston.format.colorize(),
  winston.format.timestamp({ format: 'YYYY-MM-DD HH:mm:ss' }),
  winston.format.printf(({ timestamp, level, message, ...meta }) => {
    return `${timestamp} [${level}]: ${message} ${Object.keys(meta).length ? JSON.stringify(meta, null, 2) : ''}`;
  })
);

// Create logger instance
export const logger = winston.createLogger({
  level: process.env.LOG_LEVEL || 'info',
  format: logFormat,
  defaultMeta: { 
    service: 'ai-service',
    version: process.env.APP_VERSION || '1.0.0'
  },
  transports: [
    // Console transport
    new winston.transports.Console({
      format: process.env.NODE_ENV === 'production' ? logFormat : consoleFormat
    }),

    // File transport for errors
    new DailyRotateFile({
      filename: 'logs/error-%DATE%.log',
      datePattern: 'YYYY-MM-DD',
      level: 'error',
      maxSize: process.env.LOG_FILE_MAX_SIZE || '20m',
      maxFiles: process.env.LOG_FILE_MAX_FILES || '14d',
      zippedArchive: true
    }),

    // File transport for all logs
    new DailyRotateFile({
      filename: 'logs/combined-%DATE%.log',
      datePattern: 'YYYY-MM-DD',
      maxSize: process.env.LOG_FILE_MAX_SIZE || '20m',
      maxFiles: process.env.LOG_FILE_MAX_FILES || '14d',
      zippedArchive: true
    })
  ],

  // Handle exceptions and rejections
  exceptionHandlers: [
    new winston.transports.File({ filename: 'logs/exceptions.log' })
  ],
  rejectionHandlers: [
    new winston.transports.File({ filename: 'logs/rejections.log' })
  ]
});

// Create child logger for specific modules
export const createChildLogger = (module: string) => {
  return logger.child({ module });
};


------------------------------------------------------------
FILE: backend\ai-service\src\utils\responses.ts
------------------------------------------------------------
export interface ApiResponse<T = any> {
  success: boolean;
  data?: T;
  message?: string;
  pagination?: {
    page: number;
    limit: number;
    total: number;
    totalPages: number;
  };
  meta?: {
    requestId?: string;
    timestamp: string;
    version: string;
  };
}

export const successResponse = <T>(
  data: T,
  message = 'Success',
  pagination?: any
): ApiResponse<T> => {
  return {
    success: true,
    data,
    message,
    ...(pagination && { pagination }),
    meta: {
      timestamp: new Date().toISOString(),
      version: process.env.APP_VERSION || '1.0.0'
    }
  };
};

export const errorResponse = (
  message: string,
  code = 500,
  details?: any
): ApiResponse => {
  return {
    success: false,
    message,
    ...(details && { data: details }),
    meta: {
      timestamp: new Date().toISOString(),
      version: process.env.APP_VERSION || '1.0.0'
    }
  };
};

export const paginatedResponse = <T>(
  data: T[],
  page: number,
  limit: number,
  total: number,
  message = 'Success'
): ApiResponse<T[]> => {
  return {
    success: true,
    data,
    message,
    pagination: {
      page,
      limit,
      total,
      totalPages: Math.ceil(total / limit)
    },
    meta: {
      timestamp: new Date().toISOString(),
      version: process.env.APP_VERSION || '1.0.0'
    }
  };
};


------------------------------------------------------------
FILE: backend\ai-service\src\utils\validator.ts
------------------------------------------------------------
// src/utils/validator.ts
import type { RequestHandler } from 'express';
import Joi, { Schema, ValidationOptions } from 'joi';

/**
 * Common primitives
 */
const uuid = Joi.string().guid({ version: ['uuidv4', 'uuidv5'] });

const email = Joi.string()
  .email({ tlds: { allow: false } })
  .max(254);

const password = Joi.string()
  .min(8)
  // at least one lowercase, one uppercase, one digit, one special
  .pattern(/^(?=.*[a-z])(?=.*[A-Z])(?=.*\d)(?=.*[ !"#$%&'()*+,\-./:;<=>?@[\\\]^_`{|}~]).{8,}$/)
  .messages({
    'string.pattern.base':
      'Password must include upper & lower case letters, a number, and a special character.',
  });

/**
 * E.164-ish phone: optional leading +, then 7â€“15 digits (first digit cannot be 0)
 * If you want strictly E.164 (1â€“15 digits, no leading 0), use /^\+[1-9]\d{1,14}$/
 */
const phone = Joi.string()
  .pattern(/^\+?[1-9]\d{6,14}$/)
  .messages({
    'string.pattern.base': 'Phone must be a valid international number (e.g., +15551234567).',
  });

const nonEmptyString = Joi.string().trim().min(1);

const dateISO = Joi.date().iso();

/**
 * Reusable â€œfieldâ€ library
 */
export const Fields = {
  uuid,
  email,
  password,
  phone,
  nonEmptyString,
  dateISO,
  // add as needed:
  // intId: Joi.number().integer().positive(),
  // url: Joi.string().uri({ scheme: [/https?/] }),
};

/**
 * Example composed schemas you can import directly
 */
export const Schemas = {
  // Auth
  register: Joi.object({
    email: Fields.email.required(),
    password: Fields.password.required(),
    fullName: Fields.nonEmptyString.required(),
    phone: Fields.phone.optional(),
  }),

  login: Joi.object({
    email: Fields.email.required(),
    password: Joi.string().required(),
  }),

  // Users
  userCreate: Joi.object({
    email: Fields.email.required(),
    password: Fields.password.required(),
    firstName: Fields.nonEmptyString.required(),
    lastName: Fields.nonEmptyString.required(),
    phone: Fields.phone.optional(),
  }),

  userUpdate: Joi.object({
    email: Fields.email.optional(),
    firstName: Fields.nonEmptyString.optional(),
    lastName: Fields.nonEmptyString.optional(),
    phone: Fields.phone.optional(),
  }).min(1), // at least one field

  // Generic id param
  idParam: Joi.object({ id: Fields.uuid.required() }),

  // Pagination / filtering example
  paginationQuery: Joi.object({
    page: Joi.number().integer().min(1).default(1),
    pageSize: Joi.number().integer().min(1).max(200).default(25),
    search: Joi.string().trim().max(200).optional(),
    sortBy: Joi.string().trim().max(64).optional(),
    sortDir: Joi.string().valid('asc', 'desc').default('asc'),
  }),
} as const;

/**
 * Central validator helper (useful outside of Express too)
 */
export function validate<T>(
  value: unknown,
  schema: Schema,
  options: ValidationOptions = { abortEarly: false, stripUnknown: true }
): T {
  const { error, value: out } = schema.validate(value, options);
  if (error) {
    // Throw a structured error (you may map to your APIError)
    const details = error.details.map(d => d.message);
    throw new Error(`Validation failed: ${details.join('; ')}`);
  }
  return out as T;
}

/**
 * Express middlewares for validation
 */
type MiddlewareBuilder = (schema: Schema, options?: ValidationOptions) => RequestHandler;

export const validateBody: MiddlewareBuilder = (schema, options = { abortEarly: false, stripUnknown: true }) =>
  (req, _res, next) => {
    try {
      req.body = validate(req.body, schema, options);
      next();
    } catch (e) {
      next(e);
    }
  };

export const validateQuery: MiddlewareBuilder = (schema, options = { abortEarly: false, stripUnknown: true }) =>
  (req, _res, next) => {
    try {
      req.query = validate(req.query, schema, options);
      next();
    } catch (e) {
      next(e);
    }
  };

export const validateParams: MiddlewareBuilder = (schema, options = { abortEarly: false, stripUnknown: true }) =>
  (req, _res, next) => {
    try {
      req.params = validate(req.params, schema, options);
      next();
    } catch (e) {
      next(e);
    }
  };



====================================================================================================
  PIPELINE SERVICE - SRC
====================================================================================================


------------------------------------------------------------
FILE: backend\pipeline-service\src\app.ts
------------------------------------------------------------
import cors from 'cors';
import 'dotenv/config';
import express from 'express';
import helmet from 'helmet';
import morgan from 'morgan';

export const app = express();

const corsOrigin = process.env.CORS_ORIGIN || 'http://localhost:5173';
app.use(helmet());
app.use(cors({ origin: corsOrigin }));
app.use(express.json());
app.use(morgan('dev'));

app.get('/health', (_req, res) => {
  res.json({ service: process.env.SERVICE_NAME || 'pipeline-service', status: 'ok' });
});

app.get('/', (_req, res) => {
  res.json({ service: process.env.SERVICE_NAME || 'pipeline-service', message: 'Service up and running' });
});



------------------------------------------------------------
FILE: backend\pipeline-service\src\server.ts
------------------------------------------------------------
import { app } from './app.js';

const fallback = Number(process.env.FALLBACK_PORT || 3004);
const port = Number(process.env.PORT || fallback);

app.listen(port, () => {
  console.log(`[${process.env.SERVICE_NAME || 'pipeline-service'}] listening on :${port}`);
});



====================================================================================================
  NOTIFICATION SERVICE - SRC
====================================================================================================


------------------------------------------------------------
FILE: backend\notification-service\src\app.ts
------------------------------------------------------------
import cors from 'cors';
import 'dotenv/config';
import express from 'express';
import helmet from 'helmet';
import morgan from 'morgan';

export const app = express();

const corsOrigin = process.env.CORS_ORIGIN || 'http://localhost:5173';
app.use(helmet());
app.use(cors({ origin: corsOrigin }));
app.use(express.json());
app.use(morgan('dev'));

app.get('/health', (_req, res) => {
  res.json({ service: process.env.SERVICE_NAME || 'notification-service', status: 'ok' });
});

app.get('/', (_req, res) => {
  res.json({ service: process.env.SERVICE_NAME || 'notification-service', message: 'Service up and running' });
});



------------------------------------------------------------
FILE: backend\notification-service\src\server.ts
------------------------------------------------------------
import { app } from './app.js';

const fallback = Number(process.env.FALLBACK_PORT || 3007);
const port = Number(process.env.PORT || fallback);

app.listen(port, () => {
  console.log(`[${process.env.SERVICE_NAME || 'notification-service'}] listening on :${port}`);
});



====================================================================================================
  INTEGRATION SERVICE - SRC
====================================================================================================


------------------------------------------------------------
FILE: backend\integration-service\src\app.ts
------------------------------------------------------------
import cors from 'cors';
import 'dotenv/config';
import express from 'express';
import helmet from 'helmet';
import morgan from 'morgan';

export const app = express();

const corsOrigin = process.env.CORS_ORIGIN || 'http://localhost:5173';
app.use(helmet());
app.use(cors({ origin: corsOrigin }));
app.use(express.json());
app.use(morgan('dev'));

app.get('/health', (_req, res) => {
  res.json({ service: process.env.SERVICE_NAME || 'integration-service', status: 'ok' });
});

app.get('/', (_req, res) => {
  res.json({ service: process.env.SERVICE_NAME || 'integration-service', message: 'Service up and running' });
});



------------------------------------------------------------
FILE: backend\integration-service\src\server.ts
------------------------------------------------------------
import { app } from './app.js';

const fallback = Number(process.env.FALLBACK_PORT || 3006);
const port = Number(process.env.PORT || fallback);

app.listen(port, () => {
  console.log(`[${process.env.SERVICE_NAME || 'integration-service'}] listening on :${port}`);
});



====================================================================================================
  FRONTEND - SRC
====================================================================================================


------------------------------------------------------------
FILE: frontend\src\App.tsx
------------------------------------------------------------
import { Layout } from '@/components/layout'
import { AIAssistant } from '@/pages/AIAssistant'
import { Connections } from '@/pages/Connections'
import { Dashboard } from '@/pages/Dashboard'
import { DataCatalog } from '@/pages/DataCatalog'
import { DataLineage } from '@/pages/DataLineage'
import { DataQuality } from '@/pages/DataQuality'
import { Governance } from '@/pages/Governance'
import { Monitoring } from '@/pages/Monitoring'
import { Pipelines } from '@/pages/Pipelines'
import { Requests } from '@/pages/Requests'
import { Settings } from '@/pages/Settings'
import { Navigate, Route, Routes } from 'react-router-dom'

export default function App() {
  return (
    <Layout>
      <Routes>
        <Route path="/" element={<Navigate to="/dashboard" replace />} />
        <Route path="/dashboard" element={<Dashboard />} />
        <Route path="/ai-assistant" element={<AIAssistant />} />
        <Route path="/data-catalog" element={<DataCatalog />} />
        <Route path="/data-quality" element={<DataQuality />} />
        <Route path="/data-lineage" element={<DataLineage />} />
        <Route path="/pipelines" element={<Pipelines />} />
        <Route path="/requests" element={<Requests />} />
        <Route path="/connections" element={<Connections />} />
        <Route path="/governance" element={<Governance />} />
        <Route path="/monitoring" element={<Monitoring />} />
        <Route path="/settings" element={<Settings />} />
        <Route path="*" element={<Navigate to="/dashboard" replace />} />
      </Routes>
    </Layout>
  )
}



------------------------------------------------------------
FILE: frontend\src\common\ConfirmDialog.tsx
------------------------------------------------------------
export const ConfirmDialog=()=>null;


------------------------------------------------------------
FILE: frontend\src\common\DataTable.tsx
------------------------------------------------------------
export const DataTable=()=>null;


------------------------------------------------------------
FILE: frontend\src\common\ErrorBoundary.tsx
------------------------------------------------------------
export default function ErrorBoundary(){return null;}


------------------------------------------------------------
FILE: frontend\src\common\index.ts
------------------------------------------------------------
// barrel


------------------------------------------------------------
FILE: frontend\src\common\LoadingSpinner.tsx
------------------------------------------------------------
export const LoadingSpinner=()=>(<div className='animate-spin'>â³</div>);


------------------------------------------------------------
FILE: frontend\src\components\common\ConfirmDialog.tsx
------------------------------------------------------------
# Empty file


------------------------------------------------------------
FILE: frontend\src\components\common\DataTable.tsx
------------------------------------------------------------
# Empty file


------------------------------------------------------------
FILE: frontend\src\components\common\ErrorBoundary.tsx
------------------------------------------------------------
// src/components/common/ErrorBoundary.tsx
import * as React from 'react'

type Props = {
  children: React.ReactNode
  /** Optional custom fallback UI */
  fallback?: React.ReactNode
  /** Called when the user clicks â€œTry againâ€ */
  onReset?: () => void
}

type State = {
  hasError: boolean
  error?: Error
}

class ErrorBoundary extends React.Component<Props, State> {
  state: State = { hasError: false }

  static getDerivedStateFromError(error: Error): State {
    return { hasError: true, error }
  }

  componentDidCatch(error: Error, info: React.ErrorInfo) {
    // Log to your telemetry here (Sentry, Datadog, etc.)
    console.error('ErrorBoundary caught an error', error, info)
  }

  private handleReset = () => {
    this.setState({ hasError: false, error: undefined })
    this.props.onReset?.()
  }

  render() {
    if (this.state.hasError) {
      if (this.props.fallback) return <>{this.props.fallback}</>

      return (
        <div className="min-h-screen bg-gray-50 flex items-center justify-center p-6">
          <div className="max-w-md w-full rounded-2xl border border-gray-200 bg-white p-6 shadow-sm">
            <h2 className="text-lg font-semibold text-gray-900">Something went wrong</h2>
            <p className="mt-2 text-sm text-gray-600">
              The page crashed. You can try again or reload the app.
            </p>
            {this.state.error && (
              <pre className="mt-3 max-h-32 overflow-auto rounded bg-gray-100 p-2 text-xs text-gray-700">
                {this.state.error.message}
              </pre>
            )}
            <div className="mt-4 flex gap-2">
              <button
                type="button"
                onClick={this.handleReset}
                className="inline-flex items-center rounded-lg bg-blue-600 px-3 py-2 text-sm font-medium text-white hover:bg-blue-700"
              >
                Try again
              </button>
              <button
                type="button"
                onClick={() => window.location.reload()}
                className="inline-flex items-center rounded-lg border border-gray-300 bg-white px-3 py-2 text-sm font-medium text-gray-700 hover:bg-gray-50"
              >
                Reload
              </button>
            </div>
          </div>
        </div>
      )
    }

    return this.props.children
  }
}

export default ErrorBoundary
export { ErrorBoundary }




------------------------------------------------------------
FILE: frontend\src\components\common\index.ts
------------------------------------------------------------
# Empty file


------------------------------------------------------------
FILE: frontend\src\components\common\LoadingSpinner.tsx
------------------------------------------------------------
// src/components/common/LoadingSpinner.tsx
import React from 'react'

export type LoadingSpinnerProps = {
  size?: number
  color?: string
  className?: string
  /** Optional accessible label shown next to the spinner */
  label?: string
  /** If true, render inline (no block wrapper spacing) */
  inline?: boolean
}

export const LoadingSpinner: React.FC<LoadingSpinnerProps> = ({
  size = 24,
  color = 'currentColor',
  className = '',
  label,
  inline = false,
}) => {
  const content = (
    <>
      <svg
        className={`animate-spin ${label ? 'mr-2' : ''} ${className}`}
        width={size}
        height={size}
        viewBox="0 0 24 24"
        fill="none"
        role="img"
        aria-hidden={label ? 'true' : 'false'}
      >
        <circle cx="12" cy="12" r="10" stroke={color} strokeWidth="4" className="opacity-25" />
        <path d="M4 12a8 8 0 018-8v4a4 4 0 00-4 4H4z" fill={color} className="opacity-75" />
      </svg>
      {label ? (
        <span className="text-sm text-gray-700" aria-live="polite" aria-atomic="true">
          {label}
        </span>
      ) : null}
    </>
  )

  return inline ? (
    <span className="inline-flex items-center" role="status">
      {content}
    </span>
  ) : (
    <div className="flex items-center" role="status">
      {content}
    </div>
  )
}

export default LoadingSpinner



------------------------------------------------------------
FILE: frontend\src\components\features\ai-assistant\ActionButtons.tsx
------------------------------------------------------------
import React from 'react';

interface ActionButtonsProps {
  onClearChat: () => void;
  onRetry: () => void;
  disabled?: boolean;
  messageCount: number;
  characterCount: number;
  maxCharacters?: number;
}

export const ActionButtons: React.FC<ActionButtonsProps> = ({
  onClearChat,
  onRetry,
  disabled = false,
  messageCount,
  characterCount,
  maxCharacters = 500
}) => {
  return (
    <div className="action-buttons">
      <div className="button-group">
        <button
          onClick={onClearChat}
          disabled={disabled || messageCount === 0}
          className="action-btn clear-btn"
          title="Clear chat history"
        >
          ðŸ—‘ï¸ Clear Chat
        </button>
        
        <button
          onClick={onRetry}
          disabled={disabled || messageCount === 0}
          className="action-btn retry-btn"
          title="Retry last message"
        >
          ðŸ”„ Retry
        </button>
      </div>
      
      <div className="chat-info">
        <span className="message-count">
          Messages: {messageCount}
        </span>
        
        <span className={`character-count ${characterCount > maxCharacters * 0.9 ? 'warning' : ''}`}>
          {characterCount}/{maxCharacters}
        </span>
      </div>
    </div>
  );
};

// Default export for compatibility
export default ActionButtons;


------------------------------------------------------------
FILE: frontend\src\components\features\ai-assistant\ChatInterface.tsx
------------------------------------------------------------
// src/components/ai/ChatInterface.tsx
import aiAssistantService from '@/services/api/aiAssistant';
import {
  AlertTriangle,
  CheckCheck,
  Copy,
  Database,
  RotateCcw,
  Send,
  Shield,
  Sparkles,
  Trash2,
  Zap
} from 'lucide-react';
import React, { useCallback, useEffect, useMemo, useRef, useState } from 'react';

/* =========================
   Types / Props
   ========================= */
type MessageKind = 'user' | 'assistant' | 'system' | 'error';

interface AIMessage {
  id: string;
  type: MessageKind;
  content: string;
  timestamp: Date;
  metadata?: {
    processingTime?: number;
    confidence?: number;
    status?: 'sending' | 'delivered' | 'error';
  };
}

interface ChatInterfaceProps {
  className?: string;
  placeholder?: string;
  /** Hide internal header to avoid duplicate page headings */
  showHeader?: boolean; // default false
}

/* =========================
   Env / Feature flags
   ========================= */
const USE_BACKEND = import.meta.env.VITE_USE_AI_BACKEND === 'true';

/* =========================
   Utilities
   ========================= */
const cx = (...parts: Array<string | false | undefined | null>) =>
  parts.filter(Boolean).join(' ');

const fmtTime = (d: Date) =>
  d.toLocaleTimeString([], { hour: '2-digit', minute: '2-digit' });

/** Very small â€œnormalizerâ€ for backend responses */
const normalizeBackendResponse = (res: any): { text: string; meta?: any } => {
  if (!res) return { text: 'No response from AI service.' };

  const d = res.data ?? res; // allow raw or { data }
  const candidates = [
    typeof d?.message === 'string' ? d.message : undefined,
    typeof d?.text === 'string' ? d.text : undefined,
    typeof d?.answer === 'string' ? d.answer : undefined,
    typeof d?.results === 'string' ? d.results : undefined,
  ].filter((v) => typeof v === 'string' && v.trim().length > 0) as string[];

  if (candidates.length) {
    return { text: candidates[0], meta: res.meta };
  }

  // Render objects/arrays sensibly
  if (d?.results && typeof d.results === 'object') {
    return {
      text: '```json\n' + JSON.stringify(d.results, null, 2) + '\n```',
      meta: res.meta,
    };
  }

  if (res?.error?.message) {
    return { text: `âš ï¸ ${res.error.message}`, meta: res.meta };
  }
  return { text: 'No response from AI service.', meta: res.meta };
};

/* =========================
   Mock AI (unchanged logic)
   ========================= */
const mockAIService = {
  async sendMessage(content: string): Promise<{ message: string; processingTime: number; confidence: number }> {
    const processingTime = 1200 + Math.random() * 1800;
    await new Promise((r) => setTimeout(r, processingTime));

    const responses: Record<string, { message: string; confidence: number }> = {
      'show me data quality issues': {
        message: `ðŸ” **Data Quality Analysis Complete**

**Overall Quality Score: 87/100** âœ…

**Critical Issues Identified:**
â€¢ **Missing Values**: 234 records in customer_email (12.3% of dataset)
â€¢ **Duplicate Records**: 12 duplicate entries in orders table
â€¢ **Format Issues**: 5 invalid date formats in transaction_date field
â€¢ **Outliers**: 89 statistical outliers in revenue_amount column

**Quality Metrics by Category:**
ðŸ“Š **Completeness**: 94.2% (Target: 95%)
ðŸ“‹ **Validity**: 89.7% (Target: 92%)
ðŸ”„ **Consistency**: 91.3% (Target: 90%) âœ…
ðŸŽ¯ **Accuracy**: 85.8% (Target: 88%)

**Immediate Actions Required:**
1. âœ… Implement email validation rules for customer_email
2. âš ï¸ Add unique constraints to prevent order duplicates
3. ðŸ”§ Standardize date formats across all transaction tables
4. ðŸ“ˆ Review outlier detection thresholds for revenue data

**Estimated Fix Time**: 2-3 business days
**Impact**: Will improve overall data quality to 93/100`,
        confidence: 0.94,
      },
      'find sensitive data in my database': {
        message: `ðŸ›¡ï¸ **Sensitive Data Discovery Report**

**PII Detection Summary:**
Found **67,234 sensitive records** across 15 database tables

**Sensitive Data Breakdown:**
ðŸ”´ **Social Security Numbers**: 1,247 records
   â€¢ Tables: customers, employees, contractors
   â€¢ Encryption Status: âŒ Unencrypted

ðŸ’³ **Credit Card Numbers**: 892 records
   â€¢ Tables: payments, billing_history
   â€¢ Encryption Status: âš ï¸ Partially encrypted

ðŸ“§ **Email Addresses**: 45,123 records
   â€¢ Tables: customers, marketing_contacts, employees
   â€¢ Encryption Status: âŒ Plain text

**Compliance Status:**
ðŸŸ¡ **GDPR**: 67% compliant (Needs consent tracking)
ðŸŸ¡ **CCPA**: 72% compliant (Missing data deletion processes)
ðŸ”´ **PCI-DSS**: 23% compliant (Critical - credit card data exposed)
ðŸŸ¡ **HIPAA**: 58% compliant (Healthcare data needs encryption)

**Critical Actions (Within 24 Hours):**
1. ðŸš¨ **Immediate**: Encrypt all credit card data
2. ðŸ”’ **High Priority**: Implement data masking for SSNs
3. ðŸ“ **Required**: Add consent tracking for email collection
4. ðŸ—‚ï¸ **Compliance**: Establish data retention policies

**Risk Level**: HIGH - Potential regulatory fines up to $2.1M`,
        confidence: 0.96,
      },
      'generate quality rules for customer data': {
        message: `âš™ï¸ **AI-Generated Data Quality Rules**

**Customer Data Validation Rules Created:**

**1. Email Validation Rule**
\`\`\`sql
RULE: email_format_validation
REGEX: ^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$
APPLIES_TO: customer_email, contact_email, billing_email
SEVERITY: HIGH
\`\`\`

**2. Phone Number Standardization**
\`\`\`sql
RULE: phone_standardization
FORMAT: (XXX) XXX-XXXX
VALIDATION: LENGTH = 14 AND STARTS_WITH('(')
APPLIES_TO: phone_number, mobile_number, emergency_contact
SEVERITY: MEDIUM
\`\`\`

**Implementation Summary:**
âœ… **Rules Created**: 6 validation rules
ðŸ“Š **Coverage**: 98% of customer data fields
âš¡ **Performance Impact**: <2% query overhead
ðŸŽ¯ **Expected Quality Improvement**: 23% increase

**Deployment Status**: Ready for immediate implementation`,
        confidence: 0.91,
      },
      "what's the status of my pipelines?": {
        message: `ðŸ“Š **Real-Time Pipeline Status Dashboard**

**System Overview**: 8 of 10 pipelines operational

**ðŸŸ¢ HEALTHY PIPELINES (6)**

**Customer Data Sync Pipeline**
â€¢ Source: Salesforce â†’ Snowflake Data Warehouse
â€¢ Status: âœ… Running smoothly
â€¢ Last Execution: 2 minutes ago
â€¢ Records Processed: 45,231 (batched)
â€¢ Success Rate: 99.7%

**Transaction Processing Pipeline**
â€¢ Source: Payment Gateway â†’ PostgreSQL
â€¢ Status: âœ… Real-time processing
â€¢ Last Transaction: 15 seconds ago
â€¢ Records/Hour: 3,694 transactions
â€¢ Latency: 0.3s average

**ðŸ”´ FAILED PIPELINES (2)**

**Inventory Sync Pipeline**
â€¢ Source: ERP System â†’ Data Warehouse
â€¢ Status: âŒ Connection timeout
â€¢ Error: Database connection lost at 14:23
â€¢ **Action Required**: Manual intervention needed

**ðŸ“ˆ Performance Metrics (24h)**
â€¢ Total Records Processed: 2.3M
â€¢ Average Processing Time: 1.2 minutes
â€¢ Success Rate: 92.3%`,
        confidence: 0.88,
      },
      hello: {
        message: `ðŸ‘‹ **Welcome to CWIC AI Assistant!**

I'm your intelligent data governance companion, designed to help you navigate the complex world of data management with ease.

**ðŸ” Data Discovery & Cataloging**
â€¢ Automated discovery and lineage tracking
â€¢ Smart cataloging with AI-powered metadata

**ðŸ“Š Data Quality Management**
â€¢ Real-time monitoring and scoring
â€¢ Anomaly detection and validation rules

**ðŸ›¡ï¸ Compliance & Governance**
â€¢ PII/PHI discovery and classification
â€¢ GDPR / CCPA / HIPAA / PCI-DSS checks

**âš™ï¸ Pipeline & Workflow Management**
â€¢ Pipeline health monitoring
â€¢ Optimization recommendations

What would you like to explore first?`,
        confidence: 0.99,
      },
    };

    const lower = content.toLowerCase();
    for (const [key, resp] of Object.entries(responses)) {
      if (lower.includes(key)) {
        return { message: resp.message, processingTime, confidence: resp.confidence };
      }
    }
    return {
      message: `I understand you're asking about "${content}". Try topics like **"data quality issues"** or **"sensitive data discovery"**.`,
      processingTime,
      confidence: 0.85,
    };
  },
};

/* =========================
   Simple Markdown-ish renderer
   (bold, lists, code fences)
   ========================= */
const MarkdownBlock: React.FC<{ text: string }> = ({ text }) => {
  // Split by code fences ```lang\n...\n```
  const parts = useMemo(() => {
    const result: Array<{ kind: 'code' | 'text'; lang?: string; value: string }> = [];
    const fence = /```(\w+)?\n([\s\S]*?)```/g;
    let lastIndex = 0;
    let match: RegExpExecArray | null;

    while ((match = fence.exec(text))) {
      if (match.index > lastIndex) {
        result.push({ kind: 'text', value: text.slice(lastIndex, match.index) });
      }
      result.push({ kind: 'code', lang: match[1], value: match[2] });
      lastIndex = fence.lastIndex;
    }
    if (lastIndex < text.length) result.push({ kind: 'text', value: text.slice(lastIndex) });
    return result;
  }, [text]);

  const renderInline = (s: string) => {
    // **bold**
    const segments = s.split(/(\*\*.+?\*\*)/g);
    return segments.map((seg, i) =>
      seg.startsWith('**') && seg.endsWith('**') ? <strong key={i}>{seg.slice(2, -2)}</strong> : <React.Fragment key={i}>{seg}</React.Fragment>
    );
  };

  const renderText = (t: string) => {
    // split into lines and detect bullets
    return t.split('\n').map((line, i) => {
      if (!line.trim()) return <div key={i} className="h-1" />;

      const bullet = line.trim().match(/^(\*|-|â€¢)\s+/);
      if (bullet) {
        const content = line.trim().slice(bullet[0].length);
        return (
          <div key={i} className="pl-6 relative">
            <span className="absolute left-1 top-1.5 h-1.5 w-1.5 rounded-full bg-muted-foreground/70" />
            <span>{renderInline(content)}</span>
          </div>
        );
      }
      return <div key={i}>{renderInline(line)}</div>;
    });
  };

  return (
    <>
      {parts.map((p, idx) =>
        p.kind === 'code' ? (
          <pre
            key={idx}
            className="my-3 w-full overflow-x-auto rounded-lg bg-slate-900/95 p-3 text-slate-100 text-sm shadow-inner"
          >
            <div className="mb-2 text-xs uppercase tracking-wide opacity-60">{p.lang || 'code'}</div>
            <code>{p.value}</code>
          </pre>
        ) : (
          <div key={idx} className="space-y-1">
            {renderText(p.value)}
          </div>
        )
      )}
    </>
  );
};

/* =========================
   Hook: chat state
   ========================= */
const useAIChat = () => {
  const [messages, setMessages] = useState<AIMessage[]>([]);
  const [loading, setLoading] = useState(false);
  const [error, setError] = useState<string | null>(null);

  const sendMessage = useCallback(async (content: string) => {
    if (!content.trim()) return;

    const userMsg: AIMessage = {
      id: `m_${Date.now()}_${Math.random().toString(36).slice(2, 8)}`,
      type: 'user',
      content: content.trim(),
      timestamp: new Date(),
      metadata: { status: 'sending' },
    };

    setMessages((prev) => [...prev, userMsg]);
    setLoading(true);
    setError(null);

    try {
      let replyText = '';
      let processingTime = 0;
      let confidence: number | undefined;

      if (USE_BACKEND) {
        const res = await aiAssistantService.sendMessageWithFallback(content, {
          cacheKey: `q:${content}`,
        });
        const norm = normalizeBackendResponse(res);
        replyText = norm.text || '';
        processingTime = res?.meta?.processingTime ?? 0;
        confidence = res?.meta?.confidence;
      } else {
        const mock = await mockAIService.sendMessage(content);
        replyText = mock.message;
        processingTime = mock.processingTime;
        confidence = mock.confidence;
      }

      // Mark user message delivered
      setMessages((prev) =>
        prev.map((m) => (m.id === userMsg.id ? { ...m, metadata: { ...m.metadata, status: 'delivered' } } : m))
      );

      const assistantMsg: AIMessage = {
        id: `a_${Date.now()}_${Math.random().toString(36).slice(2, 8)}`,
        type: replyText ? 'assistant' : 'error',
        content: replyText || 'No response from AI service.',
        timestamp: new Date(),
        metadata: {
          processingTime,
          confidence,
          status: replyText ? 'delivered' : 'error',
        },
      };
      setMessages((prev) => [...prev, assistantMsg]);
    } catch (e: any) {
      setError(e?.message || 'Failed to get response.');
      setMessages((prev) =>
        prev.map((m) => (m.id === userMsg.id ? { ...m, metadata: { ...m.metadata, status: 'error' } } : m))
      );
    } finally {
      setLoading(false);
    }
  }, []);

  const clear = useCallback(() => {
    setMessages([]);
    setError(null);
  }, []);

  const retryLast = useCallback(() => {
    const lastUser = [...messages].reverse().find((m) => m.type === 'user');
    if (lastUser) sendMessage(lastUser.content);
  }, [messages, sendMessage]);

  return { messages, loading, error, sendMessage, clear, retryLast, isTyping: loading };
};

/* =========================
   Message bubble
   ========================= */
const MessageBubble: React.FC<{ message: AIMessage; onCopy?: (ok: boolean) => void }> = ({ message, onCopy }) => {
  const [copied, setCopied] = useState(false);
  const canCopy = message.type !== 'system';

  const handleCopy = async () => {
    try {
      await navigator.clipboard.writeText(message.content);
      setCopied(true);
      onCopy?.(true);
      setTimeout(() => setCopied(false), 1200);
    } catch {
      onCopy?.(false);
    }
  };

  const isUser = message.type === 'user';
  const isError = message.type === 'error';

  return (
    <div
      className={cx(
        'group relative mb-3 flex w-full',
        isUser ? 'justify-end' : 'justify-start'
      )}
    >
      <div
        className={cx(
          'max-w-[85%] rounded-2xl px-4 py-3 shadow-sm ring-1',
          isUser
            ? 'bg-violet-600 text-white ring-violet-600/20'
            : isError
            ? 'bg-rose-50 text-rose-900 ring-rose-200'
            : 'bg-white text-slate-900 ring-slate-200'
        )}
      >
        {/* Content */}
        <div className="prose prose-sm max-w-none prose-headings:my-2 prose-p:my-2 prose-strong:font-semibold prose-pre:my-0 prose-ul:my-2 prose-li:my-0">
          <MarkdownBlock text={message.content} />
        </div>

        {/* Meta row */}
        <div className={cx('mt-2 flex items-center gap-2 text-[11px]', isUser ? 'text-white/80' : 'text-slate-500')}>
          <span>{fmtTime(message.timestamp)}</span>
          {typeof message.metadata?.processingTime === 'number' && (
            <span>{Math.round(message.metadata.processingTime)}ms</span>
          )}
          {typeof message.metadata?.confidence === 'number' && (
            <span>{Math.round(message.metadata.confidence * 100)}%</span>
          )}
          {canCopy && (
            <button
              onClick={handleCopy}
              className={cx(
                'ml-auto inline-flex items-center gap-1 rounded-md px-2 py-0.5 text-[11px] transition',
                isUser
                  ? 'bg-white/15 hover:bg-white/25 active:bg-white/30'
                  : 'bg-slate-100 hover:bg-slate-200 active:bg-slate-300'
              )}
              title="Copy"
              aria-label="Copy message"
            >
              {copied ? <CheckCheck size={14} /> : <Copy size={14} />}
              {copied ? 'Copied' : 'Copy'}
            </button>
          )}
        </div>
      </div>
    </div>
  );
};

/* =========================
   Typing indicator
   ========================= */
const TypingIndicator: React.FC = () => (
  <div className="mb-3 flex w-full justify-start">
    <div className="rounded-2xl bg-white px-4 py-3 ring-1 ring-slate-200">
      <div className="flex items-center gap-2 text-slate-500">
        <div className="flex items-center gap-1">
          <span className="h-1.5 w-1.5 animate-bounce rounded-full bg-slate-400 [animation-delay:-200ms]" />
          <span className="h-1.5 w-1.5 animate-bounce rounded-full bg-slate-400" />
          <span className="h-1.5 w-1.5 animate-bounce rounded-full bg-slate-400 [animation-delay:200ms]" />
        </div>
        <span className="text-xs">AI is thinkingâ€¦</span>
      </div>
    </div>
  </div>
);

/* =========================
   Main component
   ========================= */
export const ChatInterface: React.FC<ChatInterfaceProps> = ({
  className,
  placeholder = 'Ask me anything about your dataâ€¦',
  showHeader = false, // avoid duplicate page titles by default
}) => {
  const [input, setInput] = useState('');
  const suggestions = useMemo(
    () => [
      'Show me data quality issues',
      'Find sensitive data in my database',
      'Generate quality rules for customer data',
      "Whatâ€™s the status of my pipelines?",
    ],
    []
  );

  const { messages, loading, error, sendMessage, clear, retryLast, isTyping } = useAIChat();
  const endRef = useRef<HTMLDivElement>(null);
  const inputRef = useRef<HTMLInputElement>(null);

  useEffect(() => {
    endRef.current?.scrollIntoView({ behavior: 'smooth' });
  }, [messages, isTyping]);

  const handleSend = useCallback(async () => {
    if (!input.trim() || loading) return;
    const msg = input.trim();
    setInput('');
    try {
      await sendMessage(msg);
    } catch {
      setInput(msg);
    }
  }, [input, loading, sendMessage]);

  const handleKeyDown = useCallback(
    (e: React.KeyboardEvent<HTMLInputElement>) => {
      if (e.key === 'Enter' && !e.shiftKey) {
        e.preventDefault();
        handleSend();
      }
    },
    [handleSend]
  );

  const handleSuggestion = useCallback(
    (s: string) => {
      setInput(s);
      setTimeout(() => handleSend(), 50);
    },
    [handleSend]
  );

  return (
    <div
      className={cx(
        'flex h-full min-h-[580px] w-full flex-col rounded-xl border border-slate-200 bg-slate-50/60',
        'shadow-sm backdrop-blur-[2px]',
        className
      )}
    >
      {/* Header (optional, subdued) */}
      {showHeader && (
        <div className="flex items-center justify-between border-b border-slate-200/80 px-4 py-3">
          <div className="flex items-center gap-3">
            <div className="flex h-8 w-8 items-center justify-center rounded-full bg-violet-600 text-white shadow">
              <Sparkles size={18} />
            </div>
            <div>
              <div className="text-sm font-semibold leading-tight">CWIC AI Assistant</div>
              <div className="text-xs text-slate-500 leading-tight">Your intelligent data governance companion</div>
            </div>
          </div>
          {messages.length > 0 && (
            <button
              onClick={clear}
              className="inline-flex items-center gap-2 rounded-md border border-slate-200 bg-white px-3 py-1.5 text-xs text-slate-700 hover:bg-slate-50"
              title="Clear conversation"
              aria-label="Clear conversation"
            >
              <Trash2 size={14} />
              Clear
            </button>
          )}
        </div>
      )}

      {/* Messages */}
      <div className="flex-1 overflow-y-auto px-4 py-4">
        {/* Empty welcome state */}
        {messages.length === 0 && (
          <div className="mb-4 rounded-xl border border-slate-200 bg-white p-5 shadow-sm">
            <div className="mb-4 flex items-center gap-3">
              <div className="flex h-9 w-9 items-center justify-center rounded-full bg-violet-600 text-white">
                <Sparkles size={18} />
              </div>
              <div>
                <div className="text-sm font-semibold">Welcome to CWIC AI</div>
                <div className="text-xs text-slate-500">
                  Ask about discovery, quality, compliance, or pipelines.
                </div>
              </div>
            </div>

            <div className="grid grid-cols-1 gap-3 sm:grid-cols-3">
              <div className="rounded-lg border border-slate-200 p-4">
                <Database className="mb-2 text-slate-600" size={28} />
                <div className="text-sm font-medium">Data Discovery</div>
                <div className="text-xs text-slate-500">Find and catalog data across sources</div>
              </div>
              <div className="rounded-lg border border-slate-200 p-4">
                <Zap className="mb-2 text-slate-600" size={28} />
                <div className="text-sm font-medium">Quality Analysis</div>
                <div className="text-xs text-slate-500">Monitor and improve data quality</div>
              </div>
              <div className="rounded-lg border border-slate-200 p-4">
                <Shield className="mb-2 text-slate-600" size={28} />
                <div className="text-sm font-medium">Compliance</div>
                <div className="text-xs text-slate-500">Ensure regulatory compliance</div>
              </div>
            </div>

            <div className="mt-4">
              <div className="mb-2 text-xs font-medium text-slate-600">Try asking:</div>
              <div className="flex flex-wrap gap-2">
                {suggestions.map((s) => (
                  <button
                    key={s}
                    onClick={() => handleSuggestion(s)}
                    className="rounded-full border border-slate-200 bg-white px-3 py-1.5 text-xs text-slate-700 hover:bg-slate-50"
                  >
                    {s}
                  </button>
                ))}
              </div>
            </div>
          </div>
        )}

        {/* Conversation */}
        {messages.map((m) => (
          <MessageBubble key={m.id} message={m} />
        ))}

        {isTyping && <TypingIndicator />}

        {error && (
          <div
            className="mt-3 flex items-center gap-2 rounded-md border border-amber-200 bg-amber-50 px-3 py-2 text-sm text-amber-800"
            role="alert"
          >
            <AlertTriangle size={16} />
            <span>{error}</span>
            <button
              onClick={retryLast}
              className="ml-auto inline-flex items-center gap-1 rounded-md border border-amber-200 bg-white px-2 py-1 text-xs text-amber-800 hover:bg-amber-50"
            >
              Retry
            </button>
          </div>
        )}

        <div ref={endRef} aria-hidden="true" />
      </div>

      {/* Composer */}
      <div className="border-t border-slate-200/80 bg-white/80 px-4 py-3">
        <div className="flex items-end gap-2">
          <div className="relative flex-1">
            <input
              ref={inputRef}
              type="text"
              value={input}
              onChange={(e) => setInput(e.target.value)}
              onKeyDown={handleKeyDown}
              placeholder={placeholder}
              disabled={loading}
              maxLength={500}
              aria-label="Message"
              className={cx(
                'w-full rounded-xl border border-slate-300 bg-white px-4 py-3 text-sm shadow-sm outline-none',
                'placeholder:text-slate-400 focus:border-violet-500 focus:ring-2 focus:ring-violet-200 disabled:opacity-60'
              )}
            />
            <div className="pointer-events-none absolute bottom-2 right-3 text-[11px] text-slate-400">
              {input.length}/500
            </div>
          </div>

          <button
            onClick={handleSend}
            disabled={!input.trim() || loading}
            className={cx(
              'inline-flex h-11 items-center justify-center gap-2 rounded-xl px-4 text-sm font-medium text-white shadow-sm transition',
              loading
                ? 'bg-violet-400'
                : 'bg-violet-600 hover:bg-violet-700 active:bg-violet-800'
            )}
            aria-label={loading ? 'Sending' : 'Send message'}
          >
            {loading ? <RotateCcw className="animate-spin" size={18} /> : <Send size={18} />}
            <span className="hidden sm:inline">{loading ? 'Sending' : 'Send'}</span>
          </button>
        </div>
        <div className="mt-1 text-[11px] text-slate-400">Press Enter to send</div>
      </div>
    </div>
  );
};

export default ChatInterface;



------------------------------------------------------------
FILE: frontend\src\components\features\ai-assistant\index.ts
------------------------------------------------------------
export { ActionButtons } from './ActionButtons';
export { ChatInterface } from './ChatInterface';
export { MessageBubble } from './MessageBubble';
export { TypingIndicator } from './TypingIndicator';

// Default exports for compatibility
export { default as ActionButtonsDefault } from './ActionButtons';
export { default as ChatInterfaceDefault } from './ChatInterface';
export { default as MessageBubbleDefault } from './MessageBubble';
export { default as TypingIndicatorDefault } from './TypingIndicator';

// Types
export type { AIMessage } from './MessageBubble';



------------------------------------------------------------
FILE: frontend\src\components\features\ai-assistant\MessageBubble.tsx
------------------------------------------------------------
import React from 'react';

export interface AIMessage {
  id: string;
  type: 'user' | 'assistant' | 'system';
  content: string;
  timestamp: Date | string;
  metadata?: {
    processingTime?: number;
    confidence?: number;   // 0..1
    sources?: string[];
  };
}

export interface MessageBubbleProps {
  message: AIMessage;
  showMetadata?: boolean;
}

export const MessageBubble: React.FC<MessageBubbleProps> = ({ message, showMetadata = false }) => {
  const isUser = message.type === 'user';
  const ts = message.timestamp instanceof Date ? message.timestamp : new Date(message.timestamp);

  const formatTime = (d: Date) => d.toLocaleTimeString([], { hour: '2-digit', minute: '2-digit' });

  const lines = String(message.content || '').split('\n');

  const hasProcessing = typeof message.metadata?.processingTime === 'number';
  const hasConfidence = typeof message.metadata?.confidence === 'number';
  const hasSources   = Array.isArray(message.metadata?.sources) && message.metadata!.sources!.length > 0;

  return (
    <div className={`message-bubble ${isUser ? 'user' : 'assistant'}`}>
      <div className="message-content">
        <div className="message-text">
          {lines.map((line, i) => (
            <React.Fragment key={i}>
              {line}{i < lines.length - 1 && <br />}
            </React.Fragment>
          ))}
        </div>

        <div className="message-meta">
          <span className="timestamp">{formatTime(ts)}</span>
          {showMetadata && (
            <>
              {hasProcessing && <span className="processing-time">{message.metadata!.processingTime}ms</span>}
              {hasConfidence && (
                <span className="confidence">
                  {Math.round((message.metadata!.confidence as number) * 100)}% confident
                </span>
              )}
              {hasSources && <span className="sources">Sources: {message.metadata!.sources!.join(', ')}</span>}
            </>
          )}
        </div>
      </div>
    </div>
  );
};

export default MessageBubble;



------------------------------------------------------------
FILE: frontend\src\components\features\ai-assistant\TypingIndicator.tsx
------------------------------------------------------------
import React from 'react';

interface TypingIndicatorProps {
  className?: string;
  message?: string;
}

export const TypingIndicator: React.FC<TypingIndicatorProps> = ({ 
  className = '', 
  message = 'AI is thinking...' 
}) => {
  return (
    <div className={`typing-indicator ${className}`}>
      <div className="typing-bubble">
        <div className="typing-dots">
          <span className="dot"></span>
          <span className="dot"></span>
          <span className="dot"></span>
        </div>
        <div className="typing-message">{message}</div>
      </div>
    </div>
  );
};

// Default export for compatibility
export default TypingIndicator;


------------------------------------------------------------
FILE: frontend\src\components\features\connections\ConnectionForm.tsx
------------------------------------------------------------
import type { DataSource, DataSourceType } from '@/types/dataSources'
import { Button } from '@components/ui/Button'
import { Card, CardContent, CardHeader, CardTitle } from '@components/ui/Card'
import { Input } from '@components/ui/Input'
import { Select } from '@components/ui/Select'
import * as React from 'react'

export interface ConnectionFormProps {
  initial?: Partial<DataSource>
  onSave?: (draft: Partial<DataSource>) => Promise<void> | void
  onClose?: () => void // <-- make onClose valid; your page is passing it
}

export function ConnectionForm({ initial, onSave, onClose }: ConnectionFormProps) {
  const [draft, setDraft] = React.useState<Partial<DataSource>>({
    name: initial?.name ?? '',
    type: (initial?.type as DataSourceType) ?? 'azure-sql',
    host: initial?.host ?? '',
    database: initial?.database ?? '',
    schema: initial?.schema ?? '',
    username: initial?.username ?? '',
  })

  function patch<K extends keyof DataSource>(k: K, v: DataSource[K] | string) {
    setDraft((d) => ({ ...d, [k]: v as any }))
  }

  async function submit(e: React.FormEvent) {
    e.preventDefault()
    await onSave?.(draft)
  }

  return (
    <Card>
      <CardHeader>
        <CardTitle>{initial?.id ? 'Edit Connection' : 'New Connection'}</CardTitle>
      </CardHeader>
      <CardContent>
        <form className="space-y-4" onSubmit={submit}>
          <Input placeholder="Name" value={draft.name ?? ''} onChange={(e) => patch('name', e.target.value)} />
          <Select
            label="Type"
            value={(draft.type as string) ?? 'azure-sql'}
            onChange={(e) => patch('type', e.target.value)}
            options={[
              { label: 'Azure SQL', value: 'azure-sql' },
              { label: 'Synapse', value: 'synapse' },
              { label: 'Fabric', value: 'fabric' },
              { label: 'Data Lake', value: 'data-lake' },
              { label: 'Postgres', value: 'postgres' },
              { label: 'Snowflake', value: 'snowflake' },
            ]}
          />
          <div className="grid gap-3 sm:grid-cols-2">
            <Input placeholder="Host" value={draft.host ?? ''} onChange={(e) => patch('host', e.target.value)} />
            <Input placeholder="Database" value={draft.database ?? ''} onChange={(e) => patch('database', e.target.value)} />
            <Input placeholder="Schema" value={draft.schema ?? ''} onChange={(e) => patch('schema', e.target.value)} />
            <Input placeholder="Username" value={draft.username ?? ''} onChange={(e) => patch('username', e.target.value)} />
          </div>

          <div className="flex justify-end gap-2">
            <Button variant="outline" type="button" onClick={onClose}>Cancel</Button>
            <Button type="submit">Save</Button>
          </div>
        </form>
      </CardContent>
    </Card>
  )
}



------------------------------------------------------------
FILE: frontend\src\components\features\connections\DataSourceList.tsx
------------------------------------------------------------
import type { DataSource } from '@/types/dataSources'
import { Badge } from '@components/ui/Badge'
import { Card, CardContent } from '@components/ui/Card'

export function DataSourceList({
  items = [],
  onSelect,
}: {
  items?: DataSource[]
  onSelect?: (id: string) => void
}) {
  if (!items.length) {
    return <div className="text-sm text-gray-600">No data sources connected.</div>
  }
  return (
    <div className="grid grid-cols-1 gap-4 md:grid-cols-2 xl:grid-cols-3">
      {items.map((ds) => (
        <Card
          key={ds.id}
          className="cursor-pointer transition hover:shadow-sm"
          onClick={() => onSelect?.(ds.id)}
          role="button"
          tabIndex={0}
          onKeyDown={(e) => (e.key === 'Enter' || e.key === ' ') && onSelect?.(ds.id)}
        >
          <CardContent className="p-5">
            <div className="flex items-start justify-between">
              <div className="min-w-0">
                <div className="truncate text-base font-semibold text-gray-900">{ds.name}</div>
                <div className="mt-1 text-sm text-gray-600">{ds.host ?? 'â€”'}</div>
              </div>
              <div className="text-right">
                <Badge tone="neutral" className="capitalize">{ds.type}</Badge>
                {ds.status && (
                  <div className="mt-2">
                    <Badge tone={ds.status === 'healthy' ? 'success' : ds.status === 'warning' ? 'warning' : 'danger'}>
                      {ds.status}
                    </Badge>
                  </div>
                )}
              </div>
            </div>
            {ds.updatedAt && (
              <div className="mt-3 text-xs text-gray-500">Updated {new Date(ds.updatedAt).toLocaleString()}</div>
            )}
          </CardContent>
        </Card>
      ))}
    </div>
  )
}



------------------------------------------------------------
FILE: frontend\src\components\features\connections\HealthMonitor.tsx
------------------------------------------------------------
import type { DataSource } from '@/types/dataSources';
import { Card, CardContent, CardHeader, CardTitle } from '@components/ui/Card';
import * as React from 'react';

type LegacyItem = { name: string; status: 'up' | 'down'; latencyMs?: number }

type Props =
  | { dataSources: DataSource[]; items?: never }
  | { items: LegacyItem[]; dataSources?: never }
  | { dataSources?: DataSource[]; items?: LegacyItem[] } // allow both; dataSources wins

export function HealthMonitor(props: Props) {
  // Normalize to a single render shape
  const normalized: LegacyItem[] = React.useMemo(() => {
    if (props.dataSources && props.dataSources.length) {
      return props.dataSources.map((ds) => ({
        name: ds.name,
        status: ds.status === 'down' || ds.status === 'error' ? 'down' : 'up',
        latencyMs:
          typeof ds.metadata === 'object' && ds.metadata
            ? (ds.metadata['latencyMs'] as number | undefined)
            : undefined,
      }))
    }
    return (props.items ?? []).map((x) => ({ ...x }))
  }, [props])

  const totals = React.useMemo(() => {
    const total = normalized.length
    const up = normalized.filter((i) => i.status === 'up').length
    const down = total - up
    return { total, up, down }
  }, [normalized])

  return (
    <Card>
      <CardHeader>
        <div className="flex items-center justify-between">
          <CardTitle>Health Monitor</CardTitle>
          <div className="text-sm text-gray-600">
            Total: <strong>{totals.total}</strong> Â· Up: <strong className="text-green-600">{totals.up}</strong> Â· Down:{' '}
            <strong className="text-red-600">{totals.down}</strong>
          </div>
        </div>
      </CardHeader>
      <CardContent>
        {normalized.length === 0 ? (
          <div className="text-sm text-gray-600">No sources to monitor.</div>
        ) : (
          <div className="overflow-x-auto">
            <table className="min-w-full text-sm">
              <thead className="text-left text-gray-500">
                <tr>
                  <th className="py-2 pr-4">Source</th>
                  <th className="py-2 pr-4">Status</th>
                  <th className="py-2 pr-4">Latency</th>
                </tr>
              </thead>
              <tbody>
                {normalized.map((i) => (
                  <tr key={i.name} className="border-t">
                    <td className="py-2 pr-4 font-medium text-gray-900">{i.name}</td>
                    <td className="py-2 pr-4">
                      <span
                        className={[
                          'inline-flex items-center rounded-full px-2 py-0.5 text-xs font-medium',
                          i.status === 'up'
                            ? 'bg-green-100 text-green-800'
                            : 'bg-red-100 text-red-800',
                        ].join(' ')}
                      >
                        <span
                          className={[
                            'mr-1 inline-block h-2 w-2 rounded-full',
                            i.status === 'up' ? 'bg-green-500' : 'bg-red-500',
                          ].join(' ')}
                        />
                        {i.status}
                      </span>
                    </td>
                    <td className="py-2 pr-4">
                      {typeof i.latencyMs === 'number' ? `${i.latencyMs} ms` : 'â€”'}
                    </td>
                  </tr>
                ))}
              </tbody>
            </table>
          </div>
        )}
      </CardContent>
    </Card>
  )
}

export default HealthMonitor



------------------------------------------------------------
FILE: frontend\src\components\features\connections\index.ts
------------------------------------------------------------
export { ConnectionForm } from './ConnectionForm'
export { ConnectionTest } from './ConnectionTest'
export { DataSourceList } from './DataSourceList'
export { HealthMonitor } from './HealthMonitor'




------------------------------------------------------------
FILE: frontend\src\components\features\dashboard\ActivityFeed.tsx
------------------------------------------------------------
import { Badge } from '@components/ui/Badge'
import { Card, CardContent, CardHeader, CardTitle } from '@components/ui/Card'

export type Activity = {
  id: string
  time: string            // ISO
  title: string
  detail?: string
  type?: 'info' | 'success' | 'warning' | 'error'
}

export interface ActivityFeedProps {
  items?: Activity[]
  emptyText?: string
  title?: string
  loading?: boolean
}

export function ActivityFeed({
  items = [],
  emptyText = 'No recent activity.',
  title = 'Recent Activity',
  loading,
}: ActivityFeedProps) {
  return (
    <Card>
      <CardHeader>
        <CardTitle>{title}</CardTitle>
      </CardHeader>
      <CardContent>
        {loading ? (
          <ul className="divide-y">
            {Array.from({ length: 5 }).map((_, i) => (
              <li key={i} className="py-3">
                <div className="h-4 w-56 rounded bg-gray-200 animate-pulse" />
                <div className="mt-2 h-4 w-72 rounded bg-gray-200 animate-pulse" />
              </li>
            ))}
          </ul>
        ) : items.length === 0 ? (
          <div className="text-sm text-gray-600">{emptyText}</div>
        ) : (
          <ul className="divide-y">
            {items.map((a) => (
              <li key={a.id} className="py-3">
                <div className="flex items-start justify-between gap-3">
                  <div>
                    <div className="text-sm font-medium text-gray-900">{a.title}</div>
                    {a.detail && <div className="text-sm text-gray-600">{a.detail}</div>}
                  </div>
                  <div className="flex items-center gap-2">
                    {a.type && <Badge tone={mapTone(a.type)}>{a.type}</Badge>}
                    <span className="text-xs text-gray-500">{fmt(a.time)}</span>
                  </div>
                </div>
              </li>
            ))}
          </ul>
        )}
      </CardContent>
    </Card>
  )
}

function mapTone(t: NonNullable<Activity['type']>) {
  return t === 'success' ? 'success'
    : t === 'warning' ? 'warning'
    : t === 'error' ? 'danger'
    : 'info'
}
function fmt(iso: string) {
  try { return new Date(iso).toLocaleString() } catch { return iso }
}



------------------------------------------------------------
FILE: frontend\src\components\features\dashboard\DashboardOverview.tsx
------------------------------------------------------------
import type { Activity } from './ActivityFeed'
import { ActivityFeed } from './ActivityFeed'
import type { KPI } from './KPICards'
import { KPICards } from './KPICards'
import { QuickActions } from './QuickActions'

export interface DashboardOverviewProps {
  kpis: KPI[]
  activities: Activity[]
  loadingKpis?: boolean
  loadingActivity?: boolean
  onNewScan?: () => void
  onRefresh?: () => void
  onImport?: () => void
}

/** A layout helper that arranges KPI, actions, and activity into a single section */
export function DashboardOverview({
  kpis,
  activities,
  loadingKpis,
  loadingActivity,
  onNewScan,
  onRefresh,
  onImport,
}: DashboardOverviewProps) {
  return (
    <div className="space-y-6">
      <KPICards items={kpis} loading={loadingKpis} />
      <QuickActions onNewScan={onNewScan} onRefresh={onRefresh} onImport={onImport} />
      <ActivityFeed items={activities} loading={loadingActivity} />
    </div>
  )
}



------------------------------------------------------------
FILE: frontend\src\components\features\dashboard\index.ts
------------------------------------------------------------
export { KPICards } from './KPICards'
export type { KPI } from './KPICards'

export { ActivityFeed } from './ActivityFeed'
export type { Activity } from './ActivityFeed'

export { DashboardOverview } from './DashboardOverview'
export { QuickActions } from './QuickActions'




------------------------------------------------------------
FILE: frontend\src\components\features\dashboard\KPICards.tsx
------------------------------------------------------------
import { Badge } from '@components/ui/Badge'
import { Card, CardContent } from '@components/ui/Card'
import { Activity, Database, Shield, Users } from 'lucide-react'

export type Trend = 'up' | 'down' | 'flat'

export interface KPI {
  id: string
  label: string
  value: number | string
  diff?: number // percentage points
  trend?: Trend
  icon?: 'activity' | 'shield' | 'database' | 'users'
  tone?: 'default' | 'success' | 'warning' | 'danger' | 'info' | 'neutral'
}

export interface KPICardsProps {
  items: KPI[]
  loading?: boolean
}

export function KPICards({ items, loading }: KPICardsProps) {
  if (loading) return <KPISkeleton />
  return (
    <div className="grid grid-cols-1 gap-4 md:grid-cols-2 xl:grid-cols-4">
      {items.map((k) => (
        <Card key={k.id} className="transition hover:shadow-sm">
          <CardContent className="p-5">
            <div className="flex items-center justify-between">
              <div className="text-sm text-gray-600">{k.label}</div>
              <Icon name={k.icon} />
            </div>

            <div className="mt-2 text-2xl font-semibold text-gray-900">{k.value}</div>

            {typeof k.diff === 'number' && (
              <div className="mt-2">
                <Badge tone={diffTone(k.trend)}>{diffLabel(k.diff, k.trend)}</Badge>
              </div>
            )}
          </CardContent>
        </Card>
      ))}
    </div>
  )
}

function Icon({ name }: { name?: KPI['icon'] }) {
  const cls = 'h-6 w-6 text-blue-600'
  if (name === 'shield') return <Shield className={cls} />
  if (name === 'database') return <Database className={cls} />
  if (name === 'users') return <Users className={cls} />
  return <Activity className={cls} />
}

function diffLabel(diff: number, trend?: Trend) {
  const sign = trend === 'down' ? 'âˆ’' : trend === 'up' ? '+' : ''
  return `${sign}${Math.abs(diff).toFixed(1)}%`
}
function diffTone(trend?: Trend): NonNullable<KPI['tone']> {
  if (trend === 'up') return 'success'
  if (trend === 'down') return 'danger'
  return 'neutral'
}

function KPISkeleton() {
  return (
    <div className="grid grid-cols-1 gap-4 md:grid-cols-2 xl:grid-cols-4">
      {Array.from({ length: 4 }).map((_, i) => (
        <Card key={i}>
          <CardContent className="p-5">
            <div className="flex items-center justify-between">
              <div className="h-4 w-24 animate-pulse rounded bg-gray-200" />
              <div className="h-6 w-6 animate-pulse rounded bg-gray-200" />
            </div>
            <div className="mt-2 h-7 w-20 animate-pulse rounded bg-gray-200" />
            <div className="mt-2 h-5 w-16 animate-pulse rounded bg-gray-200" />
          </CardContent>
        </Card>
      ))}
    </div>
  )
}



------------------------------------------------------------
FILE: frontend\src\components\features\dashboard\QuickActions.tsx
------------------------------------------------------------
import { Button } from '@components/ui/Button'
import { Card, CardContent, CardHeader, CardTitle } from '@components/ui/Card'
import { Play, RefreshCcw, Upload } from 'lucide-react'

export interface QuickActionsProps {
  onNewScan?: () => void
  onRefresh?: () => void
  onImport?: () => void
  busy?: boolean
}

export function QuickActions({ onNewScan, onRefresh, onImport, busy }: QuickActionsProps) {
  return (
    <Card>
      <CardHeader>
        <CardTitle>Quick Actions</CardTitle>
      </CardHeader>
      <CardContent className="flex flex-wrap gap-3">
        <Button onClick={onNewScan} disabled={busy} leftIcon={<Play className="h-4 w-4" />}>
          Start New Scan
        </Button>
        <Button variant="outline" onClick={onRefresh} disabled={busy} leftIcon={<RefreshCcw className="h-4 w-4" />}>
          Refresh Data
        </Button>
        <Button variant="secondary" onClick={onImport} disabled={busy} leftIcon={<Upload className="h-4 w-4" />}>
          Import Metadata
        </Button>
      </CardContent>
    </Card>
  )
}



------------------------------------------------------------
FILE: frontend\src\components\features\data-catalog\AssetAnalytics.tsx
------------------------------------------------------------
// src/components/features/data-catalog/AssetAnalytics.tsx - Fixed version
import { Button } from '@/components/ui/Button';
import { BarChart3, Calendar, PieChart, TrendingDown, TrendingUp, X } from 'lucide-react';
import React, { useState } from 'react';

interface AssetAnalyticsProps {
  metrics: {
    totalAssets: number;
    activeUsers: number;
    dailyViews: number;
    qualityScore: number;
    usageByType: Record<string, number>;
    qualityDistribution: Record<string, number>;
    recentActivity: Array<{
      date: string;
      views: number;
      searches: number;
      creations: number;
    }>;
  } | null;
  trends: {
    totalAssets?: { value: number; direction: 'up' | 'down'; period: string };
    activeUsers?: { value: number; direction: 'up' | 'down'; period: string };
    qualityScore?: { value: number; direction: 'up' | 'down'; period: string };
  } | null;
  filters: any;
  onClose: () => void;
}

export const AssetAnalytics: React.FC<AssetAnalyticsProps> = ({
  metrics,
  trends,
  filters,
  onClose
}) => {
  const [timeRange, setTimeRange] = useState('7d');
  const [chartType, setChartType] = useState('usage');

  if (!metrics) {
    return (
      <div className="bg-white border border-gray-200 rounded-lg p-6">
        <div className="flex items-center justify-between mb-4">
          <h3 className="text-lg font-medium text-gray-900">Analytics Dashboard</h3>
          <button onClick={onClose} className="text-gray-400 hover:text-gray-600">
            <X className="h-5 w-5" />
          </button>
        </div>
        <div className="text-center py-8">
          <BarChart3 className="mx-auto h-12 w-12 text-gray-400 mb-4" />
          <p className="text-gray-500">Loading analytics data...</p>
        </div>
      </div>
    );
  }

  const renderUsageChart = () => (
    <div className="space-y-4">
      <h4 className="text-sm font-medium text-gray-900">Usage by Asset Type</h4>
      <div className="space-y-2">
        {Object.entries(metrics.usageByType).map(([type, count]) => {
          const percentage = (count / metrics.totalAssets) * 100;
          return (
            <div key={type} className="flex items-center space-x-3">
              <div className="w-20 text-sm text-gray-600 capitalize">{type}</div>
              <div className="flex-1 bg-gray-200 rounded-full h-2">
                <div 
                  className="bg-blue-600 h-2 rounded-full transition-all duration-300"
                  style={{ width: `${percentage}%` }}
                />
              </div>
              <div className="w-16 text-sm text-gray-900 text-right">
                {count} ({percentage.toFixed(1)}%)
              </div>
            </div>
          );
        })}
      </div>
    </div>
  );

  const renderQualityChart = () => (
    <div className="space-y-4">
      <h4 className="text-sm font-medium text-gray-900">Quality Distribution</h4>
      <div className="space-y-2">
        {Object.entries(metrics.qualityDistribution).map(([quality, count]) => {
          const percentage = (count / metrics.totalAssets) * 100;
          const colorMap: Record<string, string> = {
            high: 'bg-green-600',
            medium: 'bg-yellow-600',
            low: 'bg-red-600'
          };
          return (
            <div key={quality} className="flex items-center space-x-3">
              <div className="w-20 text-sm text-gray-600 capitalize">{quality}</div>
              <div className="flex-1 bg-gray-200 rounded-full h-2">
                <div 
                  className={`h-2 rounded-full transition-all duration-300 ${colorMap[quality] || 'bg-gray-400'}`}
                  style={{ width: `${percentage}%` }}
                />
              </div>
              <div className="w-16 text-sm text-gray-900 text-right">
                {count} ({percentage.toFixed(1)}%)
              </div>
            </div>
          );
        })}
      </div>
    </div>
  );

  const renderActivityChart = () => (
    <div className="space-y-4">
      <h4 className="text-sm font-medium text-gray-900">Recent Activity</h4>
      <div className="space-y-3">
        {metrics.recentActivity.slice(0, 7).map((activity, index) => (
          <div key={index} className="flex items-center justify-between p-3 bg-gray-50 rounded-lg">
            <div className="text-sm text-gray-600">
              {new Date(activity.date).toLocaleDateString()}
            </div>
            <div className="flex space-x-4 text-sm">
              <span className="text-blue-600">{activity.views} views</span>
              <span className="text-green-600">{activity.searches} searches</span>
              <span className="text-purple-600">{activity.creations} created</span>
            </div>
          </div>
        ))}
      </div>
    </div>
  );

  return (
    <div className="bg-white border border-gray-200 rounded-lg p-6 mb-6">
      {/* Header */}
      <div className="flex items-center justify-between mb-6">
        <div className="flex items-center space-x-3">
          <BarChart3 className="h-6 w-6 text-blue-600" />
          <h3 className="text-lg font-medium text-gray-900">Analytics Dashboard</h3>
        </div>
        <div className="flex items-center space-x-3">
          <select
            value={timeRange}
            onChange={(e) => setTimeRange(e.target.value)}
            className="text-sm border border-gray-300 rounded-md px-3 py-1 focus:outline-none focus:ring-2 focus:ring-blue-500"
          >
            <option value="1d">Last 24 hours</option>
            <option value="7d">Last 7 days</option>
            <option value="30d">Last 30 days</option>
            <option value="90d">Last 90 days</option>
          </select>
          <button 
            onClick={onClose} 
            className="text-gray-400 hover:text-gray-600 p-1 rounded-md hover:bg-gray-100"
          >
            <X className="h-5 w-5" />
          </button>
        </div>
      </div>

      {/* Key Metrics */}
      <div className="grid grid-cols-2 md:grid-cols-4 gap-4 mb-6">
        <div className="text-center p-4 bg-blue-50 rounded-lg">
          <div className="text-2xl font-bold text-blue-900">{metrics.totalAssets.toLocaleString()}</div>
          <div className="text-sm text-blue-700">Total Assets</div>
          {trends?.totalAssets && (
            <div className="flex items-center justify-center mt-1">
              {trends.totalAssets.direction === 'up' ? (
                <TrendingUp className="h-3 w-3 text-green-500 mr-1" />
              ) : (
                <TrendingDown className="h-3 w-3 text-red-500 mr-1" />
              )}
              <span className="text-xs text-gray-600">
                {trends.totalAssets.value}% {trends.totalAssets.period}
              </span>
            </div>
          )}
        </div>

        <div className="text-center p-4 bg-green-50 rounded-lg">
          <div className="text-2xl font-bold text-green-900">{metrics.activeUsers.toLocaleString()}</div>
          <div className="text-sm text-green-700">Active Users</div>
          {trends?.activeUsers && (
            <div className="flex items-center justify-center mt-1">
              {trends.activeUsers.direction === 'up' ? (
                <TrendingUp className="h-3 w-3 text-green-500 mr-1" />
              ) : (
                <TrendingDown className="h-3 w-3 text-red-500 mr-1" />
              )}
              <span className="text-xs text-gray-600">
                {trends.activeUsers.value}% {trends.activeUsers.period}
              </span>
            </div>
          )}
        </div>

        <div className="text-center p-4 bg-purple-50 rounded-lg">
          <div className="text-2xl font-bold text-purple-900">{metrics.dailyViews.toLocaleString()}</div>
          <div className="text-sm text-purple-700">Daily Views</div>
        </div>

        <div className="text-center p-4 bg-yellow-50 rounded-lg">
          <div className="text-2xl font-bold text-yellow-900">{metrics.qualityScore}%</div>
          <div className="text-sm text-yellow-700">Quality Score</div>
          {trends?.qualityScore && (
            <div className="flex items-center justify-center mt-1">
              {trends.qualityScore.direction === 'up' ? (
                <TrendingUp className="h-3 w-3 text-green-500 mr-1" />
              ) : (
                <TrendingDown className="h-3 w-3 text-red-500 mr-1" />
              )}
              <span className="text-xs text-gray-600">
                {trends.qualityScore.value}% {trends.qualityScore.period}
              </span>
            </div>
          )}
        </div>
      </div>

      {/* Chart Selection - Fixed variant types */}
      <div className="flex space-x-2 mb-6">
        <Button
          variant={chartType === 'usage' ? 'default' : 'outline'}
          size="sm"
          onClick={() => setChartType('usage')}
        >
          <PieChart className="mr-2 h-4 w-4" />
          Usage
        </Button>
        <Button
          variant={chartType === 'quality' ? 'default' : 'outline'}
          size="sm"
          onClick={() => setChartType('quality')}
        >
          <BarChart3 className="mr-2 h-4 w-4" />
          Quality
        </Button>
        <Button
          variant={chartType === 'activity' ? 'default' : 'outline'}
          size="sm"
          onClick={() => setChartType('activity')}
        >
          <Calendar className="mr-2 h-4 w-4" />
          Activity
        </Button>
      </div>

      {/* Charts */}
      <div className="bg-gray-50 rounded-lg p-4">
        {chartType === 'usage' && renderUsageChart()}
        {chartType === 'quality' && renderQualityChart()}
        {chartType === 'activity' && renderActivityChart()}
      </div>
    </div>
  );
};


------------------------------------------------------------
FILE: frontend\src\components\features\data-catalog\AssetCard.tsx
------------------------------------------------------------
import { Badge } from '@components/ui/Badge'
import { Card, CardContent } from '@components/ui/Card'
import { cn } from '@utils'

export type Asset = {
  id: string
  name: string
  description?: string
  type?: 'table' | 'view' | 'file' | 'dashboard' | 'ml-model' | string
  owner?: string
  tags?: string[]
  updatedAt?: string
  qualityScore?: number
}

export interface AssetCardProps {
  asset: Asset
  onClick?: (id: string) => void
  className?: string
}

export function AssetCard({ asset, onClick, className }: AssetCardProps) {
  const tone = typeof asset.qualityScore === 'number'
    ? asset.qualityScore >= 90 ? 'success'
      : asset.qualityScore >= 75 ? 'warning'
      : 'danger'
    : 'neutral'

  return (
    <Card
      className={cn('cursor-pointer transition hover:shadow-md', className)}
      onClick={() => onClick?.(asset.id)}
      role="button"
      tabIndex={0}
      onKeyDown={(e) => (e.key === 'Enter' || e.key === ' ') && onClick?.(asset.id)}
    >
      <CardContent className="p-5">
        <div className="flex items-start justify-between gap-3">
          <div className="min-w-0">
            <div className="truncate text-base font-semibold text-gray-900">{asset.name}</div>
            {asset.description && (
              <div className="mt-1 line-clamp-2 text-sm text-gray-600">{asset.description}</div>
            )}
            <div className="mt-2 flex flex-wrap gap-1">
              {asset.tags?.slice(0, 4).map((t) => (
                <span key={t} className="rounded bg-gray-100 px-2 py-0.5 text-[11px] text-gray-700">{t}</span>
              ))}
              {asset.tags && asset.tags.length > 4 && (
                <span className="rounded bg-gray-100 px-2 py-0.5 text-[11px] text-gray-700">+{asset.tags.length - 4}</span>
              )}
            </div>
          </div>
          <div className="text-right">
            <Badge tone="neutral">{asset.type ?? 'asset'}</Badge>
            {typeof asset.qualityScore === 'number' && (
              <div className="mt-2">
                <Badge tone={tone}>QS: {asset.qualityScore.toFixed(1)}%</Badge>
              </div>
            )}
          </div>
        </div>
        {asset.owner || asset.updatedAt ? (
          <div className="mt-3 flex flex-wrap items-center gap-3 text-xs text-gray-500">
            {asset.owner && <span>Owner: {asset.owner}</span>}
            {asset.updatedAt && <span>Updated: {fmt(asset.updatedAt)}</span>}
          </div>
        ) : null}
      </CardContent>
    </Card>
  )
}

function fmt(iso: string) {
  try { return new Date(iso).toLocaleString() } catch { return iso }
}



------------------------------------------------------------
FILE: frontend\src\components\features\data-catalog\AssetDetails.tsx
------------------------------------------------------------
import type { Asset } from '@/types/dataAssets'
import { Badge } from '@components/ui/Badge'
import { Button } from '@components/ui/Button'
import { Card, CardContent, CardHeader, CardTitle } from '@components/ui/Card'
import { Modal } from '@components/ui/Modal'
import * as React from 'react'

export function AssetDetails({
  asset,
  isOpen,
  onClose,
  onRequestAccess,
}: {
  asset: Asset | null
  isOpen: boolean
  onClose: () => void
  onRequestAccess?: (assetId: string) => void
}) {
  if (!asset) return null

  const scoreTone =
    typeof asset.qualityScore === 'number'
      ? asset.qualityScore >= 90 ? 'success' : asset.qualityScore >= 75 ? 'warning' : 'danger'
      : 'neutral'

  return (
    <Modal isOpen={isOpen} onClose={onClose} title={`Asset â€¢ ${asset.name}`} size="lg">
      <div className="space-y-5">
        <Card>
          <CardHeader>
            <CardTitle>Overview</CardTitle>
          </CardHeader>
          <CardContent className="space-y-3 text-sm">
            <div className="grid grid-cols-1 gap-3 sm:grid-cols-2">
              <Detail label="Type"><Badge tone="neutral">{asset.type ?? 'asset'}</Badge></Detail>
              <Detail label="Owner">{asset.owner ?? 'â€”'}</Detail>
              <Detail label="Updated">{asset.updatedAt ? fmt(asset.updatedAt) : 'â€”'}</Detail>
              <Detail label="Quality">
                {typeof asset.qualityScore === 'number'
                  ? <Badge tone={scoreTone}>{asset.qualityScore.toFixed(1)}%</Badge>
                  : 'â€”'}
              </Detail>
            </div>
            {asset.description && <p className="text-gray-700">{asset.description}</p>}
            {asset.tags?.length ? (
              <div className="flex flex-wrap gap-1">
                {asset.tags.map((t) => (
                  <span key={t} className="rounded bg-gray-100 px-2 py-0.5 text-xs text-gray-700">{t}</span>
                ))}
              </div>
            ) : null}
          </CardContent>
        </Card>

        <div className="flex justify-end gap-2">
          <Button variant="outline" onClick={onClose}>Close</Button>
          <Button onClick={() => asset && onRequestAccess?.(asset.id)}>Request Access</Button>
        </div>
      </div>
    </Modal>
  )
}

function Detail({ label, children }: { label: string; children?: React.ReactNode }) {
  return (
    <div>
      <div className="text-xs text-gray-500">{label}</div>
      <div className="text-sm text-gray-900">{children}</div>
    </div>
  )
}

function fmt(iso: string) {
  try { return new Date(iso).toLocaleString() } catch { return iso }
}



------------------------------------------------------------
FILE: frontend\src\components\features\data-catalog\AssetGrid.tsx
------------------------------------------------------------
// src/components/features/data-catalog/AssetGrid.tsx - Enhanced Version
import { Button } from '@/components/ui/Button';
import { Skeleton } from '@/components/ui/Skeleton';
import { Asset, PaginationInfo } from '@/types/dataAssets';
import {
  BarChart3,
  Clock,
  Database,
  Eye,
  FileText,
  Globe,
  MoreHorizontal,
  Share,
  Shield,
  Star
} from 'lucide-react';
import React from 'react';

interface AssetGridProps {
  items: Asset[];
  onSelect: (id: string) => void;
  loading: boolean;
  validating?: boolean;
  pagination: PaginationInfo;
  onPageChange: (page: number) => void;
  error: string | null;
  isEmpty: boolean;
  hasFilters: boolean;
  viewMode?: 'grid' | 'table' | 'cards';
  selectedAssets?: Set<string>;
  onBulkSelect?: (assetId: string, selected: boolean) => void;
  permissions?: string[];
  userRole?: string;
  onQuickAction?: (assetId: string, action: string) => void;
}

export const AssetGrid: React.FC<AssetGridProps> = ({
  items,
  onSelect,
  loading,
  validating = false,
  pagination,
  onPageChange,
  error,
  isEmpty,
  hasFilters,
  viewMode = 'grid',
  selectedAssets,
  onBulkSelect,
  permissions = [],
  userRole = 'user',
  onQuickAction
}) => {
  const getAssetIcon = (type: Asset['type']) => {
    const icons = {
      table: Database,
      view: Database,
      file: FileText,
      api: Globe,
      dashboard: BarChart3,
      report: FileText
    };
    return icons[type] || Database;
  };

  const getQualityColor = (quality: Asset['quality']) => {
    const colors = {
      high: 'text-green-600 bg-green-100',
      medium: 'text-yellow-600 bg-yellow-100',
      low: 'text-red-600 bg-red-100'
    };
    return colors[quality];
  };

  const getClassificationColor = (classification: Asset['classification']) => {
    const colors = {
      public: 'text-blue-600 bg-blue-100',
      internal: 'text-gray-600 bg-gray-100',
      confidential: 'text-orange-600 bg-orange-100',
      restricted: 'text-red-600 bg-red-100'
    };
    return colors[classification];
  };

  const formatLastUpdated = (dateString: string) => {
    const date = new Date(dateString);
    const now = new Date();
    const diffInHours = (now.getTime() - date.getTime()) / (1000 * 60 * 60);

    if (diffInHours < 1) return 'Just now';
    if (diffInHours < 24) return `${Math.floor(diffInHours)}h ago`;
    if (diffInHours < 168) return `${Math.floor(diffInHours / 24)}d ago`;
    return date.toLocaleDateString();
  };

  // Loading state
  if (loading && items.length === 0) {
    return (
      <div className="space-y-6">
        <div className="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-6">
          {[...Array(6)].map((_, i) => (
            <div key={i} className="bg-white rounded-lg border p-6 space-y-4">
              <div className="flex items-start justify-between">
                <Skeleton className="h-5 w-5 rounded" />
                <Skeleton className="h-4 w-16 rounded" />
              </div>
              <Skeleton className="h-6 w-3/4" />
              <Skeleton className="h-4 w-full" />
              <Skeleton className="h-4 w-2/3" />
              <div className="flex justify-between items-center">
                <Skeleton className="h-4 w-20" />
                <Skeleton className="h-4 w-16" />
              </div>
            </div>
          ))}
        </div>
      </div>
    );
  }

  // Empty state
  if (isEmpty) {
    return (
      <div className="text-center py-12">
        <Database className="mx-auto h-12 w-12 text-gray-400 mb-4" />
        <h3 className="text-lg font-medium text-gray-900 mb-2">
          {hasFilters ? 'No assets match your filters' : 'No assets found'}
        </h3>
        <p className="text-gray-500 mb-6">
          {hasFilters 
            ? 'Try adjusting your search criteria or clearing filters'
            : 'Get started by registering your first data asset'
          }
        </p>
        {hasFilters && (
          <Button variant="outline" onClick={() => window.location.reload()}>
            Clear all filters
          </Button>
        )}
      </div>
    );
  }

  const AssetCard = ({ asset }: { asset: Asset }) => {
    const IconComponent = getAssetIcon(asset.type);
    const isSelected = selectedAssets?.has(asset.id) || false;

    return (
      <div
        className={`bg-white rounded-lg border hover:border-blue-300 transition-all duration-200 cursor-pointer group relative ${
          isSelected ? 'ring-2 ring-blue-500 border-blue-300' : ''
        } ${validating ? 'opacity-75' : ''}`}
        onClick={() => onSelect(asset.id)}
      >
        <div className="p-6">
          {/* Header */}
          <div className="flex items-start justify-between mb-4">
            <div className="flex items-center space-x-3">
              {onBulkSelect && (
                <input
                  type="checkbox"
                  checked={isSelected}
                  onChange={(e) => {
                    e.stopPropagation();
                    onBulkSelect(asset.id, e.target.checked);
                  }}
                  className="h-4 w-4 text-blue-600 focus:ring-blue-500 border-gray-300 rounded"
                />
              )}
              <IconComponent className="h-5 w-5 text-gray-600" />
            </div>
            <div className="flex items-center space-x-2">
              <span className={`px-2 py-1 text-xs font-medium rounded-full ${getQualityColor(asset.quality)}`}>
                {asset.quality}
              </span>
              <div className="opacity-0 group-hover:opacity-100 transition-opacity">
                <button
                  onClick={(e) => {
                    e.stopPropagation();
                    onQuickAction?.(asset.id, 'bookmark');
                  }}
                  className="p-1 text-gray-400 hover:text-yellow-500"
                  title="Bookmark"
                >
                  {asset.isBookmarked ? <Star className="h-4 w-4 fill-current text-yellow-500" /> : <Star className="h-4 w-4" />}
                </button>
              </div>
            </div>
          </div>

          {/* Asset Info */}
          <div className="mb-4">
            <h3 className="text-lg font-semibold text-gray-900 mb-1 group-hover:text-blue-600 transition-colors">
              {asset.name}
            </h3>
            <p className="text-sm text-gray-500 mb-2">
              {asset.schema}.{asset.table}
            </p>
            {asset.description && (
              <p className="text-sm text-gray-600 line-clamp-2">
                {asset.description}
              </p>
            )}
          </div>

          {/* Tags */}
          {asset.tags && asset.tags.length > 0 && (
            <div className="flex flex-wrap gap-1 mb-4">
              {asset.tags.slice(0, 3).map((tag, index) => (
                <span
                  key={index}
                  className="px-2 py-1 bg-gray-100 text-gray-700 text-xs rounded-full"
                >
                  {tag}
                </span>
              ))}
              {asset.tags.length > 3 && (
                <span className="px-2 py-1 bg-gray-100 text-gray-500 text-xs rounded-full">
                  +{asset.tags.length - 3}
                </span>
              )}
            </div>
          )}

          {/* Footer */}
          <div className="flex items-center justify-between text-sm text-gray-500">
            <div className="flex items-center space-x-4">
              <div className="flex items-center space-x-1">
                <Shield className="h-3 w-3" />
                <span className={`px-1 py-0.5 text-xs rounded ${getClassificationColor(asset.classification)}`}>
                  {asset.classification}
                </span>
              </div>
              {asset.viewCount && (
                <div className="flex items-center space-x-1">
                  <Eye className="h-3 w-3" />
                  <span>{asset.viewCount}</span>
                </div>
              )}
            </div>
            <div className="flex items-center space-x-1">
              <Clock className="h-3 w-3" />
              <span>{formatLastUpdated(asset.lastUpdated)}</span>
            </div>
          </div>
        </div>

        {/* Quick Actions Menu */}
        <div className="absolute top-2 right-2 opacity-0 group-hover:opacity-100 transition-opacity">
          <div className="relative">
            <button
              onClick={(e) => {
                e.stopPropagation();
                // You could implement a dropdown menu here
              }}
              className="p-1 text-gray-400 hover:text-gray-600 bg-white rounded-full shadow-sm"
            >
              <MoreHorizontal className="h-4 w-4" />
            </button>
          </div>
        </div>
      </div>
    );
  };

  const TableRow = ({ asset }: { asset: Asset }) => {
    const IconComponent = getAssetIcon(asset.type);
    const isSelected = selectedAssets?.has(asset.id) || false;

    return (
      <tr
        className={`hover:bg-gray-50 cursor-pointer ${isSelected ? 'bg-blue-50' : ''}`}
        onClick={() => onSelect(asset.id)}
      >
        {onBulkSelect && (
          <td className="px-6 py-4">
            <input
              type="checkbox"
              checked={isSelected}
              onChange={(e) => {
                e.stopPropagation();
                onBulkSelect(asset.id, e.target.checked);
              }}
              className="h-4 w-4 text-blue-600 focus:ring-blue-500 border-gray-300 rounded"
            />
          </td>
        )}
        <td className="px-6 py-4">
          <div className="flex items-center space-x-3">
            <IconComponent className="h-5 w-5 text-gray-600" />
            <div>
              <div className="font-medium text-gray-900">{asset.name}</div>
              <div className="text-sm text-gray-500">{asset.schema}.{asset.table}</div>
            </div>
          </div>
        </td>
        <td className="px-6 py-4">
          <span className="capitalize text-sm text-gray-700">{asset.type}</span>
        </td>
        <td className="px-6 py-4">
          <span className="text-sm text-gray-700">{asset.owner}</span>
        </td>
        <td className="px-6 py-4">
          <span className={`px-2 py-1 text-xs font-medium rounded-full ${getQualityColor(asset.quality)}`}>
            {asset.quality}
          </span>
        </td>
        <td className="px-6 py-4">
          <span className={`px-2 py-1 text-xs font-medium rounded-full ${getClassificationColor(asset.classification)}`}>
            {asset.classification}
          </span>
        </td>
        <td className="px-6 py-4 text-sm text-gray-500">
          {formatLastUpdated(asset.lastUpdated)}
        </td>
        <td className="px-6 py-4">
          <div className="flex items-center space-x-2">
            <button
              onClick={(e) => {
                e.stopPropagation();
                onQuickAction?.(asset.id, 'bookmark');
              }}
              className="text-gray-400 hover:text-yellow-500"
            >
              {asset.isBookmarked ? <Star className="h-4 w-4 fill-current text-yellow-500" /> : <Star className="h-4 w-4" />}
            </button>
            <button
              onClick={(e) => {
                e.stopPropagation();
                onQuickAction?.(asset.id, 'share');
              }}
              className="text-gray-400 hover:text-blue-500"
            >
              <Share className="h-4 w-4" />
            </button>
          </div>
        </td>
      </tr>
    );
  };

  const Pagination = () => {
    if (pagination.totalPages <= 1) return null;

    const pages = [];
    const maxVisiblePages = 7;
    const halfVisible = Math.floor(maxVisiblePages / 2);
    
    let startPage = Math.max(1, pagination.page - halfVisible);
    let endPage = Math.min(pagination.totalPages, pagination.page + halfVisible);
    
    if (endPage - startPage + 1 < maxVisiblePages) {
      if (startPage === 1) {
        endPage = Math.min(pagination.totalPages, startPage + maxVisiblePages - 1);
      } else {
        startPage = Math.max(1, endPage - maxVisiblePages + 1);
      }
    }

    for (let i = startPage; i <= endPage; i++) {
      pages.push(i);
    }

    return (
      <div className="flex items-center justify-between px-6 py-4 border-t">
        <div className="text-sm text-gray-700">
          Showing {((pagination.page - 1) * pagination.limit) + 1} to{' '}
          {Math.min(pagination.page * pagination.limit, pagination.total)} of{' '}
          {pagination.total} results
        </div>
        
        <div className="flex items-center space-x-2">
          <Button
            variant="outline"
            size="sm"
            disabled={!pagination.hasPrev || loading}
            onClick={() => onPageChange(pagination.page - 1)}
          >
            Previous
          </Button>
          
          {startPage > 1 && (
            <>
              <button
                onClick={() => onPageChange(1)}
                className="px-3 py-1 text-sm border border-gray-300 rounded hover:bg-gray-50"
              >
                1
              </button>
              {startPage > 2 && <span className="text-gray-500">...</span>}
            </>
          )}
          
          {pages.map((page) => (
            <button
              key={page}
              onClick={() => onPageChange(page)}
              disabled={loading}
              className={`px-3 py-1 text-sm border rounded ${
                page === pagination.page
                  ? 'bg-blue-600 text-white border-blue-600'
                  : 'border-gray-300 hover:bg-gray-50'
              }`}
            >
              {page}
            </button>
          ))}
          
          {endPage < pagination.totalPages && (
            <>
              {endPage < pagination.totalPages - 1 && <span className="text-gray-500">...</span>}
              <button
                onClick={() => onPageChange(pagination.totalPages)}
                className="px-3 py-1 text-sm border border-gray-300 rounded hover:bg-gray-50"
              >
                {pagination.totalPages}
              </button>
            </>
          )}
          
          <Button
            variant="outline"
            size="sm"
            disabled={!pagination.hasNext || loading}
            onClick={() => onPageChange(pagination.page + 1)}
          >
            Next
          </Button>
        </div>
      </div>
    );
  };

  return (
    <div className="space-y-6">
      {/* Grid View */}
      {viewMode === 'grid' && (
        <div className="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-6">
          {items.map((asset) => (
            <AssetCard key={asset.id} asset={asset} />
          ))}
        </div>
      )}

      {/* Table View */}
      {viewMode === 'table' && (
        <div className="bg-white border border-gray-200 rounded-lg overflow-hidden">
          <table className="min-w-full divide-y divide-gray-200">
            <thead className="bg-gray-50">
              <tr>
                {onBulkSelect && (
                  <th className="px-6 py-3 text-left text-xs font-medium text-gray-500 uppercase tracking-wider">
                    <span className="sr-only">Select</span>
                  </th>
                )}
                <th className="px-6 py-3 text-left text-xs font-medium text-gray-500 uppercase tracking-wider">
                  Asset
                </th>
                <th className="px-6 py-3 text-left text-xs font-medium text-gray-500 uppercase tracking-wider">
                  Type
                </th>
                <th className="px-6 py-3 text-left text-xs font-medium text-gray-500 uppercase tracking-wider">
                  Owner
                </th>
                <th className="px-6 py-3 text-left text-xs font-medium text-gray-500 uppercase tracking-wider">
                  Quality
                </th>
                <th className="px-6 py-3 text-left text-xs font-medium text-gray-500 uppercase tracking-wider">
                  Classification
                </th>
                <th className="px-6 py-3 text-left text-xs font-medium text-gray-500 uppercase tracking-wider">
                  Last Updated
                </th>
                <th className="px-6 py-3 text-left text-xs font-medium text-gray-500 uppercase tracking-wider">
                  Actions
                </th>
              </tr>
            </thead>
            <tbody className="bg-white divide-y divide-gray-200">
              {items.map((asset) => (
                <TableRow key={asset.id} asset={asset} />
              ))}
            </tbody>
          </table>
        </div>
      )}

      {/* Cards View */}
      {viewMode === 'cards' && (
        <div className="grid grid-cols-1 lg:grid-cols-2 gap-4">
          {items.map((asset) => {
            const IconComponent = getAssetIcon(asset.type);
            const isSelected = selectedAssets?.has(asset.id) || false;

            return (
              <div
                key={asset.id}
                className={`bg-white border rounded-lg p-4 hover:border-blue-300 transition-colors cursor-pointer ${
                  isSelected ? 'ring-2 ring-blue-500 border-blue-300' : ''
                }`}
                onClick={() => onSelect(asset.id)}
              >
                <div className="flex items-start justify-between">
                  <div className="flex items-center space-x-3 flex-1">
                    {onBulkSelect && (
                      <input
                        type="checkbox"
                        checked={isSelected}
                        onChange={(e) => {
                          e.stopPropagation();
                          onBulkSelect(asset.id, e.target.checked);
                        }}
                        className="h-4 w-4 text-blue-600 focus:ring-blue-500 border-gray-300 rounded"
                      />
                    )}
                    <IconComponent className="h-5 w-5 text-gray-600 flex-shrink-0" />
                    <div className="flex-1 min-w-0">
                      <h3 className="font-medium text-gray-900 truncate">{asset.name}</h3>
                      <p className="text-sm text-gray-500 truncate">{asset.schema}.{asset.table}</p>
                      {asset.description && (
                        <p className="text-sm text-gray-600 mt-1 line-clamp-1">{asset.description}</p>
                      )}
                    </div>
                  </div>
                  <div className="flex items-center space-x-2 flex-shrink-0 ml-4">
                    <span className={`px-2 py-1 text-xs font-medium rounded ${getQualityColor(asset.quality)}`}>
                      {asset.quality}
                    </span>
                    <span className={`px-2 py-1 text-xs font-medium rounded ${getClassificationColor(asset.classification)}`}>
                      {asset.classification}
                    </span>
                  </div>
                </div>
              </div>
            );
          })}
        </div>
      )}

      {/* Pagination */}
      <Pagination />
    </div>
  );
};


------------------------------------------------------------
FILE: frontend\src\components\features\data-catalog\BulkActionModal.tsx
------------------------------------------------------------
// src/components/features/data-catalog/BulkActionModal.tsx - Fixed version
import { Button } from '@/components/ui/Button';
import type { BulkAction, BulkActionResult } from '@/types/bulkActions';
import { AlertTriangle, Archive, CheckCircle, Clock, Play, Tag, Trash2, Users, X } from 'lucide-react';
import React, { useState } from 'react';

interface BulkActionModalProps {
  isOpen: boolean;
  onClose: () => void;
  selectedAssets: string[];
  onAction: (action: BulkAction) => Promise<void>;
  isProcessing: boolean;
  progress?: {
    total: number;
    completed: number;
    current?: string;
  };
  results?: BulkActionResult;
}

export const BulkActionModal: React.FC<BulkActionModalProps> = ({
  isOpen,
  onClose,
  selectedAssets,
  onAction,
  isProcessing,
  progress,
  results
}) => {
  const [selectedAction, setSelectedAction] = useState<BulkAction['type']>('update_tags');
  const [actionParams, setActionParams] = useState<Record<string, any>>({});
  const [confirmAction, setConfirmAction] = useState(false);

  if (!isOpen) return null;

  const actions: Array<{
    type: BulkAction['type'];
    label: string;
    description: string;
    icon: React.ComponentType<{ className?: string }>;
    destructive?: boolean;
    requiresConfirmation?: boolean;
  }> = [
    {
      type: 'update_tags',
      label: 'Update Tags',
      description: 'Add or remove tags from selected assets',
      icon: Tag
    },
    {
      type: 'update_classification',
      label: 'Update Classification',
      description: 'Change data classification level',
      icon: Users,
      requiresConfirmation: true
    },
    {
      type: 'archive',
      label: 'Archive Assets',
      description: 'Move assets to archived state',
      icon: Archive,
      requiresConfirmation: true
    },
    {
      type: 'delete',
      label: 'Delete Assets',
      description: 'Permanently delete selected assets',
      icon: Trash2,
      destructive: true,
      requiresConfirmation: true
    }
  ];

  const handleSubmit = async () => {
    const action: BulkAction = {
      type: selectedAction,
      assetIds: selectedAssets,
      params: actionParams
    };

    await onAction(action);
  };

  const renderActionForm = () => {
    switch (selectedAction) {
      case 'update_tags':
        return (
          <div className="space-y-4">
            <div>
              <label className="block text-sm font-medium text-gray-700 mb-2">
                Action Type
              </label>
              <select
                value={actionParams.operation || 'add'}
                onChange={(e) => setActionParams(prev => ({ ...prev, operation: e.target.value }))}
                className="w-full px-3 py-2 border border-gray-300 rounded-md focus:outline-none focus:ring-2 focus:ring-blue-500"
              >
                <option value="add">Add Tags</option>
                <option value="remove">Remove Tags</option>
                <option value="replace">Replace All Tags</option>
              </select>
            </div>
            <div>
              <label className="block text-sm font-medium text-gray-700 mb-2">
                Tags
              </label>
              <input
                type="text"
                value={actionParams.tags || ''}
                onChange={(e) => setActionParams(prev => ({ 
                  ...prev, 
                  tags: e.target.value.split(',').map(t => t.trim()).filter(Boolean)
                }))}
                className="w-full px-3 py-2 border border-gray-300 rounded-md focus:outline-none focus:ring-2 focus:ring-blue-500"
                placeholder="tag1, tag2, tag3"
              />
              <p className="text-xs text-gray-500 mt-1">Separate tags with commas</p>
            </div>
          </div>
        );

      case 'update_classification':
        return (
          <div>
            <label className="block text-sm font-medium text-gray-700 mb-2">
              New Classification Level
            </label>
            <select
              value={actionParams.classification || ''}
              onChange={(e) => setActionParams(prev => ({ ...prev, classification: e.target.value }))}
              className="w-full px-3 py-2 border border-gray-300 rounded-md focus:outline-none focus:ring-2 focus:ring-blue-500"
            >
              <option value="">Select classification</option>
              <option value="public">Public</option>
              <option value="internal">Internal</option>
              <option value="confidential">Confidential</option>
              <option value="restricted">Restricted</option>
            </select>
          </div>
        );

      case 'archive':
        return (
          <div>
            <label className="block text-sm font-medium text-gray-700 mb-2">
              Archive Reason
            </label>
            <textarea
              value={actionParams.reason || ''}
              onChange={(e) => setActionParams(prev => ({ ...prev, reason: e.target.value }))}
              rows={3}
              className="w-full px-3 py-2 border border-gray-300 rounded-md focus:outline-none focus:ring-2 focus:ring-blue-500"
              placeholder="Explain why these assets are being archived"
            />
          </div>
        );

      case 'delete':
        return (
          <div className="space-y-4">
            <div className="bg-red-50 border border-red-200 rounded-lg p-4">
              <div className="flex items-start space-x-3">
                <AlertTriangle className="h-5 w-5 text-red-600 mt-0.5 flex-shrink-0" />
                <div>
                  <h3 className="text-sm font-medium text-red-800">
                    Permanent Deletion Warning
                  </h3>
                  <p className="text-sm text-red-700 mt-1">
                    This action cannot be undone. All data and metadata associated with these assets will be permanently deleted.
                  </p>
                </div>
              </div>
            </div>
            <div>
              <label className="block text-sm font-medium text-gray-700 mb-2">
                Deletion Reason (Required)
              </label>
              <textarea
                value={actionParams.reason || ''}
                onChange={(e) => setActionParams(prev => ({ ...prev, reason: e.target.value }))}
                rows={3}
                className="w-full px-3 py-2 border border-gray-300 rounded-md focus:outline-none focus:ring-2 focus:ring-blue-500"
                placeholder="Explain why these assets are being deleted"
                required
              />
            </div>
            <div className="flex items-start space-x-2">
              <input
                type="checkbox"
                id="confirm-delete"
                checked={confirmAction}
                onChange={(e) => setConfirmAction(e.target.checked)}
                className="h-4 w-4 text-red-600 focus:ring-red-500 border-gray-300 rounded mt-0.5"
              />
              <label htmlFor="confirm-delete" className="text-sm text-gray-700">
                I understand this action is permanent and cannot be undone
              </label>
            </div>
          </div>
        );

      default:
        return null;
    }
  };

  const renderProgressView = () => {
    if (!isProcessing || !progress) return null;

    const progressPercentage = (progress.completed / progress.total) * 100;

    return (
      <div className="space-y-4">
        <div className="flex items-center space-x-3">
          <Clock className="h-5 w-5 text-blue-600 animate-spin" />
          <span className="text-sm font-medium text-gray-900">
            Processing {selectedAssets.length} assets...
          </span>
        </div>
        
        <div className="w-full bg-gray-200 rounded-full h-2">
          <div 
            className="bg-blue-600 h-2 rounded-full transition-all duration-300"
            style={{ width: `${progressPercentage}%` }}
          />
        </div>
        
        <div className="flex justify-between text-sm text-gray-600">
          <span>
            {progress.completed} of {progress.total} completed
          </span>
          <span>{Math.round(progressPercentage)}%</span>
        </div>
        
        {progress.current && (
          <p className="text-sm text-gray-500">
            Currently processing: {progress.current}
          </p>
        )}
      </div>
    );
  };

  const renderResultsView = () => {
    if (!results) return null;

    return (
      <div className="space-y-4">
        <div className="flex items-center space-x-3">
          <CheckCircle className="h-5 w-5 text-green-600" />
          <span className="text-sm font-medium text-gray-900">
            Bulk action completed
          </span>
        </div>
        
        <div className="bg-gray-50 rounded-lg p-4 space-y-2">
          <div className="flex justify-between text-sm">
            <span className="text-gray-600">Total processed:</span>
            <span className="font-medium">{results.total}</span>
          </div>
          <div className="flex justify-between text-sm">
            <span className="text-green-600">Successful:</span>
            <span className="font-medium text-green-600">{results.successful}</span>
          </div>
          {results.failed > 0 && (
            <div className="flex justify-between text-sm">
              <span className="text-red-600">Failed:</span>
              <span className="font-medium text-red-600">{results.failed}</span>
            </div>
          )}
        </div>
        
        {results.errors && results.errors.length > 0 && (
          <div className="mt-4">
            <h4 className="text-sm font-medium text-gray-900 mb-2">Errors:</h4>
            <div className="max-h-32 overflow-y-auto space-y-1">
              {results.errors.map((error, index) => (
                <div key={index} className="text-xs text-red-600 bg-red-50 p-2 rounded">
                  {error.assetId}: {error.message}
                </div>
              ))}
            </div>
          </div>
        )}
      </div>
    );
  };

  const selectedActionConfig = actions.find(a => a.type === selectedAction);
  const canExecute = selectedActionConfig?.destructive ? 
    confirmAction && actionParams.reason?.trim() :
    true;

  return (
    <div className="fixed inset-0 z-50 overflow-y-auto">
      <div className="flex items-center justify-center min-h-screen px-4 pt-4 pb-20 text-center sm:block sm:p-0">
        <div className="fixed inset-0 transition-opacity bg-gray-500 bg-opacity-75" onClick={onClose} />
        
        <div className="inline-block w-full max-w-2xl p-6 my-8 overflow-hidden text-left align-middle transition-all transform bg-white shadow-xl rounded-lg">
          {/* Header */}
          <div className="flex items-center justify-between pb-4 border-b">
            <h3 className="text-lg font-medium text-gray-900">
              Bulk Actions ({selectedAssets.length} assets)
            </h3>
            <button
              onClick={onClose}
              className="text-gray-400 hover:text-gray-600 p-1 rounded-md hover:bg-gray-100"
              disabled={isProcessing}
            >
              <X className="h-6 w-6" />
            </button>
          </div>

          <div className="mt-6">
            {isProcessing ? (
              renderProgressView()
            ) : results ? (
              renderResultsView()
            ) : (
              <div className="space-y-6">
                {/* Action Selection */}
                <div>
                  <h4 className="text-sm font-medium text-gray-900 mb-3">
                    Select Action
                  </h4>
                  <div className="grid grid-cols-1 gap-2">
                    {actions.map((action) => {
                      const IconComponent = action.icon;
                      return (
                        <label
                          key={action.type}
                          className={`flex items-start space-x-3 p-3 rounded-lg border cursor-pointer hover:bg-gray-50 transition-colors ${
                            selectedAction === action.type
                              ? 'border-blue-500 bg-blue-50'
                              : 'border-gray-200'
                          }`}
                        >
                          <input
                            type="radio"
                            name="bulkAction"
                            value={action.type}
                            checked={selectedAction === action.type}
                            onChange={(e) => {
                              setSelectedAction(e.target.value as BulkAction['type']);
                              setActionParams({});
                              setConfirmAction(false);
                            }}
                            className="mt-1"
                          />
                          <IconComponent 
                            className={`h-5 w-5 mt-0.5 flex-shrink-0 ${
                              action.destructive ? 'text-red-600' : 'text-gray-600'
                            }`} 
                          />
                          <div className="flex-1">
                            <div className={`text-sm font-medium ${
                              action.destructive ? 'text-red-900' : 'text-gray-900'
                            }`}>
                              {action.label}
                            </div>
                            <div className="text-sm text-gray-500">
                              {action.description}
                            </div>
                          </div>
                        </label>
                      );
                    })}
                  </div>
                </div>

                {/* Action Configuration */}
                <div>
                  <h4 className="text-sm font-medium text-gray-900 mb-3">
                    Configuration
                  </h4>
                  {renderActionForm()}
                </div>

                {/* Actions - Fixed variant types */}
                <div className="flex justify-end space-x-3 pt-6 border-t">
                  <Button
                    variant="outline"
                    onClick={onClose}
                    disabled={isProcessing}
                  >
                    Cancel
                  </Button>
                  <Button
                    onClick={handleSubmit}
                    disabled={!canExecute || isProcessing}
                    variant={selectedActionConfig?.destructive ? 'destructive' : 'default'}
                  >
                    <Play className="mr-2 h-4 w-4" />
                    Execute Action
                  </Button>
                </div>
              </div>
            )}
          </div>
        </div>
      </div>
    </div>
  );
};



------------------------------------------------------------
FILE: frontend\src\components\features\data-catalog\CreateAssetModal.tsx
------------------------------------------------------------

// src/components/features/data-catalog/CreateAssetModal.tsx
import { Button } from '@/components/ui/Button';
import type { CreateAssetData } from '@/types/dataAssets';
import { Database, Upload, X } from 'lucide-react';
import React, { useState } from 'react';

interface CreateAssetModalProps {
  isOpen: boolean;
  onClose: () => void;
  onCreate: (data: CreateAssetData) => Promise<void>;
}

export const CreateAssetModal: React.FC<CreateAssetModalProps> = ({
  isOpen,
  onClose,
  onCreate
}) => {
  const [formData, setFormData] = useState<Partial<CreateAssetData>>({
    type: 'table',
    classification: 'internal',
    quality: 'medium'
  });
  const [isSubmitting, setIsSubmitting] = useState(false);
  const [errors, setErrors] = useState<Record<string, string>>({});

  if (!isOpen) return null;

  const handleSubmit = async (e: React.FormEvent) => {
    e.preventDefault();
    setIsSubmitting(true);
    setErrors({});

    try {
      // Basic validation
      const newErrors: Record<string, string> = {};
      if (!formData.name?.trim()) newErrors.name = 'Name is required';
      if (!formData.dataSourceId) newErrors.dataSourceId = 'Data source is required';
      if (!formData.schema?.trim()) newErrors.schema = 'Schema is required';
      if (!formData.table?.trim()) newErrors.table = 'Table is required';

      if (Object.keys(newErrors).length > 0) {
        setErrors(newErrors);
        return;
      }

      await onCreate(formData as CreateAssetData);
    } catch (error: any) {
      setErrors({ submit: error.message });
    } finally {
      setIsSubmitting(false);
    }
  };

  const handleChange = (field: keyof CreateAssetData, value: any) => {
    setFormData(prev => ({ ...prev, [field]: value }));
    if (errors[field]) {
      setErrors(prev => ({ ...prev, [field]: '' }));
    }
  };

  return (
    <div className="fixed inset-0 z-50 overflow-y-auto">
      <div className="flex items-center justify-center min-h-screen px-4 pt-4 pb-20 text-center sm:block sm:p-0">
        <div className="fixed inset-0 transition-opacity bg-gray-500 bg-opacity-75" onClick={onClose} />
        
        <div className="inline-block w-full max-w-2xl p-6 my-8 overflow-hidden text-left align-middle transition-all transform bg-white shadow-xl rounded-lg">
          {/* Header */}
          <div className="flex items-center justify-between pb-4 border-b">
            <div className="flex items-center space-x-3">
              <Database className="h-6 w-6 text-blue-600" />
              <h3 className="text-lg font-medium text-gray-900">
                Register New Asset
              </h3>
            </div>
            <button
              onClick={onClose}
              className="text-gray-400 hover:text-gray-600"
            >
              <X className="h-6 w-6" />
            </button>
          </div>

          {/* Form */}
          <form onSubmit={handleSubmit} className="mt-6 space-y-6">
            {/* Basic Information */}
            <div className="space-y-4">
              <h4 className="text-sm font-medium text-gray-900">Basic Information</h4>
              
              <div className="grid grid-cols-1 md:grid-cols-2 gap-4">
                <div>
                  <label className="block text-sm font-medium text-gray-700 mb-1">
                    Asset Name *
                  </label>
                  <input
                    type="text"
                    value={formData.name || ''}
                    onChange={(e) => handleChange('name', e.target.value)}
                    className={`w-full px-3 py-2 border rounded-md focus:outline-none focus:ring-2 focus:ring-blue-500 ${
                      errors.name ? 'border-red-300' : 'border-gray-300'
                    }`}
                    placeholder="Enter asset name"
                  />
                  {errors.name && <p className="text-sm text-red-600 mt-1">{errors.name}</p>}
                </div>

                <div>
                  <label className="block text-sm font-medium text-gray-700 mb-1">
                    Asset Type
                  </label>
                  <select
                    value={formData.type || 'table'}
                    onChange={(e) => handleChange('type', e.target.value)}
                    className="w-full px-3 py-2 border border-gray-300 rounded-md focus:outline-none focus:ring-2 focus:ring-blue-500"
                  >
                    <option value="table">Table</option>
                    <option value="view">View</option>
                    <option value="file">File</option>
                    <option value="api">API</option>
                    <option value="dashboard">Dashboard</option>
                    <option value="report">Report</option>
                  </select>
                </div>
              </div>

              <div>
                <label className="block text-sm font-medium text-gray-700 mb-1">
                  Description
                </label>
                <textarea
                  value={formData.description || ''}
                  onChange={(e) => handleChange('description', e.target.value)}
                  rows={3}
                  className="w-full px-3 py-2 border border-gray-300 rounded-md focus:outline-none focus:ring-2 focus:ring-blue-500"
                  placeholder="Describe this asset's purpose and contents"
                />
              </div>
            </div>

            {/* Location Information */}
            <div className="space-y-4">
              <h4 className="text-sm font-medium text-gray-900">Location</h4>
              
              <div className="grid grid-cols-1 md:grid-cols-3 gap-4">
                <div>
                  <label className="block text-sm font-medium text-gray-700 mb-1">
                    Data Source *
                  </label>
                  <select
                    value={formData.dataSourceId || ''}
                    onChange={(e) => handleChange('dataSourceId', e.target.value)}
                    className={`w-full px-3 py-2 border rounded-md focus:outline-none focus:ring-2 focus:ring-blue-500 ${
                      errors.dataSourceId ? 'border-red-300' : 'border-gray-300'
                    }`}
                  >
                    <option value="">Select data source</option>
                    <option value="ds-1">Production DB</option>
                    <option value="ds-2">Analytics DB</option>
                    <option value="ds-3">Data Lake</option>
                  </select>
                  {errors.dataSourceId && <p className="text-sm text-red-600 mt-1">{errors.dataSourceId}</p>}
                </div>

                <div>
                  <label className="block text-sm font-medium text-gray-700 mb-1">
                    Schema *
                  </label>
                  <input
                    type="text"
                    value={formData.schema || ''}
                    onChange={(e) => handleChange('schema', e.target.value)}
                    className={`w-full px-3 py-2 border rounded-md focus:outline-none focus:ring-2 focus:ring-blue-500 ${
                      errors.schema ? 'border-red-300' : 'border-gray-300'
                    }`}
                    placeholder="schema_name"
                  />
                  {errors.schema && <p className="text-sm text-red-600 mt-1">{errors.schema}</p>}
                </div>

                <div>
                  <label className="block text-sm font-medium text-gray-700 mb-1">
                    Table/Object *
                  </label>
                  <input
                    type="text"
                    value={formData.table || ''}
                    onChange={(e) => handleChange('table', e.target.value)}
                    className={`w-full px-3 py-2 border rounded-md focus:outline-none focus:ring-2 focus:ring-blue-500 ${
                      errors.table ? 'border-red-300' : 'border-gray-300'
                    }`}
                    placeholder="table_name"
                  />
                  {errors.table && <p className="text-sm text-red-600 mt-1">{errors.table}</p>}
                </div>
              </div>
            </div>

            {/* Classification */}
            <div className="space-y-4">
              <h4 className="text-sm font-medium text-gray-900">Classification</h4>
              
              <div className="grid grid-cols-1 md:grid-cols-2 gap-4">
                <div>
                  <label className="block text-sm font-medium text-gray-700 mb-1">
                    Data Classification
                  </label>
                  <select
                    value={formData.classification || 'internal'}
                    onChange={(e) => handleChange('classification', e.target.value)}
                    className="w-full px-3 py-2 border border-gray-300 rounded-md focus:outline-none focus:ring-2 focus:ring-blue-500"
                  >
                    <option value="public">Public</option>
                    <option value="internal">Internal</option>
                    <option value="confidential">Confidential</option>
                    <option value="restricted">Restricted</option>
                  </select>
                </div>

                <div>
                  <label className="block text-sm font-medium text-gray-700 mb-1">
                    Quality Level
                  </label>
                  <select
                    value={formData.quality || 'medium'}
                    onChange={(e) => handleChange('quality', e.target.value)}
                    className="w-full px-3 py-2 border border-gray-300 rounded-md focus:outline-none focus:ring-2 focus:ring-blue-500"
                  >
                    <option value="high">High</option>
                    <option value="medium">Medium</option>
                    <option value="low">Low</option>
                  </select>
                </div>
              </div>
            </div>

            {/* Tags */}
            <div>
              <label className="block text-sm font-medium text-gray-700 mb-1">
                Tags
              </label>
              <input
                type="text"
                value={formData.tags?.join(', ') || ''}
                onChange={(e) => handleChange('tags', e.target.value.split(',').map(t => t.trim()).filter(Boolean))}
                className="w-full px-3 py-2 border border-gray-300 rounded-md focus:outline-none focus:ring-2 focus:ring-blue-500"
                placeholder="tag1, tag2, tag3"
              />
              <p className="text-xs text-gray-500 mt-1">Separate tags with commas</p>
            </div>

            {/* Error Message */}
            {errors.submit && (
              <div className="bg-red-50 border border-red-200 rounded-md p-3">
                <p className="text-sm text-red-600">{errors.submit}</p>
              </div>
            )}

            {/* Actions */}
            <div className="flex justify-end space-x-3 pt-6 border-t">
              <Button
                type="button"
                variant="outline"
                onClick={onClose}
                disabled={isSubmitting}
              >
                Cancel
              </Button>
              <Button
                type="submit"
                disabled={isSubmitting}
              >
                {isSubmitting ? (
                  <>
                    <Upload className="mr-2 h-4 w-4 animate-spin" />
                    Creating...
                  </>
                ) : (
                  <>
                    <Database className="mr-2 h-4 w-4" />
                    Create Asset
                  </>
                )}
              </Button>
            </div>
          </form>
        </div>
      </div>
    </div>
  );
};


------------------------------------------------------------
FILE: frontend\src\components\features\data-catalog\index.ts
------------------------------------------------------------
export { AssetCard } from './AssetCard'
export type { Asset } from './AssetCard'

export { AssetGrid } from './AssetGrid'

export { AssetDetails } from './AssetDetails'

export { SearchFilters } from './SearchFilters'




------------------------------------------------------------
FILE: frontend\src\components\features\data-catalog\SearchFilters.tsx
------------------------------------------------------------
// src/components/features/data-catalog/SearchFilters.tsx - Enhanced Version
import { Button } from '@/components/ui/Button';
import {
  ChevronDown,
  Clock,
  Filter,
  Grid3x3,
  LayoutGrid,
  List,
  RefreshCw,
  Search,
  X
} from 'lucide-react';
import React, { useEffect, useRef, useState } from 'react';

interface SearchFiltersProps {
  q: string;
  setQ: (value: string) => void;
  type: string;
  setType: (value: string) => void;
  owner: string;
  setOwner: (value: string) => void;
  quality: string;
  setQuality: (value: string) => void;
  classification: string;
  setClassification: (value: string) => void;
  dataSourceId: string;
  setDataSourceId: (value: string) => void;
  totalResults: number;
  isLoading: boolean;
  hasFilters: boolean;
  onClearFilters: () => void;
  onRefresh: () => void;
  viewMode?: 'grid' | 'table' | 'cards';
  onViewModeChange?: (mode: 'grid' | 'table' | 'cards') => void;
  canSelectAll?: boolean;
  selectedCount?: number;
  onSelectAll?: (selected: boolean) => void;
  maxSelections?: number;
}

export const SearchFilters: React.FC<SearchFiltersProps> = ({
  q,
  setQ,
  type,
  setType,
  owner,
  setOwner,
  quality,
  setQuality,
  classification,
  setClassification,
  dataSourceId,
  setDataSourceId,
  totalResults,
  isLoading,
  hasFilters,
  onClearFilters,
  onRefresh,
  viewMode = 'grid',
  onViewModeChange,
  canSelectAll,
  selectedCount = 0,
  onSelectAll,
  maxSelections = 100
}) => {
  const [showAdvanced, setShowAdvanced] = useState(false);
  const [recentSearches, setRecentSearches] = useState<string[]>([]);
  const searchInputRef = useRef<HTMLInputElement>(null);

  // Load recent searches from localStorage
  useEffect(() => {
    const saved = localStorage.getItem('recentAssetSearches');
    if (saved) {
      setRecentSearches(JSON.parse(saved));
    }
  }, []);

  const handleSearchSubmit = (value: string) => {
    if (value.trim() && !recentSearches.includes(value.trim())) {
      const updated = [value.trim(), ...recentSearches.slice(0, 4)];
      setRecentSearches(updated);
      localStorage.setItem('recentAssetSearches', JSON.stringify(updated));
    }
    setQ(value);
  };

  const handleKeyDown = (e: React.KeyboardEvent<HTMLInputElement>) => {
    if (e.key === 'Enter') {
      handleSearchSubmit(e.currentTarget.value);
    }
  };

  const activeFiltersCount = [type, owner, quality, classification, dataSourceId].filter(Boolean).length;

  return (
    <div className="space-y-4">
      {/* Main Search Bar */}
      <div className="flex items-center space-x-4">
        <div className="flex-1 relative">
          <div className="relative">
            <Search className="absolute left-3 top-1/2 transform -translate-y-1/2 h-4 w-4 text-gray-400" />
            <input
              ref={searchInputRef}
              data-search-input
              type="text"
              placeholder="Search assets by name, description, schema, or tags..."
              value={q}
              onChange={(e) => setQ(e.target.value)}
              onKeyDown={handleKeyDown}
              className="w-full pl-10 pr-10 py-2 border border-gray-300 rounded-lg focus:outline-none focus:ring-2 focus:ring-blue-500 focus:border-transparent"
            />
            {q && (
              <button
                onClick={() => setQ('')}
                className="absolute right-3 top-1/2 transform -translate-y-1/2 text-gray-400 hover:text-gray-600"
              >
                <X className="h-4 w-4" />
              </button>
            )}
          </div>

          {/* Recent Searches Dropdown */}
          {recentSearches.length > 0 && q.length === 0 && (
            <div className="absolute top-full mt-1 w-full bg-white border border-gray-200 rounded-lg shadow-lg z-10">
              <div className="p-2 border-b border-gray-100">
                <div className="flex items-center space-x-2 text-xs text-gray-500">
                  <Clock className="h-3 w-3" />
                  <span>Recent searches</span>
                </div>
              </div>
              {recentSearches.map((search, index) => (
                <button
                  key={index}
                  onClick={() => handleSearchSubmit(search)}
                  className="w-full text-left px-3 py-2 hover:bg-gray-50 text-sm"
                >
                  {search}
                </button>
              ))}
            </div>
          )}
        </div>

        {/* View Mode Toggle */}
        {onViewModeChange && (
          <div className="flex items-center border border-gray-300 rounded-lg">
            <button
              onClick={() => onViewModeChange('grid')}
              className={`p-2 ${viewMode === 'grid' ? 'bg-blue-100 text-blue-600' : 'text-gray-400 hover:text-gray-600'}`}
            >
              <Grid3x3 className="h-4 w-4" />
            </button>
            <button
              onClick={() => onViewModeChange('table')}
              className={`p-2 ${viewMode === 'table' ? 'bg-blue-100 text-blue-600' : 'text-gray-400 hover:text-gray-600'}`}
            >
              <List className="h-4 w-4" />
            </button>
            <button
              onClick={() => onViewModeChange('cards')}
              className={`p-2 ${viewMode === 'cards' ? 'bg-blue-100 text-blue-600' : 'text-gray-400 hover:text-gray-600'}`}
            >
              <LayoutGrid className="h-4 w-4" />
            </button>
          </div>
        )}

        {/* Advanced Filters Toggle */}
        <Button
          variant="outline"
          onClick={() => setShowAdvanced(!showAdvanced)}
          className={activeFiltersCount > 0 ? 'border-blue-500 bg-blue-50' : ''}
        >
          <Filter className="mr-2 h-4 w-4" />
          Filters
          {activeFiltersCount > 0 && (
            <span className="ml-2 bg-blue-600 text-white text-xs rounded-full h-5 w-5 flex items-center justify-center">
              {activeFiltersCount}
            </span>
          )}
          <ChevronDown className={`ml-2 h-4 w-4 transition-transform ${showAdvanced ? 'rotate-180' : ''}`} />
        </Button>

        {/* Actions */}
        <div className="flex items-center space-x-2">
          <Button
            variant="outline"
            onClick={onRefresh}
            disabled={isLoading}
            size="sm"
          >
            <RefreshCw className={`h-4 w-4 ${isLoading ? 'animate-spin' : ''}`} />
          </Button>

          {hasFilters && (
            <Button
              variant="outline"
              onClick={onClearFilters}
              size="sm"
            >
              <X className="mr-1 h-4 w-4" />
              Clear
            </Button>
          )}
        </div>
      </div>

      {/* Advanced Filters Panel */}
      {showAdvanced && (
        <div className="bg-gray-50 rounded-lg p-4 space-y-4">
          <div className="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-4">
            {/* Asset Type */}
            <div>
              <label className="block text-sm font-medium text-gray-700 mb-2">
                Asset Type
              </label>
              <select
                value={type}
                onChange={(e) => setType(e.target.value)}
                className="w-full px-3 py-2 border border-gray-300 rounded-md focus:outline-none focus:ring-2 focus:ring-blue-500"
              >
                <option value="">All Types</option>
                <option value="table">Tables</option>
                <option value="view">Views</option>
                <option value="file">Files</option>
                <option value="api">APIs</option>
                <option value="dashboard">Dashboards</option>
                <option value="report">Reports</option>
              </select>
            </div>

            {/* Owner */}
            <div>
              <label className="block text-sm font-medium text-gray-700 mb-2">
                Owner
              </label>
              <input
                type="text"
                value={owner}
                onChange={(e) => setOwner(e.target.value)}
                placeholder="Enter owner name or email"
                className="w-full px-3 py-2 border border-gray-300 rounded-md focus:outline-none focus:ring-2 focus:ring-blue-500"
              />
            </div>

            {/* Data Quality */}
            <div>
              <label className="block text-sm font-medium text-gray-700 mb-2">
                Data Quality
              </label>
              <select
                value={quality}
                onChange={(e) => setQuality(e.target.value)}
                className="w-full px-3 py-2 border border-gray-300 rounded-md focus:outline-none focus:ring-2 focus:ring-blue-500"
              >
                <option value="">All Quality Levels</option>
                <option value="high">High Quality</option>
                <option value="medium">Medium Quality</option>
                <option value="low">Low Quality</option>
              </select>
            </div>

            {/* Classification */}
            <div>
              <label className="block text-sm font-medium text-gray-700 mb-2">
                Classification
              </label>
              <select
                value={classification}
                onChange={(e) => setClassification(e.target.value)}
                className="w-full px-3 py-2 border border-gray-300 rounded-md focus:outline-none focus:ring-2 focus:ring-blue-500"
              >
                <option value="">All Classifications</option>
                <option value="public">Public</option>
                <option value="internal">Internal</option>
                <option value="confidential">Confidential</option>
                <option value="restricted">Restricted</option>
              </select>
            </div>

            {/* Data Source */}
            <div>
              <label className="block text-sm font-medium text-gray-700 mb-2">
                Data Source
              </label>
              <select
                value={dataSourceId}
                onChange={(e) => setDataSourceId(e.target.value)}
                className="w-full px-3 py-2 border border-gray-300 rounded-md focus:outline-none focus:ring-2 focus:ring-blue-500"
              >
                <option value="">All Data Sources</option>
                <option value="ds-1">Production Database</option>
                <option value="ds-2">Analytics Database</option>
                <option value="ds-3">Data Lake</option>
                <option value="ds-4">External APIs</option>
              </select>
            </div>
          </div>
        </div>
      )}

      {/* Results Summary and Bulk Actions */}
      <div className="flex items-center justify-between">
        <div className="text-sm text-gray-600">
          {isLoading ? (
            <span>Searching...</span>
          ) : (
            <span>
              {totalResults.toLocaleString()} assets found
              {hasFilters && ' (filtered)'}
            </span>
          )}
        </div>

        {canSelectAll && onSelectAll && (
          <div className="flex items-center space-x-3">
            {selectedCount > 0 && (
              <span className="text-sm text-gray-600">
                {selectedCount} of {Math.min(totalResults, maxSelections)} selected
              </span>
            )}
            <div className="flex items-center space-x-2">
              <input
                type="checkbox"
                id="select-all"
                checked={selectedCount > 0}
                onChange={(e) => onSelectAll(e.target.checked)}
                className="h-4 w-4 text-blue-600 focus:ring-blue-500 border-gray-300 rounded"
              />
              <label htmlFor="select-all" className="text-sm text-gray-700">
                Select all
              </label>
            </div>
          </div>
        )}
      </div>
    </div>
  );
};


------------------------------------------------------------
FILE: frontend\src\components\features\data-quality\index.ts
------------------------------------------------------------
export { QualityOverview } from './QualityOverview'
export { QualityRules } from './QualityRules'
export { QualityTrends } from './QualityTrends'
export { ViolationsList } from './ViolationsList'

export type { QualityRule } from './QualityRules'
export type { TrendPoint } from './QualityTrends'
export type { Violation } from './ViolationsList'




------------------------------------------------------------
FILE: frontend\src\components\features\data-quality\QualityOverview.tsx
------------------------------------------------------------
// src/components/features/data-quality/QualityOverview.tsx
import { Card, CardContent, CardHeader, CardTitle } from '@components/ui/Card'
import { AlertTriangle, Shield, TrendingUp } from 'lucide-react'

type Totals = {
  rules: number
  activeRules: number
  violations: number
}

export type QualityOverviewProps = {
  /** Overall data quality score, 0..100 */
  score?: number
  /** Overall pass rate, 0..100 */
  passRate?: number
  /** Aggregate counts */
  totals?: Partial<Totals>
  /** ISO date string or null */
  lastUpdated?: string | null
}

/** Coerce maybe-number -> sane bounded number */
function coercePercent(v: unknown, fallback = 0): number {
  const n = typeof v === 'number' ? v : Number(v)
  if (!Number.isFinite(n)) return fallback
  return Math.min(100, Math.max(0, n))
}

/** Safe number formatter: returns e.g. "97.2%" */
function pctText(v: unknown, digits = 1, fallback = 'â€”%'): string {
  const n = typeof v === 'number' ? v : Number(v)
  if (!Number.isFinite(n)) return fallback
  return `${n.toFixed(digits)}%`
}

export function QualityOverview(props: QualityOverviewProps) {
  const score = coercePercent(props.score, 0)
  const passRate = coercePercent(props.passRate, 0)

  const activeRules = Math.max(0, Math.trunc(props.totals?.activeRules ?? 0))
  const violations = Math.max(0, Math.trunc(props.totals?.violations ?? 0))

  const updated =
    props.lastUpdated ? new Date(props.lastUpdated).toLocaleString() : 'Not available'

  return (
    <div className="grid grid-cols-1 gap-6 md:grid-cols-4">
      <Card>
        <CardHeader>
          <CardTitle className="text-sm text-gray-600">Overall Score</CardTitle>
        </CardHeader>
        <CardContent className="flex items-center justify-between">
          <p className="text-3xl font-bold text-green-600">{pctText(score, 0)}</p>
          <Shield className="h-8 w-8 text-green-600" aria-hidden />
        </CardContent>
      </Card>

      <Card>
        <CardHeader>
          <CardTitle className="text-sm text-gray-600">Pass Rate</CardTitle>
        </CardHeader>
        <CardContent className="flex items-center justify-between">
          <p className="text-3xl font-bold text-blue-600">{pctText(passRate, 0)}</p>
          <TrendingUp className="h-8 w-8 text-blue-600" aria-hidden />
        </CardContent>
      </Card>

      <Card>
        <CardHeader>
          <CardTitle className="text-sm text-gray-600">Active Rules</CardTitle>
        </CardHeader>
        <CardContent className="flex items-center justify-between">
          <p className="text-3xl font-bold text-gray-900">{activeRules}</p>
          <Shield className="h-8 w-8 text-gray-700" aria-hidden />
        </CardContent>
      </Card>

      <Card>
        <CardHeader>
          <CardTitle className="text-sm text-gray-600">Violations</CardTitle>
        </CardHeader>
        <CardContent className="flex items-center justify-between">
          <p className="text-3xl font-bold text-red-600">{violations}</p>
          <AlertTriangle className="h-8 w-8 text-red-600" aria-hidden />
        </CardContent>
      </Card>

      <div className="md:col-span-4 text-xs text-gray-500">Last updated: {updated}</div>
    </div>
  )
}

export default QualityOverview



------------------------------------------------------------
FILE: frontend\src\components\features\data-quality\QualityRules.tsx
------------------------------------------------------------
import { Badge } from '@components/ui/Badge'
import { Button } from '@components/ui/Button'
import { Card, CardContent, CardHeader, CardTitle } from '@components/ui/Card'
import { Input } from '@components/ui/Input'
import { Select } from '@components/ui/Select'
import { Filter, Plus } from 'lucide-react'
import * as React from 'react'

export type RuleSeverity = 'low' | 'medium' | 'high' | 'critical'
export type RuleStatus = 'active' | 'muted' | 'disabled'

export interface QualityRule {
  id: string
  name: string
  dataset: string
  severity: RuleSeverity
  status: RuleStatus
  lastRun?: string
  failures24h?: number
}

export interface QualityRulesProps {
  rules: QualityRule[]
  loading?: boolean
  onCreate?: () => void
  onToggleMute?: (id: string) => void
  onDisable?: (id: string) => void
}

export function QualityRules({ rules, loading, onCreate, onToggleMute, onDisable }: QualityRulesProps) {
  const [q, setQ] = React.useState('')
  const [sev, setSev] = React.useState('')
  const [status, setStatus] = React.useState('')

  const filtered = React.useMemo(() => {
    return rules.filter((r) => {
      const text = q.trim().toLowerCase()
      const matchText = !text || r.name.toLowerCase().includes(text) || r.dataset.toLowerCase().includes(text)
      const matchSev = !sev || r.severity === sev
      const matchStatus = !status || r.status === status
      return matchText && matchSev && matchStatus
    })
  }, [rules, q, sev, status])

  return (
    <Card>
      <CardHeader>
        <div className="flex items-center justify-between">
          <CardTitle>Quality Rules</CardTitle>
          <Button onClick={onCreate} leftIcon={<Plus className="h-4 w-4" />}>New Rule</Button>
        </div>
      </CardHeader>
      <CardContent>
        {/* Filters */}
        <div className="mb-4 grid grid-cols-1 gap-3 md:grid-cols-4">
          <Input value={q} onChange={(e) => setQ(e.target.value)} placeholder="Search rulesâ€¦" startIcon={<Filter className="h-4 w-4" />} />
          <Select
            label="Severity"
            value={sev}
            onChange={(e) => setSev(e.target.value)}
            options={[
              { label: 'All', value: '' },
              { label: 'Low', value: 'low' },
              { label: 'Medium', value: 'medium' },
              { label: 'High', value: 'high' },
              { label: 'Critical', value: 'critical' },
            ]}
          />
          <Select
            label="Status"
            value={status}
            onChange={(e) => setStatus(e.target.value)}
            options={[
              { label: 'All', value: '' },
              { label: 'Active', value: 'active' },
              { label: 'Muted', value: 'muted' },
              { label: 'Disabled', value: 'disabled' },
            ]}
          />
        </div>

        {/* Table */}
        {loading ? (
          <RulesSkeleton />
        ) : filtered.length === 0 ? (
          <div className="text-sm text-gray-600">No rules match your filters.</div>
        ) : (
          <div className="overflow-x-auto">
            <table className="min-w-full text-sm">
              <thead className="text-left text-gray-500">
                <tr>
                  <th className="py-2 pr-4">Rule</th>
                  <th className="py-2 pr-4">Dataset</th>
                  <th className="py-2 pr-4">Severity</th>
                  <th className="py-2 pr-4">Status</th>
                  <th className="py-2 pr-4">Failures (24h)</th>
                  <th className="py-2 pr-0 text-right">Actions</th>
                </tr>
              </thead>
              <tbody>
                {filtered.map((r) => (
                  <tr key={r.id} className="border-t">
                    <td className="py-2 pr-4 font-medium text-gray-900">{r.name}</td>
                    <td className="py-2 pr-4">{r.dataset}</td>
                    <td className="py-2 pr-4"><Badge tone={sevTone(r.severity)}>{r.severity}</Badge></td>
                    <td className="py-2 pr-4"><Badge tone={statusTone(r.status)}>{r.status}</Badge></td>
                    <td className="py-2 pr-4">{r.failures24h ?? 0}</td>
                    <td className="py-2 pr-0 text-right">
                      <div className="inline-flex gap-2">
                        <Button variant="outline" size="sm" onClick={() => onToggleMute?.(r.id)}>
                          {r.status === 'muted' ? 'Unmute' : 'Mute'}
                        </Button>
                        <Button variant="ghost" size="sm" onClick={() => onDisable?.(r.id)}>Disable</Button>
                      </div>
                    </td>
                  </tr>
                ))}
              </tbody>
            </table>
          </div>
        )}
      </CardContent>
    </Card>
  )
}

function sevTone(s: RuleSeverity) {
  return s === 'critical' ? 'danger' : s === 'high' ? 'warning' : s === 'medium' ? 'info' : 'neutral'
}
function statusTone(s: RuleStatus) {
  return s === 'active' ? 'success' : s === 'muted' ? 'neutral' : 'danger'
}

function RulesSkeleton() {
  return (
    <div className="space-y-2">
      {Array.from({ length: 6 }).map((_, i) => (
        <div key={i} className="h-10 w-full animate-pulse rounded bg-gray-200" />
      ))}
    </div>
  )
}



------------------------------------------------------------
FILE: frontend\src\components\features\data-quality\QualityTrends.tsx
------------------------------------------------------------
import { Card, CardContent, CardHeader, CardTitle } from '@components/ui/Card'

export interface TrendPoint {
  ts: string // ISO
  score: number
}

export function QualityTrends({ points = [] as TrendPoint[] }: { points?: TrendPoint[] }) {
  // Simple SVG sparkline (no external chart lib required)
  const w = 520, h = 80, pad = 6
  const ys = points.map(p => p.score)
  const min = Math.min(70, ...ys), max = Math.max(100, ...ys)
  const xStep = points.length > 1 ? (w - pad * 2) / (points.length - 1) : 0
  const path = points
    .map((p, i) => {
      const x = pad + i * xStep
      const y = pad + (1 - (p.score - min) / Math.max(1, (max - min))) * (h - pad * 2)
      return `${i === 0 ? 'M' : 'L'}${x},${y}`
    })
    .join(' ')

  return (
    <Card>
      <CardHeader><CardTitle>Quality Trends</CardTitle></CardHeader>
      <CardContent>
        {points.length === 0 ? (
          <div className="text-sm text-gray-600">No trend data available.</div>
        ) : (
          <svg width="100%" viewBox={`0 0 ${w} ${h}`} role="img" aria-label="Quality score trend">
            <path d={path} fill="none" stroke="currentColor" strokeWidth="2" />
          </svg>
        )}
      </CardContent>
    </Card>
  )
}



------------------------------------------------------------
FILE: frontend\src\components\features\data-quality\ViolationsList.tsx
------------------------------------------------------------
import { Badge } from '@components/ui/Badge'
import { Card, CardContent, CardHeader, CardTitle } from '@components/ui/Card'

export interface Violation {
  id: string
  ruleName: string
  dataset: string
  severity: 'low' | 'medium' | 'high' | 'critical'
  count: number
  firstSeen: string // ISO
  lastSeen: string  // ISO
}

export function ViolationsList({ items = [], loading }: { items?: Violation[]; loading?: boolean }) {
  if (loading) return <ListSkeleton />
  if (!items.length) return <Card><CardContent>No violations in the selected window.</CardContent></Card>

  return (
    <Card>
      <CardHeader>
        <CardTitle>Recent Violations</CardTitle>
      </CardHeader>
      <CardContent>
        <div className="overflow-x-auto">
          <table className="min-w-full text-sm">
            <thead className="text-left text-gray-500">
              <tr>
                <th className="py-2 pr-4">Rule</th>
                <th className="py-2 pr-4">Dataset</th>
                <th className="py-2 pr-4">Severity</th>
                <th className="py-2 pr-4">Count</th>
                <th className="py-2 pr-4">Last Seen</th>
              </tr>
            </thead>
            <tbody>
              {items.map((v) => (
                <tr key={v.id} className="border-t">
                  <td className="py-2 pr-4 font-medium text-gray-900">{v.ruleName}</td>
                  <td className="py-2 pr-4">{v.dataset}</td>
                  <td className="py-2 pr-4">
                    <Badge tone={v.severity === 'critical' ? 'danger' : v.severity === 'high' ? 'warning' : v.severity === 'medium' ? 'info' : 'neutral'}>
                      {v.severity}
                    </Badge>
                  </td>
                  <td className="py-2 pr-4">{v.count}</td>
                  <td className="py-2 pr-4">{fmt(v.lastSeen)}</td>
                </tr>
              ))}
            </tbody>
          </table>
        </div>
      </CardContent>
    </Card>
  )
}

function fmt(iso: string) {
  try { return new Date(iso).toLocaleString() } catch { return iso }
}

function ListSkeleton() {
  return (
    <div className="space-y-2">
      {Array.from({ length: 5 }).map((_, i) => (
        <div key={i} className="h-12 w-full animate-pulse rounded bg-gray-200" />
      ))}
    </div>
  )
}



------------------------------------------------------------
FILE: frontend\src\components\features\data-sources\AddConnectionWizard.tsx
------------------------------------------------------------
// src/components/features/data-sources/AddConnectionWizard.tsx
import {
  Activity,
  AlertTriangle,
  Check,
  CheckCircle,
  CheckCircle2,
  ChevronDown,
  ChevronLeft,
  Clock,
  Database,
  Eye,
  EyeOff,
  FileText,
  Filter,
  HardDrive,
  Info,
  Loader2,
  Lock,
  Search,
  Server,
  Settings,
  Shield,
  Star,
  TestTube,
  Unlock,
  Wand2,
  X,
  Zap,
} from 'lucide-react';
import * as React from 'react';
import { useCallback, useEffect, useMemo, useRef, useState } from 'react';

import { dataSourcesApi } from '@/services/api/dataSources'; // â¬…ï¸ fallback to your real API
import type {
  ConnectionConfig,
  CreateDataSourcePayload,
  DataSource,
  DataSourceType,
} from '@/types/dataSources';

/* ----------------------------------------------------------------------------
   Helpers: normalize test response (now with diagnostics)
---------------------------------------------------------------------------- */

type NormalizedTestResult = {
  success: boolean;
  message: string;
  databases: any[];
  metadata: any | null;
  connectionStatus?: string;
  responseTime?: number;
  testedAt?: string | number | Date;
};

function normalizeTestResponse(r: any) {
  const inner = r?.data ?? r;

  const success =
    typeof inner?.success === 'boolean'
      ? inner.success
      : typeof r?.success === 'boolean'
      ? r.success
      : false;

  const message =
    inner?.error ||
    inner?.details?.serverInfo?.statusText ||
    inner?.message ||
    r?.error ||
    r?.message ||
    (success ? 'Connection OK' : 'Connection test failed');

  const databases = Array.isArray(inner?.databases) ? inner.databases : r?.databases || [];
  const metadata  = inner?.metadata ?? r?.metadata ?? null;

  // â¬‡ï¸ pass through common diagnostics if present (your backend already returns these)
  const connectionStatus = inner?.connectionStatus ?? r?.connectionStatus;
  const responseTime     = inner?.responseTime ?? r?.responseTime;
  const testedAt         = inner?.testedAt ?? r?.testedAt;

  return { success, message, databases, metadata, connectionStatus, responseTime, testedAt };
}


/* ----------------------------------------------------------------------------
   Strong Types (UI-side)
---------------------------------------------------------------------------- */
type ConnectionScope = 'server' | 'cluster' | 'database' | 'schema'
type EnvironmentType = 'development' | 'staging' | 'production' | 'testing'
type SecurityLevel = 'basic' | 'enhanced' | 'enterprise'
type DiscoveryMode = 'auto' | 'manual' | 'scheduled' | 'guided'

export interface DatabaseInfo {
  name: string
  schema?: string
  size?: string
  tables?: number
  views?: number
  procedures?: number
  lastAccessed?: string
  accessible?: boolean
  selected?: boolean
  permissions?: string[]
  quality?: 'high' | 'medium' | 'low'
  usage?: 'active' | 'moderate' | 'inactive'
  owner?: string
  description?: string
  tags?: string[]
}

export interface ServerMetadata {
  version?: string
  edition?: string
  maxConnections?: number
  currentConnections?: number
  uptime?: string
  performance?: { cpu?: number; memory?: number; storage?: number }
}

type FieldType =
  | 'text'
  | 'password'
  | 'number'
  | 'textarea'
  | 'select'
  | 'toggle'
  | 'array'
  | 'url'
  | 'file'

interface EnhancedConnectorField {
  key: string
  label: string
  type: FieldType
  required?: boolean
  sensitive?: boolean
  placeholder?: string
  help?: string
  options?: Array<{
    label: string
    value: string
    description?: string
    recommended?: boolean
  }>
  validation?: {
    pattern?: string
    min?: number
    max?: number
    minLength?: number
    maxLength?: number
  }
  dependsOn?: {
    field: string
    value?: any
    condition?: 'equals' | 'not-equals' | 'truthy' | 'falsy' | 'contains'
  }
  wide?: boolean
  group?:
    | 'basic'
    | 'authentication'
    | 'security'
    | 'discovery'
    | 'advanced'
    | 'general'
  autoComplete?: 'on' | 'off' | 'username' | 'new-password'
}

interface ConnectionExample {
  id: string
  name: string
  description: string
  environment: EnvironmentType
  security: SecurityLevel
  config: Record<string, any>
  requirements?: string[]
  notes?: string
}

interface ValidationRule {
  field: string
  rule: 'required' | 'format' | 'range'
  params?: any
  message: string
  severity: 'error' | 'warning' | 'info'
}

/**
 * Connector template drives UI + safe config mapping to backend ConnectionConfig
 */
interface ConnectorTemplate {
  id: string // UI id
  submitType: DataSourceType // backend DataSourceType
  name: string
  description: string
  icon: string
  category: string
  scope: ConnectionScope
  environment: EnvironmentType
  security: SecurityLevel
  defaultPort?: number
  supportsDiscovery?: boolean
  supportsServerLevel?: boolean
  fields: EnhancedConnectorField[]
  examples: ConnectionExample[]
  validationRules: ValidationRule[]
  /** Allow-list of keys to send inside connectionConfig for this connector */
  configKeys: readonly string[]
  /** Optional custom mapper to transform UI cfg -> ConnectionConfig */
  toConfig?: (ui: Record<string, any>) => ConnectionConfig
  tags: string[]
  isPopular?: boolean
  isNew?: boolean
  isEnterprise?: boolean
  documentation?: string
  troubleshooting?: Array<{ issue: string; solution: string }>
}

/* utils */
function pick<T extends object, K extends readonly string[]>(
  obj: T,
  keys: K,
): Record<K[number], any> {
  const out: Record<string, any> = {}
  for (const k of keys) {
    if (k in obj) out[k] = (obj as any)[k]
  }
  return out as Record<K[number], any>
}

/* ----------------------------------------------------------------------------
   Connector Registry
---------------------------------------------------------------------------- */
const CONNECTORS: ConnectorTemplate[] = [
  {
    id: 'postgresql-server',
    submitType: 'postgresql',
    name: 'PostgreSQL Server',
    description: 'Server-level connection; auto-discover databases.',
    icon: 'ðŸ˜',
    category: 'Relational Databases',
    scope: 'server',
    environment: 'production',
    security: 'enterprise',
    defaultPort: 5432,
    supportsDiscovery: true,
    supportsServerLevel: true,
    tags: ['sql', 'server-level', 'acid', 'oss'],
    fields: [
      {
        key: 'name',
        label: 'Connection Name',
        type: 'text',
        required: true,
        wide: true,
        group: 'basic',
        autoComplete: 'off',
      },
      {
        key: 'host',
        label: 'Server Host',
        type: 'text',
        required: true,
        placeholder: 'db.company.com',
        validation: { pattern: '^[a-zA-Z0-9.-]+$' },
        group: 'basic',
        autoComplete: 'off',
      },
      {
        key: 'port',
        label: 'Port',
        type: 'number',
        required: true,
        placeholder: '5432',
        validation: { min: 1, max: 65535 },
        group: 'basic',
      },
      {
        key: 'database',
        label: 'Database',
        type: 'text',
        required: false,
        placeholder: 'postgres',
        group: 'basic',
        help: 'Used for the connectivity test. Defaults to "postgres".',
      },
      {
        key: 'username',
        label: 'Username',
        type: 'text',
        required: true,
        placeholder: 'postgres',
        group: 'authentication',
        autoComplete: 'username',
      },
      {
        key: 'password',
        label: 'Password',
        type: 'password',
        required: true,
        sensitive: true,
        group: 'authentication',
        autoComplete: 'new-password',
      },
      { key: 'ssl', label: 'Enable SSL/TLS', type: 'toggle', group: 'security' },
      {
        key: 'discoveryMode',
        label: 'Database Discovery',
        type: 'select',
        group: 'discovery',
        options: [
          {
            label: 'Automatic',
            value: 'auto',
            description: 'Auto-discover new databases',
            recommended: true,
          },
          { label: 'Manual', value: 'manual' },
          { label: 'Scheduled', value: 'scheduled' },
        ],
      },
    ],
    validationRules: [
      {
        field: 'host',
        rule: 'required',
        message: 'Server host is required',
        severity: 'error',
      },
      {
        field: 'port',
        rule: 'range',
        params: { min: 1, max: 65535 },
        message: 'Port must be between 1 and 65535',
        severity: 'error',
      },
    ],
    examples: [
      {
        id: 'pg-local',
        name: 'Local Dev',
        description: 'Local Docker/Homebrew',
        environment: 'development',
        security: 'basic',
        config: {
          host: 'localhost',
          port: 5432,
          database: 'postgres', 
          username: 'postgres',
          ssl: false,
          discoveryMode: 'auto',
        },
      },
      {
        id: 'pg-rds',
        name: 'AWS RDS',
        description: 'Production with SSL',
        environment: 'production',
        security: 'enterprise',
        config: { port: 5432, ssl: true, discoveryMode: 'scheduled' },
      },
    ],
    configKeys: ['host', 'port','database' ,'username', 'password', 'ssl'] as const,
  },

  {
    id: 'mysql-server',
    submitType: 'mysql',
    name: 'MySQL Server',
    description: 'Server-level connection; auto-discover databases.',
    icon: 'ðŸ¬',
    category: 'Relational Databases',
    scope: 'server',
    environment: 'production',
    security: 'enhanced',
    defaultPort: 3306,
    supportsDiscovery: true,
    supportsServerLevel: true,
    tags: ['sql', 'server-level'],
    fields: [
      {
        key: 'name',
        label: 'Connection Name',
        type: 'text',
        required: true,
        wide: true,
        group: 'basic',
      },
      {
        key: 'host',
        label: 'Server Host',
        type: 'text',
        required: true,
        placeholder: 'mysql.company.com',
        group: 'basic',
      },
      {
        key: 'port',
        label: 'Port',
        type: 'number',
        required: true,
        placeholder: '3306',
        validation: { min: 1, max: 65535 },
        group: 'basic',
      },
      { key: 'username', label: 'Username', type: 'text', required: true, group: 'authentication' },
      {
        key: 'password',
        label: 'Password',
        type: 'password',
        required: true,
        sensitive: true,
        group: 'authentication',
      },
      { key: 'ssl', label: 'Enable SSL', type: 'toggle', group: 'security' },
    ],
    validationRules: [
      {
        field: 'host',
        rule: 'required',
        message: 'Server host is required',
        severity: 'error',
      },
    ],
    examples: [
      {
        id: 'mysql-local',
        name: 'Local Dev',
        description: 'Local MySQL',
        environment: 'development',
        security: 'basic',
        config: { host: 'localhost', port: 3306, ssl: false },
      },
    ],
    configKeys: ['host', 'port', 'username', 'password', 'ssl'] as const,
  },

  {
    id: 'mssql-server',
    submitType: 'mssql',
    name: 'SQL Server',
    description: 'Connect to SQL Server instance and discover databases.',
    icon: 'ðŸ¢',
    category: 'Relational Databases',
    scope: 'server',
    environment: 'production',
    security: 'enhanced',
    defaultPort: 1433,
    supportsDiscovery: true,
    supportsServerLevel: true,
    tags: ['microsoft', 'azure', 'managed'],
    fields: [
      {
        key: 'name',
        label: 'Connection Name',
        type: 'text',
        required: true,
        wide: true,
        group: 'basic',
      },
      {
        key: 'host',
        label: 'Server Host',
        type: 'text',
        required: true,
        placeholder: 'myserver.database.windows.net',
        group: 'basic',
      },
      {
        key: 'port',
        label: 'Port',
        type: 'number',
        required: true,
        placeholder: '1433',
        validation: { min: 1, max: 65535 },
        group: 'basic',
      },
      { key: 'username', label: 'Username', type: 'text', required: true, group: 'authentication' },
      {
        key: 'password',
        label: 'Password',
        type: 'password',
        required: true,
        sensitive: true,
        group: 'authentication',
      },
      { key: 'ssl', label: 'Encrypt/SSL', type: 'toggle', group: 'security' },
    ],
    validationRules: [
      {
        field: 'host',
        rule: 'required',
        message: 'Server host is required',
        severity: 'error',
      },
    ],
    examples: [
      {
        id: 'mssql-azure',
        name: 'Azure SQL',
        description: 'Azure-hosted SQL Server',
        environment: 'production',
        security: 'enhanced',
        config: { port: 1433, ssl: true },
      },
    ],
    configKeys: ['host', 'port', 'username', 'password', 'ssl'] as const,
  },

  {
    id: 'snowflake-account',
    submitType: 'snowflake',
    name: 'Snowflake Account',
    description: 'Account-level connection (warehouses/databases discovery).',
    icon: 'â„ï¸',
    category: 'Cloud Warehouses',
    scope: 'cluster',
    environment: 'production',
    security: 'enterprise',
    defaultPort: 443,
    supportsDiscovery: true,
    supportsServerLevel: true,
    isPopular: true,
    tags: ['cloud', 'warehouse', 'account-level'],
    fields: [
      {
        key: 'name',
        label: 'Connection Name',
        type: 'text',
        required: true,
        wide: true,
        group: 'basic',
      },
      {
        key: 'account',
        label: 'Account Identifier',
        type: 'text',
        required: true,
        placeholder: 'xyz12345.us-east-1',
        group: 'basic',
      },
      { key: 'username', label: 'Username', type: 'text', required: true, group: 'authentication' },
      {
        key: 'password',
        label: 'Password',
        type: 'password',
        required: true,
        sensitive: true,
        group: 'authentication',
      },
      {
        key: 'warehouse',
        label: 'Default Warehouse',
        type: 'text',
        required: true,
        group: 'basic',
      },
    ],
    validationRules: [
      {
        field: 'account',
        rule: 'format',
        params: { pattern: '^[a-zA-Z0-9._-]+$' },
        message: 'Invalid account format',
        severity: 'error',
      },
    ],
    examples: [
      {
        id: 'sn-prod',
        name: 'Production',
        description: 'Full access account',
        environment: 'production',
        security: 'enterprise',
        config: { warehouse: 'COMPUTE_WH' },
      },
    ],
    configKeys: ['account', 'username', 'password', 'warehouse'] as const,
  },

  {
    id: 'bigquery-project',
    submitType: 'bigquery',
    name: 'BigQuery Project',
    description: 'Connect to a GCP project and discover datasets.',
    icon: 'ðŸ“Š',
    category: 'Cloud Warehouses',
    scope: 'cluster',
    environment: 'production',
    security: 'enterprise',
    supportsDiscovery: true,
    tags: ['gcp', 'warehouse'],
    fields: [
      {
        key: 'name',
        label: 'Connection Name',
        type: 'text',
        required: true,
        wide: true,
        group: 'basic',
      },
      { key: 'projectId', label: 'Project ID', type: 'text', required: true, group: 'basic' },
      {
        key: 'serviceAccountKey',
        label: 'Service Account JSON',
        type: 'textarea',
        required: true,
        sensitive: true,
        group: 'authentication',
      },
    ],
    validationRules: [
      {
        field: 'projectId',
        rule: 'required',
        message: 'Project ID is required',
        severity: 'error',
      },
    ],
    examples: [
      {
        id: 'bq-prod',
        name: 'Prod Project',
        description: 'Org prod project',
        environment: 'production',
        security: 'enterprise',
        config: {},
      },
    ],
    configKeys: ['projectId', 'serviceAccountKey'] as const,
  },

  {
    id: 'redshift-cluster',
    submitType: 'redshift',
    name: 'Amazon Redshift',
    description: 'Connect to your Redshift cluster.',
    icon: 'ðŸ”´',
    category: 'Cloud Warehouses',
    scope: 'cluster',
    environment: 'production',
    security: 'enterprise',
    defaultPort: 5439,
    supportsDiscovery: true,
    tags: ['aws', 'warehouse'],
    fields: [
      {
        key: 'name',
        label: 'Connection Name',
        type: 'text',
        required: true,
        wide: true,
        group: 'basic',
      },
      { key: 'host', label: 'Cluster Endpoint', type: 'text', required: true, group: 'basic' },
      {
        key: 'port',
        label: 'Port',
        type: 'number',
        required: true,
        placeholder: '5439',
        validation: { min: 1, max: 65535 },
        group: 'basic',
      },
      { key: 'username', label: 'Username', type: 'text', required: true, group: 'authentication' },
      {
        key: 'password',
        label: 'Password',
        type: 'password',
        required: true,
        sensitive: true,
        group: 'authentication',
      },
      { key: 'ssl', label: 'Enable SSL', type: 'toggle', group: 'security' },
    ],
    validationRules: [
      {
        field: 'host',
        rule: 'required',
        message: 'Cluster endpoint is required',
        severity: 'error',
      },
    ],
    examples: [
      {
        id: 'rs-prod',
        name: 'Production',
        description: 'Prod cluster',
        environment: 'production',
        security: 'enterprise',
        config: { ssl: true },
      },
    ],
    configKeys: ['host', 'port', 'username', 'password', 'ssl'] as const,
  },

  {
    id: 'databricks-sql',
    submitType: 'databricks',
    name: 'Databricks SQL',
    description: 'Connect to a Databricks SQL endpoint.',
    icon: 'ðŸ§±',
    category: 'Cloud Warehouses',
    scope: 'cluster',
    environment: 'production',
    security: 'enterprise',
    supportsDiscovery: true,
    tags: ['lakehouse', 'warehouse'],
    fields: [
      {
        key: 'name',
        label: 'Connection Name',
        type: 'text',
        required: true,
        wide: true,
        group: 'basic',
      },
      { key: 'host', label: 'Host', type: 'text', required: true, group: 'basic' },
      { key: 'httpPath', label: 'HTTP Path', type: 'text', required: true, group: 'basic' },
      {
        key: 'accessToken',
        label: 'Access Token',
        type: 'password',
        required: true,
        sensitive: true,
        group: 'authentication',
      },
    ],
    validationRules: [
      { field: 'host', rule: 'required', message: 'Host is required', severity: 'error' },
    ],
    examples: [
      {
        id: 'dbx-sql',
        name: 'Workspace SQL',
        description: 'SQL Warehouse endpoint',
        environment: 'production',
        security: 'enterprise',
        config: {},
      },
    ],
    configKeys: ['host', 'httpPath', 'accessToken'] as const,
  },

  {
    id: 'mongodb-server',
    submitType: 'mongodb',
    name: 'MongoDB Server',
    description: 'Connect to Mongo and discover databases.',
    icon: 'ðŸƒ',
    category: 'NoSQL',
    scope: 'server',
    environment: 'production',
    security: 'enhanced',
    defaultPort: 27017,
    supportsDiscovery: true,
    tags: ['nosql', 'document'],
    fields: [
      {
        key: 'name',
        label: 'Connection Name',
        type: 'text',
        required: true,
        wide: true,
        group: 'basic',
      },
      { key: 'host', label: 'Server Host', type: 'text', required: true, group: 'basic' },
      {
        key: 'port',
        label: 'Port',
        type: 'number',
        required: true,
        placeholder: '27017',
        validation: { min: 1, max: 65535 },
        group: 'basic',
      },
      { key: 'username', label: 'Username', type: 'text', required: false, group: 'authentication' },
      {
        key: 'password',
        label: 'Password',
        type: 'password',
        required: false,
        sensitive: true,
        group: 'authentication',
      },
      {
        key: 'replicaSet',
        label: 'Replica Set',
        type: 'text',
        required: false,
        group: 'advanced',
      },
      { key: 'ssl', label: 'Enable SSL', type: 'toggle', group: 'security' },
    ],
    validationRules: [
      { field: 'host', rule: 'required', message: 'Host is required', severity: 'error' },
    ],
    examples: [
      {
        id: 'mongo-dev',
        name: 'Dev Cluster',
        description: 'Dev replica set',
        environment: 'development',
        security: 'enhanced',
        config: { ssl: false },
      },
    ],
    configKeys: ['host', 'port', 'username', 'password', 'replicaSet', 'ssl'] as const,
  },

  {
    id: 'elasticsearch-cluster',
    submitType: 'elasticsearch',
    name: 'Elasticsearch',
    description: 'Connect to cluster for index discovery.',
    icon: 'ðŸ”',
    category: 'Search',
    scope: 'cluster',
    environment: 'production',
    security: 'enhanced',
    supportsDiscovery: true,
    tags: ['search', 'indices'],
    fields: [
      {
        key: 'name',
        label: 'Connection Name',
        type: 'text',
        required: true,
        wide: true,
        group: 'basic',
      },
      {
        key: 'host',
        label: 'Cluster URL',
        type: 'text',
        required: true,
        placeholder: 'https://es.company.com:9200',
        group: 'basic',
      },
      { key: 'username', label: 'Username', type: 'text', required: false, group: 'authentication' },
      {
        key: 'password',
        label: 'Password',
        type: 'password',
        required: false,
        sensitive: true,
        group: 'authentication',
      },
    ],
    validationRules: [
      {
        field: 'host',
        rule: 'required',
        message: 'Cluster URL is required',
        severity: 'error',
      },
    ],
    examples: [
      {
        id: 'es-prod',
        name: 'Prod ES',
        description: 'Managed cluster',
        environment: 'production',
        security: 'enhanced',
        config: {},
      },
    ],
    configKeys: ['host', 'username', 'password'] as const,
  },

  {
    id: 's3-bucket',
    submitType: 's3',
    name: 'Amazon S3',
    description: 'Connect to S3 bucket (object discovery/browse).',
    icon: 'â˜ï¸',
    category: 'Object Storage',
    scope: 'cluster',
    environment: 'production',
    security: 'enhanced',
    supportsDiscovery: true,
    tags: ['files', 'lake'],
    fields: [
      {
        key: 'name',
        label: 'Connection Name',
        type: 'text',
        required: true,
        wide: true,
        group: 'basic',
      },
      { key: 'bucket', label: 'Bucket', type: 'text', required: true, group: 'basic' },
      { key: 'region', label: 'Region', type: 'text', required: false, group: 'basic' },
      {
        key: 'accessKeyId',
        label: 'Access Key ID',
        type: 'text',
        required: true,
        group: 'authentication',
      },
      {
        key: 'secretAccessKey',
        label: 'Secret Access Key',
        type: 'password',
        required: true,
        sensitive: true,
        group: 'authentication',
      },
    ],
    validationRules: [
      { field: 'bucket', rule: 'required', message: 'Bucket is required', severity: 'error' },
    ],
    examples: [
      {
        id: 's3-lake',
        name: 'Data Lake',
        description: 'Central lake bucket',
        environment: 'production',
        security: 'enhanced',
        config: {},
      },
    ],
    configKeys: ['bucket', 'region', 'accessKeyId', 'secretAccessKey'] as const,
  },

  {
    id: 'azure-blob',
    submitType: 'azure-blob',
    name: 'Azure Blob Storage',
    description: 'Connect to Azure blob container.',
    icon: 'ðŸŸ¦',
    category: 'Object Storage',
    scope: 'cluster',
    environment: 'production',
    security: 'enhanced',
    supportsDiscovery: true,
    tags: ['files', 'azure'],
    fields: [
      {
        key: 'name',
        label: 'Connection Name',
        type: 'text',
        required: true,
        wide: true,
        group: 'basic',
      },
      { key: 'accountName', label: 'Account Name', type: 'text', required: true, group: 'basic' },
      { key: 'containerName', label: 'Container', type: 'text', required: true, group: 'basic' },
      {
        key: 'sasToken',
        label: 'SAS Token',
        type: 'password',
        required: true,
        sensitive: true,
        group: 'authentication',
      },
    ],
    validationRules: [
      {
        field: 'containerName',
        rule: 'required',
        message: 'Container is required',
        severity: 'error',
      },
    ],
    examples: [
      {
        id: 'ab-lake',
        name: 'Lake Container',
        description: 'Landing zone',
        environment: 'production',
        security: 'enhanced',
        config: {},
      },
    ],
    configKeys: ['accountName', 'containerName', 'sasToken'] as const,
  },

  {
    id: 'gcs-bucket',
    submitType: 'gcs',
    name: 'Google Cloud Storage',
    description: 'Connect to a GCS bucket.',
    icon: 'â˜ï¸',
    category: 'Object Storage',
    scope: 'cluster',
    environment: 'production',
    security: 'enhanced',
    supportsDiscovery: true,
    tags: ['files', 'gcp'],
    fields: [
      {
        key: 'name',
        label: 'Connection Name',
        type: 'text',
        required: true,
        wide: true,
        group: 'basic',
      },
      { key: 'bucketName', label: 'Bucket', type: 'text', required: true, group: 'basic' },
      { key: 'projectId', label: 'Project ID', type: 'text', required: false, group: 'basic' },
      {
        key: 'serviceAccountKey',
        label: 'Service Account JSON',
        type: 'textarea',
        required: true,
        sensitive: true,
        group: 'authentication',
      },
    ],
    validationRules: [
      {
        field: 'bucketName',
        rule: 'required',
        message: 'Bucket is required',
        severity: 'error',
      },
    ],
    examples: [
      {
        id: 'gcs-lake',
        name: 'Lake Bucket',
        description: 'Lakehouse files',
        environment: 'production',
        security: 'enhanced',
        config: {},
      },
    ],
    configKeys: ['bucketName', 'projectId', 'serviceAccountKey'] as const,
  },

  {
    id: 'rest-api',
    submitType: 'api',
    name: 'REST API',
    description: 'Connect to a REST/HTTP data API.',
    icon: 'ðŸ”Œ',
    category: 'APIs',
    scope: 'cluster',
    environment: 'production',
    security: 'enhanced',
    supportsDiscovery: false,
    tags: ['http', 'json'],
    fields: [
      {
        key: 'name',
        label: 'Connection Name',
        type: 'text',
        required: true,
        wide: true,
        group: 'basic',
      },
      {
        key: 'baseUrl',
        label: 'Base URL',
        type: 'text',
        required: true,
        placeholder: 'https://api.company.com',
        group: 'basic',
      },
      {
        key: 'apiKey',
        label: 'API Key',
        type: 'password',
        required: false,
        sensitive: true,
        group: 'authentication',
      },
    ],
    validationRules: [
      {
        field: 'baseUrl',
        rule: 'required',
        message: 'Base URL is required',
        severity: 'error',
      },
    ],
    examples: [
      {
        id: 'api-public',
        name: 'Public API',
        description: 'Read-only public endpoints',
        environment: 'staging',
        security: 'basic',
        config: {},
      },
    ],
    configKeys: ['baseUrl', 'apiKey'] as const,
  },

  {
    id: 'oracle-db',
    submitType: 'oracle',
    name: 'Oracle Database',
    description: 'Connect to Oracle (on-prem, OCI, or Autonomous Database).',
    icon: 'ðŸ›ï¸',
    category: 'Relational Databases',
    scope: 'server',
    environment: 'production',
    security: 'enterprise',
    defaultPort: 1521,
    supportsDiscovery: true,
    isPopular: true,
    tags: ['enterprise', 'oci', 'autonomous', 'tnsnames', 'wallet'],

    fields: [
      {
        key: 'name',
        label: 'Connection Name',
        type: 'text',
        required: true,
        wide: true,
        group: 'basic',
      },
      {
        key: 'mode',
        label: 'Connect Using',
        type: 'select',
        required: true,
        group: 'basic',
        options: [
          { label: 'Host / Port / Service Name', value: 'basic', recommended: true },
          { label: 'Easy Connect String (EZCONNECT/TNS)', value: 'ez' },
        ],
      },

      {
        key: 'host',
        label: 'Host',
        type: 'text',
        required: true,
        group: 'basic',
        dependsOn: { field: 'mode', value: 'basic', condition: 'equals' },
      },
      {
        key: 'port',
        label: 'Port',
        type: 'number',
        required: true,
        placeholder: '1521',
        group: 'basic',
        validation: { min: 1, max: 65535 },
        dependsOn: { field: 'mode', value: 'basic', condition: 'equals' },
      },
      {
        key: 'serviceName',
        label: 'Service Name (or SID)',
        type: 'text',
        required: true,
        group: 'basic',
        help: 'e.g. ORCLPDB1 or a TNS service name',
        dependsOn: { field: 'mode', value: 'basic', condition: 'equals' },
      },

      {
        key: 'connectString',
        label: 'Easy Connect String',
        type: 'text',
        required: true,
        group: 'basic',
        placeholder: 'host:port/service_name or //host:port/service_name',
        help: 'EZCONNECT or a TNS alias present in tnsnames.ora',
        dependsOn: { field: 'mode', value: 'ez', condition: 'equals' },
      },

      { key: 'username', label: 'Username', type: 'text', required: true, group: 'authentication' },
      {
        key: 'password',
        label: 'Password',
        type: 'password',
        required: true,
        sensitive: true,
        group: 'authentication',
      },

      { key: 'ssl', label: 'Enable SSL/TLS', type: 'toggle', group: 'security' },
      {
        key: 'walletMode',
        label: 'Wallet',
        type: 'select',
        group: 'security',
        options: [
          { label: 'None', value: 'none', recommended: true },
          { label: 'Wallet ZIP (Base64)', value: 'zip' },
          { label: 'Wallet Directory Path', value: 'dir' },
        ],
      },
      {
        key: 'walletZipBase64',
        label: 'Wallet ZIP (base64)',
        type: 'textarea',
        sensitive: true,
        group: 'security',
        placeholder: 'Paste base64 of the wallet ZIP (Autonomous DB)',
        dependsOn: { field: 'walletMode', value: 'zip', condition: 'equals' },
      },
      {
        key: 'walletDir',
        label: 'Wallet Directory',
        type: 'text',
        group: 'security',
        placeholder: '/opt/oracle/wallet',
        dependsOn: { field: 'walletMode', value: 'dir', condition: 'equals' },
      },

      {
        key: 'role',
        label: 'Role',
        type: 'text',
        group: 'advanced',
        placeholder: 'SYSDBA, SYSOPER (if applicable)',
      },
    ],

    validationRules: [
      { field: 'mode', rule: 'required', message: 'Select a connection mode', severity: 'error' },
      { field: 'host', rule: 'required', message: 'Host is required', severity: 'error' },
      {
        field: 'port',
        rule: 'range',
        params: { min: 1, max: 65535 },
        message: 'Port must be 1â€“65535',
        severity: 'error',
      },
      {
        field: 'serviceName',
        rule: 'required',
        message: 'Service name (or SID) is required',
        severity: 'error',
      },
      {
        field: 'connectString',
        rule: 'format',
        params: { pattern: '^[^\\s]+$' },
        message: 'Provide a valid connect string',
        severity: 'error',
      },
    ],

    examples: [
      {
        id: 'oracle-onprem',
        name: 'On-prem (basic)',
        description: 'Host/port + service name',
        environment: 'production',
        security: 'enterprise',
        config: { mode: 'basic', port: 1521, ssl: false, walletMode: 'none' },
      },
      {
        id: 'oracle-oci-adb',
        name: 'OCI Autonomous DB (Wallet ZIP)',
        description: 'Wallet-based TLS connection',
        environment: 'production',
        security: 'enterprise',
        config: { mode: 'ez', ssl: true, walletMode: 'zip' },
        requirements: ['Autonomous DB wallet ZIP'],
      },
    ],

    configKeys: [
      'host',
      'port',
      'serviceName',
      'connectString',
      'username',
      'password',
      'ssl',
      'walletMode',
      'walletZipBase64',
      'walletDir',
      'role',
    ] as const,

    toConfig: (ui): ConnectionConfig => {
      const base: Record<string, any> = {
        username: ui.username,
        password: ui.password,
        ssl: !!ui.ssl,
        role: ui.role || undefined,
      }

      if (ui.mode === 'ez') {
        base.connectString = ui.connectString
      } else {
        base.host = ui.host
        base.port = ui.port
        base.serviceName = ui.serviceName
      }

      if (ui.walletMode === 'zip' && ui.walletZipBase64) {
        base.walletZipBase64 = ui.walletZipBase64
      } else if (ui.walletMode === 'dir' && ui.walletDir) {
        base.walletDir = ui.walletDir
      }

      return base as ConnectionConfig
    },
  },
]

/* ----------------------------------------------------------------------------
   Props
---------------------------------------------------------------------------- */
interface Props {
  open: boolean
  onClose: () => void
  onCreate: (payload: CreateDataSourcePayload) => Promise<DataSource>
  onTestConnection?: (
    config: {
      type: DataSourceType
      connectionConfig: ConnectionConfig
    },
    signal?: AbortSignal,
  ) => Promise<{
    success: boolean
    message?: string
    databases?: DatabaseInfo[]
    metadata?: ServerMetadata
  }>
  existingConnections?: DataSource[]
}

const STEPS = [
  'Select Connector',
  'Configure Connection',
  'Discover Resources',
  'Review & Create',
] as const
type Step = (typeof STEPS)[number]

/* ----------------------------------------------------------------------------
   Component
---------------------------------------------------------------------------- */
export default function AddConnectionWizard({
  open,
  onClose,
  onCreate,
  onTestConnection,
  existingConnections = [],
}: Props) {
  const [step, setStep] = useState<Step>('Select Connector')
  const [selected, setSelected] = useState<ConnectorTemplate | null>(null)
  const [cfg, setCfg] = useState<Record<string, any>>({})
  const [errors, setErrors] = useState<Record<string, string>>({})
  const [showSensitive, setShowSensitive] = useState<Record<string, boolean>>({})

  const [search, setSearch] = useState('')
  const [category, setCategory] = useState('All')

  const [tests, setTests] = useState<
    Array<{
      id: string
      label: string
      status: 'pending' | 'running' | 'success' | 'error'
      message?: string
    }>
  >([])
  const [isTesting, setIsTesting] = useState(false)
  const [dbs, setDbs] = useState<DatabaseInfo[]>([])
  const [selectedDbs, setSelectedDbs] = useState<Set<string>>(new Set())
  const [meta, setMeta] = useState<ServerMetadata | null>(null)
  const abortRef = useRef<AbortController | null>(null)

  const [isCreating, setIsCreating] = useState(false)
  const [createError, setCreateError] = useState<string | null>(null)

  const containerRef = useRef<HTMLDivElement | null>(null)
  const firstFocusableRef = useRef<HTMLButtonElement | null>(null)
  const lastFocusableRef = useRef<HTMLButtonElement | null>(null)

  /* lifecycle: lock body scroll, reset & focus trap */
  useEffect(() => {
    if (!open) return
    const prev = document.body.style.overflow
    document.body.style.overflow = 'hidden'

    setStep('Select Connector')
    setSelected(null)
    setCfg({})
    setErrors({})
    setShowSensitive({})
    setTests([])
    setDbs([])
    setSelectedDbs(new Set())
    setMeta(null)
    setIsCreating(false)
    setCreateError(null)

    const onKey = (e: KeyboardEvent) => {
      if (e.key === 'Escape') {
        abortRef.current?.abort()
        safeClose()
      }
      if (e.key === 'Tab' && containerRef.current) {
        const focusables = containerRef.current.querySelectorAll<HTMLElement>(
          'button, [href], input, select, textarea, [tabindex]:not([tabindex="-1"])',
        )
        if (focusables.length) {
          const first = focusables[0]
          const last = focusables[focusables.length - 1]
          if (e.shiftKey && document.activeElement === first) {
            e.preventDefault()
            ;(last as HTMLElement).focus()
          } else if (!e.shiftKey && document.activeElement === last) {
            e.preventDefault()
            ;(first as HTMLElement).focus()
          }
        }
      }
    }
    window.addEventListener('keydown', onKey)

    return () => {
      document.body.style.overflow = prev
      window.removeEventListener('keydown', onKey)
      setCfg({})
    }
    // eslint-disable-next-line react-hooks/exhaustive-deps
  }, [open])

  const safeClose = useCallback(() => {
    setCfg({})
    onClose()
  }, [onClose])

  /* categories and filtered lists (debounced search) */
  const categories = useMemo(
    () => ['All', ...Array.from(new Set(CONNECTORS.map(c => c.category)))],
    [],
  )
  const [searchQ, setSearchQ] = useState(search)
  useEffect(() => {
    const t = setTimeout(() => setSearch(searchQ), 200)
    return () => clearTimeout(t)
  }, [searchQ])

  const filtered = useMemo(() => {
    const q = search.trim().toLowerCase()
    return CONNECTORS.filter(c => {
      const okCat = category === 'All' || c.category === category
      if (!q) return okCat
      const blob = `${c.name} ${c.description} ${c.tags.join(' ')}`.toLowerCase()
      return okCat && blob.includes(q)
    })
  }, [search, category])

  /* group fields for selected connector */
  const groups = useMemo(() => {
    if (!selected) return {} as Record<string, EnhancedConnectorField[]>
    const m: Record<string, EnhancedConnectorField[]> = {}
    for (const f of selected.fields) {
      const g = f.group ?? 'general'
      ;(m[g] ||= []).push(f)
    }
    return m
  }, [selected])

  /* handlers */
  const onSelectConnector = useCallback((c: ConnectorTemplate) => {
    setSelected(c)
    const next: Record<string, any> = {}
    if (c.defaultPort != null) next.port = c.defaultPort
    if (c.examples?.[0]) Object.assign(next, c.examples[0].config)
    setCfg(next)
    setStep('Configure Connection')
  }, [])

  const onChangeField = useCallback((key: string, value: any) => {
    setCfg(prev => ({ ...prev, [key]: value }))
    setErrors(prev => {
      if (!prev[key]) return prev
      const n = { ...prev }
      delete n[key]
      return n
    })
  }, [])

  const validate = useCallback(
    (c: ConnectorTemplate, values: Record<string, any>) => {
      const errs: Record<string, string> = {}
      for (const r of c.validationRules) {
        const v = values[r.field]
        if (
          r.rule === 'required' &&
          (v === undefined || v === null || String(v).trim() === '')
        ) {
          if (r.severity === 'error') errs[r.field] = r.message
        }
        if (r.rule === 'format' && v && r.params?.pattern) {
          const re = new RegExp(r.params.pattern)
          if (!re.test(String(v))) errs[r.field] = r.message
        }
        if (r.rule === 'range' && v != null && r.params) {
          if (v < r.params.min || v > r.params.max) errs[r.field] = r.message
        }
      }
      return errs
    },
    [],
  )

  // build sanitized connectionConfig
  const buildConnectionConfig = useCallback((): ConnectionConfig => {
    if (!selected) return {} as ConnectionConfig

    if (selected.toConfig) {
      return selected.toConfig(cfg)
    }

    const picked: Record<string, any> = {}
    for (const k of selected.configKeys) {
      if (k in cfg) picked[k] = (cfg as any)[k]
    }

    // scrub File objects
    for (const k of Object.keys(picked)) {
      // eslint-disable-next-line @typescript-eslint/ban-ts-comment
      // @ts-ignore
      if (typeof File !== 'undefined' && picked[k] instanceof File) {
        delete picked[k]
      }
    }

    return picked as unknown as ConnectionConfig
  }, [selected, cfg])

  const onPickTemplate = useCallback(
    (templateId: string) => {
      if (!selected) return
      const tmpl = selected.examples.find(e => e.id === templateId)
      if (!tmpl) return
      setCfg(prev => ({ ...prev, ...tmpl.config }))
    },
    [selected],
  )

  const toggleDb = useCallback((name: string, on: boolean) => {
    setSelectedDbs(prev => {
      const next = new Set(prev)
      if (on) next.add(name)
      else next.delete(name)
      return next
    })
  }, [])

  /* ------------------------------------------------------------------------
     Default tester (keeps parent override)
  ------------------------------------------------------------------------ */
  const callTest = useCallback(
    async (
      payload: { type: DataSourceType; connectionConfig: ConnectionConfig },
      signal?: AbortSignal,
    ) => {
      if (onTestConnection) {
        return onTestConnection(payload, signal);
      }
      // Fallback to service API
      return dataSourcesApi.testConfig(payload.type, payload.connectionConfig);
    },
    [onTestConnection],
  );

  /* ------------------------------------------------------------------------
     Test & Discover (drop-in)
  ------------------------------------------------------------------------ */
  const performTestAndDiscover = useCallback(
    async (signal?: AbortSignal) => {
      if (!selected) return;

      try {
        setIsTesting(true);
        setTests([{ id: 'ping', label: 'Connectivity', status: 'running' }]);
        setDbs([]);
        setSelectedDbs(new Set());
        setMeta(null);

        const config = buildConnectionConfig();

        // 1) Test connectivity
        const raw = await callTest(
          { type: selected.submitType, connectionConfig: config },
          signal,
        );
        const res = normalizeTestResponse(raw);

        if (!res.success) {
          const hasSpecificMsg = !!res.message && res.message !== 'Connection test failed';

          const rows: Array<{
            id: string;
            label: string;
            status: 'error';
            message?: string;
          }> = [
            {
              id: 'ping',
              label: 'Connectivity',
              status: 'error',
              message: hasSpecificMsg
                ? res.message
                : 'Connection failed. No error details were returned.',
            },
          ];

          const details: string[] = [];
          if (res.connectionStatus) details.push(`Status: ${String(res.connectionStatus)}`);
          if (typeof res.responseTime === 'number') details.push(`Response time: ${res.responseTime} ms`);
          if (res.testedAt) details.push(`Tested at: ${new Date(res.testedAt).toLocaleString()}`);
          if (details.length) {
            rows.push({
              id: 'details',
              label: 'Details',
              status: 'error',
              message: details.join(' â€¢ '),
            });
          }

          if (!hasSpecificMsg) {
            const tips =
              selected.submitType === 'postgresql'
                ? [
                    'Verify host/port are reachable (localhost:5432).',
                    'Confirm username/password are correct.',
                    'Toggle SSL to match server requirement (ON if required, OFF if forbidden).',
                    'Ensure Postgres listens on 127.0.0.1/0.0.0.0 and pg_hba.conf allows your user.',
                    'Try `psql -h localhost -U <user> -p 5432` locally to validate.',
                  ]
                : [
                    'Check host/port reachability (firewall, network, container networking).',
                    'Double-check credentials and auth method.',
                    'Match the serverâ€™s SSL/TLS requirement.',
                  ];
            rows.push({
              id: 'next',
              label: 'Next steps',
              status: 'error',
              message: `Try:\nâ€¢ ${tips.join('\nâ€¢ ')}`,
            });
          }

          setTests(rows as any);
          setStep('Configure Connection');
          return;
        }

        // Success row + optional telemetry
        const okRows: any[] = [
          {
            id: 'ping',
            label: 'Connectivity',
            status: 'success',
            message: res.message || 'Connection successful',
          },
        ];
        const okDetails: string[] = [];
        if (res.connectionStatus) okDetails.push(`Status: ${String(res.connectionStatus)}`);
        if (typeof res.responseTime === 'number') okDetails.push(`Response time: ${res.responseTime} ms`);
        if (res.testedAt) okDetails.push(`Tested at: ${new Date(res.testedAt).toLocaleString()}`);
        if (okDetails.length) {
          okRows.push({
            id: 'details',
            label: 'Details',
            status: 'success',
            message: okDetails.join(' â€¢ '),
          });
        }
        setTests(okRows);

        // 2) Optional discovery for server-scope connectors
        if (selected.supportsDiscovery && selected.scope === 'server') {
          try {
            const previewResponse = await fetch(
              'http://localhost:8000/api/data-sources/databases/preview',
              {
                method: 'POST',
                headers: {
                  'Content-Type': 'application/json',
                  'x-dev-auth': '1',
                },
                body: JSON.stringify({
                  type: selected.submitType,
                  config,
                }),
                signal,
              },
            );

            const previewText = await previewResponse.text();
            let previewData: any = null;
            try {
              previewData = JSON.parse(previewText);
            } catch {
              // ignore parse error; fall through to empty
            }

            if (previewResponse.ok && previewData?.success && Array.isArray(previewData.data)) {
              const discoveredDatabases = previewData.data.map((db: any) => ({
                name: db.name || db,
                accessible: true,
                selected: false,
                quality: 'medium' as const,
                usage: 'active' as const,
              }));
              setDbs(discoveredDatabases);
            } else {
              setDbs([]);
            }
          } catch (err) {
            console.error('Database discovery failed:', err);
            setDbs([]);
          }
        }

        // 3) Metadata (if any)
        setMeta((res.metadata as ServerMetadata) ?? null);

        // 4) Advance
        setStep('Discover Resources');
      } catch (error: any) {
        if (error?.name === 'AbortError') return;
        console.error('Connection test error:', error?.message || error);
        setTests([
          {
            id: 'ping',
            label: 'Connectivity',
            status: 'error',
            message: error?.message || 'Unexpected error during test',
          },
        ]);
        setStep('Configure Connection');
      } finally {
        setIsTesting(false);
      }
    },
    [selected, buildConnectionConfig, callTest],
  );

  // Click wrapper (unchanged API)
  const handleTestAndDiscover = (event: React.MouseEvent<HTMLButtonElement>) => {
    event.preventDefault();
    const controller = new AbortController();
    performTestAndDiscover(controller.signal).catch((err) =>
      console.error('Test and discover failed:', err),
    );
  };

  const onCreateConnection = useCallback(async () => {
    if (!selected) return
    const errs = validate(selected, cfg)
    setErrors(errs)
    if (Object.keys(errs).length) {
      setStep('Configure Connection')
      return
    }

    setIsCreating(true)
    setCreateError(null)
    try {
      const payload: CreateDataSourcePayload = {
        type: selected.submitType,
        name: (cfg.name as string) || selected.name,
        connectionConfig: buildConnectionConfig(),
        options: {
          selectedDatabases: Array.from(selectedDbs),
          scope: selected.scope,
        } as any,
        tags: selected.tags ?? [],
      } as CreateDataSourcePayload

      await onCreate(payload)

      setIsCreating(false)
      safeClose()
    } catch (e: any) {
      setIsCreating(false)
      setCreateError(e?.response?.data?.message ?? e?.message ?? 'Failed to create connection')
    }
  }, [selected, cfg, selectedDbs, buildConnectionConfig, onCreate, validate, safeClose])

  const canProceedFromConfigure = useMemo(() => {
    if (!selected) return false
    const errs = validate(selected, cfg)
    return Object.keys(errs).length === 0 && !isTesting
  }, [selected, cfg, validate, isTesting])

  if (!open) return null

  /* ----------------------------------------------------------------------------
     UI
  ---------------------------------------------------------------------------- */
  return (
    <div
      className="fixed inset-0 z-50 flex items-center justify-center bg-black/50 backdrop-blur-sm"
      role="dialog"
      aria-modal="true"
      aria-label="Add Connection Wizard"
      ref={containerRef}
    >
      <div className="bg-white rounded-2xl shadow-2xl w-full max-w-7xl max-h-[95vh] flex flex-col overflow-hidden">
        {/* Header & progress */}
        <div className="flex items-center justify-between p-6 border-b border-gray-200 bg-gradient-to-b from-white to-slate-50">
          <div>
            <h2 className="text-2xl font-bold text-gray-900">Add Connection</h2>
            <p className="text-gray-600 mt-1">
              Server-level connections with automatic discovery
            </p>
            <div className="flex items-center mt-4 space-x-2">
              {STEPS.map((s, i) => (
                <React.Fragment key={s}>
                  <div
                    className={`relative flex items-center justify-center w-10 h-10 rounded-full text-sm font-medium transition-all duration-300 ${
                      s === step
                        ? 'bg-blue-600 text-white shadow-lg scale-110'
                        : STEPS.indexOf(step) > i
                        ? 'bg-green-500 text-white'
                        : 'bg-gray-200 text-gray-600'
                    }`}
                    aria-current={step === s ? 'step' : undefined}
                  >
                    {STEPS.indexOf(step) > i ? <Check className="w-5 h-5" /> : i + 1}
                  </div>
                  {i < STEPS.length - 1 && (
                    <div
                      className={`w-16 h-1 rounded-full ${
                        STEPS.indexOf(step) > i ? 'bg-green-500' : 'bg-gray-200'
                      }`}
                    />
                  )}
                </React.Fragment>
              ))}
            </div>
          </div>

          <div className="flex items-center gap-2">
            <button
              ref={firstFocusableRef}
              onClick={() => {
                abortRef.current?.abort()
                safeClose()
              }}
              className="p-2 hover:bg-gray-100 rounded-lg"
              aria-label="Close"
            >
              <X className="w-5 h-5 text-gray-600" />
            </button>
          </div>
        </div>

        {/* Body */}
        <div className="flex-1 overflow-y-auto p-6">
          {step === 'Select Connector' && (
            <ConnectorSelect
              categories={categories}
              category={category}
              setCategory={setCategory}
              search={searchQ}
              setSearch={setSearchQ}
              list={filtered}
              onSelect={onSelectConnector}
            />
          )}

          {step === 'Configure Connection' && selected && (
            <ConfigureSection
              selected={selected}
              cfg={cfg}
              groups={groups}
              errors={errors}
              showSensitive={showSensitive}
              setShowSensitive={setShowSensitive}
              onPickTemplate={onPickTemplate}
              onChangeField={onChangeField}
              tests={tests}
            />
          )}

          {step === 'Discover Resources' && (
            <DiscoverSection
              meta={meta}
              dbs={dbs}
              selectedDbs={selectedDbs}
              setSelectedDbs={setSelectedDbs}
              toggleDb={toggleDb}
            />
          )}

          {step === 'Review & Create' && selected && (
            <ReviewSection selected={selected} cfg={cfg} selectedDbs={selectedDbs} />
          )}
        </div>

        {/* Footer */}
        <div className="border-t border-gray-200 p-6 flex justify-between items-center bg-gray-50">
          <div>
            {step !== 'Select Connector' && (
              <button
                onClick={() => {
                  setCreateError(null)
                  setStep(prev =>
                    prev === 'Configure Connection'
                      ? 'Select Connector'
                      : prev === 'Discover Resources'
                      ? 'Configure Connection'
                      : 'Discover Resources',
                  )
                }}
                className="flex items-center px-4 py-2 text-gray-600 hover:text-gray-800 font-medium"
              >
                <ChevronLeft className="w-4 h-4 mr-2" />
                Back
              </button>
            )}
          </div>

          <div className="flex items-center gap-3">
            {createError && <span className="text-sm text-red-600 mr-2">{createError}</span>}

            <button
              onClick={() => {
                abortRef.current?.abort()
                safeClose()
              }}
              className="px-6 py-2 border rounded-lg hover:bg-gray-50 font-medium"
              ref={lastFocusableRef}
            >
              Cancel
            </button>

            {step === 'Configure Connection' && (
              <button
                onClick={handleTestAndDiscover}
                disabled={!canProceedFromConfigure}
                className="flex items-center px-8 py-2 bg-blue-600 text-white rounded-lg hover:bg-blue-700 disabled:opacity-50"
              >
                {isTesting && <Loader2 className="w-4 h-4 mr-2 animate-spin" />}
                Test & Discover
              </button>
            )}

            {step === 'Discover Resources' && (
              <button
                onClick={() => setStep('Review & Create')}
                className="px-8 py-2 bg-blue-600 text-white rounded-lg hover:bg-blue-700"
              >
                Review
              </button>
            )}

            {step === 'Review & Create' && (
              <button
                onClick={onCreateConnection}
                disabled={isCreating}
                className="flex items-center px-8 py-2 bg-emerald-600 text-white rounded-lg hover:bg-emerald-700 disabled:opacity-50"
              >
                {isCreating && <Loader2 className="w-4 h-4 mr-2 animate-spin" />}
                Create Connection
              </button>
            )}
          </div>
        </div>
      </div>
    </div>
  )
}

/* ----------------------------------------------------------------------------
   Sections & Subcomponents
---------------------------------------------------------------------------- */
function ConnectorSelect({
  categories,
  category,
  setCategory,
  search,
  setSearch,
  list,
  onSelect,
}: {
  categories: string[]
  category: string
  setCategory: (v: string) => void
  search: string
  setSearch: (v: string) => void
  list: ConnectorTemplate[]
  onSelect: (c: ConnectorTemplate) => void
}) {
  return (
    <div className="space-y-8">
      <div className="bg-gradient-to-r from-blue-50 to-indigo-50 p-6 rounded-2xl border border-blue-200">
        <div className="flex flex-col gap-4 md:flex-row">
          <div className="relative flex-1">
            <Search className="absolute left-4 top-1/2 -translate-y-1/2 h-5 w-5 text-gray-400" />
            <input
              value={search}
              onChange={e => setSearch(e.target.value)}
              placeholder="Search connectors by name, technology, or featureâ€¦"
              className="w-full pl-12 pr-4 py-3 border rounded-xl focus:ring-2 focus:ring-blue-500"
            />
          </div>
          <div className="relative">
            <Filter className="absolute left-3 top-1/2 -translate-y-1/2 h-4 w-4 text-gray-400" />
            <select
              value={category}
              onChange={e => setCategory(e.target.value)}
              className="pl-10 pr-8 py-3 border rounded-xl focus:ring-2 focus:ring-blue-500 appearance-none bg-white min-w[180px]"
            >
              {categories.map(c => (
                <option key={c} value={c}>
                  {c}
                </option>
              ))}
            </select>
            <ChevronDown className="absolute right-3 top-1/2 -translate-y-1/2 h-4 w-4 text-gray-400 pointer-events-none" />
          </div>
        </div>
      </div>

      {!search && category === 'All' && (
        <section>
          <div className="flex items-center justify-between mb-4">
            <h3 className="text-xl font-bold text-gray-900 flex items-center">
              <Star className="w-5 h-5 text-yellow-500 mr-2" /> Popular
            </h3>
            <span className="text-sm text-gray-500">
              Server-level & discovery-ready
            </span>
          </div>
          <div className="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-6">
            {list
              .filter(c => c.isPopular)
              .map(c => (
                <ConnectorCard
                  key={c.id}
                  connector={c}
                  onClick={() => onSelect(c)}
                  badge="Popular"
                />
              ))}
          </div>
        </section>
      )}

      <div className="space-y-10">
        {categories
          .filter(c => c !== 'All')
          .map(cat => {
            const items = list.filter(c => c.category === cat)
            if (!items.length) return null
            return (
              <section key={cat}>
                <h3 className="text-xl font-bold text-gray-900 mb-4">{cat}</h3>
                <div className="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-6">
                  {items.map(c => (
                    <ConnectorCard
                      key={c.id}
                      connector={c}
                      onClick={() => onSelect(c)}
                    />
                  ))}
                </div>
              </section>
            )
          })}
      </div>
    </div>
  )
}

function ConfigureSection({
  selected,
  cfg,
  groups,
  errors,
  showSensitive,
  setShowSensitive,
  onPickTemplate,
  onChangeField,
  tests,
}: {
  selected: ConnectorTemplate
  cfg: Record<string, any>
  groups: Record<string, EnhancedConnectorField[]>
  errors: Record<string, string>
  showSensitive: Record<string, boolean>
  setShowSensitive: React.Dispatch<
    React.SetStateAction<Record<string, boolean>>
  >
  onPickTemplate: (id: string) => void
  onChangeField: (key: string, value: any) => void
  tests: Array<{
    id: string
    label: string
    status: 'pending' | 'running' | 'success' | 'error'
    message?: string
  }>
}) {
  return (
    <div className="space-y-8">
      <div className="bg-gradient-to-r from-blue-50 to-indigo-50 p-6 rounded-2xl border border-blue-200">
        <div className="flex items-center gap-6">
          <div className="text-5xl">{selected.icon}</div>
          <div className="flex-1">
            <h3 className="text-2xl font-bold text-gray-900">{selected.name}</h3>
            <p className="text-gray-600">{selected.description}</p>
            <div className="flex items-center mt-3 space-x-6">
              <span className="flex items-center text-sm text-blue-700">
                <Server className="w-4 h-4 mr-1" /> {selected.scope.toUpperCase()} level
              </span>
              {selected.supportsDiscovery && (
                <span className="flex items-center text-sm text-purple-700">
                  <Zap className="w-4 h-4 mr-1" /> Auto-discovery
                </span>
              )}
            </div>
          </div>
        </div>
      </div>

      {selected.examples.length > 0 && (
        <div>
          <h4 className="text-lg font-semibold text-gray-900 flex items-center">
            <Wand2 className="w-5 h-5 mr-2 text-purple-600" /> Quick Setup Templates
          </h4>
          <div className="mt-3 grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-4">
            {selected.examples.map(t => (
              <button
                key={t.id}
                onClick={() => onPickTemplate(t.id)}
                className="p-4 text-left border-2 rounded-xl hover:shadow-md transition-all border-gray-200 hover:border-blue-300"
              >
                <div className="flex items-center justify-between mb-2">
                  <div className="font-semibold">{t.name}</div>
                  <span
                    className={`text-xs px-2 py-0.5 rounded-full ${
                      t.environment === 'production'
                        ? 'bg-red-100 text-red-700'
                        : 'bg-green-100 text-green-700'
                    }`}
                  >
                    {t.environment}
                  </span>
                </div>
                <p className="text-sm text-gray-600">{t.description}</p>
                {t.requirements?.length ? (
                  <div className="text-xs text-gray-500 mt-2">
                    <strong>Requirements:</strong> {t.requirements.join(', ')}
                  </div>
                ) : null}
              </button>
            ))}
          </div>
        </div>
      )}

      {Object.entries(groups).map(([g, fields]) => (
        <section key={g} className="space-y-3">
          <h4 className="text-lg font-semibold text-gray-900 capitalize flex items-center">
            {g === 'basic' && <Settings className="w-4 h-4 mr-2" />}
            {g === 'authentication' && <Lock className="w-4 h-4 mr-2" />}
            {g === 'security' && <Shield className="w-4 h-4 mr-2" />}
            {g === 'discovery' && <Search className="w-4 h-4 mr-2" />}
            {g}
          </h4>
          <div className="grid grid-cols-1 md:grid-cols-2 gap-6">
            {fields.map(f => (
              <ConfigField
                key={f.key}
                field={f}
                value={cfg[f.key] ?? (f.type === 'toggle' ? false : '')}
                onChange={v => onChangeField(f.key, v)}
                error={errors[f.key]}
                show={!!showSensitive[f.key]}
                onToggleShow={() =>
                  setShowSensitive(prev => ({ ...prev, [f.key]: !prev[f.key] }))
                }
                config={cfg}
              />
            ))}
          </div>
        </section>
      ))}

      {!!tests.length && (
        <section>
          <h4 className="text-lg font-semibold text-gray-900 flex items-center">
            <TestTube className="w-5 h-5 mr-2 text-blue-600" /> Connection Test
          </h4>
          <div className="bg-gray-50 rounded-xl p-4 space-y-3">
            {tests.map(t => (
              <TestRow key={t.id} test={t} />
            ))}
          </div>
        </section>
      )}
    </div>
  )
}

function DiscoverSection({
  meta,
  dbs,
  selectedDbs,
  setSelectedDbs,
  toggleDb,
}: {
  meta: ServerMetadata | null
  dbs: DatabaseInfo[]
  selectedDbs: Set<string>
  setSelectedDbs: React.Dispatch<React.SetStateAction<Set<string>>>
  toggleDb: (name: string, on: boolean) => void
}) {
  return (
    <div className="space-y-8">
      {meta && (
        <div className="bg-gradient-to-r from-green-50 to-emerald-50 p-6 rounded-2xl border border-green-200">
          <h3 className="text-lg font-semibold text-gray-900 mb-4 flex items-center">
            <Server className="w-5 h-5 mr-2 text-green-600" /> Server Information
          </h3>
          <div className="grid grid-cols-2 md:grid-cols-4 gap-4 text-center">
            <Stat value={meta.version ?? 'â€”'} label="Version" color="text-green-600" />
            <Stat
              value={`${meta.currentConnections ?? 0}/${meta.maxConnections ?? 'â€”'}`}
              label="Connections"
              color="text-blue-600"
            />
            <Stat value={meta.uptime ?? 'â€”'} label="Uptime" color="text-purple-600" />
            <Stat value="â€”" label="Security" color="text-orange-600" />
          </div>
        </div>
      )}

      <div className="flex items-center justify-between">
        <div>
          <h3 className="text-2xl font-bold text-gray-900">Discovered Databases</h3>
          <p className="text-gray-600">
            Select databases to include post-creation (for scope UI only)
          </p>
        </div>
        <div className="flex items-center gap-3">
          <button
            onClick={() =>
              setSelectedDbs(new Set(dbs.filter(x => x.accessible !== false).map(x => x.name)))
            }
            className="text-sm text-blue-600 hover:text-blue-700 font-medium flex items-center"
          >
            <CheckCircle className="w-4 h-4 mr-1" /> Select All Accessible
          </button>
          <button
            onClick={() => setSelectedDbs(new Set())}
            className="text-sm text-gray-600 hover:text-gray-800 font-medium"
          >
            Clear
          </button>
        </div>
      </div>

      {/* Quick stats */}
      <div className="grid grid-cols-1 md:grid-cols-4 gap-4">
        <SummaryCard
          label="Total Databases"
          value={dbs.length}
          icon={<Database className="w-8 h-8 text-blue-600" />}
          tone="blue"
        />
        <SummaryCard
          label="Accessible"
          value={dbs.filter(x => x.accessible !== false).length}
          icon={<Unlock className="w-8 h-8 text-green-600" />}
          tone="green"
        />
        <SummaryCard
          label="Selected"
          value={selectedDbs.size}
          icon={<CheckCircle className="w-8 h-8 text-purple-600" />}
          tone="purple"
        />
        <SummaryCard
          label="Total Tables"
          value={dbs.reduce((s, d) => s + (d.tables ?? 0), 0)}
          icon={<FileText className="w-8 h-8 text-orange-600" />}
          tone="orange"
        />
      </div>

      {/* DB list */}
      <div className="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-4">
        {dbs.map(d => (
          <DbCard
            key={d.name}
            db={d}
            selected={selectedDbs.has(d.name)}
            onToggle={on => toggleDb(d.name, on)}
          />
        ))}
        {!dbs.length && (
          <div className="col-span-full rounded-xl border border-dashed p-8 text-center text-gray-500">
            No databases discovered. You can still create the connection and
            discover later.
          </div>
        )}
      </div>

      {/* Selection hint */}
      <div className="bg-blue-50 p-6 rounded-xl border border-blue-200">
        <div className="flex items-center justify-between">
          <div className="flex items-center">
            <Info className="w-6 h-6 text-blue-600 mr-3" />
            <div>
              <span className="font-semibold text-blue-900">
                {selectedDbs.size} database{selectedDbs.size === 1 ? '' : 's'} selected (UI)
              </span>
              <p className="text-sm text-blue-700 mt-1">
                Weâ€™ll remember this in UI. The server connection is still created at the
                server/account level.
              </p>
            </div>
          </div>
          <div className="text-right text-blue-700">
            <div className="text-sm">Coverage</div>
            <div className="text-lg font-semibold">
              {dbs.length ? Math.round((selectedDbs.size / dbs.length) * 100) : 0}%
            </div>
          </div>
        </div>
      </div>
    </div>
  )
}

function ReviewSection({
  selected,
  cfg,
  selectedDbs,
}: {
  selected: ConnectorTemplate
  cfg: Record<string, any>
  selectedDbs: Set<string>
}) {
  return (
    <div className="space-y-8">
      <h3 className="text-2xl font-bold text-gray-900">Review Your Connection</h3>

      <div className="bg-gradient-to-r from-green-50 to-emerald-50 p-8 rounded-2xl border border-green-200">
        <div className="flex items-center justify-between">
          <div className="flex items-center gap-6">
            <div className="text-6xl">{selected.icon}</div>
            <div>
              <div className="text-2xl font-bold">
                {(cfg.name as string) || selected.name}
              </div>
              <div className="text-gray-600">
                {selected.name} ({selected.submitType})
              </div>
              <div className="flex items-center gap-4 text-sm mt-2">
                {cfg.host && (
                  <span className="text-gray-600">
                    <Server className="inline h-4 w-4 mr-1" /> {cfg.host}
                    {cfg.port ? `:${cfg.port}` : ''}
                  </span>
                )}
                <span className="text-green-700">
                  <Database className="inline h-4 w-4 mr-1" /> {selectedDbs.size} DB(s)
                </span>
              </div>
            </div>
          </div>
          <div className="text-center">
            <div className="text-4xl font-bold text-green-600">
              {selectedDbs.size}
            </div>
            <div className="text-sm text-gray-600">Databases</div>
            <div className="text-xs text-green-600 mt-1">Server-level</div>
          </div>
        </div>
      </div>

      <section className="space-y-3">
        <h4 className="text-lg font-semibold text-gray-900">Selected Databases</h4>
        {selectedDbs.size ? (
          <div className="grid grid-cols-2 md:grid-cols-3 lg:grid-cols-4 gap-3">
            {Array.from(selectedDbs).map(name => (
              <div key={name} className="p-3 bg-white border rounded-xl text-sm">
                {name}
              </div>
            ))}
          </div>
        ) : (
          <div className="rounded-xl border border-dashed p-6 text-gray-500">
            No databases selected. You can select them after creation.
          </div>
        )}
      </section>
    </div>
  )
}

/* presentational bits */
function ConnectorCard({
  connector,
  onClick,
  badge,
}: {
  connector: ConnectorTemplate
  onClick: () => void
  badge?: string
}) {
  return (
    <button
      onClick={onClick}
      className="group p-6 border-2 border-gray-200 rounded-2xl hover:border-blue-300 hover:shadow-xl transition-all bg-gradient-to-br from-white to-gray-50 relative text-left"
    >
      {badge && (
        <span className="absolute top-4 right-4 px-3 py-1 text-xs font-bold rounded-full bg-yellow-100 text-yellow-800">
          {badge}
        </span>
      )}
      <div className="flex items-start justify-between mb-4">
        <div className="text-4xl group-hover:scale-110 transition-transform">
          {connector.icon}
        </div>
        <div className="text-xs text-blue-600 uppercase">{connector.scope}</div>
      </div>
      <div className="font-bold text-xl text-gray-900 mb-1 group-hover:text-blue-600">
        {connector.name}
      </div>
      <p className="text-gray-600 text-sm mb-4 line-clamp-2">{connector.description}</p>
      <div className="flex items-center justify-between">
        <div className="flex flex-wrap gap-1">
          {connector.tags.slice(0, 2).map(t => (
            <span
              key={t}
              className="px-2 py-0.5 text-xs bg-gray-100 text-gray-600 rounded-full"
            >
              {t}
            </span>
          ))}
          {connector.tags.length > 2 && (
            <span className="px-2 py-0.5 text-xs bg-gray-100 text-gray-600 rounded-full">
              +{connector.tags.length - 2}
            </span>
          )}
        </div>
        <span className="text-xs text-gray-500">{connector.submitType}</span>
      </div>
    </button>
  )
}

function ConfigField({
  field,
  value,
  onChange,
  error,
  show,
  onToggleShow,
  config,
}: {
  field: EnhancedConnectorField
  value: any
  onChange: (v: any) => void
  error?: string
  show?: boolean
  onToggleShow?: () => void
  config: Record<string, any>
}) {
  const visible = useMemo(() => {
    if (!field.dependsOn) return true
    const { field: dep, value: depV, condition = 'equals' } = field.dependsOn
    const act = (config as Record<string, any>)[dep]
    switch (condition) {
      case 'equals':
        return act === depV
      case 'not-equals':
        return act !== depV
      case 'truthy':
        return !!act
      case 'falsy':
        return !act
      case 'contains':
        return (act ?? '').toString().includes(depV)
      default:
        return true
    }
  }, [field.dependsOn, config])

  if (!visible) return null

  const base =
    'w-full px-4 py-3 border rounded-xl focus:ring-2 focus:ring-blue-500 focus:border-transparent'
  const err = error ? 'border-red-300 focus:ring-red-500' : 'border-gray-300'

  return (
    <div className={field.wide ? 'md:col-span-2' : ''}>
      <label className="block text-sm font-semibold text-gray-700 mb-2">
        {field.label}
        {field.required && <span className="text-red-500 ml-1">*</span>}
        {field.sensitive && (
          <span className="ml-2 inline-flex items-center px-2 py-0.5 rounded text-xs bg-red-100 text-red-700">
            <Lock className="w-3 h-3 mr-1" />
            Sensitive
          </span>
        )}
      </label>

      {field.type === 'password' ? (
        <div className="relative">
          <input
            type={show ? 'text' : 'password'}
            value={value}
            onChange={e => onChange(e.target.value)}
            placeholder={field.placeholder}
            className={`${base} ${err} pr-10`}
            autoComplete={field.autoComplete ?? 'new-password'}
          />
          {onToggleShow && (
            <button
              type="button"
              aria-label="Toggle visibility"
              onClick={onToggleShow}
              className="absolute right-3 top-1/2 -translate-y-1/2 text-gray-400 hover:text-gray-600"
            >
              {show ? <EyeOff className="w-4 h-4" /> : <Eye className="w-4 h-4" />}
            </button>
          )}
        </div>
      ) : field.type === 'toggle' ? (
        <button
          type="button"
          onClick={() => onChange(!value)}
          className={`relative inline-flex h-6 w-11 rounded-full transition-colors focus:outline-none focus:ring-2 focus:ring-blue-500 ${
            value ? 'bg-blue-600' : 'bg-gray-200'
          }`}
          aria-pressed={!!value}
        >
          <span
            className={`inline-block h-4 w-4 mt-1 transform rounded-full bg-white transition-transform ${
              value ? 'translate-x-6' : 'translate-x-1'
            }`}
          />
        </button>
      ) : field.type === 'select' ? (
        <div className="relative">
          <select
            value={value ?? ''}
            onChange={e => onChange(e.target.value)}
            className={`${base} ${err} appearance-none pr-10`}
          >
            <option value="">Select {field.label}</option>
            {field.options?.map(o => (
              <option key={o.value} value={o.value}>
                {o.label}
                {o.recommended ? ' (Recommended)' : ''}
              </option>
            ))}
          </select>
          <ChevronDown className="absolute right-3 top-1/2 -translate-y-1/2 h-4 w-4 text-gray-400 pointer-events-none" />
        </div>
      ) : field.type === 'textarea' ? (
        <textarea
          value={value}
          onChange={e => onChange(e.target.value)}
          rows={4}
          placeholder={field.placeholder}
          className={`${base} ${err} resize-none`}
        />
      ) : field.type === 'number' ? (
        <input
          type="number"
          value={value === '' || value === undefined || value === null ? '' : Number(value)}
          onChange={e =>
            onChange(e.target.value === '' ? '' : Number.parseInt(e.target.value, 10))
          }
          placeholder={field.placeholder}
          min={field.validation?.min}
          max={field.validation?.max}
          className={`${base} ${err}`}
        />
      ) : (
        <input
          type="text"
          value={value}
          onChange={e => onChange(e.target.value)}
          placeholder={field.placeholder}
          className={`${base} ${err}`}
          autoComplete={field.autoComplete ?? 'off'}
        />
      )}

      {field.help && !error && (
        <p className="mt-2 text-sm text-gray-600 flex items-start">
          <Info className="w-4 h-4 text-gray-400 mr-1 mt-0.5" />
          {field.help}
        </p>
      )}
      {error && (
        <p className="mt-2 text-sm text-red-600 flex items-start">
          <AlertTriangle className="w-4 h-4 text-red-500 mr-1 mt-0.5" />
          {error}
        </p>
      )}
    </div>
  )
}

function TestRow({
  test,
}: {
  test: { label: string; status: 'pending' | 'running' | 'success' | 'error'; message?: string }
}) {
  return (
    <div className="flex items-center justify-between p-3 bg-white rounded-lg border">
      <div className="flex items-center gap-3">
        {test.status === 'pending' && <Clock className="w-5 h-5 text-gray-400" />}
        {test.status === 'running' && (
          <Loader2 className="w-5 h-5 text-blue-600 animate-spin" />
        )}
        {test.status === 'success' && (
          <CheckCircle2 className="w-5 h-5 text-green-600" />
        )}
        {test.status === 'error' && <AlertTriangle className="w-5 h-5 text-red-600" />}
        <div>
          <div className="text-sm font-medium whitespace-pre-line">{test.label}</div>
          {test.message && <div className="text-xs text-gray-600 whitespace-pre-line">{test.message}</div>}
        </div>
      </div>
    </div>
  )
}

function DbCard({
  db,
  selected,
  onToggle,
}: {
  db: DatabaseInfo
  selected: boolean
  onToggle: (on: boolean) => void
}) {
  const disabled = db.accessible === false
  return (
    <div
      className={`p-4 border-2 rounded-xl transition-all cursor-pointer ${
        selected
          ? 'border-blue-500 bg-blue-50 shadow'
          : disabled
          ? 'border-gray-100 bg-gray-50 opacity-60'
          : 'border-gray-200 hover:border-blue-300 hover:shadow-sm'
      }`}
      onClick={() => !disabled && onToggle(!selected)}
      role="checkbox"
      aria-checked={selected}
      aria-disabled={disabled}
      tabIndex={0}
      onKeyDown={e => {
        if (e.key === ' ' || e.key === 'Enter') {
          e.preventDefault()
          if (!disabled) onToggle(!selected)
        }
      }}
    >
      <div className="flex items-start justify-between mb-2">
        <div className="font-semibold truncate">{db.name}</div>
        <div
          className={`w-2.5 h-2.5 rounded-full ${
            db.quality === 'high'
              ? 'bg-green-500'
              : db.quality === 'medium'
              ? 'bg-yellow-500'
              : 'bg-red-500'
          }`}
        />
      </div>

      <div className="grid grid-cols-2 gap-2 text-xs text-gray-600 mb-2">
        {db.tables != null && (
          <div className="flex items-center">
            <FileText className="w-3 h-3 mr-1" />
            {db.tables} tables
          </div>
        )}
        {db.views != null && (
          <div className="flex items-center">
            <Eye className="w-3 h-3 mr-1" />
            {db.views} views
          </div>
        )}
        {db.size && (
          <div className="flex items-center">
            <HardDrive className="w-3 h-3 mr-1" />
            {db.size}
          </div>
        )}
        {db.usage && (
          <div className="flex items-center">
            <Activity
              className={`w-3 h-3 mr-1 ${
                db.usage === 'active'
                  ? 'text-green-500'
                  : db.usage === 'moderate'
                  ? 'text-yellow-500'
                  : 'text-gray-400'
              }`}
            />
            {db.usage}
          </div>
        )}
      </div>

      {db.description && (
        <p className="text-xs text-gray-500 truncate">{db.description}</p>
      )}
      {disabled && (
        <div className="mt-2 text-xs text-red-600 bg-red-50 px-2 py-1 rounded">
          Access denied
        </div>
      )}

      <div className="mt-3 flex items-center gap-2">
        <input
          type="checkbox"
          checked={selected}
          onChange={e => onToggle(e.target.checked)}
          disabled={disabled}
          className="h-4 w-4"
          onClick={e => e.stopPropagation()}
        />
        <span className="text-sm">{selected ? 'Selected' : 'Select'}</span>
      </div>
    </div>
  )
}

function SummaryCard({
  icon,
  label,
  value,
  tone,
}: {
  icon: React.ReactNode
  label: string
  value: number | string
  tone: 'blue' | 'green' | 'purple' | 'orange'
}) {
  const map = {
    blue: 'bg-blue-50 border-blue-200',
    green: 'bg-green-50 border-green-200',
    purple: 'bg-purple-50 border-purple-200',
    orange: 'bg-orange-50 border-orange-200',
  }
  return (
    <div className={`p-4 rounded-xl border ${map[tone]}`}>
      <div className="flex items-center justify-between">
        <div>
          <div className="text-2xl font-bold">{value}</div>
          <div className="text-sm">{label}</div>
        </div>
        {icon}
      </div>
    </div>
  )
}

function Stat({
  value,
  label,
  color,
}: {
  value: string | number
  label: string
  color: string
}) {
  return (
    <div className="text-center">
      <div className={`text-2xl font-bold ${color}`}>{value}</div>
      <div className="text-sm text-gray-600">{label}</div>
    </div>
  )
}



------------------------------------------------------------
FILE: frontend\src\components\features\data-sources\connectors.ts
------------------------------------------------------------
import type { ConnectionConfig, DataSourceType } from '@/types/dataSources';

/* =========================
   Types
========================= */
export type ConnectorCategory =
  | 'Databases'
  | 'Warehouses'
  | 'Storage'
  | 'Streaming'
  | 'API & Files';

export type FieldType =
  | 'text'
  | 'password'
  | 'number'
  | 'textarea'
  | 'checkbox'
  | 'select'
  | 'connectionString';

// connector ids, including aliases that submit as another backend type
export type ConnectorId =
  | DataSourceType
  | 'azure-sql'
  | 'synapse-dedicated'
  | 'synapse-serverless'
  | 'aws-rds-postgres'
  | 'aws-rds-mysql'
  | 'planetscale'
  | 'neon'
  | 'supabase';

// NOTE: key/dependsOn.field are strings to avoid TS friction with custom keys like "brokers"
export type FieldDef = {
  key: string;
  label: string;
  type: FieldType;
  placeholder?: string;
  required?: boolean;
  help?: string;
  options?: { value: string; label: string }[];
  dependsOn?: {
    field: string;
    value?: any;
    condition?: 'equals' | 'not-equals' | 'truthy' | 'falsy';
  };
  validation?: {
    pattern?: RegExp;
    min?: number;
    max?: number;
    custom?: (value: any, config: ConnectionConfig) => string | null;
  };
};

export type ConnectionTemplate = {
  name: string;
  description: string;
  config: Partial<ConnectionConfig>;
  icon?: string;
};

export type ConnectorMeta = {
  id: ConnectorId;
  submitType: DataSourceType; // what your backend expects in "type"
  label: string;
  category: ConnectorCategory;
  icon: string;
  description?: string;
  defaultPort?: number;
  fields: FieldDef[];
  tips?: string[];
  supportsConnectionString?: boolean;
  connectionStringPlaceholder?: string;
  parseConnectionString?: (url: string) => Partial<ConnectionConfig>;
  templates?: ConnectionTemplate[];
  tags?: string[];
  popularity?: number;
  isNew?: boolean;
  isBeta?: boolean;
  documentationUrl?: string;
};

/* =========================
   Validation helpers
========================= */
export const VALIDATION_PATTERNS = {
  url: /^https?:\/\/.+/,
  hostname:
    /^[a-zA-Z0-9]([a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?(\.[a-zA-Z0-9]([a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?)*$/,
  snowflakeAccount: /^[a-zA-Z0-9_-]+\.snowflakecomputing\.com$/,
  azureServer: /^[a-zA-Z0-9-]+\.database\.windows\.net$/,
  gcpProject: /^[a-z][a-z0-9-]{4,28}[a-z0-9]$/,
};

/* =========================
   Connection string parsers
========================= */
export const CONNECTION_STRING_PARSERS = {
  postgresql: (url: string): Partial<ConnectionConfig> => {
    try {
      const parsed = new URL(url);
      return {
        host: parsed.hostname,
        port: parsed.port ? parseInt(parsed.port, 10) : 5432,
        database: parsed.pathname.replace(/^\//, ''),
        username: decodeURIComponent(parsed.username),
        password: decodeURIComponent(parsed.password),
        ssl:
          parsed.searchParams.get('sslmode') === 'require' ||
          parsed.searchParams.get('ssl') === 'true',
      };
    } catch {
      return {};
    }
  },

  mysql: (url: string): Partial<ConnectionConfig> => {
    try {
      const parsed = new URL(url);
      return {
        host: parsed.hostname,
        port: parsed.port ? parseInt(parsed.port, 10) : 3306,
        database: parsed.pathname.replace(/^\//, ''),
        username: decodeURIComponent(parsed.username),
        password: decodeURIComponent(parsed.password),
        ssl: parsed.searchParams.get('ssl') === 'true',
      };
    } catch {
      return {};
    }
  },

  mongodb: (url: string): Partial<ConnectionConfig> => {
    return { connectionString: url };
  },
};

/* =========================
   Templates
========================= */
const ENVIRONMENT_TEMPLATES: Record<string, ConnectionTemplate[]> = {
  postgresql: [
    {
      name: 'Local Development',
      description: 'Default PostgreSQL on localhost',
      icon: 'ðŸ’»',
      config: { host: 'localhost', port: 5432, ssl: false },
    },
    {
      name: 'Production',
      description: 'Secure production setup',
      icon: 'ðŸ”',
      config: { port: 5432, ssl: true },
    },
  ],
  mysql: [
    {
      name: 'Local Development',
      description: 'Default MySQL on localhost',
      icon: 'ðŸ’»',
      config: { host: 'localhost', port: 3306, ssl: false },
    },
    {
      name: 'Production',
      description: 'Secure production setup',
      icon: 'ðŸ”',
      config: { port: 3306, ssl: true },
    },
  ],
};

/* =========================
   Default config per connector
========================= */
export function defaultConfigFor(meta: ConnectorMeta): Partial<ConnectionConfig> {
  // Use Record<string, any> for flexibility since ConnectionConfig is a union type
  const base: Record<string, any> = {};
  
  // Set default port if specified
  if (meta.defaultPort) {
    base.port = meta.defaultPort;
  }

  // Set connector-specific defaults
  switch (meta.id) {
    case 'azure-sql':
    case 'synapse-dedicated':
    case 'synapse-serverless':
      base.ssl = true;
      base.encrypt = true;
      break;
      
    case 'neon':
    case 'supabase':
    case 'planetscale':
    case 'aws-rds-postgres':
    case 'aws-rds-mysql':
      base.ssl = true;
      break;
      
    case 'snowflake':
      base.ssl = true;
      base.warehouse = 'COMPUTE_WH';
      // Note: Snowflake doesn't use 'port', it uses the host URL
      break;
      
    case 'bigquery':
      base.location = 'US';
      // Note: BigQuery doesn't use traditional connection properties
      break;
      
    case 'redis':
      base.database = 0; // Default Redis database
      break;
      
    case 'kafka':
      base.securityProtocol = 'PLAINTEXT';
      break;
      
    case 'api':
      base.timeout = 30;
      base.authType = 'none';
      break;
      
    case 'file':
      base.format = 'csv';
      base.encoding = 'utf-8';
      base.recursive = false;
      break;
      
    case 'elasticsearch':
      base.ssl = false;
      break;
  }
    // Cast back to Partial<ConnectionConfig> for type compatibility
  return base as Partial<ConnectionConfig>;
}

/* =========================
   Connectors
========================= */
export const CONNECTORS: ConnectorMeta[] = [
  // --- Databases ---
  {
    id: 'postgresql',
    submitType: 'postgresql',
    label: 'PostgreSQL',
    category: 'Databases',
    icon: 'ðŸ˜',
    description: 'Open-source relational database',
    defaultPort: 5432,
    popularity: 95,
    supportsConnectionString: true,
    connectionStringPlaceholder: 'postgresql://user:pass@host:5432/db',
    parseConnectionString: CONNECTION_STRING_PARSERS.postgresql,
    templates: ENVIRONMENT_TEMPLATES.postgresql,
    documentationUrl: 'https://www.postgresql.org/docs/',
    fields: [
      { key: 'host', label: 'Host', type: 'text', placeholder: 'localhost', required: true, validation: { pattern: VALIDATION_PATTERNS.hostname } },
      { key: 'port', label: 'Port', type: 'number', placeholder: '5432', required: true },
      { key: 'database', label: 'Database', type: 'text', required: true },
      { key: 'username', label: 'Username', type: 'text', required: true },
      { key: 'password', label: 'Password', type: 'password', required: true },
      { key: 'ssl', label: 'Use SSL', type: 'checkbox', help: 'Enable for production' },
      {
        key: 'sslmode',
        label: 'SSL Mode',
        type: 'select',
        options: [
          { value: 'disable', label: 'Disable' },
          { value: 'require', label: 'Require' },
          { value: 'verify-ca', label: 'Verify CA' },
          { value: 'verify-full', label: 'Verify Full' },
        ],
        dependsOn: { field: 'ssl', value: true, condition: 'equals' },
      },
    ],
    tips: ['Use a read-only user', 'Consider pooling', 'Enable SSL in prod'],
    tags: ['sql', 'relational', 'open-source'],
  },
  {
    id: 'aws-rds-postgres',
    submitType: 'postgresql',
    label: 'AWS RDS PostgreSQL',
    category: 'Databases',
    icon: 'ðŸŸ ',
    description: 'Managed PostgreSQL on AWS',
    defaultPort: 5432,
    popularity: 85,
    fields: [
      { key: 'host', label: 'RDS Endpoint', type: 'text', placeholder: 'mydb.cluster-xyz.us-east-1.rds.amazonaws.com', required: true },
      { key: 'port', label: 'Port', type: 'number', placeholder: '5432', required: true },
      { key: 'database', label: 'Database', type: 'text', required: true },
      { key: 'username', label: 'Master Username', type: 'text', required: true },
      { key: 'password', label: 'Master Password', type: 'password', required: true },
      { key: 'ssl', label: 'Force SSL', type: 'checkbox' },
    ],
    tips: ['Backups', 'IAM auth', 'Security groups'],
    tags: ['aws', 'managed', 'postgresql', 'cloud'],
  },
  {
    id: 'neon',
    submitType: 'postgresql',
    label: 'Neon',
    category: 'Databases',
    icon: 'âš¡',
    description: 'Serverless PostgreSQL platform',
    defaultPort: 5432,
    popularity: 75,
    isNew: true,
    supportsConnectionString: true,
    connectionStringPlaceholder: 'postgresql://user:pass@ep-xxx.neon.tech/db',
    parseConnectionString: CONNECTION_STRING_PARSERS.postgresql,
    fields: [
      { key: 'host', label: 'Neon Host', type: 'text', placeholder: 'ep-xxx.neon.tech', required: true },
      { key: 'database', label: 'Database', type: 'text', required: true },
      { key: 'username', label: 'Username', type: 'text', required: true },
      { key: 'password', label: 'Password', type: 'password', required: true },
      { key: 'ssl', label: 'SSL (Required)', type: 'checkbox' },
    ],
    tips: ['Pooling recommended', 'SSL required'],
    tags: ['serverless', 'postgresql', 'modern'],
  },
  {
    id: 'supabase',
    submitType: 'postgresql',
    label: 'Supabase',
    category: 'Databases',
    icon: 'ðŸŸ¢',
    description: 'Open-source Firebase alternative',
    defaultPort: 5432,
    popularity: 80,
    supportsConnectionString: true,
    connectionStringPlaceholder: 'postgresql://postgres:pass@db.xxx.supabase.co:5432/postgres',
    parseConnectionString: CONNECTION_STRING_PARSERS.postgresql,
    fields: [
      { key: 'host', label: 'Supabase Host', type: 'text', placeholder: 'db.xxx.supabase.co', required: true },
      { key: 'port', label: 'Port', type: 'number', placeholder: '5432', required: true },
      { key: 'database', label: 'Database', type: 'text', placeholder: 'postgres', required: true },
      { key: 'username', label: 'Username', type: 'text', placeholder: 'postgres', required: true },
      { key: 'password', label: 'Password', type: 'password', required: true },
      { key: 'ssl', label: 'SSL (Required)', type: 'checkbox' },
    ],
    tips: ['Use dashboard for creds'],
    tags: ['baas', 'postgresql', 'open-source'],
  },
  {
    id: 'mysql',
    submitType: 'mysql',
    label: 'MySQL',
    category: 'Databases',
    icon: 'ðŸ¬',
    description: 'Popular open-source database',
    defaultPort: 3306,
    popularity: 90,
    supportsConnectionString: true,
    connectionStringPlaceholder: 'mysql://user:pass@host:3306/db',
    parseConnectionString: CONNECTION_STRING_PARSERS.mysql,
    fields: [
      { key: 'host', label: 'Host', type: 'text', placeholder: 'localhost', required: true },
      { key: 'port', label: 'Port', type: 'number', placeholder: '3306', required: true },
      { key: 'database', label: 'Database', type: 'text', required: true },
      { key: 'username', label: 'Username', type: 'text', required: true },
      { key: 'password', label: 'Password', type: 'password', required: true },
      { key: 'ssl', label: 'Use SSL', type: 'checkbox' },
    ],
    tips: ['Enable SSL in prod'],
    tags: ['sql', 'relational', 'open-source'],
  },
  {
    id: 'planetscale',
    submitType: 'mysql',
    label: 'PlanetScale',
    category: 'Databases',
    icon: 'ðŸª',
    description: 'Serverless MySQL platform',
    defaultPort: 3306,
    popularity: 70,
    isNew: true,
    fields: [
      { key: 'host', label: 'Host', type: 'text', placeholder: 'xxx.planetscale.dev', required: true },
      { key: 'database', label: 'Database', type: 'text', required: true },
      { key: 'username', label: 'Username', type: 'text', required: true },
      { key: 'password', label: 'Password', type: 'password', required: true },
      { key: 'ssl', label: 'SSL (Required)', type: 'checkbox' },
    ],
    tips: ['SSL is required'],
    tags: ['serverless', 'mysql', 'modern'],
  },
  {
    id: 'mssql',
    submitType: 'mssql',
    label: 'SQL Server',
    category: 'Databases',
    icon: 'ðŸ¢',
    description: 'Microsoft SQL Server',
    defaultPort: 1433,
    popularity: 75,
    fields: [
      { key: 'host', label: 'Server', type: 'text', placeholder: 'localhost', required: true },
      { key: 'port', label: 'Port', type: 'number', placeholder: '1433', required: true },
      { key: 'database', label: 'Database', type: 'text', required: true },
      { key: 'username', label: 'Username', type: 'text', required: true },
      { key: 'password', label: 'Password', type: 'password', required: true },
      { key: 'ssl', label: 'Encrypt Connection', type: 'checkbox' },
      {
        key: 'trustServerCertificate',
        label: 'Trust Server Certificate',
        type: 'checkbox',
        dependsOn: { field: 'ssl', value: true, condition: 'equals' },
        help: 'Use for self-signed certs',
      },
    ],
    tips: ['Enable encryption in prod'],
    tags: ['microsoft', 'sql', 'enterprise'],
  },
  {
    id: 'azure-sql',
    submitType: 'mssql',
    label: 'Azure SQL Database',
    category: 'Databases',
    icon: 'ðŸŸ¦',
    description: 'Managed SQL Server on Azure',
    defaultPort: 1433,
    popularity: 80,
    fields: [
      {
        key: 'host',
        label: 'Server Name',
        type: 'text',
        placeholder: 'myserver.database.windows.net',
        required: true,
        validation: { pattern: VALIDATION_PATTERNS.azureServer },
      },
      { key: 'port', label: 'Port', type: 'number', placeholder: '1433', required: true },
      { key: 'database', label: 'Database', type: 'text', required: true },
      { key: 'username', label: 'Username', type: 'text', required: true },
      { key: 'password', label: 'Password', type: 'password', required: true },
      { key: 'ssl', label: 'Encrypt (Required)', type: 'checkbox' },
    ],
    tips: ['Configure firewall rules', 'Use Azure AD if possible'],
    tags: ['azure', 'managed', 'microsoft', 'cloud'],
  },
  {
    id: 'mongodb',
    submitType: 'mongodb',
    label: 'MongoDB',
    category: 'Databases',
    icon: 'ðŸƒ',
    description: 'NoSQL document database',
    defaultPort: 27017,
    popularity: 85,
    supportsConnectionString: true,
    connectionStringPlaceholder: 'mongodb+srv://user:pass@cluster.mongodb.net/db',
    parseConnectionString: CONNECTION_STRING_PARSERS.mongodb,
    fields: [
      { key: 'connectionString', label: 'Connection String (Recommended)', type: 'connectionString', placeholder: 'mongodb+srv://...' },
      { key: 'host', label: 'Host', type: 'text', placeholder: 'localhost', dependsOn: { field: 'connectionString', condition: 'falsy' } },
      { key: 'port', label: 'Port', type: 'number', placeholder: '27017', dependsOn: { field: 'connectionString', condition: 'falsy' } },
      { key: 'database', label: 'Database', type: 'text' },
      { key: 'username', label: 'Username', type: 'text' },
      { key: 'password', label: 'Password', type: 'password' },
      { key: 'ssl', label: 'Use TLS', type: 'checkbox' },
    ],
    tips: ['Prefer connection strings for Atlas'],
    tags: ['nosql', 'document', 'json'],
  },

  // --- Warehouses ---
  {
    id: 'snowflake',
    submitType: 'snowflake',
    label: 'Snowflake',
    category: 'Warehouses',
    icon: 'â„ï¸',
    description: 'Cloud data warehouse',
    popularity: 90,
    fields: [
      { key: 'host', label: 'Account Identifier', type: 'text', placeholder: 'abc123.region.snowflakecomputing.com', required: true, validation: { pattern: VALIDATION_PATTERNS.snowflakeAccount } },
      { key: 'database', label: 'Database', type: 'text', required: true },
      { key: 'warehouse', label: 'Warehouse', type: 'text', placeholder: 'COMPUTE_WH', required: true },
      { key: 'schema', label: 'Schema', type: 'text', placeholder: 'PUBLIC' },
      { key: 'username', label: 'Username', type: 'text', required: true },
      { key: 'password', label: 'Password', type: 'password', required: true },
      { key: 'role', label: 'Role', type: 'text', placeholder: 'PUBLIC' },
    ],
    tips: ['Use dedicated warehouses', 'Key-pair auth for prod'],
    tags: ['warehouse', 'cloud', 'enterprise'],
  },
  {
    id: 'bigquery',
    submitType: 'bigquery',
    label: 'Google BigQuery',
    category: 'Warehouses',
    icon: 'ðŸ“Š',
    description: 'Serverless data warehouse',
    popularity: 85,
    fields: [
      {
        key: 'serviceAccountKey',
        label: 'Service Account JSON',
        type: 'textarea',
        placeholder: '{ "type": "service_account", ... }',
        required: true,
        validation: {
          custom: (value) => {
            try {
              const parsed = JSON.parse(value);
              return parsed?.type === 'service_account'
                ? null
                : 'Must be a service account JSON key';
            } catch {
              return 'Invalid JSON format';
            }
          },
        },
      },
      { key: 'projectId', label: 'Project ID', type: 'text', required: true, validation: { pattern: VALIDATION_PATTERNS.gcpProject } },
      {
        key: 'location',
        label: 'Location',
        type: 'select',
        options: [
          { value: 'US', label: 'US (Multi-region)' },
          { value: 'EU', label: 'EU (Multi-region)' },
          { value: 'us-central1', label: 'US Central 1' },
          { value: 'us-east1', label: 'US East 1' },
          { value: 'europe-west1', label: 'Europe West 1' },
        ],
      },
    ],
    tips: ['Least privilege for service accounts'],
    tags: ['google', 'serverless', 'warehouse'],
  },
  {
    id: 'synapse-dedicated',
    submitType: 'mssql',
    label: 'Azure Synapse Analytics',
    category: 'Warehouses',
    icon: 'ðŸŸ¦',
    description: 'Enterprise data warehouse',
    defaultPort: 1433,
    popularity: 70,
    fields: [
      { key: 'host', label: 'Synapse Endpoint', type: 'text', placeholder: 'myworkspace.sql.azuresynapse.net', required: true },
      { key: 'port', label: 'Port', type: 'number', placeholder: '1433', required: true },
      { key: 'database', label: 'SQL Pool', type: 'text', required: true },
      { key: 'username', label: 'SQL Admin User', type: 'text', required: true },
      { key: 'password', label: 'Password', type: 'password', required: true },
      { key: 'ssl', label: 'Encrypt (Required)', type: 'checkbox' },
    ],
    tips: ['Firewall rules for your IP'],
    tags: ['azure', 'warehouse', 'enterprise'],
  },

  // --- Storage ---
  {
    id: 's3',
    submitType: 's3',
    label: 'Amazon S3',
    category: 'Storage',
    icon: 'â˜ï¸',
    description: 'Object storage service',
    popularity: 95,
    fields: [
      { key: 'accessKeyId', label: 'Access Key ID', type: 'text', required: true },
      { key: 'secretAccessKey', label: 'Secret Access Key', type: 'password', required: true },
      { key: 'bucket', label: 'Bucket Name', type: 'text', required: true },
      {
        key: 'region',
        label: 'Region',
        type: 'select',
        options: [
          { value: 'us-east-1', label: 'US East (N. Virginia)' },
          { value: 'us-east-2', label: 'US East (Ohio)' },
          { value: 'us-west-2', label: 'US West (Oregon)' },
          { value: 'eu-west-1', label: 'Europe (Ireland)' },
          { value: 'eu-central-1', label: 'Europe (Frankfurt)' },
          { value: 'ap-southeast-1', label: 'AP (Singapore)' },
        ],
        required: true,
      },
      { key: 'prefix', label: 'Prefix/Folder', type: 'text', placeholder: 'data/' },
    ],
    tips: ['Prefer IAM roles', 'Enable versioning'],
    tags: ['aws', 'storage', 'object'],
  },
  {
    id: 'azure-blob',
    submitType: 'azure-blob',
    label: 'Azure Blob Storage',
    category: 'Storage',
    icon: 'ðŸŸ¦',
    description: 'Azure object storage',
    popularity: 70,
    fields: [
      { key: 'accountName', label: 'Storage Account Name', type: 'text', required: true },
      { key: 'accountKey', label: 'Account Key', type: 'password', required: true },
      { key: 'containerName', label: 'Container Name', type: 'text', required: true },
      { key: 'prefix', label: 'Blob Prefix', type: 'text', placeholder: 'data/' },
      { key: 'endpoint', label: 'Endpoint', type: 'text', placeholder: 'https://myaccount.blob.core.windows.net' },
    ],
    tips: ['Use SAS for fine-grained access'],
    tags: ['azure', 'storage', 'blob'],
  },
  {
    id: 'gcs',
    submitType: 'gcs',
    label: 'Google Cloud Storage',
    category: 'Storage',
    icon: 'â˜ï¸',
    description: 'Google object storage',
    popularity: 75,
    fields: [
      {
        key: 'serviceAccountKey',
        label: 'Service Account JSON',
        type: 'textarea',
        required: true,
        validation: {
          custom: (v) => {
            try {
              JSON.parse(v);
              return null;
            } catch {
              return 'Invalid JSON format';
            }
          },
        },
      },
      { key: 'bucketName', label: 'Bucket Name', type: 'text', required: true },
      { key: 'prefix', label: 'Object Prefix', type: 'text', placeholder: 'data/' },
      { key: 'projectId', label: 'Project ID', type: 'text', validation: { pattern: VALIDATION_PATTERNS.gcpProject } },
    ],
    tips: ['Uniform bucket-level access'],
    tags: ['google', 'storage', 'gcp'],
  },

  // --- Streaming ---
  {
    id: 'kafka',
    submitType: 'kafka',
    label: 'Apache Kafka',
    category: 'Streaming',
    icon: 'ðŸš€',
    description: 'Distributed streaming platform',
    popularity: 80,
    fields: [
      { key: 'brokers', label: 'Bootstrap Servers (CSV)', type: 'text', placeholder: 'broker1:9092,broker2:9092', required: true, help: 'Comma-separated list' },
      { key: 'consumerGroup', label: 'Consumer Group', type: 'text', placeholder: 'cwic-consumer' },
      {
        key: 'securityProtocol',
        label: 'Security Protocol',
        type: 'select',
        options: [
          { value: 'PLAINTEXT', label: 'PLAINTEXT' },
          { value: 'SASL_PLAINTEXT', label: 'SASL_PLAINTEXT' },
          { value: 'SASL_SSL', label: 'SASL_SSL' },
          { value: 'SSL', label: 'SSL' },
        ],
      },
      {
        key: 'saslMechanism',
        label: 'SASL Mechanism',
        type: 'select',
        options: [
          { value: 'PLAIN', label: 'PLAIN' },
          { value: 'SCRAM-SHA-256', label: 'SCRAM-SHA-256' },
          { value: 'SCRAM-SHA-512', label: 'SCRAM-SHA-512' },
        ],
        dependsOn: { field: 'securityProtocol', value: 'SASL_PLAINTEXT', condition: 'equals' },
      },
      { key: 'saslUsername', label: 'SASL Username', type: 'text' },
      { key: 'saslPassword', label: 'SASL Password', type: 'password' },
    ],
    tips: ['Use SASL_SSL for prod', 'Monitor lag'],
    tags: ['streaming', 'real-time', 'apache'],
  },

  // --- API & Files ---
  {
    id: 'api',
    submitType: 'api',
    label: 'REST API',
    category: 'API & Files',
    icon: 'ðŸ”Œ',
    description: 'HTTP REST API endpoint',
    popularity: 75,
    fields: [
      { key: 'baseUrl', label: 'Base URL', type: 'text', placeholder: 'https://api.example.com', required: true, validation: { pattern: VALIDATION_PATTERNS.url } },
      {
        key: 'authType',
        label: 'Authentication Type',
        type: 'select',
        options: [
          { value: 'none', label: 'None' },
          { value: 'api-key', label: 'API Key' },
          { value: 'bearer', label: 'Bearer Token' },
          { value: 'basic', label: 'Basic Auth' },
          { value: 'oauth2', label: 'OAuth 2.0' },
        ],
      },
      { key: 'apiKey', label: 'API Key', type: 'password', dependsOn: { field: 'authType', value: 'api-key', condition: 'equals' } },
      { key: 'apiKeyHeader', label: 'API Key Header', type: 'text', placeholder: 'X-API-Key', dependsOn: { field: 'authType', value: 'api-key', condition: 'equals' } },
      { key: 'bearerToken', label: 'Bearer Token', type: 'password', dependsOn: { field: 'authType', value: 'bearer', condition: 'equals' } },
      { key: 'username', label: 'Username', type: 'text', dependsOn: { field: 'authType', value: 'basic', condition: 'equals' } },
      { key: 'password', label: 'Password', type: 'password', dependsOn: { field: 'authType', value: 'basic', condition: 'equals' } },
      { key: 'timeout', label: 'Timeout (seconds)', type: 'number', placeholder: '30', validation: { min: 1, max: 300 } },
      { key: 'rateLimit', label: 'Rate Limit (req/min)', type: 'number', placeholder: '100' },
    ],
    tips: ['Put API keys in headers', 'Rate limit to avoid throttling'],
    tags: ['http', 'rest', 'api'],
  },
  {
    id: 'file',
    submitType: 'file',
    label: 'File System',
    category: 'API & Files',
    icon: 'ðŸ“',
    description: 'Local or network file system',
    popularity: 60,
    fields: [
      { key: 'path', label: 'File Path / Glob', type: 'text', placeholder: '/data/*.csv or C:\\data\\*.json', required: true, help: 'Supports glob patterns' },
      {
        key: 'format',
        label: 'File Format',
        type: 'select',
        options: [
          { value: 'csv', label: 'CSV' },
          { value: 'json', label: 'JSON' },
          { value: 'jsonl', label: 'JSON Lines' },
          { value: 'parquet', label: 'Parquet' },
          { value: 'xlsx', label: 'Excel (XLSX)' },
          { value: 'xml', label: 'XML' },
          { value: 'txt', label: 'Text' },
        ],
        required: true,
      },
      { key: 'encoding', label: 'Text Encoding', type: 'select', options: [{ value: 'utf-8', label: 'UTF-8' }, { value: 'utf-16', label: 'UTF-16' }, { value: 'latin1', label: 'Latin-1' }, { value: 'ascii', label: 'ASCII' }], dependsOn: { field: 'format', value: 'csv', condition: 'equals' } },
      { key: 'delimiter', label: 'Delimiter', type: 'text', placeholder: ',', dependsOn: { field: 'format', value: 'csv', condition: 'equals' } },
      { key: 'hasHeader', label: 'Has Header Row', type: 'checkbox', dependsOn: { field: 'format', value: 'csv', condition: 'equals' } },
      { key: 'recursive', label: 'Scan Subdirectories', type: 'checkbox' },
    ],
    tips: ['Check file permissions', 'Start with a small subset'],
    tags: ['filesystem', 'local', 'files'],
  },
  {
    id: 'elasticsearch',
    submitType: 'elasticsearch',
    label: 'Elasticsearch',
    category: 'Databases',
    icon: 'ðŸ”',
    description: 'Search and analytics engine',
    defaultPort: 9200,
    popularity: 70,
    fields: [
      { key: 'host', label: 'Host', type: 'text', placeholder: 'localhost', required: true },
      { key: 'port', label: 'Port', type: 'number', placeholder: '9200' },
      { key: 'username', label: 'Username', type: 'text' },
      { key: 'password', label: 'Password', type: 'password' },
      { key: 'ssl', label: 'Use HTTPS', type: 'checkbox' },
      { key: 'apiKey', label: 'API Key', type: 'password' },
      { key: 'cloudId', label: 'Elastic Cloud ID', type: 'text', placeholder: 'deployment:base64...' },
      { key: 'index', label: 'Default Index Pattern', type: 'text', placeholder: 'logs-*' },
    ],
    tips: ['Use API keys', 'Enable security features'],
    tags: ['search', 'analytics', 'elk'],
  },
  {
    id: 'redis',
    submitType: 'redis',
    label: 'Redis',
    category: 'Databases',
    icon: 'ðŸ“¦',
    description: 'In-memory data store',
    defaultPort: 6379,
    popularity: 85,
    fields: [
      { key: 'host', label: 'Host', type: 'text', placeholder: 'localhost', required: true },
      { key: 'port', label: 'Port', type: 'number', placeholder: '6379', required: true },
      { key: 'password', label: 'Password', type: 'password' },
      { key: 'database', label: 'Database Number', type: 'number', placeholder: '0' },
      { key: 'ssl', label: 'Use TLS', type: 'checkbox' },
      { key: 'keyPrefix', label: 'Key Prefix', type: 'text', placeholder: 'myapp:' },
    ],
    tips: ['Use AUTH in prod', 'Expiry for memory mgmt'],
    tags: ['cache', 'memory', 'key-value'],
  },
];

/* =========================
   Category / helpers
========================= */
export const CATEGORIES: ConnectorCategory[] = [
  'Databases',
  'Warehouses',
  'Storage',
  'Streaming',
  'API & Files',
];

export function getPopularConnectors(limit = 6): ConnectorMeta[] {
  return [...CONNECTORS]
    .sort((a, b) => (b.popularity || 0) - (a.popularity || 0))
    .slice(0, limit);
}

export function getNewConnectors(): ConnectorMeta[] {
  return CONNECTORS.filter((c) => c.isNew);
}

export function searchConnectors(query: string): ConnectorMeta[] {
  const q = query.toLowerCase().trim();
  return CONNECTORS.filter(
    (c) =>
      c.label.toLowerCase().includes(q) ||
      c.description?.toLowerCase().includes(q) ||
      c.tags?.some((t) => t.toLowerCase().includes(q)) ||
      String(c.id).toLowerCase().includes(q)
  );
}

export function validateField(
  field: FieldDef,
  value: any,
  config: ConnectionConfig
): string | null {
  if (field.required && (value === undefined || value === null || value === '')) {
    return `${field.label} is required`;
  }
  if (!value && !field.required) return null;

  if (field.validation?.pattern && !field.validation.pattern.test(String(value))) {
    return `${field.label} format is invalid`;
  }

  if (field.type === 'number') {
    const n = Number(value);
    if (field.validation?.min !== undefined && n < field.validation.min) {
      return `${field.label} must be at least ${field.validation.min}`;
    }
    if (field.validation?.max !== undefined && n > field.validation.max) {
      return `${field.label} must be at most ${field.validation.max}`;
    }
  }

  if (field.validation?.custom) {
    return field.validation.custom(value, config);
  }
  return null;
}

export function shouldShowField(field: FieldDef, config: ConnectionConfig): boolean {
  if (!field.dependsOn) return true;

  const { field: dep, value, condition = 'equals' } = field.dependsOn;
  const dv =
    dep.startsWith('custom.')
      ? (config.customOptions || {})[dep.slice('custom.'.length)]
      : (config as any)[dep];

  switch (condition) {
    case 'equals':
      return dv === value;
    case 'not-equals':
      return dv !== value;
    case 'truthy':
      return !!dv;
    case 'falsy':
      return !dv;
    default:
      return true;
  }
}

/* =========================
   Migration helpers
========================= */
type MigrationPath = {
  name: string;
  description: string;
  fieldMapping: Record<string, string>;
  transformations: Record<string, (v: any) => any>;
};

export const MIGRATION_PATHS: Record<string, MigrationPath> = {
  'mysql-to-postgresql': {
    name: 'MySQL to PostgreSQL',
    description: 'Copy common fields; toggle SSL on',
    fieldMapping: { host: 'host', port: 'port', database: 'database', username: 'username', password: 'password' },
    transformations: { port: (v: number) => (v === 3306 ? 5432 : v), ssl: () => true },
  },
};

export function getMigrationPath(fromId: ConnectorId, toId: ConnectorId) {
  return MIGRATION_PATHS[`${fromId}-to-${toId}`];
}



------------------------------------------------------------
FILE: frontend\src\components\features\data-sources\DatabasePicker.tsx
------------------------------------------------------------
// src/components/features/datasources/DatabasePicker.tsx
import { useDb } from '@/store/dbContext';
import { cn } from '@/utils';
import { ChevronDown, Database, Server } from 'lucide-react';
import React from 'react';

export interface DatabasePickerProps {
  className?: string;
  compact?: boolean; // smaller for header
}

export const DatabasePicker: React.FC<DatabasePickerProps> = ({ className = '', compact = true }) => {
  const { servers, databases, selection, status, error, setServer, setDatabase, refreshServers, refreshDatabases } = useDb();

  const loading = status === 'loading';

  return (
    <div className={cn('flex items-center gap-2', className)}>
      {/* Server select */}
      <label className="relative inline-flex items-center">
        <Server className={cn('mr-2 h-4 w-4 text-gray-500', compact && 'h-3 w-3')} />
        <select
          value={selection?.serverId ?? ''}
          onChange={(e) => {
            const id = e.target.value || null;
            setServer(id);
            if (id) refreshDatabases(id);
          }}
          className={cn(
            'rounded-lg border border-gray-300 bg-white text-sm',
            compact ? 'px-2 py-1' : 'px-3 py-2'
          )}
          title="Select server"
        >
          <option value="">{loading ? 'Loading serversâ€¦' : 'Select server'}</option>
          {servers.map(s => (
            <option key={s.id} value={s.id}>
              {s.name} Â· {s.engine}
            </option>
          ))}
        </select>
      </label>

      {/* Database select */}
      <label className="relative inline-flex items-center">
        <Database className={cn('mr-2 h-4 w-4 text-gray-500', compact && 'h-3 w-3')} />
        <select
          value={selection?.dbName ?? ''}
          onChange={(e) => setDatabase(e.target.value || null)}
          disabled={!selection?.serverId || loading}
          className={cn(
            'rounded-lg border border-gray-300 bg-white text-sm disabled:bg-gray-100 disabled:text-gray-400',
            compact ? 'px-2 py-1' : 'px-3 py-2'
          )}
          title={selection?.serverId ? 'Select database' : 'Pick a server first'}
        >
          <option value="">
            {!selection?.serverId ? 'Pick server first' : loading ? 'Loading databasesâ€¦' : 'Select database'}
          </option>
          {databases.map(d => (
            <option key={d.name} value={d.name}>{d.name}</option>
          ))}
        </select>
        <ChevronDown className={cn('pointer-events-none -ml-5 h-4 w-4 text-gray-400', compact && 'h-3 w-3')} />
      </label>

      {error && (
        <button
          onClick={() => {
            refreshServers();
            if (selection?.serverId) refreshDatabases(selection.serverId);
          }}
          className="text-xs text-red-600 underline"
          title={error}
        >
          Retry
        </button>
      )}
    </div>
  );
};



------------------------------------------------------------
FILE: frontend\src\components\features\data-sources\DataSourceCard.tsx
------------------------------------------------------------
// src/components/features/data-sources/DataSourceCard.tsx
import type { DataSource, DataSourceType } from '@/types/dataSources'
import {
  Activity,
  CheckCircle,
  Clock,
  Database,
  Globe,
  HardDrive,
  MoreHorizontal,
  Pause,
  Play,
  RefreshCw,
  Server,
  Settings,
  Shield,
  Trash2,
  TrendingUp,
  XCircle,
  Zap,
} from 'lucide-react'
import { useCallback, useEffect, useMemo, useRef, useState } from 'react'

/* --------------------------------- UI helpers -------------------------------- */

const statusChipClasses: Record<DataSource['status'], string> = {
  active: 'bg-emerald-50 text-emerald-700 border-emerald-200',
  inactive: 'bg-gray-50 text-gray-600 border-gray-200',
  pending: 'bg-amber-50 text-amber-700 border-amber-200',
  error: 'bg-red-50 text-red-700 border-red-200',
  testing: 'bg-blue-50 text-blue-700 border-blue-200',
}

// Safe icon map; use Partial until your union surely includes 'oracle'
function getConnectorIcon(type: DataSourceType): string {
  const icons: Partial<Record<DataSourceType, string>> = {
    postgresql: 'ðŸ˜',
    mysql: 'ðŸ¬',
    mssql: 'ðŸ¢',
    mongodb: 'ðŸƒ',
    redis: 'ðŸ“¦',
    snowflake: 'â„ï¸',
    bigquery: 'ðŸ“Š',
    redshift: 'ðŸ”´',
    databricks: 'ðŸ§±',
    s3: 'â˜ï¸',
    'azure-blob': 'ðŸŸ¦',
    gcs: 'â˜ï¸',
    kafka: 'ðŸš€',
    api: 'ðŸ”Œ',
    file: 'ðŸ“',
    ftp: 'ðŸ“¡',
    elasticsearch: 'ðŸ”',
    // add 'oracle' to your DataSourceType to remove the cast
    oracle: 'ðŸŸ ' as any,
  }
  return icons[type] ?? 'ðŸ’¾'
}

function getTypeDisplayName(type: DataSourceType): string {
  const names: Partial<Record<DataSourceType, string>> = {
    postgresql: 'PostgreSQL',
    mysql: 'MySQL',
    mssql: 'SQL Server',
    mongodb: 'MongoDB',
    redis: 'Redis',
    snowflake: 'Snowflake',
    bigquery: 'BigQuery',
    redshift: 'Amazon Redshift',
    databricks: 'Databricks',
    s3: 'Amazon S3',
    'azure-blob': 'Azure Blob Storage',
    gcs: 'Google Cloud Storage',
    kafka: 'Apache Kafka',
    api: 'REST API',
    file: 'File System',
    ftp: 'FTP/SFTP',
    elasticsearch: 'Elasticsearch',
    oracle: 'Oracle Database' as any,
  }
  return names[type] ?? type
}

function formatRelativeTime(dateString?: string): string {
  if (!dateString) return 'Never'
  try {
    const d = new Date(dateString)
    const diff = Date.now() - d.getTime()
    const minutes = Math.floor(diff / 60000)
    const hours = Math.floor(minutes / 60)
    const days = Math.floor(hours / 24)

    if (days > 7) return d.toLocaleDateString()
    if (days > 0) return `${days} day${days > 1 ? 's' : ''} ago`
    if (hours > 0) return `${hours}h ago`
    if (minutes > 0) return `${minutes}m ago`
    return 'Just now'
  } catch {
    return 'Unknown'
  }
}

/* ---------------------------- connection info ---------------------------- */

function getEnhancedConnectionInfo(
  config: DataSource['connectionConfig'],
  type: DataSourceType,
) {
  const info: {
    host?: string
    database?: string
    databases?: string[]
    bucket?: string
    baseUrl?: string
    scope?: 'server' | 'cluster' | 'database' | string
    discoveryMode?: string
    ssl?: boolean
    port?: number
  } = {}

  if (config && typeof config === 'object') {
    const anyCfg = config as any
    info.scope = anyCfg.scope || 'database'
    info.discoveryMode = anyCfg.discoveryMode
    if (Array.isArray(anyCfg.databases)) info.databases = anyCfg.databases
    info.ssl = Boolean(anyCfg.ssl ?? anyCfg.encrypt)
    if (typeof anyCfg.port === 'number') info.port = anyCfg.port
  }

  // DB-like
  if (['postgresql', 'mysql', 'mssql', 'mongodb', 'redis', 'elasticsearch', 'oracle'].includes(type)) {
    const anyCfg = config as any
    info.host = anyCfg?.host
    info.database = anyCfg?.database
  }
  // Object storage
  else if (['s3', 'azure-blob', 'gcs'].includes(type)) {
    const anyCfg = config as any
    info.bucket = anyCfg?.bucket || anyCfg?.containerName || anyCfg?.bucketName
  }
  // API
  else if (type === 'api') {
    const anyCfg = config as any
    info.baseUrl = anyCfg?.baseUrl
  }
  // Warehouses
  else if (['snowflake', 'bigquery', 'redshift', 'databricks'].includes(type)) {
    const anyCfg = config as any
    info.host = anyCfg?.host || anyCfg?.account
    info.database = anyCfg?.database || anyCfg?.projectId
  }

  return info
}

/* --------------------------------- props --------------------------------- */

interface DataSourceCardProps {
  ds: DataSource
  onTest: (id: string) => Promise<void>
  onSync: (id: string) => Promise<void>
  onDelete: (id: string) => Promise<void>
  onConfigure?: (id: string) => void
  onBrowseDatabases?: (id: string) => void
  showAdvanced?: boolean
}

/* --------------------------------- card ---------------------------------- */

export default function DataSourceCard({
  ds,
  onTest,
  onSync,
  onDelete,
  onConfigure,
  onBrowseDatabases,
  showAdvanced = false,
}: DataSourceCardProps) {
  const [isExpanded, setIsExpanded] = useState(false)
  const [menuOpen, setMenuOpen] = useState(false)
  const menuRef = useRef<HTMLDivElement | null>(null)
  const triggerRef = useRef<HTMLButtonElement | null>(null)

  const connectionInfo = useMemo(
    () => getEnhancedConnectionInfo(ds.connectionConfig, ds.type),
    [ds.connectionConfig, ds.type],
  )

  const hasError = ds.status === 'error' || ds.healthStatus?.status === 'down'
  const isLoading = ds.status === 'testing' || ds.syncStatus?.status === 'syncing'
  const isServerLevel =
    connectionInfo.scope === 'server' || connectionInfo.scope === 'cluster'
  const dbList = Array.isArray(connectionInfo.databases) ? connectionInfo.databases : []

  const healthScore = useMemo(() => {
    if (hasError) return 0
    if (ds.status === 'active' && ds.healthStatus?.status === 'healthy') return 100
    if (ds.status === 'active') return 80
    if (ds.status === 'pending') return 60
    return 40
  }, [ds.status, ds.healthStatus, hasError])

  // Close menu on outside click / Esc
  useEffect(() => {
    function onDocClick(e: MouseEvent) {
      if (!menuOpen) return
      const t = e.target as Node
      if (
        menuRef.current &&
        !menuRef.current.contains(t) &&
        triggerRef.current &&
        !triggerRef.current.contains(t)
      ) {
        setMenuOpen(false)
      }
    }
    function onKey(e: KeyboardEvent) {
      if (e.key === 'Escape') setMenuOpen(false)
    }
    document.addEventListener('mousedown', onDocClick)
    document.addEventListener('keydown', onKey)
    return () => {
      document.removeEventListener('mousedown', onDocClick)
      document.removeEventListener('keydown', onKey)
    }
  }, [menuOpen])

  useEffect(() => {
    if (!menuOpen) triggerRef.current?.focus()
  }, [menuOpen])

  const handleAction = useCallback(
    async (action: 'test' | 'sync' | 'delete' | 'configure' | 'browse') => {
      try {
        if (action === 'test') await onTest(ds.id)
        else if (action === 'sync') await onSync(ds.id)
        else if (action === 'delete') await onDelete(ds.id)
        else if (action === 'configure') onConfigure?.(ds.id)
        else if (action === 'browse') onBrowseDatabases?.(ds.id)
      } catch (err) {
        console.error(`[DataSourceCard] ${action} failed`, err)
      } finally {
        setMenuOpen(false)
      }
    },
    [ds.id, onTest, onSync, onDelete, onConfigure, onBrowseDatabases],
  )

  return (
    // IMPORTANT: no overflow-hidden here, so the menu can render outside
    <div className="group rounded-2xl border bg-white shadow-sm hover:shadow-md transition-all duration-300">
      {/* Header */}
      <div className="p-6 pb-4">
        <div className="flex items-start justify-between">
          {/* Left */}
          <div className="flex-1 min-w-0">
            <div className="flex items-center gap-3 mb-3">
              <div className="w-12 h-12 rounded-xl bg-gradient-to-br from-blue-50 to-indigo-50 flex items-center justify-center text-2xl border border-blue-100">
                {getConnectorIcon(ds.type)}
              </div>
              <div>
                <div className="text-sm font-medium text-gray-600">{getTypeDisplayName(ds.type)}</div>
                {isServerLevel && (
                  <div className="flex items-center gap-1 text-xs text-blue-600 font-medium">
                    <Server className="w-3 h-3" />
                    Server-Level Connection
                  </div>
                )}
              </div>
            </div>

            <div className="mb-3">
              <h3 className="text-lg font-semibold text-gray-900 truncate mb-1" title={ds.name}>
                {ds.name}
              </h3>
              {ds.description && (
                <p className="text-sm text-gray-600 line-clamp-2" title={ds.description}>
                  {ds.description}
                </p>
              )}
            </div>
          </div>

          {/* Right: status + actions */}
          <div className="flex flex-col items-end gap-2">
            <div className={`rounded-full px-3 py-1 text-xs font-medium border ${statusChipClasses[ds.status]}`}>
              <div className="flex items-center gap-1">
                {ds.status === 'active' && <CheckCircle className="w-3 h-3" />}
                {ds.status === 'error' && <XCircle className="w-3 h-3" />}
                {ds.status === 'testing' && <Clock className="w-3 h-3 animate-pulse" />}
                {ds.status === 'pending' && <Clock className="w-3 h-3" />}
                {ds.status === 'inactive' && <Pause className="w-3 h-3" />}
                {ds.status.charAt(0).toUpperCase() + ds.status.slice(1)}
              </div>
            </div>

            {isLoading && (
              <div className="flex items-center gap-1 text-xs text-blue-600">
                <div className="w-3 h-3 border-2 border-blue-600 border-t-transparent rounded-full animate-spin" />
                {ds.status === 'testing' ? 'Testing...' : 'Syncing...'}
              </div>
            )}

            <div className="relative" ref={menuRef}>
              <button
                ref={triggerRef}
                onClick={() => setMenuOpen(v => !v)}
                className="p-1 rounded-lg hover:bg-gray-100 transition-colors"
                title="More actions"
                aria-haspopup="menu"
                aria-expanded={menuOpen}
              >
                <MoreHorizontal className="w-4 h-4 text-gray-500" />
              </button>

              {menuOpen && (
                <div
                  role="menu"
                  className="absolute right-0 top-8 bg-white border rounded-lg shadow-lg z-20 min-w-[180px] overflow-hidden"
                >
                  <button
                    role="menuitem"
                    onClick={() => handleAction('test')}
                    disabled={isLoading}
                    className="w-full px-4 py-2 text-left text-sm hover:bg-gray-50 flex items-center gap-2 disabled:opacity-50"
                  >
                    <Play className="w-4 h-4" />
                    Test Connection
                  </button>
                  <button
                    role="menuitem"
                    onClick={() => handleAction('sync')}
                    disabled={isLoading}
                    className="w-full px-4 py-2 text-left text-sm hover:bg-gray-50 flex items-center gap-2 disabled:opacity-50"
                  >
                    <RefreshCw className="w-4 h-4" />
                    Sync Data
                  </button>
                  {isServerLevel && (
                    <button
                      role="menuitem"
                      onClick={() => handleAction('browse')}
                      className="w-full px-4 py-2 text-left text-sm hover:bg-gray-50 flex items-center gap-2"
                    >
                      <Database className="w-4 h-4" />
                      Browse Databases
                    </button>
                  )}
                  <button
                    role="menuitem"
                    onClick={() => handleAction('configure')}
                    className="w-full px-4 py-2 text-left text-sm hover:bg-gray-50 flex items-center gap-2"
                  >
                    <Settings className="w-4 h-4" />
                    Configure
                  </button>
                  <hr className="my-1" />
                  <button
                    role="menuitem"
                    onClick={() => handleAction('delete')}
                    disabled={isLoading}
                    className="w-full px-4 py-2 text-left text-sm hover:bg-red-50 text-red-600 flex items-center gap-2 disabled:opacity-50"
                  >
                    <Trash2 className="w-4 h-4" />
                    Delete
                  </button>
                </div>
              )}
            </div>
          </div>
        </div>
      </div>

      {/* Connection Details */}
      <div className="px-6 pb-4">
        <div className="grid grid-cols-2 gap-3 text-xs">
          {connectionInfo.host && (
            <div className="flex items-center gap-1">
              <Globe className="w-3 h-3 text-gray-400" />
              <span className="text-gray-500">Host:</span>
              <span className="font-medium text-gray-900 truncate">{connectionInfo.host}</span>
              {connectionInfo.port && <span className="text-gray-500">:{connectionInfo.port}</span>}
            </div>
          )}

          {isServerLevel && dbList.length > 0 && (
            <div className="flex items-center gap-1">
              <Database className="w-3 h-3 text-gray-400" />
              <span className="text-gray-500">Databases:</span>
              <span className="font-medium text-blue-600">{dbList.length}</span>
            </div>
          )}

          {!isServerLevel && connectionInfo.database && (
            <div className="flex items-center gap-1">
              <Database className="w-3 h-3 text-gray-400" />
              <span className="text-gray-500">Database:</span>
              <span className="font-medium text-gray-900 truncate">{connectionInfo.database}</span>
            </div>
          )}

          {connectionInfo.bucket && (
            <div className="flex items-center gap-1">
              <HardDrive className="w-3 h-3 text-gray-400" />
              <span className="text-gray-500">Bucket:</span>
              <span className="font-medium text-gray-900 truncate">{connectionInfo.bucket}</span>
            </div>
          )}

          <div className="flex items-center gap-1">
            <Clock className="w-3 h-3 text-gray-400" />
            <span className="text-gray-500">Last Sync:</span>
            <span className="font-medium text-gray-900">{formatRelativeTime(ds.lastSyncAt)}</span>
          </div>

          <div className="flex items-center gap-1">
            <Activity className="w-3 h-3 text-gray-400" />
            <span className="text-gray-500">Last Test:</span>
            <span className="font-medium text-gray-900">{formatRelativeTime(ds.lastTestedAt)}</span>
          </div>
        </div>

        {connectionInfo.baseUrl && (
          <div className="mt-2 flex items-center gap-1 text-xs">
            <Globe className="w-3 h-3 text-gray-400" />
            <span className="text-gray-500">URL:</span>
            <span className="font-medium text-gray-900 truncate flex-1">{connectionInfo.baseUrl}</span>
          </div>
        )}
      </div>

      {/* Security & Discovery */}
      <div className="px-6 pb-4">
        <div className="flex items-center gap-3">
          {connectionInfo.ssl && (
            <div className="flex items-center gap-1 text-xs text-green-600">
              <Shield className="w-3 h-3" />
              <span>SSL Enabled</span>
            </div>
          )}
          {connectionInfo.discoveryMode && (
            <div className="flex items-center gap-1 text-xs text-purple-600">
              <Zap className="w-3 h-3" />
              <span className="capitalize">{connectionInfo.discoveryMode} Discovery</span>
            </div>
          )}
          <div className="ml-auto flex items-center gap-2">
            <div className="flex items-center gap-1 text-xs">
              <div
                className={`w-2 h-2 rounded-full ${
                  healthScore >= 80 ? 'bg-green-500' : healthScore >= 60 ? 'bg-yellow-500' : 'bg-red-500'
                }`}
              />
              <span className="text-gray-500">Health: {healthScore}%</span>
            </div>
          </div>
        </div>
      </div>

      {/* Error */}
      {hasError && ds.healthStatus?.message && (
        <div className="mx-6 mb-4 rounded-lg bg-red-50 border border-red-200 p-3">
          <div className="flex items-start gap-2">
            <XCircle className="w-4 h-4 text-red-500 mt-0.5 flex-shrink-0" />
            <div>
              <div className="text-sm font-medium text-red-800">Connection Error</div>
              <div className="text-xs text-red-600 mt-1">{ds.healthStatus.message}</div>
            </div>
          </div>
        </div>
      )}

      {/* Usage */}
      {ds.usage && (ds.usage.queriesCount > 0 || ds.usage.lastUsed) && (
        <div className="mx-6 mb-4 rounded-lg bg-blue-50 border border-blue-200 p-3">
          <div className="grid grid-cols-2 gap-3 text-xs">
            {ds.usage.queriesCount > 0 && (
              <div className="flex items-center gap-1">
                <TrendingUp className="w-3 h-3 text-blue-500" />
                <span className="text-blue-600">Queries:</span>
                <span className="font-medium text-blue-800">{ds.usage.queriesCount.toLocaleString()}</span>
              </div>
            )}
            {ds.usage.lastUsed && (
              <div className="flex items-center gap-1">
                <Clock className="w-3 h-3 text-blue-500" />
                <span className="text-blue-600">Last Used:</span>
                <span className="font-medium text-blue-800">{formatRelativeTime(ds.usage.lastUsed)}</span>
              </div>
            )}
          </div>
        </div>
      )}

      {/* Tags */}
      {ds.tags && ds.tags.length > 0 && (
        <div className="px-6 pb-4">
          <div className="flex flex-wrap gap-1">
            {ds.tags.slice(0, isExpanded ? ds.tags.length : 3).map(tag => (
              <span
                key={tag}
                className="inline-flex items-center px-2 py-1 rounded-full text-xs bg-gray-100 text-gray-700 hover:bg-gray-200 transition-colors"
              >
                {tag}
              </span>
            ))}
            {ds.tags.length > 3 && !isExpanded && (
              <button
                onClick={() => setIsExpanded(true)}
                className="inline-flex items-center px-2 py-1 rounded-full text-xs bg-gray-100 text-gray-500 hover:bg-gray-200 transition-colors"
              >
                +{ds.tags.length - 3} more
              </button>
            )}
          </div>
        </div>
      )}

      {/* Server-level DB list */}
      {isServerLevel && dbList.length > 0 && (
        <div className="border-t border-gray-100">
          <div className="p-4 bg-gray-50">
            <div className="flex items-center justify-between mb-3">
              <div className="flex items-center gap-2">
                <Database className="w-4 h-4 text-gray-600" />
                <span className="text-sm font-medium text-gray-900">Managed Databases</span>
                <span className="text-xs text-gray-500">({dbList.length})</span>
              </div>
              {onBrowseDatabases && (
                <button
                  onClick={() => onBrowseDatabases(ds.id)}
                  className="text-xs text-blue-600 hover:text-blue-700 font-medium"
                >
                  Browse All
                </button>
              )}
            </div>
            <div className="grid grid-cols-2 gap-2">
              {dbList.slice(0, isExpanded ? dbList.length : 4).map(dbName => (
                <div key={dbName} className="flex items-center gap-2 text-xs">
                  <div className="w-2 h-2 rounded-full bg-green-500" />
                  <span className="text-gray-700 truncate">{dbName}</span>
                </div>
              ))}
            </div>
            {dbList.length > 4 && !isExpanded && (
              <button
                onClick={() => setIsExpanded(true)}
                className="mt-2 text-xs text-gray-500 hover:text-gray-700"
              >
                Show {dbList.length - 4} more databases
              </button>
            )}
          </div>
        </div>
      )}

      {/* Quick Actions */}
      <div className="border-top border-gray-100 p-4 bg-gray-50">
        <div className="flex gap-2">
          <button
            onClick={() => handleAction('test')}
            disabled={isLoading}
            className="flex-1 flex items-center justify-center gap-2 px-3 py-2 text-sm font-medium rounded-lg border border-gray-300 hover:bg-white hover:shadow-sm disabled:opacity-50 disabled:cursor-not-allowed transition-all"
          >
            {ds.status === 'testing' ? (
              <>
                <div className="w-3 h-3 border-2 border-gray-600 border-t-transparent rounded-full animate-spin" />
                Testing...
              </>
            ) : (
              <>
                <Play className="w-4 h-4" />
                Test
              </>
            )}
          </button>

          <button
            onClick={() => handleAction('sync')}
            disabled={isLoading}
            className="flex-1 flex items-center justify-center gap-2 px-3 py-2 text-sm font-medium rounded-lg bg-blue-600 text-white hover:bg-blue-700 disabled:opacity-50 disabled:cursor-not-allowed transition-colors"
          >
            {ds.syncStatus?.status === 'syncing' ? (
              <>
                <div className="w-3 h-3 border-2 border-white border-t-transparent rounded-full animate-spin" />
                Syncing...
              </>
            ) : (
              <>
                <RefreshCw className="w-4 h-4" />
                Sync
              </>
            )}
          </button>
        </div>
      </div>

      {/* Metadata */}
      <div className="px-4 py-3 border-t border-gray-100 bg-gray-50">
        <div className="flex justify-between items-center text-xs text-gray-500">
          <span>Created {formatRelativeTime(ds.createdAt)}</span>
          <div className="flex items-center gap-3">
            {ds.createdBy && <span>by {ds.createdBy}</span>}
            {showAdvanced && <span className="text-gray-400">ID: {ds.id.slice(-8)}</span>}
          </div>
        </div>
      </div>
    </div>
  )
}



------------------------------------------------------------
FILE: frontend\src\components\features\pipelines\DeploymentHistory.tsx
------------------------------------------------------------
# Empty file


------------------------------------------------------------
FILE: frontend\src\components\features\pipelines\index.ts
------------------------------------------------------------
// barrel


------------------------------------------------------------
FILE: frontend\src\components\features\pipelines\PipelineCard.tsx
------------------------------------------------------------
# Empty file


------------------------------------------------------------
FILE: frontend\src\components\features\pipelines\PipelineDetails.tsx
------------------------------------------------------------
# Empty file


------------------------------------------------------------
FILE: frontend\src\components\features\pipelines\PipelineList.tsx
------------------------------------------------------------
# Empty file


------------------------------------------------------------
FILE: frontend\src\components\features\requests\ApprovalWorkflow.tsx
------------------------------------------------------------
import { Badge } from '@components/ui/Badge'
import { Card, CardContent, CardHeader, CardTitle } from '@components/ui/Card'
import { Check, Clock, X } from 'lucide-react'

export type StepState = 'pending' | 'approved' | 'rejected'

export interface WorkflowStep {
  id: string
  label: string
  approver: string
  state: StepState
  updatedAt?: string
}

export function ApprovalWorkflow({ steps = [] as WorkflowStep[] }: { steps?: WorkflowStep[] }) {
  if (!steps.length) {
    return (
      <Card>
        <CardHeader><CardTitle>Approval Workflow</CardTitle></CardHeader>
        <CardContent className="text-sm text-gray-600">No workflow configured.</CardContent>
      </Card>
    )
  }

  return (
    <Card>
      <CardHeader><CardTitle>Approval Workflow</CardTitle></CardHeader>
      <CardContent>
        <ol className="space-y-3">
          {steps.map((s, i) => (
            <li key={s.id} className="flex items-center justify-between rounded-lg border p-3">
              <div className="flex items-center gap-3">
                <span className="inline-flex h-7 w-7 items-center justify-center rounded-full bg-gray-100 text-xs font-semibold">
                  {i + 1}
                </span>
                <div>
                  <div className="text-sm font-medium text-gray-900">{s.label}</div>
                  <div className="text-xs text-gray-600">Approver: {s.approver}</div>
                </div>
              </div>
              <div className="flex items-center gap-2">
                <Badge tone={tone(s.state)} className="capitalize">{s.state}</Badge>
                <span className="text-xs text-gray-500">{s.updatedAt ? fmt(s.updatedAt) : ''}</span>
                {icon(s.state)}
              </div>
            </li>
          ))}
        </ol>
      </CardContent>
    </Card>
  )
}

function tone(s: StepState) {
  return s === 'approved' ? 'success' : s === 'rejected' ? 'danger' : 'info'
}
function icon(s: StepState) {
  const cls = 'h-4 w-4'
  if (s === 'approved') return <Check className={cls} />
  if (s === 'rejected') return <X className={cls} />
  return <Clock className={cls} />
}
function fmt(iso: string) {
  try { return new Date(iso).toLocaleString() } catch { return iso }
}



------------------------------------------------------------
FILE: frontend\src\components\features\requests\index.ts
------------------------------------------------------------
// barrelexport { RequestList } from './RequestList'
export type { RequestItem, RequestStatus } from './RequestList'

export { RequestForm } from './RequestForm'
export type { RequestFormValues } from './RequestForm'

export { RequestDetails } from './RequestDetails'

export { ApprovalWorkflow } from './ApprovalWorkflow'
export type { StepState, WorkflowStep } from './ApprovalWorkflow'




------------------------------------------------------------
FILE: frontend\src\components\features\requests\RequestDetails.tsx
------------------------------------------------------------
import { Badge } from '@components/ui/Badge'
import { Button } from '@components/ui/Button'
import { Card, CardContent, CardHeader, CardTitle } from '@components/ui/Card'
import type { RequestItem } from './RequestList'

export function RequestDetails({
  request,
  onApprove,
  onReject,
  onComplete,
}: {
  request: RequestItem | null
  onApprove?: (id: string) => void
  onReject?: (id: string) => void
  onComplete?: (id: string) => void
}) {
  if (!request) return null

  const statusTone =
    request.status === 'approved'
      ? 'success'
      : request.status === 'rejected'
      ? 'danger'
      : request.status === 'in_review'
      ? 'info'
      : request.status === 'completed'
      ? 'neutral'
      : 'warning'

  return (
    <Card>
      <CardHeader>
        <div className="flex items-center justify-between">
          <CardTitle>{request.title}</CardTitle>
          <Badge tone={statusTone}>{request.status}</Badge>
        </div>
      </CardHeader>
      <CardContent className="space-y-4 text-sm">
        <div><span className="text-gray-500">Requester: </span>{request.requester}</div>
        <div><span className="text-gray-500">Created: </span>{fmt(request.createdAt)}</div>
        {request.summary && <p className="text-gray-700">{request.summary}</p>}
        <div className="flex flex-wrap gap-2">
          <Button variant="outline" onClick={() => onApprove?.(request.id)}>Approve</Button>
          <Button variant="ghost" onClick={() => onReject?.(request.id)}>Reject</Button>
          <Button onClick={() => onComplete?.(request.id)}>Mark Complete</Button>
        </div>
      </CardContent>
    </Card>
  )
}

function fmt(iso: string) {
  try { return new Date(iso).toLocaleString() } catch { return iso }
}



------------------------------------------------------------
FILE: frontend\src\components\features\requests\RequestForm.tsx
------------------------------------------------------------
import { Button } from '@components/ui/Button'
import { Card, CardContent, CardHeader, CardTitle } from '@components/ui/Card'
import { Input } from '@components/ui/Input'
import { Select } from '@components/ui/Select'
import * as React from 'react'

export interface RequestFormValues {
  title: string
  description: string
  priority: 'low' | 'medium' | 'high'
  dataset?: string
}

export function RequestForm({
  value,
  onChange,
  onSubmit,
  busy,
}: {
  value?: Partial<RequestFormValues>
  onChange?: (v: Partial<RequestFormValues>) => void
  onSubmit?: (v: RequestFormValues) => Promise<void> | void
  busy?: boolean
}) {
  const [form, setForm] = React.useState<RequestFormValues>({
    title: value?.title ?? '',
    description: value?.description ?? '',
    priority: (value?.priority as RequestFormValues['priority']) ?? 'medium',
    dataset: value?.dataset ?? '',
  })

  function patch<K extends keyof RequestFormValues>(k: K, v: RequestFormValues[K]) {
    const next = { ...form, [k]: v }
    setForm(next)
    onChange?.(next)
  }

  async function submit(e: React.FormEvent) {
    e.preventDefault()
    await onSubmit?.(form)
  }

  return (
    <Card>
      <CardHeader><CardTitle>Create New Request</CardTitle></CardHeader>
      <CardContent>
        <form onSubmit={submit} className="space-y-4">
          <Input placeholder="Title" value={form.title} onChange={(e) => patch('title', e.target.value)} />
          <Input
            placeholder="Dataset / Asset (optional)"
            value={form.dataset ?? ''}
            onChange={(e) => patch('dataset', e.target.value)}
          />
          <textarea
            value={form.description}
            onChange={(e) => patch('description', e.target.value)}
            placeholder="Describe the business requirementâ€¦"
            className="w-full rounded-xl border border-gray-300 p-3 text-sm focus:outline-none focus:ring-2 focus:ring-blue-500"
            rows={4}
          />
          <div className="grid gap-3 sm:grid-cols-2">
            <Select
              label="Priority"
              value={form.priority}
              onChange={(e) => patch('priority', e.target.value as RequestFormValues['priority'])}
              options={[
                { label: 'Low', value: 'low' },
                { label: 'Medium', value: 'medium' },
                { label: 'High', value: 'high' },
              ]}
            />
            <div className="flex items-end justify-end">
              <Button type="submit" disabled={busy}>
                {busy ? 'Submittingâ€¦' : 'Create Request'}
              </Button>
            </div>
          </div>
        </form>
      </CardContent>
    </Card>
  )
}



------------------------------------------------------------
FILE: frontend\src\components\features\requests\RequestList.tsx
------------------------------------------------------------
import { Badge } from '@components/ui/Badge'
import { Button } from '@components/ui/Button'
import { Card, CardContent, CardHeader, CardTitle } from '@components/ui/Card'

export type RequestStatus = 'open' | 'in_review' | 'approved' | 'rejected' | 'completed'

export interface RequestItem {
  id: string
  title: string
  requester: string
  createdAt: string  // ISO
  priority?: 'low' | 'medium' | 'high'
  status: RequestStatus
  summary?: string
}

export function RequestList({
  items = [],
  loading,
  onSelect,
  onNew,
}: {
  items?: RequestItem[]
  loading?: boolean
  onSelect?: (id: string) => void
  onNew?: () => void
}) {
  return (
    <Card>
      <CardHeader>
        <div className="flex items-center justify-between">
          <CardTitle>Requests</CardTitle>
          <Button onClick={onNew}>Create Request</Button>
        </div>
      </CardHeader>
      <CardContent>
        {loading ? (
          <ListSkeleton />
        ) : items.length === 0 ? (
          <div className="text-sm text-gray-600">No requests found.</div>
        ) : (
          <div className="overflow-x-auto">
            <table className="min-w-full text-sm">
              <thead className="text-left text-gray-500">
                <tr>
                  <th className="py-2 pr-4">Title</th>
                  <th className="py-2 pr-4">Requester</th>
                  <th className="py-2 pr-4">Priority</th>
                  <th className="py-2 pr-4">Status</th>
                  <th className="py-2 pr-4">Created</th>
                  <th className="py-2 pr-0 text-right">Actions</th>
                </tr>
              </thead>
              <tbody>
                {items.map((r) => (
                  <tr key={r.id} className="border-t">
                    <td className="py-2 pr-4 font-medium text-gray-900">{r.title}</td>
                    <td className="py-2 pr-4">{r.requester}</td>
                    <td className="py-2 pr-4">
                      <Badge tone={r.priority === 'high' ? 'danger' : r.priority === 'medium' ? 'warning' : 'neutral'}>
                        {r.priority ?? 'low'}
                      </Badge>
                    </td>
                    <td className="py-2 pr-4">
                      <Badge tone={statusTone(r.status)}>{r.status}</Badge>
                    </td>
                    <td className="py-2 pr-4">{fmt(r.createdAt)}</td>
                    <td className="py-2 pr-0 text-right">
                      <Button variant="outline" size="sm" onClick={() => onSelect?.(r.id)}>
                        View
                      </Button>
                    </td>
                  </tr>
                ))}
              </tbody>
            </table>
          </div>
        )}
      </CardContent>
    </Card>
  )
}

function statusTone(s: RequestStatus) {
  return s === 'approved'
    ? 'success'
    : s === 'rejected'
    ? 'danger'
    : s === 'in_review'
    ? 'info'
    : s === 'completed'
    ? 'neutral'
    : 'warning'
}

function fmt(iso: string) {
  try {
    return new Date(iso).toLocaleString()
  } catch {
    return iso
  }
}

function ListSkeleton() {
  return (
    <div className="space-y-2">
      {Array.from({ length: 6 }).map((_, i) => (
        <div key={i} className="h-12 w-full animate-pulse rounded bg-gray-200" />
      ))}
    </div>
  )
}



------------------------------------------------------------
FILE: frontend\src\components\layout\Footer.tsx
------------------------------------------------------------
import * as React from 'react'

export const Footer: React.FC = () => (
  <footer className="border-t border-gray-200 bg-white">
    <div className="mx-auto max-w-7xl px-6 py-4 text-xs text-gray-500 flex items-center justify-between">
      <span>© {new Date().getFullYear()} CWIC Platform</span>
      <span>v1.0.0</span>
    </div>
  </footer>
)



------------------------------------------------------------
FILE: frontend\src\components\layout\Header.tsx
------------------------------------------------------------
import { Bell, ChevronDown, Search, Zap } from "lucide-react";
import { useEffect } from "react";

type Props = {
  title: string;
  onOpenQuickActions: () => void;
  onOpenCommandPalette: () => void;
  user?: { name?: string; email?: string; initials?: string };
};

export default function Header({ title, onOpenQuickActions, onOpenCommandPalette, user }: Props) {
  useEffect(() => {
    const onKey = (e: KeyboardEvent) => {
      if ((e.metaKey || e.ctrlKey) && e.key.toLowerCase() === "k") {
        e.preventDefault();
        onOpenCommandPalette();
      }
    };
    window.addEventListener("keydown", onKey);
    return () => window.removeEventListener("keydown", onKey);
  }, [onOpenCommandPalette]);

  return (
    <header className="bg-white border-b border-gray-200 sticky top-0 z-30 shadow-sm">
      <div className="px-6 py-4 flex items-center justify-between">
        <div>
          <h2 className="text-xl font-bold text-gray-900">{title}</h2>
          <p className="text-sm text-gray-500">Last updated: 2 min ago</p>
        </div>

        <div className="flex items-center gap-3">
          <button
            onClick={onOpenQuickActions}
            className="px-4 py-2 bg-gradient-to-r from-blue-600 to-purple-600 text-white rounded-xl hover:shadow-lg transition-all font-medium flex items-center gap-2"
          >
            <Zap className="h-4 w-4" /> Quick Actions
          </button>

          <button
            onClick={onOpenCommandPalette}
            className="flex items-center gap-2 px-4 py-2 bg-gray-100 text-gray-700 rounded-xl hover:bg-gray-200 transition-colors"
          >
            <Search className="h-4 w-4" />
            <kbd className="px-2 py-1 text-xs bg-white rounded border border-gray-300 font-mono">âŒ˜K</kbd>
          </button>

          <button className="relative p-2 text-gray-600 hover:bg-gray-100 rounded-xl transition-colors" aria-label="Notifications">
            <Bell className="h-5 w-5" />
            <span className="absolute top-0 right-0 w-5 h-5 bg-gradient-to-r from-red-500 to-pink-500 text-white text-xs rounded-full flex items-center justify-center font-bold shadow-lg">
              3
            </span>
          </button>

          <div className="flex items-center gap-3 px-4 py-2 bg-gradient-to-r from-gray-100 to-gray-200 rounded-xl hover:shadow-md transition-all cursor-pointer">
            <div className="w-9 h-9 bg-gradient-to-br from-blue-600 to-purple-600 rounded-xl flex items-center justify-center text-white font-bold shadow-lg">
              {user?.initials ?? "A"}
            </div>
            <div className="text-left">
              <p className="text-sm font-bold text-gray-900">{user?.name ?? "Admin User"}</p>
              <p className="text-xs text-gray-500">{user?.email ?? "admin@cwic.io"}</p>
            </div>
            <ChevronDown className="h-4 w-4 text-gray-500" />
          </div>
        </div>
      </div>
    </header>
  );
}



------------------------------------------------------------
FILE: frontend\src\components\layout\index.ts
------------------------------------------------------------
export { Footer } from './Footer';
export { Header } from './Header';
export { Layout } from './layout';
export { Navigation } from './Navigation';
export { default as PageContainer } from "./PageContainer";
export { SectionCard } from "./SectionCard";




------------------------------------------------------------
FILE: frontend\src\components\layout\Navigation.tsx
------------------------------------------------------------
import clsx from "clsx";
import {
  Activity,
  BarChart3,
  BookOpen,
  Bot,
  ChevronRight,
  Database,
  DollarSign,
  FileCheck,
  GitBranch,
  GitMerge,
  Home,
  Link2,
  Menu,
  Package,
  Shield
} from "lucide-react";
import { useState } from "react";
import { NavLink } from "react-router-dom";

type Item = { to: string; label: string; icon: any };
type Section = { id: string; label: string; items: Item[] };

const sections: Section[] = [
  { id: "overview", label: "OVERVIEW", items: [{ to: "/", label: "Dashboard", icon: Home }] },
  {
    id: "data", label: "DATA", items: [
      { to: "/sources", label: "Data Sources", icon: Database },
      { to: "/catalog", label: "Data Catalog", icon: BookOpen },
      { to: "/lineage", label: "Lineage", icon: GitMerge }
    ]
  },
  {
    id: "operations", label: "OPERATIONS", items: [
      { to: "/pipelines", label: "Pipelines", icon: GitBranch },
      { to: "/quality", label: "Data Quality", icon: Shield },
      { to: "/monitoring", label: "Monitoring", icon: Activity }
    ]
  },
  {
    id: "governance", label: "GOVERNANCE", items: [
      { to: "/policies", label: "Policies", icon: FileCheck },
      { to: "/evidence", label: "Evidence Vault", icon: Package }
    ]
  },
  {
    id: "ai", label: "AI & AUTOMATION", items: [
      { to: "/ai", label: "AI Assistant", icon: Bot },
      { to: "/integrations", label: "Integrations", icon: Link2 }
    ]
  },
  { id: "insights", label: "INSIGHTS", items: [{ to: "/analytics", label: "Analytics", icon: BarChart3 }, { to: "/costs", label: "Costs & Usage", icon: DollarSign }] }
];

export default function Navigation() {
  const [collapsed, setCollapsed] = useState(false);
  const [open, setOpen] = useState<string>("overview");

  return (
    <aside className={clsx(
      "fixed left-0 top-0 h-full bg-white border-r border-gray-200 transition-all z-40 shadow-xl overflow-y-auto",
      collapsed ? "w-20" : "w-72"
    )}>
      <div className="p-4 border-b border-gray-200">
        <div className="flex items-center justify-between">
          {!collapsed && (
            <div className="flex items-center gap-3">
              <div className="bg-gradient-to-br from-blue-600 to-purple-600 p-2.5 rounded-xl shadow-lg">
                <Shield className="h-7 w-7 text-white" />
              </div>
              <div>
                <h1 className="text-xl font-bold bg-gradient-to-r from-blue-600 to-purple-600 bg-clip-text text-transparent">CWIC</h1>
                <p className="text-xs text-gray-500 font-medium">Platform</p>
              </div>
            </div>
          )}
          <button
            onClick={() => setCollapsed(!collapsed)}
            className="p-2.5 hover:bg-gray-100 rounded-xl transition-colors"
            aria-label="Toggle sidebar"
          >
            <Menu className="h-5 w-5 text-gray-600" />
          </button>
        </div>
      </div>

      <nav className="p-3">
        {sections.map(section => (
          <div key={section.id} className="mb-2">
            {!collapsed && (
              <button
                onClick={() => setOpen(open === section.id ? "" : section.id)}
                className="w-full flex items-center justify-between px-3 py-2 text-xs font-bold text-gray-500 uppercase tracking-wider hover:text-gray-700 transition-colors"
              >
                {section.label}
                <ChevronRight
                  className={clsx("h-4 w-4 transition-transform", open === section.id && "rotate-90")}
                />
              </button>
            )}

            {(collapsed || open === section.id) && (
              <div className="space-y-1">
                {section.items.map(({ to, label, icon: Icon }) => (
                  <NavLink
                    key={to}
                    to={to}
                    end
                    className={({ isActive }) => clsx(
                      "w-full flex items-center gap-3 px-4 py-3 rounded-xl transition-all font-medium mb-1",
                      isActive
                        ? "bg-gradient-to-r from-blue-600 to-purple-600 text-white shadow-lg scale-[1.02]"
                        : "text-gray-600 hover:bg-gray-100",
                      collapsed && "justify-center"
                    )}
                    title={collapsed ? label : undefined}
                  >
                    <Icon className="h-5 w-5" />
                    {!collapsed && <span className="text-sm">{label}</span>}
                    {!collapsed && (
                      <span className="ml-auto w-2 h-2 rounded-full"
                        aria-hidden="true"
                        style={{ background: "transparent" }}
                      />
                    )}
                  </NavLink>
                ))}
              </div>
            )}
          </div>
        ))}
      </nav>
    </aside>
  );
}



------------------------------------------------------------
FILE: frontend\src\components\layout\overlays\CommandPalette.tsx
------------------------------------------------------------

type Props = {
  open: boolean;
  onClose: () => void;
};

export default function CommandPalette({ open, onClose }: Props) {
  if (!open) return null;

  return (
    <div
      role="dialog"
      aria-modal="true"
      className="fixed inset-0 z-50 flex items-start justify-center bg-black/30 p-4"
      onClick={onClose}
    >
      <div
        className="w-full max-w-xl rounded-lg border bg-white p-4 shadow-lg"
        onClick={(e) => e.stopPropagation()}
      >
        <div className="mb-3 text-sm text-gray-600">Command Palette</div>
        <input
          autoFocus
          className="w-full rounded border px-3 py-2 text-sm outline-none"
          placeholder="Type a commandâ€¦"
          onKeyDown={(e) => e.key === 'Escape' && onClose()}
        />
        <div className="mt-3 flex justify-end">
          <button className="text-sm text-blue-600 hover:underline" onClick={onClose}>
            Close
          </button>
        </div>
      </div>
    </div>
  );
}



------------------------------------------------------------
FILE: frontend\src\components\layout\overlays\QuickActions.tsx
------------------------------------------------------------

type Props = {
  open: boolean;
  onClose: () => void;
};

export default function QuickActions({ open, onClose }: Props) {
  if (!open) return null;

  const actions = [
    { id: 'new-request', label: 'New Request' },
    { id: 'ingest-now', label: 'Trigger Ingestion' },
    { id: 'open-settings', label: 'Open Settings' },
  ];

  return (
    <div
      role="dialog"
      aria-modal="true"
      className="fixed inset-0 z-50 flex items-start justify-end bg-black/30 p-4"
      onClick={onClose}
    >
      <div
        className="w-full max-w-sm rounded-lg border bg-white p-4 shadow-lg"
        onClick={(e) => e.stopPropagation()}
      >
        <div className="mb-3 text-sm font-medium text-gray-900">Quick Actions</div>
        <ul className="space-y-2">
          {actions.map((a) => (
            <li key={a.id}>
              <button
                className="w-full rounded border px-3 py-2 text-left text-sm hover:bg-gray-50"
                onClick={onClose}
              >
                {a.label}
              </button>
            </li>
          ))}
        </ul>
        <div className="mt-3 flex justify-end">
          <button className="text-sm text-blue-600 hover:underline" onClick={onClose}>
            Close
          </button>
        </div>
      </div>
    </div>
  );
}



------------------------------------------------------------
FILE: frontend\src\components\layout\PageContainer.tsx
------------------------------------------------------------
import { cn } from "@/utils/cn";
import * as React from "react";

type Props = {
  /** Big page title. If string, it gets the standard styling */
  title?: React.ReactNode;
  /** Subheading under the title */
  subtitle?: React.ReactNode;
  /** Right-side header actions (buttons, filters, etc.) */
  actions?: React.ReactNode;
  /** Extra classes for the outer wrapper */
  className?: string;
  children: React.ReactNode;
};

export default function PageContainer({
  title,
  subtitle,
  actions,
  className,
  children,
}: Props) {
  return (
    <div className={cn("container mx-auto px-6 py-6 space-y-6", className)}>
      {(title || subtitle || actions) && (
        <div className="flex items-start justify-between gap-4">
          <div className="space-y-1">
            {typeof title === "string" ? (
              <h1 className="text-[22px] font-semibold tracking-[-0.01em]">
                {title}
              </h1>
            ) : (
              title
            )}
            {subtitle ? (
              <p className="text-muted-foreground">{subtitle}</p>
            ) : null}
          </div>
          {actions ? (
            <div className="flex items-center gap-2">{actions}</div>
          ) : null}
        </div>
      )}
      {children}
    </div>
  );
}

